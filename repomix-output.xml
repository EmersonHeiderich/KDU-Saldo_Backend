This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.gitignore
AccountsReceivable.json
alembic.ini
alembic/env.py
alembic/README
alembic/script.py.mako
alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py
alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py
alembic/versions/75de064288e5_adiciona_tabelas_iniciais.py
alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py
backend_structure.md
README.md
requirements.txt
run.py
src/__init__.py
src/api/__init__.py
src/api/decorators.py
src/api/errors.py
src/api/README.md
src/api/routes/__init__.py
src/api/routes/accounts_receivable.py
src/api/routes/auth.py
src/api/routes/customer_panel.py
src/api/routes/fabrics.py
src/api/routes/fiscal.py
src/api/routes/observations.py
src/api/routes/products.py
src/api/routes/users.py
src/app.py
src/config/__init__.py
src/config/README.md
src/config/settings.py
src/database/__init__.py
src/database/base_repository.py
src/database/base.py
src/database/fiscal_repository.py
src/database/observation_repository.py
src/database/product_repository.py
src/database/README.md
src/database/schema_manager.py
src/database/user_repository.py
src/domain/__init__.py
src/domain/accounts_receivable.py
src/domain/balance.py
src/domain/cost.py
src/domain/fabric_details.py
src/domain/fiscal_orm.py
src/domain/fiscal.py
src/domain/observation.py
src/domain/person.py
src/domain/README.md
src/domain/user.py
src/erp_integration/__init__.py
src/erp_integration/erp_accounts_receivable_service.py
src/erp_integration/erp_auth_service.py
src/erp_integration/erp_balance_service.py
src/erp_integration/erp_cost_service.py
src/erp_integration/erp_fiscal_service.py
src/erp_integration/erp_person_service.py
src/erp_integration/erp_product_service.py
src/erp_integration/README.md
src/services/__init__.py
src/services/accounts_receivable_service.py
src/services/auth_service.py
src/services/customer_service.py
src/services/fabric_service.py
src/services/fiscal_service.py
src/services/fiscal_sync_service.py
src/services/observation_service.py
src/services/product_service.py
src/services/README.md
src/utils/__init__.py
src/utils/data_conversion.py
src/utils/fabric_list_builder.py
src/utils/logger.py
src/utils/matrix_builder.py
src/utils/pdf_utils.py
src/utils/README.md
src/utils/system_monitor.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
# .gitignore
# Specifies intentionally untracked files that Git should ignore.

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
# Usually these files are created by pyinstaller, if you plan to use it
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/  # Flask instance folder
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# PEP 582; used by PDM, Flit and potentially other tools
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rove concepts
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static analysis results
.pytype/

# Cython debug symbols
cython_debug/

# VS Code settings
.vscode/

# Local database files (if named differently than standard Django/Flask)
# Example:
database/app.db
database/app.db-shm
database/app.db-wal
*.db
# database/app.db-journal # Add specific DB files if not covered by .env path

# Logs directory (defined in logger.py)
logs/

# Temporary files
*.tmp
*.bak
*~
</file>

<file path="AccountsReceivable.json">
{
    "openapi": "3.0.1",
    "info": {
      "title": "API Accounts Receivable",
      "description": "TOTVS.Moda API Swagger Surface",
      "contact": {
        "name": "TOTVS.Moda Atendimento",
        "url": "https://totvssuporte.zendesk.com",
        "email": "atendimentova@totvs.com.br"
      },
      "license": {
        "name": "TOTVS",
        "url": "https://www.totvs.com/"
      },
      "version": "2.8.18"
    },
    "paths": {
      "/api/totvsmoda/accounts-receivable/v2/documents/search": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Obter dados de documentos de contas a receber.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DocumentResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      },
      "/api/totvsmoda/accounts-receivable/v2/bank-slip": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Retorna o Base64 do Boleto Banc√°rio.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/AccountsReceivableTomasResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      },
      "/api/totvsmoda/accounts-receivable/v2/payment-link": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Retorna o Link de Pagamento (PIX) da Fatura.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/AccountsReceivableTomasResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      }
    },
    "components": {
      "schemas": {
        "AccountsReceivableTomasResponseModel": {
          "type": "object",
          "properties": {
            "content": {
              "type": "string",
              "description": "Conte√∫do retornado na execu√ß√£o do Tomas.",
              "nullable": true
            },
            "unifaceResponseStatus": {
              "type": "string",
              "description": "Status da resposta da requisi√ß√£o do Tomas no Uniface.",
              "nullable": true
            },
            "unifaceMessage": {
              "type": "string",
              "description": "Mensagem de retorno do Uniface.",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "BankSlipRequestModel": {
          "required": [
            "branchCode",
            "customerCode",
            "installmentNumber",
            "receivableCode"
          ],
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "C√≥digo de empresa. Campo \"Empresa\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 4 caracteres.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "C√≥digo do cliente. Campo \"Cliente\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres.\u003Cbr\u003EN√£o pode ser informado junto com customerCpfCnpj, mas um deles dever√° ser informado.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "Cpf/Cnpj do cliente. Campo \"Cpf/Cnpj\" do componente PESFM010.\r\n\u003Cbr\u003ETamanho m√°ximo de 14 caracteres, informar apenas n√∫meros.\u003Cbr\u003EN√£o pode ser informado junto com customerCode, mas um deles dever√° ser informado.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "C√≥digo da fatura do cliente. Campo \"Fatura\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 10 caracteres.",
              "format": "int64"
            },
            "installmentNumber": {
              "type": "integer",
              "description": "N√∫mero da parcela da fatura do cliente. Campo \"Parcela\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 3 caracteres.",
              "format": "int32"
            }
          },
          "additionalProperties": false
        },
        "CalculatedValuesModel": {
          "type": "object",
          "properties": {
            "daysLate": {
              "type": "integer",
              "description": "Dias de atraso.",
              "format": "int32",
              "nullable": true
            },
            "increaseValue": {
              "type": "number",
              "description": "Valor de acr√©scimo.",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "description": "Valor de juros/mora.",
              "format": "double",
              "nullable": true
            },
            "fineValue": {
              "type": "number",
              "description": "Valor da multa",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "description": "Valor total dos descontos",
              "format": "double",
              "nullable": true
            },
            "correctedValue": {
              "type": "number",
              "description": "Valor corridigo.",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Valores calculados para t√≠tulos vencidos conforme a taxa de juros/multa do t√≠tulo."
        },
        "CheckInstallmentModel": {
          "type": "object",
          "properties": {
            "checkBand": {
              "type": "string",
              "description": "N√∫mero da banda do cheque. Campo \"Banda magn√©tica\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            },
            "checkReturnDate1": {
              "type": "string",
              "description": "Data de devolu√ß√£o do primeiro retorno do cheque. Campo \"Data devolu√ß√£o 1\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode1": {
              "type": "integer",
              "description": "C√≥digo do motivo de devolu√ß√£o do primeiro retorno do cheque. Campo \"Motivo devolu√ß√£o 1\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription1": {
              "type": "string",
              "description": "Descri√ß√£o do motivo de devolu√ß√£o do primeiro retorno do cheque. Campo \"Motivo devolu√ß√£o 1\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            },
            "checkReturnDate2": {
              "type": "string",
              "description": "Data de devolu√ß√£o do segundo retorno do cheque. Campo \"Data devolu√ß√£o 2\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode2": {
              "type": "integer",
              "description": "C√≥digo do motivo de devolu√ß√£o do segundo retorno do cheque. Campo \"Motivo devolu√ß√£o 2\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription2": {
              "type": "string",
              "description": "Descri√ß√£o do motivo de devolu√ß√£o do segundo retorno do cheque. Campo \"Motivo devolu√ß√£o 2\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            },
            "checkReturnDate3": {
              "type": "string",
              "description": "Data de devolu√ß√£o do terceiro retorno do cheque. Campo \"Data devolu√ß√£o 3\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode3": {
              "type": "integer",
              "description": "C√≥digo do motivo de devolu√ß√£o do terceiro retorno do cheque. Campo \"Motivo devolu√ß√£o 3\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription3": {
              "type": "string",
              "description": "Descri√ß√£o do motivo de devolu√ß√£o do terceiro retorno do cheque. Campo \"Motivo devolu√ß√£o 3\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            },
            "bankNumber": {
              "type": "integer",
              "description": "N√∫mero do banco do cheque. Campo \"Banco\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "agencyNumber": {
              "type": "integer",
              "description": "N√∫mero da ag√™ncia do banco do cheque.. Campo \"Ag√™ncia\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "checkNumber": {
              "type": "integer",
              "description": "N√∫mero sequncial do cheque. Campo \"N√∫mero cheque\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "format": "int32",
              "nullable": true
            },
            "account": {
              "type": "string",
              "description": "N√∫mero da conta do cliente do cheque. Campo \"Conta\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            },
            "checkThirdName": {
              "type": "string",
              "description": "Nome do titular do cheque de terceiro. Campo \"Titular chq. terceiro\" do frame \"Informa√ß√£o do cheque\" do componente FCRFM002(FCRFM001 -\u003E Bot√£o informa√ß√£o cheque)",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Lista de cheque da fatura."
        },
        "CommissionDataModel": {
          "type": "object",
          "properties": {
            "commissionedCode": {
              "type": "integer",
              "description": "C√≥digo do comissionado. Campo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres",
              "format": "int32"
            },
            "commissionedCpfCnpj": {
              "type": "string",
              "description": "CPF ou CNPJ do comissionado vinculado √† pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 14 caracteres",
              "nullable": true
            },
            "typeCode": {
              "type": "integer",
              "description": "C√≥digo do tipo comissionado do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 3 caracteres",
              "format": "int32"
            },
            "typeDescription": {
              "type": "string",
              "description": "Descri√ß√£o do tipo comissionado do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 30 caracteres",
              "nullable": true
            },
            "status": {
              "type": "integer",
              "description": "Situa√ß√£o da comiss√£o. Campo \"Situa√ß√£o\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003E0 Normal\u003Cbr\u003E1 Excluida\u003Cbr\u003E2 Transferida\u003Cbr\u003E3 Transferida recebimento\u003Cbr\u003E4 Trocado comissionado\u003Cbr\u003E5 Responsabilidade\u003Cbr\u003E6 Abatida por exporta√ß√£o\u003Cbr\u003E9 Cancelada",
              "format": "int32"
            },
            "percentageBilling": {
              "type": "number",
              "description": "Percentual de comiss√£o de faturamento. Campo \"% Faturamento\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo: 3 n√∫meros inteiros com 6 casas decimais.",
              "format": "double"
            },
            "valueBilling": {
              "type": "number",
              "description": "Valor de comiss√£o de faturamento. Campo \"Vl. comis. fat.\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo: 12 caracteres mais 2 caracteres para casas decimais.",
              "format": "double"
            },
            "isPaidBilling": {
              "type": "boolean",
              "description": "Se a comiss√£o de faturamento est√° paga. Campo Pago do bloco \"Comissionado\" do componente FCRFM001."
            },
            "percentageReceived": {
              "type": "number",
              "description": "Percentual de comiss√£o de recebimento. Campo \"% Recebimento\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo: 3 n√∫meros inteiros com 6 casas decimais.",
              "format": "double"
            },
            "valueReceived": {
              "type": "number",
              "description": "Valor de comiss√£o de recebimento. Campo \"Vl. comis. rec.\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo: 12 caracteres mais 2 caracteres para casas decimais.",
              "format": "double"
            },
            "isPaidReceived": {
              "type": "boolean",
              "description": "Se a comiss√£o de recebimento est√° paga. Campo Pago do bloco \"Comissionado\" do componente FCRFM001."
            },
            "rebateValue": {
              "type": "number",
              "description": "Valor de abatimento que incide na comiss√£o. Frame Comiss√£o - Campo Abatimento - Valor - do componente COMFC008 -\u003E \"Detalhe\"  COMFD008.",
              "format": "double",
              "nullable": true
            },
            "paymentCompany": {
              "type": "integer",
              "description": "Se a comiss√£o est√° paga. C√≥digo da empresa do fechamento da comiss√£o. Frame Fechamento - Campo Emp. - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 4 caracteres",
              "format": "int32",
              "nullable": true
            },
            "paymentDateReceived": {
              "type": "string",
              "description": "Se a comiss√£o de recebimento est√° paga. Data do fechamento do recebimento da comiss√£o. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.",
              "format": "date-time",
              "nullable": true
            },
            "paymentCodeReceived": {
              "type": "number",
              "description": "Se a comiss√£o de recebimento est√° paga. N√∫mero do fechamento do recebimento da comiss√£o. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres",
              "format": "double",
              "nullable": true
            },
            "paymentDateBilling": {
              "type": "string",
              "description": "Se a comiss√£o de faturamento est√° paga. Data do fechamento do pagamento da comiss√£o. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.",
              "format": "date-time",
              "nullable": true
            },
            "paymentCodeBilling": {
              "type": "number",
              "description": "Se a comiss√£o de faturamento est√° paga. N√∫mero do fechamento do pagamento  da comiss√£o. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Lista de comiss√£o relacionado a fatura."
        },
        "DocumentChangeModel": {
          "type": "object",
          "properties": {
            "startDate": {
              "type": "string",
              "description": "Data/hora inicial de altera√ß√£o.",
              "format": "date-time",
              "nullable": true
            },
            "endDate": {
              "type": "string",
              "description": "Data/hora final de altera√ß√£o.",
              "format": "date-time",
              "nullable": true
            },
            "inCheck": {
              "type": "boolean",
              "description": "Houve altera√ß√£o de cheque."
            }
          },
          "additionalProperties": false
        },
        "DocumentFilterModel": {
          "type": "object",
          "properties": {
            "change": {
              "$ref": "#/components/schemas/DocumentChangeModel"
            },
            "branchCodeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Lista de c√≥digo empresa. Campo \"C√≥digo\" do componente GERFM009.",
              "nullable": true
            },
            "customerCodeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Lista de c√≥digo de cliente. Campo \"C√≥digo\" do componente PESFM010.",
              "nullable": true
            },
            "customerCpfCnpjList": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Lista de c√≥digo CPF/CNPJ de cliente. Campo \"N√∫mero CPF\" ou \"N√∫mero CNPJ\" do componente PESFM010.",
              "nullable": true
            },
            "startExpiredDate": {
              "type": "string",
              "description": "Filtro inicial de data de vencimento da fatura. Campo \"Data.vencto\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endExpiredDate": {
              "type": "string",
              "description": "Filtro final de data de vencimento da fatura. Campo \"Data.vencto\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "startPaymentDate": {
              "type": "string",
              "description": "Filtro inicial de data de baixa da fatura. Campo \"Data liquida√ß√£o\" do componente FCRFM001 bot√£o \"Informa√ß√£o baixa\".",
              "format": "date-time",
              "nullable": true
            },
            "endPaymentDate": {
              "type": "string",
              "description": "Filtro final de data de baixa da fatura. Campo \"Data liquida√ß√£o\" do componente FCRFM001 bot√£o \"Informa√ß√£o baixa\".",
              "format": "date-time",
              "nullable": true
            },
            "startIssueDate": {
              "type": "string",
              "description": "Filtro inicial de data de emiss√£o da fatura. Campo \"Dt.emiss√£o\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endIssueDate": {
              "type": "string",
              "description": "Filtro final de data de emiss√£o da fatura. Campo \"Dt.emiss√£o\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "startCreditDate": {
              "type": "string",
              "description": "Filtro inicial de data de liquida√ß√£o da fatura. Campo \"Emp./Dt.Cr√©dito/Nr.Liq\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endCreditDate": {
              "type": "string",
              "description": "Filtro final de data de liquida√ß√£o da fatura. Campo \"Emp./Dt.Cr√©dito/Nr.Liq\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "statusList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": " Filtro de Tipo de situa√ß√£o. Campo \"Situa√ß√£o\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o c√≥digo n√∫merico referente ao tipo de situa√ß√£o \u003Cbr\u003E 1 - Normal \u003Cbr\u003E 2 - Devolvido \u003Cbr\u003E 3 - Cancelado \u003Cbr\u003E 4 - Quebrada ",
              "nullable": true
            },
            "documentTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de documento. Campo \"Tipo documento\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o c√≥digo n√∫merico referente ao tipo de documento \u003Cbr\u003E 1 - fatura  \u003Cbr\u003E 2 - cheque  \u003Cbr\u003E 3 - dinheiro  \u003Cbr\u003E 4 - cart√£o de cr√©dito  \u003Cbr\u003E 5 - cart√£o de d√©bito  \u003Cbr\u003E 6 - nota d√©beito \u003Cbr\u003E 7 - TEF  \u003Cbr\u003E 8 - cheque TEF  \u003Cbr\u003E 9 - Toco  \u003Cbr\u003E 10 - Adiantamento(saida cx.)  \u003Cbr\u003E 11 - desconto financeiro \u003Cbr\u003E 12 - DOFINI   \u003Cbr\u003E 13 - vale  \u003Cbr\u003E 14 - nota promissoria  \u003Cbr\u003E 15 - cheque garantido  \u003Cbr\u003E 16 - TED/DOC  \u003Cbr\u003E 17 - pr√©-autoriza√ß√£o TEF  \u003Cbr\u003E 18 - cheque presente  \u003Cbr\u003E 19 - TEF/TECBAN - BANRISUL \u003Cbr\u003E 20 - CREDEV  \u003Cbr\u003E 21 - cart√£o pr√≥prio  \u003Cbr\u003E 22 - TEF/HYPERCARD  \u003Cbr\u003E 23 - B√¥nus desconto \u003Cbr\u003E 25 - voucher  \u003Cbr\u003E 26 - PIX  \u003Cbr\u003E 27 - PicPay  \u003Cbr\u003E 28 - ame  \u003Cbr\u003E 29 - Mercado pago  \u003Cbr\u003E 30 - Marketplace \u003Cbr\u003E 50 - Outro documento ",
              "nullable": true
            },
            "billingTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de faturamento. Campo \"Tipo faturamento\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o c√≥digo n√∫merico referente ao tipo de faturamento \u003Cbr\u003E 1 - Venda √† vista \u003Cbr\u003E 2 - Venda a prazo \u003Cbr\u003E 3 - Recebimento √† vista \u003Cbr\u003E 4 - Recebimento a prazo \u003Cbr\u003E 5 - Juro \u003Cbr\u003E 6 - Adiantamento(entrada cx) \u003Cbr\u003E 7 - Dev. adiantamento \u003Cbr\u003E 8 - Tarifa \u003Cbr\u003E 9 - Outra despesa \u003Cbr\u003E 10 - Emprestimo \u003Cbr\u003E 11 - Troca Cheque Por Dinheiro \u003Cbr\u003E 12 - Renegocia√ß√£o de titulo \u003Cbr\u003E 13 - Cobran√ßa cart√£o \u003Cbr\u003E 14 - Cheque devolvido \u003Cbr\u003E 15 - Compra cheque presente \u003Cbr\u003E 16 - Presta√ß√£o conta agencia \u003Cbr\u003E 17 - Via exporta√ß√£o \u003Cbr\u003E 18 - Agrupamento de Fatura \u003Cbr\u003E 19 - Vale/adiant. funcion√°rio \u003Cbr\u003E 20 - Loca√ß√£o \u003Cbr\u003E 21 - Cheque presente \u003Cbr\u003E 22 - Recebimento fatura terceiro \u003Cbr\u003E 23 - Cess√£o direito/cr√©dito \u003Cbr\u003E 24 - Compra para terceiros \u003Cbr\u003E 25 - servi√ßo \u003Cbr\u003E 26 - Titulo terceiros \u003Cbr\u003E 27 - Corre√ß√£o monet√°ria \u003Cbr\u003E 30 - Correio \u003Cbr\u003E 31 - Transferencia de divida \u003Cbr\u003E 32 - Quebra \u003Cbr\u003E 33 - Endosso central de guias \u003Cbr\u003E 34 - Fatura central de guias \u003Cbr\u003E 35 - Condominio \u003Cbr\u003E 36 - Fechamento de Conv√™nio \u003Cbr\u003E 37 - Rateio de despesas \u003Cbr\u003E 38 - Rareio de receitas \u003Cbr\u003E 39 - Pgto duplicata entre empresas \u003Cbr\u003E 40 - Receb faturas entre empresas \u003Cbr\u003E 41 - Receb Chq Pres de outra empresa \u003Cbr\u003E 42 - Transf. saldo entre empresas ",
              "nullable": true
            },
            "dischargeTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de baixa. Campo \"Tipo baixa\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o c√≥digo n√∫merico referente ao tipo de baixa \u003Cbr\u003E 0 - T√≠tulo n√£o baixado\u003Cbr\u003E 1 - Via recebimento\u003Cbr\u003E 2 - Baixa para dep√≥sito\u003Cbr\u003E 3 - Agrupamento de fatura\u003Cbr\u003E 4 - Devolu√ß√£o de adiant.\u003Cbr\u003E 5 - - Deb. conta (comis., folha)\u003Cbr\u003E 6 - Autom√°tica (outro proc)\u003Cbr\u003E 7 - Via banco\u003Cbr\u003E 8 - Baixa para desconto\u003Cbr\u003E 9 - Baixa por renegocia√ß√£o\u003Cbr\u003E 10 - Via faturamento\u003Cbr\u003E 11 - Recebimento de garantia\u003Cbr\u003E 12 - Baixa por conta banc√°ria\u003Cbr\u003E 13 - Baixa na conta representante\u003Cbr\u003E 14 - Baixa por rec√°lculo de cart√£o\u003Cbr\u003E 15 - Baixa por central de opera√ß√£o\u003Cbr\u003E 16 - Isentado\u003Cbr\u003E 17 - Baixa por abatimento total\u003Cbr\u003E 18 - Baixa t√≠tulo descontado\u003Cbr\u003E 19 - Baixa transfer√™ncia d√≠vida\u003Cbr\u003E 20 - Baixa por extrato eletronico\u003Cbr\u003E 21 - Baixa por prorroga√ß√£o\u003Cbr\u003E 22 - Baixa por exporta√ß√£o\u003Cbr\u003E 23 - Baixa por vendor\u003Cbr\u003E 24 - Baixa fatura de funcion√°rio\u003Cbr\u003E 25 - Baixa fatura s√≥cio\u003Cbr\u003E 26 - Baixa adiantamento futuro\u003Cbr\u003E 27 - Baixa CREDEV futuro\u003Cbr\u003E 28 - Baixa t√≠tulo endossado\u003Cbr\u003E 29 - Desconto em comiss√£o\u003Cbr\u003E 30 - Baixa acerto loja\u003Cbr\u003E 31 - Baixa cart√£o com credev\u003Cbr\u003E 32 - Baixa por Quebra\u003Cbr\u003E 33 - Baixa cobran√ßa terceirizada\u003Cbr\u003E 34 - Baixa por retirada de cobran√ßa terceirizada\u003Cbr\u003E 35 - Boleto e-commerce\u003Cbr\u003E 36 - Baixa por t√≠tulo de terceiros\u003Cbr\u003E 37 - Fechamento de Conv√™nio\u003Cbr\u003E 38 - Acerto entre empresas\u003Cbr\u003E 39 - Baixa adiant. operadora\u003Cbr\u003E 40 - Dep√≥sito e-commerce\u003Cbr\u003E 41 - Transfer√™ncia online e-commerce\u003Cbr\u003E 50 - Outra baixa",
              "nullable": true
            },
            "chargeTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de coban√ßa. Campo \"Tipo cobran√ßa\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o c√≥digo n√∫merico referente ao tipo de cobran√ßa \u003Cbr\u003E 0 - N√£o est√° em cobran√ßa \u003Cbr\u003E 1 - Simples \u003Cbr\u003E 2 - Descontada \u003Cbr\u003E 3 - Caucionada \u003Cbr\u003E 4 - Vinculada \u003Cbr\u003E 5 - Sem registro \u003Cbr\u003E 6 - Vendor \u003Cbr\u003E 8 - Protestado \u003Cbr\u003E 9 - Cust√≥dia \u003Cbr\u003E 11 - Retirado para renegocia√ß√£o \u003Cbr\u003E 12 - Fora de negocia√ß√£o \u003Cbr\u003E 13 - Endossado \u003Cbr\u003E 14 - Operadora de cr√©dito \u003Cbr\u003E 15 - Em cart√≥rio \u003Cbr\u003E 16 - Cobran√ßa na loja/empresa \u003Cbr\u003E 17 - Aguardando recebimento \u003Cbr\u003E 18 - Direto para boleto \u003Cbr\u003E 19 - Abatimento total \u003Cbr\u003E 20 - Custodia chq recusado \u003Cbr\u003E 21 - Custodia chq baixa/retirada \u003Cbr\u003E 22 - Custodia chq devolucao \u003Cbr\u003E 23 - Desconto chq recusado \u003Cbr\u003E 24 - Desconto chq baixa/retirada \u003Cbr\u003E 25 - Desconto chq devolucao \u003Cbr\u003E 26 - Cobran√ßa terceirizada \u003Cbr\u003E 27 - SCPC \u003Cbr\u003E 28 - Exporta√ß√£o \u003Cbr\u003E 29 - Cess√£o direito/cr√©dito \u003Cbr\u003E 30 - Compra para terceiros \u003Cbr\u003E 31 - Conv√™nio \u003Cbr\u003E 32 - Cobran√ßa judicial \u003Cbr\u003E 33 - Negativado \u003Cbr\u003E 34 - Sustado em cart√≥rio \u003Cbr\u003E 35 - Protesto cancelado \u003Cbr\u003E 36 - Dispon√≠vel para cart√≥rio \u003Cbr\u003E 51 - Reserva cob. simples \u003Cbr\u003E 52 - Reserva cob. desc. fat. \u003Cbr\u003E 53 - Reserva cob. desc. chq. \u003Cbr\u003E 54 - Reserva cob. caucionada \u003Cbr\u003E 56 - Reserva cob. vinculada \u003Cbr\u003E 59 - Reserva cob. vendor \u003Cbr\u003E 60 - Reserva cob. cust√≥dia \u003Cbr\u003E 70 - Reserva para endosso \u003Cbr\u003E 80 - Reserva cheque \u003Cbr\u003E 85 - Reserva desconto cust√≥dia \u003Cbr\u003E 90 - Reserva desconto compror \u003Cbr\u003E 98 - Perdas \u003Cbr\u003E 99 - PDD - Fundo Perdido ",
              "nullable": true
            },
            "hasOpenInvoices": {
              "type": "boolean",
              "description": "Indica filtro de fatura em aberto",
              "nullable": true
            },
            "receivableCodeList": {
              "type": "array",
              "items": {
                "type": "number",
                "format": "double"
              },
              "description": "Lista de c√≥digo de fatura. Campo \"Fatura\" do frame \"Fatura\" do componente FCRFM001.",
              "nullable": true
            },
            "ourNumberList": {
              "type": "array",
              "items": {
                "type": "number",
                "format": "double"
              },
              "description": "Lista de \"Nosso n√∫mero\" referente a parcela da fatura. Campo \"Nosso n√∫mero\" do frame \"Parcela\" do componente FCRFM001.",
              "nullable": true
            },
            "commissionedCode": {
              "type": "integer",
              "description": "Filtro pelo C√≥digo do comissionado. Campo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres\u003Cbr\u003EN√£o deve ser informado junto com o CommissionedCpfCnpj",
              "format": "int32",
              "nullable": true
            },
            "commissionedCpfCnpj": {
              "type": "string",
              "description": "Filtro pelo CPF ou CNPJ do comissionado vinculado √† pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 14 caracteres\u003Cbr\u003EN√£o deve ser informado junto com o CommissionedCode",
              "nullable": true
            },
            "closingCodeCommission": {
              "type": "integer",
              "description": "Se a comiss√£o est√° paga. Filtro pelo N√∫mero do fechamento da comiss√£o. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres\u003Cbr\u003EAo informar obrigat√≥rio tamb√©m informar o ClosingCompanyCommission e ClosingDateCommission",
              "format": "int32",
              "nullable": true
            },
            "closingCompanyCommission": {
              "type": "integer",
              "description": "Se a comiss√£o est√° paga. Filtro pelo C√≥digo da empresa do fechamento da comiss√£o. Frame Fechamento - Campo Emp. - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 4 caracteres\u003Cbr\u003EAo informar obrigat√≥rio tamb√©m informar o ClosingCodeCommission e ClosingDateCommission",
              "format": "int32",
              "nullable": true
            },
            "closingDateCommission": {
              "type": "string",
              "description": "Se a comiss√£o est√° paga. Filtro pela Data do fechamento da comiss√£o. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003EAo informar obrigat√≥rio tamb√©m informar o ClosingCompanyCommission e ClosingCodeCommission",
              "format": "date-time",
              "nullable": true
            },
            "closingCommissionedCode": {
              "type": "integer",
              "description": "Filtro pelo c√≥digo do comissionado do fechamento de comiss√£o. Campo \"Comissionado\" do bloco \"Comiss√£o\" do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres\u003Cbr\u003EN√£o deve ser informado junto com o ClosingCommissionedCpfCnpj",
              "format": "int32",
              "nullable": true
            },
            "closingCommissionedCpfCnpj": {
              "type": "string",
              "description": "Filtro pelo CPF ou CNPJ do comissionado vinculado √† pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comiss√£o\" do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho m√°ximo de 14 caracteres\u003Cbr\u003EN√£o deve ser informado junto com o ClosingCommissionedCode",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentModel": {
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "C√≥digo da empresa da fatura. Campo \"Empresa\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "C√≥digo do cliente da fatura. Campo \"Cliente\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "CPF/CNPJ do cliente. Campo \"N√∫mero CPF\" ou \"N√∫mero CNPJ\" do componente PESFM010.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "C√≥digo da fatura. Campo \"Fatura\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int64"
            },
            "installmentCode": {
              "type": "integer",
              "description": "C√≥digo da parcela fatura. Campo \"Parcela\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32"
            },
            "maxChangeFilterDate": {
              "type": "string",
              "description": "Maior data de altera√ß√£o dentro do filtro de intervalo de data. Campo populado apenas quando os campos \"filter.change.startDate\" e \"filter.change.endDate\" s√£o informados.",
              "format": "date-time",
              "nullable": true
            },
            "expiredDate": {
              "type": "string",
              "description": "Data de vencimento parcela da fatura. Campo \"Data vencto.\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "paymentDate": {
              "type": "string",
              "description": "Data de pagamento da parcela da fatura. Campo \"Oper./Pagamento\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "issueDate": {
              "type": "string",
              "description": "Data de emiss√£o da parcela da fatura. Campo \"Dt. emiss√£o\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "settlementBranchCode": {
              "type": "integer",
              "description": "Empresa da liquida√ß√£o da parcela da fatura. Campo \"Emp/Dt. cr√©dito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "settlementDate": {
              "type": "string",
              "description": "Data de cr√©dito da parcela da fatura. Campo \"Emp/Dt. cr√©dito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "settlementSequence": {
              "type": "integer",
              "description": "Nr. da liquida√ß√£o da parcela da fatura. Campo \"Emp/Dt. cr√©dito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "status": {
              "$ref": "#/components/schemas/ReceivableStatusType"
            },
            "documentType": {
              "$ref": "#/components/schemas/DocumentTypeSearchAvailable"
            },
            "billingType": {
              "$ref": "#/components/schemas/ReceivableBillingType"
            },
            "dischargeType": {
              "$ref": "#/components/schemas/ReceivableDischargeType"
            },
            "chargeType": {
              "$ref": "#/components/schemas/ReceivableChargeType"
            },
            "originInstallment": {
              "type": "integer",
              "description": "Parcela origem relacionado a parcela. Campo \"Parcela origem\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "bearerCode": {
              "type": "integer",
              "description": "C√≥digo do portador da parcela da fatura. Campo \"Portador\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "bearerName": {
              "type": "string",
              "description": "Nome do portador da parcela da fatura. Campo \"Portador\" do frame \"Parcela\" do componente FCRFM001.",
              "nullable": true
            },
            "installmentValue": {
              "type": "number",
              "description": "Valor da parcela da fatura. Campo \"Valor\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "paidValue": {
              "type": "number",
              "description": "Valor pago da parcela da fatura. Campo \"Vl. pago\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "netValue": {
              "type": "number",
              "description": "Valor l√≠quido da parcela da fatura. Campo \"Valor l√≠quido\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "description": "Valor de desconto da parcela da fatura. Campo \"Valor desconto\" do frame \"Valor dedu√ß√£o\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "rebateValue": {
              "type": "number",
              "description": "Valor de abatimento da parcela da fatura. Campo \"Valor abatimento\" do frame \"Valor dedu√ß√£o\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "description": "Valor de juros da parcela da fatura. Campo \"Valor juro\" do frame \"Valor acr√©scimo\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "assessmentValue": {
              "type": "number",
              "description": "Valor de multa da parcela da fatura. Campo \"Valor multa\" do frame \"Valor acr√©scimo\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "barCode": {
              "type": "string",
              "description": "Imagem do c√≥digo de barras da parcela da fatura. Imagem do c√≥digo de barras do boleto impresso pelo componente FCRFP098.",
              "nullable": true
            },
            "digitableLine": {
              "type": "string",
              "description": "Linha digit√°vel da parcela da fatura. C√≥digo da linha digit√°vel do boleto impresso pelo componente FCRFP098.",
              "nullable": true
            },
            "ourNumber": {
              "type": "integer",
              "description": "Nosso n√∫mero da parcela da fatura. Campo \"Nosso n√∫mero\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int64",
              "nullable": true
            },
            "dacOurNumber": {
              "type": "string",
              "description": "DAC nosso n√∫mero da parcela da fatura. Campo \"Nosso n√∫mero\" do frame \"Valor acr√©scimo\" do componente FCRFM001.",
              "nullable": true
            },
            "qrCodePix": {
              "type": "string",
              "description": "Link de pagamento para PIX. Campo \"link\" do conte√∫do do retorno da gera√ß√£o do PIX no componente GERFC014.",
              "nullable": true
            },
            "dischargeUser": {
              "type": "integer",
              "description": "Operador de baixa da parcela da fatura. Campo \"Oper./Pagamento\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "registrationUser": {
              "type": "integer",
              "description": "Operador de cadastro da parcela da fatura. Campo \"Oper./Inclus√£o\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32"
            },
            "calculatedValues": {
              "$ref": "#/components/schemas/CalculatedValuesModel"
            },
            "check": {
              "$ref": "#/components/schemas/CheckInstallmentModel"
            },
            "invoice": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/InvoiceDataModel"
              },
              "nullable": true
            },
            "commissions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/CommissionDataModel"
              },
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentRequestModel": {
          "type": "object",
          "properties": {
            "filter": {
              "$ref": "#/components/schemas/DocumentFilterModel"
            },
            "expand": {
              "type": "string",
              "description": "Lista de grupo de dados para expans√£o separados por  \",\".\r\n\u003Cbr\u003EAs seguintes express√µes s√£o suportadas: \"check\", \"invoice\", \"commissioneds\", \"calculateValue\".\u003Cbr\u003EEx.: \"expand\": \"check,invoice,commissioneds,calculateValue\".",
              "nullable": true
            },
            "order": {
              "type": "string",
              "description": " Lista de campos para ordena√ß√£o separados por \",\". Para ordena√ß√£o descendente utilizar o caracter \"-\".\r\n As seguintes express√µes s√£o suportadas: \"branchCode\", \"customerCode\",\"customerCpfCnpj\", \"receivableCode\", \"installmentCode\" e \"maxChangeFilterDate\"\r\nEx.: \"order\": \"-customerCode,maxChangeFilterDate\"",
              "nullable": true
            },
            "page": {
              "type": "integer",
              "description": "N√∫mero da p√°gina. P√°gina inicial √© 1.",
              "format": "int32"
            },
            "pageSize": {
              "type": "integer",
              "description": "Quantidade de itens por p√°gina. Valor padr√£o √© 100. Valor m√°ximo √© 100.",
              "format": "int32"
            }
          },
          "additionalProperties": false
        },
        "DocumentResponseModel": {
          "type": "object",
          "properties": {
            "count": {
              "type": "integer",
              "format": "int32"
            },
            "totalPages": {
              "type": "integer",
              "format": "int32"
            },
            "hasNext": {
              "type": "boolean"
            },
            "totalItems": {
              "type": "integer",
              "format": "int32"
            },
            "items": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/DocumentModel"
              },
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentTypeSearchAvailable": {
          "enum": [
            "Invoice",
            "Check",
            "Cash",
            "CreditCard",
            "DebitCard",
            "DebitNote"
          ],
          "type": "integer",
          "description": "tipo de documento das faturas. Campo \"Tipo documento\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Fatura\u003Cbr\u003E2 - Cheque\u003Cbr\u003E3 - Dinheiro\u003Cbr\u003E4 - Cart√£o de cr√©dito\u003Cbr\u003E5 - Cart√£o de d√©bito\u003Cbr\u003E6 - Nota de d√©bito\u003Cbr\u003E Somente ser√° realizado consulta para as tipagens acima",
          "format": "int32"
        },
        "DomainNotificationMessage": {
          "type": "object",
          "properties": {
            "code": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            },
            "message": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            },
            "detailedMessage": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            }
          },
          "additionalProperties": false
        },
        "InvoiceDataModel": {
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "C√≥digo da empresa. Campo \"Empresa\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32"
            },
            "invoiceSequence": {
              "type": "integer",
              "description": "C√≥digo sequencial da nota fiscal. Campo \"Fatura\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32"
            },
            "invoiceDate": {
              "type": "string",
              "description": "Data de movimento da nota fiscal. Campo \"Data fatura\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "date-time"
            },
            "invoiceCode": {
              "type": "integer",
              "description": "N√∫mero da nota fiscal. Primeiro campo \"Nota fiscal\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Documento fiscal."
        },
        "PaymentLinkRequestModel": {
          "required": [
            "branchCode",
            "customerCode",
            "installmentNumber",
            "receivableCode"
          ],
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "C√≥digo de empresa. Campo \"Empresa\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 4 caracteres.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "C√≥digo do cliente. Campo \"Cliente\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 9 caracteres.\u003Cbr\u003EN√£o pode ser informado junto com customerCpfCnpj, mas um deles dever√° ser informado.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "Cpf/Cnpj do cliente. Campo \"Cpf/Cnpj\" do componente PESFM010.\r\n\u003Cbr\u003ETamanho m√°ximo de 14 caracteres, informar apenas n√∫meros.\u003Cbr\u003EN√£o pode ser informado junto com customerCode, mas um deles dever√° ser informado.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "C√≥digo da fatura do cliente. Campo \"Fatura\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 10 caracteres.",
              "format": "int64"
            },
            "installmentNumber": {
              "type": "integer",
              "description": "N√∫mero da parcela da fatura do cliente. Campo \"Parcela\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho m√°ximo de 3 caracteres.",
              "format": "int32"
            },
            "daysLate": {
              "type": "integer",
              "format": "int32",
              "nullable": true
            },
            "increaseValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "fineValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "correctedValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "ReceivableBillingType": {
          "enum": [
            "CashSale",
            "InstallmentSale",
            "CashReceivable",
            "InstallmentReceivable",
            "Interest",
            "Advance",
            "AdvanceReturn",
            "Tariff",
            "OtherExpense",
            "Loan",
            "ExchangeCheckForCash",
            "TitleRenegotiation",
            "ChargeCard",
            "CheckReturned",
            "PurchaseCheckCurrent",
            "AccountabilityAgency",
            "ViaExport",
            "InvoiceGrouping",
            "EmployeeVoucherAdvance",
            "Location",
            "CheckCurrent",
            "ReceiptInvoiceOthers",
            "RightAssignmentCredit",
            "PurchaseForOthers",
            "Service",
            "OtherTitle",
            "MonetaryCorrection",
            "PostOffice",
            "DebitTransfer",
            "Break",
            "EndorsementCentralGuides",
            "InvoiceCentralGuides",
            "Condominium",
            "AgreementClosing",
            "ApportionmentCosts",
            "ApportionmentRevenue",
            "PaymentDuplicateBetweenCompanies",
            "ReceivingInvoicesBetweenCompanies",
            "ReceivesCheckCurrentFromAnotherCompany",
            "BalanceTransferBetweenCompanies"
          ],
          "type": "integer",
          "description": "tipo de faturamento das faturas. Campo \"Tipo faturamento\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Venda √† vista\u003Cbr\u003E2 - Venda a prazo\u003Cbr\u003E3 - Recebimento √† vista\u003Cbr\u003E4 - Recebimento a prazo\u003Cbr\u003E5 - Juro\u003Cbr\u003E6 - Adiantamento (entrada cx.)\u003Cbr\u003E7 - Dev.adiantamento\u003Cbr\u003E8 - Tarifa\u003Cbr\u003E9 - Outra despesa\u003Cbr\u003E10 - Emprestimo\u003Cbr\u003E11 - Troca cheque por Dinheiro\u003Cbr\u003E12 - Renegocia√ß√£o de t√≠tulo\u003Cbr\u003E13 - Cobran√ßa cart√£o\u003Cbr\u003E14 - Cheque devolvido\u003Cbr\u003E15 - Compra cheque presente\u003Cbr\u003E16 - Prestacao conta agencia\u003Cbr\u003E17 - Via exportacao\u003Cbr\u003E18 - Agrupamento de Fatura\u003Cbr\u003E19 - Vale/adiant. funcion√°rio\u003Cbr\u003E20 - Loca√ß√£o\u003Cbr\u003E21 - Cheque presente\u003Cbr\u003E22 - Recebimento fatura terceiro\u003Cbr\u003E23 - Cess√£o direito/cr√©dito\u003Cbr\u003E24 - Compra para terceiros\u003Cbr\u003E25 - Servi√ßo\u003Cbr\u003E26 - T√≠tulo de terceiros\u003Cbr\u003E27 - Corre√ß√£o monet√°ria\u003Cbr\u003E30 - Correio\u003Cbr\u003E31 - Transfer√™ncia de d√≠vida\u003Cbr\u003E32 - Quebra\u003Cbr\u003E33 - Endosso central de guias\u003Cbr\u003E34 - Fatura central de guias\u003Cbr\u003E35 - Condom√≠nio\u003Cbr\u003E36 - Fechamento de Conv√™nio\u003Cbr\u003E37 - Rateio de despesas\u003Cbr\u003E38 - Rateio de receitas\u003Cbr\u003E39 - Pgto duplicata entre empresas\u003Cbr\u003E40 - Receb faturas entre empresas\u003Cbr\u003E41 - Receb Chq Pres de outra empresa\u003Cbr\u003E42 - Transf. saldo entre empresas",
          "format": "int32"
        },
        "ReceivableChargeType": {
          "enum": [
            "NotCharged",
            "Simple",
            "Discounted",
            "Guaranteed",
            "Linked",
            "WithoutRegistration",
            "Vendor",
            "Protested",
            "Custody",
            "WithdrawnForRenegotiation",
            "OutOfTrade",
            "Endorsed",
            "CreditOperator",
            "InNotaryOffice",
            "InStoreCompanyCharge",
            "AwaitingReceipt",
            "DirectToBoleto",
            "TotalSupply",
            "CustodyDeclinedCheck",
            "CheckWithdrawalDeposit",
            "CustodyReturnCheck",
            "CheckDeclinedDiscount",
            "LowCheckWithdrawalDiscount",
            "CheckReturnDiscount",
            "OutsourcedBilling",
            "SCPC",
            "Export",
            "DirectAssignmentCredit",
            "ThirdPartyPurchase",
            "Agreement",
            "JudicialCollection",
            "Negative",
            "SupportedByNotaryPublic",
            "ProtestCanceled",
            "AvailableForNotaryPublic",
            "DigitalWallet",
            "Bolepix",
            "BookingSimpleCharge",
            "ReservationChargeDiscountInvoice",
            "ReservationChargeDiscountCheck",
            "GuaranteedCollectionReserve",
            "LinkedChargeReserve",
            "VendorBillingReserve",
            "CustodyChargeReservation",
            "ReservationForEndorsement",
            "ReservationCheck",
            "ReserveCustodyDiscount",
            "ReservationDiscountCompror",
            "Losses",
            "LostFund"
          ],
          "type": "integer",
          "description": "Tipo de cobran√ßa da parcela da fatura. Campo \"Tipo cobran√ßa\" do frame \"Parcela\" do componente FCRFM001.    \r\n\u003Cbr\u003E0 - N√£o est√° em cobran√ßa\u003Cbr\u003E1 - Simples\u003Cbr\u003E 2 - Descontada\u003Cbr\u003E 3 - Caucionada\u003Cbr\u003E 4 - Vinculada\u003Cbr\u003E 5 - Sem registro\u003Cbr\u003E 6 - Vendor\u003Cbr\u003E 8 - Protestado\u003Cbr\u003E 9 - Cust√≥dia\u003Cbr\u003E11 - Retirado para renegocia√ß√£o\u003Cbr\u003E12 - Fora de negocia√ß√£o\u003Cbr\u003E13 - Endossado\u003Cbr\u003E14 - Operadora de cr√©dito\u003Cbr\u003E15 - Em cart√≥rio\u003Cbr\u003E16 - Cobran√ßa na loja/empresa\u003Cbr\u003E17 - Aguardando recebimento\u003Cbr\u003E18 - Direto para boleto\u003Cbr\u003E19 - Abatimento total\u003Cbr\u003E20 - Cust√≥dia cheque recusado\u003Cbr\u003E21 - Cust√≥dia cheque baixa/retirada\u003Cbr\u003E22 - Cust√≥dia cheque devolu√ß√£o\u003Cbr\u003E23 - Desconto cheque recusado\u003Cbr\u003E24 - Desconto cheque baixa/retirada\u003Cbr\u003E25 - Desconto cheque devolu√ß√£o\u003Cbr\u003E26 - Cobran√ßa terceirizada\u003Cbr\u003E27 - SCPC\u003Cbr\u003E28 - Exporta√ß√£o\u003Cbr\u003E29 - Cess√£o direito/cr√©dito\u003Cbr\u003E30 - Compra para terceiros\u003Cbr\u003E31 - Conv√™nio\u003Cbr\u003E32 - Cobran√ßa Judicial\u003Cbr\u003E33 - Negativado\u003Cbr\u003E34 - Sustado em cart√≥rio\u003Cbr\u003E35 - Protesto cancelado\u003Cbr\u003E36 - Dispon√≠vel para cart√≥rio\u003Cbr\u003E37 - Carteira digital\u003Cbr\u003E38 - Bolepix\u003Cbr\u003E51 - Reserva cobran√ßa simples\u003Cbr\u003E52 - Reserva cobran√ßa desconto faturado\u003Cbr\u003E53 - Reserva cobran√ßa desconto cheque\u003Cbr\u003E54 - Reserva cobran√ßa caucionada\u003Cbr\u003E56 - Reserva cobran√ßa vinculada\u003Cbr\u003E59 - Reserva cobran√ßa vendor\u003Cbr\u003E60 - Reserva cobran√ßa cust√≥dia\u003Cbr\u003E70 - Reserva para endosso\u003Cbr\u003E80 - Reserva cheque\u003Cbr\u003E85 - Reserva desconto cust√≥dia\u003Cbr\u003E90 - Reserva desconto compror\u003Cbr\u003E98 - Perdas\u003Cbr\u003E99 - PDD - Fundo perdido",
          "format": "int32"
        },
        "ReceivableDischargeType": {
          "enum": [
            "TitleNotDischarged",
            "ViaReceipt",
            "DischargeForDeposit",
            "InvoiceGrouping",
            "AdvanceReturn",
            "DebitAccount",
            "Automatic",
            "ViaBank",
            "DischargeForDiscount",
            "DischargeByRenegotiation",
            "ViaBilling",
            "WarrantyReceipt",
            "DischargeByBankAccount",
            "DischargeOnRepresentativeAccount",
            "DischargeByCardRecalculation",
            "DischargeByOperationCenter",
            "Exempt",
            "DischargeByTotalReduction",
            "DischargeDiscountedTitle",
            "DischargeDebtTransfer",
            "DischargeByElectronicExtract",
            "DischargeByExtension",
            "DischargeByExport",
            "DischargeByVendor",
            "DischargeEmployeeInvoice",
            "DischargePartnerInvoice",
            "DischargeFutureAdvance",
            "DischargeCredevFuture",
            "DischargeEndorsedTitle",
            "CommissionDiscount",
            "DischargeSettleShop",
            "DischargeCardWithCredev",
            "DischargeByBreak",
            "DischargeOutsourcedBilling",
            "DischargeByWithdrawalChargeOutsourced",
            "EcommerceBillet",
            "DischargeByThirdPartyTitle",
            "AgreementClosing",
            "SettleBetweenCompanies",
            "EcommerceDeposit",
            "OnlineEcommerceTransfer",
            "AnotherDischarge"
          ],
          "type": "integer",
          "description": "tipo de faturamento das faturas. Campo \"Tipo faturamento\" do componente FCRFM001\".\r\n\u003Cbr\u003E0 - T√≠tulo n√£o baixado\u003Cbr\u003E1 - Via recebimento\u003Cbr\u003E2 - Baixa para dep√≥sito\u003Cbr\u003E3 - Agrupamento de fatura\u003Cbr\u003E4 - Devolu√ß√£o de adiant.\u003Cbr\u003E5 - Deb. conta (comis., folha)\u003Cbr\u003E6 - Autom√°tica (outro proc)\u003Cbr\u003E7 - Via banco\u003Cbr\u003E8 - Baixa para desconto\u003Cbr\u003E9 - Baixa por renegocia√ß√£o\u003Cbr\u003E10 - Via faturamento\u003Cbr\u003E11 - Recebimento de garantia\u003Cbr\u003E12 - Baixa por conta banc√°ria\u003Cbr\u003E13 - Baixa na conta representante\u003Cbr\u003E14 - Baixa por rec√°lculo de cart√£o\u003Cbr\u003E15 - Baixa por central de opera√ß√£o\u003Cbr\u003E16 - Isentado\u003Cbr\u003E17 - Baixa por abatimento total\u003Cbr\u003E18 - Baixa t√≠tulo descontado\u003Cbr\u003E19 - Baixa transfer√™ncia d√≠vida\u003Cbr\u003E20 - Baixa por extrato eletronico\u003Cbr\u003E21 - Baixa por prorroga√ß√£o\u003Cbr\u003E22 - Baixa por exporta√ß√£o\u003Cbr\u003E23 - Baixa por vendor\u003Cbr\u003E24 - Baixa fatura de funcion√°rio\u003Cbr\u003E25 - Baixa fatura s√≥cio\u003Cbr\u003E26 - Baixa adiantamento futuro\u003Cbr\u003E27 - Baixa CREDEV futuro\u003Cbr\u003E28 - Baixa t√≠tulo endossado\u003Cbr\u003E29 - Desconto em comiss√£o\u003Cbr\u003E30 - Baixa acerto loja\u003Cbr\u003E31 - Baixa cart√£o com credev\u003Cbr\u003E32 - Baixa por Quebra\u003Cbr\u003E33 - Baixa cobran√ßa terceirizada\u003Cbr\u003E34 - Baixa por retirada de cobran√ßa terceirizada\u003Cbr\u003E35 - Boleto e-commerce\u003Cbr\u003E36 - Baixa por t√≠tulo de terceiros\u003Cbr\u003E37 - Fechamento de Conv√™nio\u003Cbr\u003E38 - Acerto entre empresas\u003Cbr\u003E40 - Dep√≥sito e-commerces\u003Cbr\u003E41 - Transfer√™ncia online e-commerce\u003Cbr\u003E50 - Outra baixa",
          "format": "int32"
        },
        "ReceivableStatusType": {
          "enum": [
            "Normal",
            "Returned",
            "Canceled",
            "Broken"
          ],
          "type": "integer",
          "description": "Situa√ß√£o das faturas. Campo \"Situa√ß√£o\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Normal\u003Cbr\u003E2 - Devolvido\u003Cbr\u003E3 - Cancelado\u003Cbr\u003E4 - Quebrada",
          "format": "int32"
        }
      },
      "securitySchemes": {
        "Bearer": {
          "type": "apiKey",
          "description": "JWT Authorization header using the Bearer scheme. Example: \"Authorization: Bearer {token}\"",
          "name": "Authorization",
          "in": "header"
        }
      }
    },
    "security": [
      {
        "Bearer": []
      }
    ]
  }
</file>

<file path="alembic.ini">
# A configuration file for Alembic.
# See: https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file

[alembic]
# path to migration scripts
script_location = alembic

# template for migration file names, e.g. "%%(year)d%%(month).2d%%(day).2d_%%(rev)s"
# file_template = %%(rev)s_%%(slug)s

# timezone for computation of timestamps within migration files
# Eg: UTC, EST5EDT
# timezone =

# sys.path path, will be prepended to sys.path if present.
# defaults to %%(here)s
# prepend_sys_path = .

# sqlalchemy.url = driver://user:pass@localhost/dbname
# O URL ser√° carregado dinamicamente a partir da configura√ß√£o da aplica√ß√£o em alembic/env.py
sqlalchemy.url = postgresql+psycopg://user:password@host:port/database

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="alembic/env.py">
import os
import sys
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# --- Adicionar Raiz do Projeto ao sys.path ---
# Garante que o Alembic possa encontrar os m√≥dulos da sua aplica√ß√£o
# Ajuste para adicionar o diret√≥rio PAI do diret√≥rio 'alembic', que √© a raiz do projeto.
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT) # Adiciona a raiz do projeto
# --------------------------------------------

# --- Importar configura√ß√µes e Base dos modelos ---
try:
    # As importa√ß√µes agora devem funcionar, pois 'src' est√° dentro de PROJECT_ROOT
    from src.config import config as app_config
    from src.database.base import Base
    # Importar todos os modelos ORM para que o Alembic os reconhe√ßa
    import src.domain # Garante que __init__.py de domain importe os modelos
except ImportError as e:
    print(f"Erro ao importar m√≥dulos da aplica√ß√£o: {e}")
    print("Certifique-se de que est√° executando o alembic a partir do diret√≥rio raiz do projeto")
    print(f"PROJECT_ROOT: {PROJECT_ROOT}")
    print(f"sys.path: {sys.path}")
    sys.exit(1)
# ----------------------------------------------

# este √© o objeto MetaData do Alembic para suporte a 'autogenerate'
# --- Definir target_metadata a partir do Base importado ---
target_metadata = Base.metadata
# -------------------------------------------------------

# outras configura√ß√µes do arquivo .ini, se houver:
config = context.config

# --- Configurar a URL do banco dinamicamente ---
db_url = app_config.SQLALCHEMY_DATABASE_URI
if not db_url:
    print("Erro: SQLALCHEMY_DATABASE_URI n√£o est√° configurado na aplica√ß√£o.")
    sys.exit(1)
config.set_main_option('sqlalchemy.url', db_url)
# ---------------------------------------------

# Interpreta o arquivo de configura√ß√£o para logging do Python.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Demais configura√ß√µes e fun√ß√µes run_migrations_offline/online permanecem iguais...

def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        compare_type=True,
        # Usar a conven√ß√£o de nomenclatura definida em Base
        naming_convention=target_metadata.naming_convention,
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            compare_type=True,
            # Usar a conven√ß√£o de nomenclatura definida em Base
            naming_convention=target_metadata.naming_convention,
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
</file>

<file path="alembic/README">
Generic single-database configuration.
</file>

<file path="alembic/script.py.mako">
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
</file>

<file path="alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py">
# alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py
"""Increase size of freight_type columns in nota_fiscal

Revision ID: 29ece17d793b
Revises: 75de064288e5 # ID da migra√ß√£o anterior que criou as tabelas fiscais
Create Date: 2025-04-03 13:34:08.282181 # Data de cria√ß√£o original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# sqlalchemy.dialects n√£o √© estritamente necess√°rio para VARCHAR, mas n√£o prejudica
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '29ece17d793b'
down_revision: Union[str, None] = '75de064288e5' # Aponta para a migra√ß√£o anterior
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comandos CORRIGIDOS para ALTERAR as colunas ###
    # Alterar apenas o tipo/tamanho das colunas necess√°rias na tabela nota_fiscal
    op.alter_column('nota_fiscal', 'freight_type',
           existing_type=sa.VARCHAR(length=10), # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=50),      # Define o novo tipo/tamanho
           existing_nullable=True)           # Mant√©m a nulidade existente

    op.alter_column('nota_fiscal', 'freight_type_redispatch',
           existing_type=sa.VARCHAR(length=20), # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=50),      # Define o novo tipo/tamanho
           existing_nullable=True)           # Mant√©m a nulidade existente
    # ### Fim dos Comandos CORRIGIDOS ###


def downgrade() -> None:
    # ### Comandos CORRIGIDOS para REVERTER a altera√ß√£o ###
    # Reverter para os tipos/tamanhos originais
    op.alter_column('nota_fiscal', 'freight_type_redispatch',
           existing_type=sa.VARCHAR(length=50), # Informa o tipo atual (VARCHAR 50)
           type_=sa.VARCHAR(length=20),      # Define o tipo antigo (VARCHAR 20)
           existing_nullable=True)

    op.alter_column('nota_fiscal', 'freight_type',
           existing_type=sa.VARCHAR(length=50), # Informa o tipo atual (VARCHAR 50)
           type_=sa.VARCHAR(length=10),      # Define o tipo antigo (VARCHAR 10)
           existing_nullable=True)
    # ### Fim dos Comandos CORRIGIDOS ###
</file>

<file path="alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py">
# alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py
"""Increase size of ncm column in nota_fiscal_item

Revision ID: 72333f760af5
Revises: 29ece17d793b # ID da migra√ß√£o anterior (a que alterou freight_type)
Create Date: 2025-04-03 13:47:41.300907 # Data de cria√ß√£o original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# Removido import n√£o utilizado de postgresql, mas pode manter se preferir
# from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '72333f760af5'
down_revision: Union[str, None] = '29ece17d793b' # Aponta para a migra√ß√£o que alterou freight_type
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comandos CORRIGIDOS para ALTERAR a coluna ncm ###
    op.alter_column('nota_fiscal_item', 'ncm',
           existing_type=sa.VARCHAR(length=8),  # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=12),     # Define o novo tipo/tamanho
           existing_nullable=True)          # Mant√©m a nulidade existente
    # ### Fim dos Comandos CORRIGIDOS ###


def downgrade() -> None:
    # ### Comandos CORRIGIDOS para REVERTER a altera√ß√£o ###
    op.alter_column('nota_fiscal_item', 'ncm',
           existing_type=sa.VARCHAR(length=12), # Informa o tipo atual (VARCHAR 12)
           type_=sa.VARCHAR(length=8),       # Define o tipo antigo (VARCHAR 8)
           existing_nullable=True)
    # ### Fim dos Comandos CORRIGIDOS ###
</file>

<file path="alembic/versions/75de064288e5_adiciona_tabelas_iniciais.py">
"""Adiciona tabelas iniciais

Revision ID: 75de064288e5
Revises: 
Create Date: 2025-04-03 11:25:43.778254

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '75de064288e5'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('product_observations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('reference_code', sa.Text(), nullable=False),
    sa.Column('observation', sa.Text(), nullable=False),
    sa.Column('user', sa.Text(), nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('resolved', sa.Boolean(), nullable=False),
    sa.Column('resolved_user', sa.Text(), nullable=True),
    sa.Column('resolved_timestamp', postgresql.TIMESTAMP(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_product_observations'))
    )
    op.create_index(op.f('ix_product_observations_reference_code'), 'product_observations', ['reference_code'], unique=False)
    op.create_index(op.f('ix_product_observations_resolved'), 'product_observations', ['resolved'], unique=False)
    op.create_table('users',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('username', sa.Text(), nullable=False),
    sa.Column('password_hash', sa.Text(), nullable=False),
    sa.Column('name', sa.Text(), nullable=False),
    sa.Column('email', sa.Text(), nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('last_login', postgresql.TIMESTAMP(timezone=True), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_users'))
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_index(op.f('ix_users_username'), 'users', ['username'], unique=True)
    op.create_table('user_permissions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('is_admin', sa.Boolean(), nullable=False),
    sa.Column('can_access_products', sa.Boolean(), nullable=False),
    sa.Column('can_access_fabrics', sa.Boolean(), nullable=False),
    sa.Column('can_access_customer_panel', sa.Boolean(), nullable=False),
    sa.Column('can_access_fiscal', sa.Boolean(), nullable=False),
    sa.Column('can_access_accounts_receivable', sa.Boolean(), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_user_permissions_user_id_users'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_user_permissions'))
    )
    op.create_index(op.f('ix_user_permissions_user_id'), 'user_permissions', ['user_id'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_user_permissions_user_id'), table_name='user_permissions')
    op.drop_table('user_permissions')
    op.drop_index(op.f('ix_users_username'), table_name='users')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    op.drop_index(op.f('ix_product_observations_resolved'), table_name='product_observations')
    op.drop_index(op.f('ix_product_observations_reference_code'), table_name='product_observations')
    op.drop_table('product_observations')
    # ### end Alembic commands ###
</file>

<file path="alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py">
# alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py
"""Add unique constraint on branch, sequence, date for nota_fiscal

Revision ID: 863da6d8e21b
Revises: 72333f760af5 # ID da migra√ß√£o anterior (a que alterou ncm)
Create Date: 2025-04-03 14:36:59.832089 # Data de cria√ß√£o original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# Removido import n√£o utilizado
# from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '863da6d8e21b'
down_revision: Union[str, None] = '72333f760af5' # Aponta para a migra√ß√£o que alterou ncm
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comando CORRIGIDO para ADICIONAR a constraint UNIQUE ###
    # Adicionar a constraint unique composta na tabela nota_fiscal
    op.create_unique_constraint(
        'uq_nota_fiscal_branch_sequence_date', # Nome sugerido para a constraint
        'nota_fiscal',                         # Nome da tabela
        ['branch_code', 'invoice_sequence', 'invoice_date'] # Colunas na constraint
    )
    # ### Fim do Comando CORRIGIDO ###


def downgrade() -> None:
    # ### Comando CORRIGIDO para REMOVER a constraint UNIQUE ###
    # Remover a constraint unique ao reverter
    op.drop_constraint(
        'uq_nota_fiscal_branch_sequence_date', # Nome da constraint a ser removida
        'nota_fiscal',                         # Nome da tabela
        type_='unique'                         # Tipo da constraint
    )
    # ### Fim do Comando CORRIGIDO ###
</file>

<file path="backend_structure.md">
saldo-api/
‚îú‚îÄ‚îÄ .env                 # Environment variables (SECRET_KEY, API creds, DB connection, etc.) # MODIFIED
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt     # MODIFIED (Added SQLAlchemy, psycopg)
‚îú‚îÄ‚îÄ run.py               # Simple script to run the Flask app
‚îú‚îÄ‚îÄ README.md            # Project overview, setup, structure # MODIFIED
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ app.py               # Flask app factory (create_app) # MODIFIED (SQLAlchemy init)
    ‚îú‚îÄ‚îÄ config/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ settings.py      # Load env vars, define Config object, build DB URI # MODIFIED
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of config files # MODIFIED
    ‚îÇ
    ‚îú‚îÄ‚îÄ domain/              # Data models (DTOs for ERP and Local DB)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ accounts_receivable.py
    ‚îÇ   ‚îú‚îÄ‚îÄ balance.py
    ‚îÇ   ‚îú‚îÄ‚îÄ cost.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fabric_details.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fiscal.py
    ‚îÇ   ‚îú‚îÄ‚îÄ observation.py
    ‚îÇ   ‚îú‚îÄ‚îÄ person.py
    ‚îÇ   ‚îú‚îÄ‚îÄ user.py
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of domain models
    ‚îÇ
    ‚îú‚îÄ‚îÄ database/            # Database interaction layer (PostgreSQL with SQLAlchemy Core)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      # Initialize SQLAlchemy engine, repositories, schema
    ‚îÇ   ‚îú‚îÄ‚îÄ base_repository.py # Uses SQLAlchemy Engine and text()
    ‚îÇ   ‚îú‚îÄ‚îÄ observation_repository.py # Adapted for SQLAlchemy
    ‚îÇ   ‚îú‚îÄ‚îÄ product_repository.py # Adapted for SQLAlchemy (Placeholder)
    ‚îÇ   ‚îú‚îÄ‚îÄ schema_manager.py # Handles table creation/migration (PostgreSQL syntax)
    ‚îÇ   ‚îú‚îÄ‚îÄ user_repository.py # Adapted for SQLAlchemy
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of database layer
    ‚îÇ
    ‚îú‚îÄ‚îÄ services/            # Business logic layer
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ accounts_receivable_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ auth_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ customer_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fabric_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fiscal_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ observation_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ product_service.py
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of business services
    ‚îÇ
    ‚îú‚îÄ‚îÄ erp_integration/     # Layer for interacting with the TOTVS ERP API
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ accounts_receivable_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_auth_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_balance_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_cost_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_fiscal_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_person_service.py
    ‚îÇ   ‚îú‚îÄ‚îÄ erp_product_service.py
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of ERP integration layer
    ‚îÇ
    ‚îú‚îÄ‚îÄ api/                 # Flask Blueprints and route definitions
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ routes/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accounts_receivable.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ customer_panel.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fabrics.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fiscal.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observations.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ products.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ users.py
    ‚îÇ   ‚îú‚îÄ‚îÄ decorators.py
    ‚îÇ   ‚îú‚îÄ‚îÄ errors.py
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Explanation of the API layer
    ‚îÇ
    ‚îî‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ fabric_list_builder.py
        ‚îú‚îÄ‚îÄ logger.py
        ‚îú‚îÄ‚îÄ matrix_builder.py
        ‚îú‚îÄ‚îÄ pdf_utils.py
        ‚îú‚îÄ‚îÄ system_monitor.py
        ‚îî‚îÄ‚îÄ README.md        # Explanation of utility functions
</file>

<file path="README.md">
# Saldo API

API Flask para consulta de saldos de produtos e tecidos, custos, dados de clientes e contas a receber, integrando-se a um ERP TOTVS e utilizando PostgreSQL como banco de dados com SQLAlchemy ORM e Alembic para migra√ß√µes.

## Funcionalidades Principais

*   **Consulta de Saldo de Produtos:** Retorna o saldo de produtos acabados em formato de matriz (cor x tamanho), com diferentes modos de c√°lculo (base, vendas, produ√ß√£o).
*   **Consulta de Saldo de Tecidos:** Retorna uma lista de tecidos (mat√©rias-primas) com saldo, custo e detalhes (largura, gramatura, encolhimento).
*   **Gerenciamento de Observa√ß√µes:** Permite adicionar, visualizar e resolver observa√ß√µes associadas a produtos (armazenadas no PostgreSQL).
*   **Painel do Cliente:** Busca dados cadastrais (PF/PJ) e estat√≠sticas financeiras de clientes diretamente do ERP.
*   **Contas a Receber:** Permite buscar documentos de contas a receber com filtros avan√ßados e gerar boletos em PDF via ERP.
*   **M√≥dulo Fiscal:** Permite buscar notas fiscais (NF-e) com filtros e gerar DANFE em PDF via ERP.
*   **Gerenciamento de Usu√°rios:** CRUD de usu√°rios e suas permiss√µes (armazenadas no PostgreSQL, acesso restrito a administradores).
*   **Autentica√ß√£o e Autoriza√ß√£o:** Sistema de login baseado em token JWT com controle de acesso por permiss√µes.
*   **Migra√ß√µes de Banco de Dados:** Gerenciamento do schema do banco de dados PostgreSQL usando Alembic.

## Estrutura do Projeto

O projeto segue uma arquitetura em camadas para melhor organiza√ß√£o e manutenibilidade:

```
saldo-api/
‚îú‚îÄ‚îÄ .env # Vari√°veis de ambiente (Credenciais DB, API, Chaves)
‚îú‚îÄ‚îÄ requirements.txt # Depend√™ncias Python
‚îú‚îÄ‚îÄ run.py # Ponto de entrada para execu√ß√£o
‚îú‚îÄ‚îÄ alembic.ini # Configura√ß√£o do Alembic
‚îú‚îÄ‚îÄ alembic/ # Diret√≥rio de migra√ß√µes do Alembic
‚îÇ ‚îú‚îÄ‚îÄ env.py # Script de ambiente do Alembic
‚îÇ ‚îú‚îÄ‚îÄ script.py.mako # Template de migra√ß√£o
‚îÇ ‚îî‚îÄ‚îÄ versions/ # Arquivos de scripts de migra√ß√£o
‚îú‚îÄ‚îÄ README.md # Este arquivo
‚îÇ
‚îî‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ app.py # F√°brica da aplica√ß√£o Flask (create_app)
‚îú‚îÄ‚îÄ config/ # Configura√ß√µes (l√™ .env, define objeto Config)
‚îú‚îÄ‚îÄ domain/ # Modelos de dados (ORM para DB local, Dataclasses para ERP/DTOs)
‚îú‚îÄ‚îÄ database/ # Camada de acesso ao banco de dados (PostgreSQL com SQLAlchemy ORM)
‚îú‚îÄ‚îÄ services/ # Camada de l√≥gica de neg√≥cio
‚îú‚îÄ‚îÄ erp_integration/ # Camada de integra√ß√£o com a API ERP TOTVS
‚îú‚îÄ‚îÄ api/ # Camada da API REST (Blueprints, rotas, decorators, errors)
‚îî‚îÄ‚îÄ utils/ # Utilit√°rios (logger, builders, etc.)
```



Consulte os `README.md` dentro de cada diret√≥rio (`src/config`, `src/database`, etc.) para mais detalhes sobre sua responsabilidade.

## Setup e Instala√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone <url-do-repositorio>
    cd saldo-api
    ```

2.  **Pr√©-requisitos:**
    *   **Python:** 3.10 ou superior.
    *   **PostgreSQL:** Um servidor PostgreSQL instalado e acess√≠vel.
    *   **Cliente PostgreSQL (libpq):** Bibliotecas cliente do PostgreSQL instaladas e acess√≠veis.
    *   **Git:** Sistema de controle de vers√£o.

3.  **Crie e Ative um Ambiente Virtual:**
    ```bash
    python -m venv venv
    # Linux/macOS:
    source venv/bin/activate
    # Windows:
    .\venv\Scripts\activate
    ```

4.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configure o Banco de Dados PostgreSQL:** (Instru√ß√µes permanecem as mesmas)
    *   Crie um banco de dados (ex: `connector_db`).
    *   Crie um usu√°rio (ex: `saldo_api_user`) com senha segura.
    *   Conceda privil√©gios ao usu√°rio no banco.
    *   Configure o `pg_hba.conf` para permitir conex√µes.

6.  **Configure as Vari√°veis de Ambiente (`.env`):** (Instru√ß√µes permanecem as mesmas)
    *   Copie `.env.example` para `.env` (se existir) ou crie um novo.
    *   Preencha `SECRET_KEY`, `DB_TYPE=POSTGRES`, `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`, credenciais da API TOTVS, e configura√ß√µes da app Flask.

7.  **Aplique as Migra√ß√µes do Banco de Dados:**
    *   Com as vari√°veis de ambiente configuradas e o banco acess√≠vel, aplique as migra√ß√µes do Alembic para criar/atualizar o schema:
    ```bash
    alembic upgrade head
    ```
    *   Na primeira execu√ß√£o, isso criar√° todas as tabelas (`users`, `user_permissions`, `product_observations`, `alembic_version`). A fun√ß√£o `initialize_schema` em `src/app.py` tamb√©m garantir√° a cria√ß√£o do usu√°rio `admin` padr√£o se ele n√£o existir.

8.  **Execute a Aplica√ß√£o:**
    ```bash
    python run.py
    ```
    A API Flask iniciar√° e estar√° dispon√≠vel em `http://<APP_HOST>:<APP_PORT>`.

## Fluxo de Trabalho de Migra√ß√£o (Alembic)

Sempre que voc√™ modificar os modelos ORM em `src/domain/` (adicionar/remover/alterar tabelas ou colunas):

1.  **Gere uma Nova Migra√ß√£o Autom√°tica:**
    ```bash
    alembic revision --autogenerate -m "Descreva a mudan√ßa aqui"
    ```

2.  **Revise o Script Gerado:** Verifique o arquivo Python criado em `alembic/versions/`. Ajuste se necess√°rio (o autogenerate pode precisar de retoques em casos complexos).

3.  **Aplique a Migra√ß√£o ao Banco:**
    ```bash
    alembic upgrade head
    ```

4.  **Commite** o novo script de migra√ß√£o junto com as altera√ß√µes nos modelos.

Para reverter a √∫ltima migra√ß√£o (use com cuidado):
```bash
alembic downgrade -1
```
Para ver o hist√≥rico de migra√ß√µes e o estado atual:
```bash
alembic history
alembic current
```

## Padr√µes de Desenvolvimento

*   **Nomenclatura:** `snake_case` para vari√°veis/fun√ß√µes, `PascalCase` para classes, `UPPER_SNAKE_CASE` para constantes.
*   **Estrutura:** Arquitetura em camadas (API, Services, ERP Integration, Database, Domain).
*   **Banco de Dados:** PostgreSQL.
*   **ORM/DB Layer:** **SQLAlchemy ORM** para intera√ß√£o com o banco de dados local.
*   **Migra√ß√µes:** Alembic para gerenciamento do schema do banco de dados.
*   **Tipagem:** Uso extensivo de type hints.
*   **Modelos:** Uso de **classes ORM (herdando de `Base`)** para representar tabelas do banco local e **`dataclasses`** para representar estruturas de dados do ERP ou DTOs espec√≠ficos.
*   **Logs:** Logs detalhados usando o m√≥dulo `logging` e `ConcurrentRotatingFileHandler`.
*   **Error Handling:** Exce√ß√µes customizadas e tratamento robusto de erros.
*   **Documenta√ß√£o:** Docstrings, READMEs nos diret√≥rios chave.
*   **Vari√°veis de Ambiente:** Configura√ß√µes gerenciadas via `.env`.

## Desenvolvimento Futuro

*   Implementar caching para respostas da API ERP.
*   Adicionar testes unit√°rios e de integra√ß√£o.
*   Melhorar a configura√ß√£o de CORS para produ√ß√£o.
*   Expandir funcionalidades (Detalhes NF, Link PIX, etc.).
*   Armazenar dados do ERP no PostgreSQL para relat√≥rios/an√°lises futuras.
</file>

<file path="requirements.txt">
Flask>=2.0.0
Flask-Cors>=3.0.0
python-dotenv>=0.19.0
requests>=2.25.0
psutil>=5.8.0
PyJWT>=2.0.0
bcrypt>=3.2.0
cachetools>=5.0.0
SQLAlchemy>=2.0
psycopg>=3.0
alembic>=1.7
</file>

<file path="run.py">
# run.py
# Entry point for running the Flask application.
import os
import sys
import traceback
from src.app import create_app
from src.utils.logger import logger
from src.config.settings import load_config

# Load configuration early
config = load_config()

if __name__ == '__main__':
    app = create_app(config)
    logger.info(f"Starting server on {config.APP_HOST}:{config.APP_PORT}")

    try:
        # Use waitress or gunicorn for production instead of app.run
        app.run(host=config.APP_HOST, port=config.APP_PORT, debug=config.APP_DEBUG)
    except Exception as e:
        logger.critical(f"Fatal error starting server: {e}", exc_info=True)
        logger.critical(f"Traceback: {traceback.format_exc()}")
        sys.exit(1)
</file>

<file path="src/__init__.py">
# src/__init__.py
# This file marks the 'src' directory as a Python package.
</file>

<file path="src/api/__init__.py">
# src/api/__init__.py
# Initializes the API layer and registers blueprints.

from flask import Flask
from .routes.auth import auth_bp
from .routes.users import users_bp
from .routes.products import products_bp
from .routes.fabrics import fabrics_bp
from .routes.observations import observations_bp
from .routes.customer_panel import customer_panel_bp
from .routes.fiscal import fiscal_bp
from .routes.accounts_receivable import accounts_receivable_bp # <<<--- ADDED
from src.utils.logger import logger

# List of blueprints to register
# Add new blueprints here as they are created
BLUEPRINTS = [
    (auth_bp, '/api/auth'),
    (users_bp, '/api/users'),
    (products_bp, '/api/products'),
    (fabrics_bp, '/api/fabrics'),
    (observations_bp, '/api/observations'),
    (customer_panel_bp, '/api/customer_panel'),
    (fiscal_bp, '/api/fiscal'),
    (accounts_receivable_bp, '/api/accounts-receivable'), # <<<--- ADDED
]

def register_blueprints(app: Flask):
    """
    Registers all defined blueprints with the Flask application.

    Args:
        app: The Flask application instance.
    """
    logger.info("Registering API blueprints...")
    for bp, prefix in BLUEPRINTS:
        app.register_blueprint(bp, url_prefix=prefix)
        logger.debug(f"Blueprint '{bp.name}' registered with prefix '{prefix}'.")
    logger.info("All API blueprints registered.")

__all__ = ["register_blueprints"]
</file>

<file path="src/api/decorators.py">
# src/api/decorators.py
# Defines custom decorators for API endpoints, primarily for authentication and authorization.

from functools import wraps
from flask import request, current_app, jsonify
from src.services.auth_service import AuthService
from src.api.errors import AuthenticationError, ForbiddenError, ApiError, ConfigurationError # Added Config Error
from src.utils.logger import logger

# Helper to get auth_service instance from app context
def _get_auth_service() -> AuthService:
        service = current_app.config.get('auth_service')
        if not service:
            logger.critical("AuthService not found in application config!")
            # Raising allows Flask's error handlers to catch it
            raise ApiError("Authentication service is unavailable.", 503)
        return service

def login_required(f):
    """
    Decorator to ensure the user is logged in (valid token).
    Attaches the user object to request.current_user.
    """
    @wraps(f)
    def decorated_function(*args, **kwargs):
        try:
            auth_service = _get_auth_service()
            user = auth_service.get_current_user_from_request()
            if not user:
                    logger.debug("Access denied: No valid token/user found.")
                    # Raise specific error type for handler
                    raise AuthenticationError("Authentication required. Please log in.")

            # Attach user to the request context for use in the endpoint
            request.current_user = user
            logger.debug(f"Access granted for user: {user.username} (ID: {user.id})")
            return f(*args, **kwargs)
        except AuthenticationError as e:
                # Handle auth errors specifically (e.g., token expired, invalid)
                return jsonify({"error": str(e)}), 401
        except ConfigurationError as e: # Handle missing secret key during verification
                logger.critical(f"Auth configuration error during login_required: {e}")
                return jsonify({"error": "Internal server configuration error."}), 500
        except ApiError as e:
                # Handle service unavailable error
                return jsonify({"error": e.message}), e.status_code
        except Exception as e:
                # Catch unexpected errors during user retrieval
                logger.error(f"Error during login_required check: {e}", exc_info=True)
                return jsonify({"error": "Internal server error during authentication check."}), 500
    return decorated_function

def admin_required(f):
    """
    Decorator to ensure the user is logged in AND is an administrator.
    Must be used *after* @login_required.
    """
    @wraps(f)
    @login_required # Ensures login_required runs first and sets request.current_user
    def decorated_function(*args, **kwargs):
        # request.current_user is guaranteed to exist here if @login_required passed
        user = request.current_user
        # Check permissions object exists before accessing attributes
        if not user.permissions or not user.permissions.is_admin:
            logger.warning(f"Access denied: User '{user.username}' (ID: {user.id}) is not an admin.")
            # Raise specific error type for handler
            raise ForbiddenError("Admin privileges required.")

        logger.debug(f"Admin access granted for user: {user.username}")
        return f(*args, **kwargs)
    return decorated_function

# --- Permission-specific decorators ---

def _permission_required(permission_attr: str, error_message: str):
    """Generic factory for permission decorators."""
    def decorator(f):
        @wraps(f)
        @login_required # Always require login first
        def decorated_function(*args, **kwargs):
            user = request.current_user
            # Check if user has permissions object and the specific permission OR is admin
            has_perm = (user.permissions and getattr(user.permissions, permission_attr, False))
            is_admin = (user.permissions and user.permissions.is_admin)

            if not (has_perm or is_admin):
                logger.warning(f"Access denied for user '{user.username}': Lacks permission '{permission_attr}'.")
                raise ForbiddenError(error_message)

            logger.debug(f"Permission '{permission_attr}' granted for user: {user.username} (Admin={is_admin})")
            return f(*args, **kwargs)
        return decorated_function
    return decorator

# Define specific permission decorators using the factory
products_access_required = _permission_required(
    'can_access_products',
    'Access to product information required.'
)

fabrics_access_required = _permission_required(
    'can_access_fabrics',
    'Access to fabric information required.'
)

customer_panel_access_required = _permission_required(
    'can_access_customer_panel',
    'Access to customer panel required.'
)

fiscal_access_required = _permission_required(
    'can_access_fiscal',
    'Access to fiscal module required.'
)

accounts_receivable_access_required = _permission_required( # <<<--- ADDED
    'can_access_accounts_receivable',
    'Access to accounts receivable module required.'
)
</file>

<file path="src/api/errors.py">
# src/api/errors.py
# Defines custom application exceptions and Flask error handlers.

from flask import jsonify, request
from werkzeug.exceptions import HTTPException
from src.utils.logger import logger

# --- Custom Application Exceptions ---

class ApiError(Exception):
    """Base class for custom API errors."""
    status_code = 500
    message = "An internal server error occurred."

    def __init__(self, message=None, status_code=None, payload=None):
        super().__init__()
        if message is not None:
            self.message = message
        if status_code is not None:
            self.status_code = status_code
        self.payload = payload # Optional additional data

    def to_dict(self):
        rv = dict(self.payload or ())
        rv['error'] = self.message
        return rv

class ValidationError(ApiError):
    """Indicates invalid data provided by the client."""
    status_code = 400
    message = "Validation failed."

class AuthenticationError(ApiError):
    """Indicates failure to authenticate."""
    status_code = 401
    message = "Authentication failed."

class InvalidTokenError(AuthenticationError):
    """Indicates the provided token is invalid."""
    message = "Invalid authentication token provided."

class ExpiredTokenError(AuthenticationError):
    """Indicates the provided token has expired."""
    message = "Authentication token has expired."

class ForbiddenError(ApiError):
    """Indicates the user does not have permission for the action."""
    status_code = 403
    message = "You do not have permission to perform this action."

class NotFoundError(ApiError):
    """Indicates a requested resource was not found."""
    status_code = 404
    message = "The requested resource was not found."

class ServiceError(ApiError):
     """Indicates a general error within a service layer operation."""
     status_code = 500
     message = "A service error occurred."

class DatabaseError(ApiError):
    """Indicates an error during a database operation."""
    status_code = 500
    message = "A database error occurred."

class ErpIntegrationError(ApiError):
    """Indicates an error during communication with the external ERP."""
    status_code = 502 # Bad Gateway might be appropriate
    message = "Error communicating with the ERP system."

class ErpNotFoundError(NotFoundError):
     """Indicates a resource was specifically not found in the ERP."""
     message = "Resource not found in the ERP system."

class ConfigurationError(ApiError):
     """Indicates a problem with the application's configuration."""
     status_code = 500
     message = "Application configuration error."


# --- Flask Error Handlers ---

def register_error_handlers(app):
    """Registers custom error handlers with the Flask app."""

    @app.errorhandler(ApiError)
    def handle_api_error(error):
        """Handler for custom ApiError exceptions."""
        logger.warning(f"API Error Handled: {type(error).__name__} - Status: {error.status_code} - Msg: {error.message}")
        response = jsonify(error.to_dict())
        response.status_code = error.status_code
        return response

    @app.errorhandler(HTTPException)
    def handle_http_exception(error):
        """Handler for standard werkzeug HTTPExceptions (like 404, 405)."""
        # Log werkzeug's default exceptions
        # Now 'request' is available
        logger.warning(f"HTTP Exception Handled: {error.code} {error.name} - Path: {request.path} - Msg: {error.description}")
        response = jsonify({"error": f"{error.name}: {error.description}"})
        response.status_code = error.code
        # CORS headers should be handled by Flask-CORS middleware even for errors
        return response

    @app.errorhandler(Exception)
    def handle_generic_exception(error):
        """Handler for any other unhandled exceptions."""
        # Log the full traceback for unexpected errors
        logger.error(f"Unhandled Exception: {error}", exc_info=True)
        # Return a generic 500 error to the client
        response = jsonify({"error": "An unexpected internal server error occurred."})
        response.status_code = 500
        return response

    logger.info("Custom error handlers registered.")
</file>

<file path="src/api/README.md">
# src/api

Este diret√≥rio cont√©m a camada da API da aplica√ß√£o, respons√°vel por expor os endpoints HTTP e lidar com as requisi√ß√µes e respostas, utilizando Flask.

## Arquivos e Subdiret√≥rios

*   **`__init__.py`**: Inicializa o pacote `api` e cont√©m a fun√ß√£o `register_blueprints` para registrar todos os blueprints da API na aplica√ß√£o Flask principal.
*   **`decorators.py`**: Define decoradores customizados (`@login_required`, `@admin_required`, etc.) para controle de acesso (autentica√ß√£o e autoriza√ß√£o). O `@login_required` agora utiliza o `AuthService` (com sua pr√≥pria sess√£o de banco de dados) para validar o token e carregar o usu√°rio (`request.current_user`).
*   **`errors.py`**: Define exce√ß√µes customizadas (`ApiError`, `ValidationError`, etc.) e registra os manipuladores de erro (`@app.errorhandler`) no Flask para respostas JSON padronizadas.
*   **`routes/`**: Subdiret√≥rio contendo os blueprints Flask:
    *   `accounts_receivable.py`: Endpoints de Contas a Receber.
    *   `auth.py`: Endpoints de autentica√ß√£o (`/login`, `/logout`, `/verify`). O endpoint de login chama o `AuthService`.
    *   `customer_panel.py`: Endpoints do painel do cliente.
    *   `fabrics.py`: Endpoint para consulta de tecidos.
    *   `fiscal.py`: Endpoints para o m√≥dulo Fiscal.
    *   `observations.py`: Endpoints para gerenciamento de observa√ß√µes. Chamam o `ObservationService` e convertem os objetos ORM `Observation` retornados em JSON usando `.to_dict()`.
    *   `products.py`: Endpoints para produtos acabados.
    *   `users.py`: Endpoints para gerenciamento de usu√°rios (CRUD). Chamam diretamente os m√©todos do `UserRepository` (obtendo a sess√£o via `get_db_session` dentro da rota) ou o `AuthService`. Convertem os objetos ORM `User` em JSON usando `.to_dict()`.
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Definir os endpoints da API usando Flask Blueprints.
*   Receber requisi√ß√µes HTTP, validar e extrair dados.
*   Utilizar os decoradores de `decorators.py` para autentica√ß√£o/autoriza√ß√£o.
*   Chamar os m√©todos apropriados na camada de servi√ßo (`src/services`). **A camada da API n√£o gerencia mais diretamente as sess√µes de banco de dados; isso √© feito pelos servi√ßos que precisam delas.**
*   Receber os resultados (dados brutos, objetos ORM, Dataclasses) ou exce√ß√µes da camada de servi√ßo.
*   Formatar os resultados em respostas JSON. Para objetos ORM, utiliza o m√©todo `.to_dict()` do objeto antes de serializar.
*   Utilizar os manipuladores de erro de `errors.py` para respostas de erro consistentes.
*   Interagir com o contexto da aplica√ß√£o Flask (`current_app`, `request`, `session`).

## Fluxo de Requisi√ß√£o T√≠pico (com ORM)

1.  Requisi√ß√£o HTTP chega ao Flask.
2.  Flask roteia para o endpoint correspondente.
3.  Decoradores (`@login_required`, etc.) s√£o executados. `@login_required` chama `AuthService.get_current_user_from_request()`, que usa `get_db_session()` para buscar o usu√°rio no banco via `UserRepository`. Se ok, `request.current_user` √© populado com o objeto `User` ORM. Se falhar, erro 401/403 √© retornado.
4.  A fun√ß√£o do endpoint √© executada.
5.  A fun√ß√£o extrai dados da `request`.
6.  A fun√ß√£o chama o m√©todo do servi√ßo apropriado (ex: `ObservationService.add_observation`).
7.  O servi√ßo executa a l√≥gica:
    *   Se precisar do banco, ele usa `with get_db_session() as db:`.
    *   Obt√©m o reposit√≥rio necess√°rio (ex: `self.observation_repository`).
    *   Chama o m√©todo do reposit√≥rio, **passando a sess√£o `db`**.
    *   O reposit√≥rio interage com o banco usando a sess√£o ORM.
    *   Se precisar do ERP, chama o servi√ßo de integra√ß√£o ERP correspondente.
8.  O servi√ßo retorna dados (podem ser objetos ORM, Dataclasses, dicts) ou lan√ßa uma exce√ß√£o. A sess√£o do banco √© commitada/revertida/fechada pelo `get_db_session()`.
9.  Se o servi√ßo retornar dados:
    *   Se forem objetos ORM, a fun√ß√£o do endpoint chama `.to_dict()` neles.
    *   Os dados (agora dicion√°rios/listas) s√£o formatados em JSON e retornados com status 2xx.
10. Se o servi√ßo lan√ßar uma exce√ß√£o, o manipulador de erro correspondente em `errors.py` captura e retorna a resposta JSON apropriada (4xx ou 5xx).
11. Se ocorrer uma exce√ß√£o inesperada, o manipulador gen√©rico em `errors.py` captura, loga e retorna 500.
</file>

<file path="src/api/routes/__init__.py">
# src/api/routes/__init__.py
# Makes 'routes' a sub-package of 'api'.
</file>

<file path="src/api/routes/accounts_receivable.py">
# src/api/routes/accounts_receivable.py
# Defines API endpoints for the Accounts Receivable module.

from flask import Blueprint, request, jsonify, current_app, Response
from src.services.accounts_receivable_service import AccountsReceivableService
from src.api.decorators import login_required, accounts_receivable_access_required # Use new decorator
from src.api.errors import ApiError, ErpIntegrationError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger
from src.config import config

accounts_receivable_bp = Blueprint('accounts_receivable', __name__)

# Helper to get Service instance
def _get_ar_service() -> AccountsReceivableService:
    service = current_app.config.get('accounts_receivable_service')
    if not service:
        logger.critical("AccountsReceivableService not found in application config!")
        raise ServiceError("Accounts Receivable service is unavailable.", 503)
    return service

@accounts_receivable_bp.route('/search', methods=['POST'])
@login_required
@accounts_receivable_access_required # Apply permission check
def search_receivables():
    """
    Searches for accounts receivable documents based on provided filters.
    Handles pagination and customer name enrichment.
    ---
    tags: [Accounts Receivable]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      description: JSON payload containing filters, pagination, order, and expand options.
      content:
        application/json:
          schema:
            # Ideally reference the DocumentRequestModel schema defined elsewhere
            # For now, define structure inline or reference external file if using swagger gen
            type: object
            properties:
              filter:
                type: object
                description: "Object containing various filter fields (see DocumentFilterModel)."
                # Add example filter properties here if needed
                example: {"customerCpfCnpjList": ["11122233300"], "startExpiredDate": "2023-01-01"}
              expand:
                type: string
                description: "Comma-separated list of fields to expand (e.g., 'check,invoice,commissioneds,calculateValue'). 'calculateValue' and 'invoice' are implicitly added if needed."
                example: "check,commissions"
              order:
                type: string
                description: "Comma-separated list for ordering (e.g., '-expiredDate,receivableCode')."
                example: "-expiredDate"
              page:
                type: integer
                description: "Page number (default: 1)"
                default: 1
              pageSize:
                type: integer
                description: "Items per page (default/max: 100)"
                default: 100
    responses:
      200:
        description: List of receivable documents found with pagination info.
        content:
          application/json:
            schema:
              type: object
              properties:
                items:
                  type: array
                  items:
                    # Define schema for FormattedReceivableListItem
                    type: object
                    properties:
                      customer_code: { type: integer, nullable: true }
                      customer_cpf_cnpj: { type: string, nullable: true }
                      customer_name: { type: string, nullable: true }
                      invoice_number: { type: integer, nullable: true }
                      document_number: { type: integer, nullable: true } # receivableCode
                      installment_number: { type: integer, nullable: true }
                      bearer_name: { type: string, nullable: true }
                      issue_date: { type: string, format: "date-time", nullable: true }
                      expired_date: { type: string, format: "date-time", nullable: true }
                      days_late: { type: integer, nullable: true }
                      payment_date: { type: string, format: "date-time", nullable: true }
                      value_original: { type: number, format: "float", nullable: true }
                      value_increase: { type: number, format: "float", nullable: true }
                      value_rebate: { type: number, format: "float", nullable: true }
                      value_paid: { type: number, format: "float", nullable: true }
                      value_corrected: { type: number, format: "float", nullable: true }
                      status: { type: integer, nullable: true, description: "1=Normal, 2=Devolvido, 3=Cancelado, 4=Quebrada" }
                      document_type: { type: integer, nullable: true, description: "e.g., 1=Fatura, 2=Cheque..." }
                      billing_type: { type: integer, nullable: true, description: "e.g., 1=Venda Vista, 2=Venda Prazo..." }
                      discharge_type: { type: integer, nullable: true, description: "e.g., 0=N√£o Baixado, 1=Via Recebimento..." }
                      charge_type: { type: integer, nullable: true, description: "e.g., 0=N√£o Cobran√ßa, 1=Simples..." }
                page: { type: integer }
                pageSize: { type: integer }
                totalItems: { type: integer }
                totalPages: { type: integer }
                hasNext: { type: boolean }
      400:
        description: Bad request (Invalid JSON, invalid filters or parameters).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      500:
        description: Internal server error or ERP integration error.
      503:
        description: Service unavailable.
    """
    logger.info("Search accounts receivable request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
        return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Extract filters and pagination
    raw_filters = data.get('filter')
    expand = data.get('expand')
    order = data.get('order')
    try:
        page = int(data.get('page', 1))
        page_size = int(data.get('pageSize', 100)) # Use AR page size limit
    except (ValueError, TypeError):
         return jsonify({"error": "Invalid page or pageSize parameters. Must be integers."}), 400

    try:
        service = _get_ar_service()
        result = service.search_receivables(raw_filters, page, page_size, expand, order)
        return jsonify(result), 200

    except ValidationError as e:
        logger.warning(f"Validation error searching receivables: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Not found error searching receivables: {e}")
        # Return 200 with empty list for search not found? Or 404?
        # Let's follow existing pattern and maybe return 200 OK with empty data for search misses
        return jsonify({ "items": [], "page": page, "pageSize": page_size, "totalItems": 0, "totalPages": 0, "hasNext": False }), 200
        # return jsonify({"error": str(e)}), 404 # Alternative: return 404
    except ServiceError as e:
        logger.error(f"Service error searching receivables: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except ApiError as e: # Catch other specific API errors if needed
        logger.error(f"API error searching receivables: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error searching receivables: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while searching receivables."}), 500


@accounts_receivable_bp.route('/boleto', methods=['POST'])
@login_required
@accounts_receivable_access_required # Apply permission check
def generate_boleto():
    """
    Generates and returns the Bank Slip (Boleto) PDF for a specific installment.
    ---
    tags: [Accounts Receivable]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            # Reference BankSlipRequestModel schema
            type: object
            properties:
              branchCode:
                type: integer
                description: "C√≥digo da empresa (max 4)."
                example: 1
              customerCode:
                type: integer
                description: "C√≥digo do cliente (max 9)."
                example: 12345
              customerCpfCnpj:
                type: string
                description: "CPF/CNPJ do cliente (alternativa a customerCode)."
                example: "11122233300"
              receivableCode:
                type: integer
                format: int64 # As per swagger
                description: "C√≥digo da fatura (max 10)."
                example: 98765
              installmentNumber:
                type: integer
                description: "N√∫mero da parcela (max 3)."
                example: 1
            required: [branchCode, customerCode, receivableCode, installmentNumber]
    responses:
      200:
        description: Boleto PDF content.
        content:
          application/pdf:
            schema:
              type: string
              format: binary
      400:
        description: Bad request (Invalid JSON, missing required fields, validation error).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      404:
        description: Boleto could not be generated (e.g., installment not found or not eligible).
      500:
        description: Internal server error or ERP integration error.
      502:
        description: Error communicating with ERP during Boleto generation.
      503:
        description: Service unavailable.
    """
    logger.info("Generate boleto request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
        return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Basic check for required fields
    required = ['branchCode', 'customerCode', 'receivableCode', 'installmentNumber']
    if not all(field in data for field in required):
         missing = [field for field in required if field not in data]
         return jsonify({"error": f"Missing required fields: {', '.join(missing)}"}), 400

    try:
        service = _get_ar_service()
        pdf_bytes = service.generate_boleto_pdf(data)

        doc_num = data.get('receivableCode', 'unknown')
        inst_num = data.get('installmentNumber', 'unknown')
        filename = f"boleto_{doc_num}_{inst_num}.pdf"

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'inline; filename="{filename}"'
            }
        )

    except ValidationError as e:
        logger.warning(f"Validation error generating boleto: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Boleto generation failed - Not Found: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error generating boleto: {e.message}", exc_info=True if e.status_code >= 500 else False)
        status_code = e.status_code
        # Check if underlying cause was ERP specific status code
        if isinstance(e.__cause__, ErpIntegrationError) and hasattr(e.__cause__, 'status_code'):
             status_code = e.__cause__.status_code # Use original ERP status if available
        return jsonify({"error": e.message}), status_code
    except ApiError as e: # Catch other specific API errors if needed
        logger.error(f"API error generating boleto: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error generating boleto: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while generating the boleto."}), 500
</file>

<file path="src/api/routes/auth.py">
# src/api/routes/auth.py
# Defines API endpoints related to user authentication and session management.

from flask import Blueprint, request, jsonify, current_app, session
from src.services.auth_service import AuthService # Import the specific service
from src.api.decorators import login_required # Import decorators
from src.api.errors import AuthenticationError, ApiError # Import custom errors
from src.utils.logger import logger

auth_bp = Blueprint('auth', __name__)

# Helper to get auth_service instance from app context
def _get_auth_service() -> AuthService:
     service = current_app.config.get('auth_service')
     if not service:
          logger.critical("AuthService not found in application config!")
          raise ApiError("Authentication service is unavailable.", 503)
     return service

@auth_bp.route('/login', methods=['POST'])
def login():
    """
    Endpoint for user login. Expects JSON payload with 'username' and 'password'.
    Sets a token in the session and returns user info upon success.
    ---
    tags: [Authentication]
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              username:
                type: string
                example: "testuser"
              password:
                type: string
                example: "password123"
            required: [username, password]
    responses:
      200:
        description: Login successful
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Login successful"
                token:
                  type: string
                  description: JWT token (also set in session cookie)
                user:
                  type: object
                  # Define user object structure here based on User.to_dict()
                  example: {"id": 1, "username": "testuser", "name": "Test User", "email": "test@example.com", "is_active": true, "permissions": {"is_admin": false, ...}}
      400:
        description: Bad request (missing fields or invalid JSON)
      401:
        description: Authentication failed (invalid credentials or inactive user)
      500:
        description: Internal server error
    """
    logger.info("Login request received.")
    if not request.is_json:
        logger.warning("Login failed: Request is not JSON.")
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    username = data.get('username')
    password = data.get('password')

    if not username or not password:
        logger.warning("Login failed: Missing username or password.")
        return jsonify({"error": "Username and password are required"}), 400

    try:
        auth_service = _get_auth_service()
        token, user_data = auth_service.login(username, password)
        logger.info(f"User '{username}' logged in successfully.")
        # Token is set in session by the service, return it in response body too
        return jsonify({
            "message": "Login successful",
            "token": token,
            "user": user_data
        }), 200
    except AuthenticationError as e:
        logger.warning(f"Login failed for '{username}': {e}")
        return jsonify({"error": str(e)}), 401
    except ApiError as e: # Catch specific internal errors if needed
         logger.error(f"API error during login for '{username}': {e.message}", exc_info=True)
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error during login for '{username}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred during login."}), 500


@auth_bp.route('/logout', methods=['POST'])
@login_required # Ensure user is logged in to log out
def logout():
    """
    Endpoint for user logout. Clears the session token.
    ---
    tags: [Authentication]
    security:
      - bearerAuth: [] # Indicate JWT Bearer token is expected
    responses:
      200:
        description: Logout successful
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Logout successful"
      401:
        description: Unauthorized (not logged in)
      500:
        description: Internal server error
    """
    logger.info(f"Logout request received for user: {getattr(request, 'current_user', 'Unknown')}")
    try:
        auth_service = _get_auth_service()
        auth_service.logout()
        return jsonify({"message": "Logout successful"}), 200
    except Exception as e:
        logger.error(f"Error during logout: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred during logout."}), 500


@auth_bp.route('/verify', methods=['GET'])
@login_required # Uses the decorator to handle token verification
def verify_token():
    """
    Endpoint to verify the current user's token (passed via header or session).
    Returns current user information if the token is valid.
    Implicitly tested by the @login_required decorator.
    ---
    tags: [Authentication]
    security:
      - bearerAuth: []
    responses:
      200:
        description: Token is valid
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Token is valid"
                user:
                  type: object
                  # Define user object structure here
                  example: {"id": 1, "username": "testuser", ...}
      401:
        description: Unauthorized (invalid or expired token)
      500:
        description: Internal server error
    """
    # If @login_required passes, the token is valid and request.current_user is set.
    try:
        user = request.current_user # Access user set by decorator
        logger.info(f"Token verified for user: {user.username} (ID: {user.id})")
        # Return user data (ensure sensitive info like password hash is excluded)
        user_data = user.to_dict(include_hash=False)
        return jsonify({
            "message": "Token is valid",
            "user": user_data
        }), 200
    except AttributeError:
         # Should not happen if decorator works, but handle defensively
         logger.error("request.current_user not set after @login_required passed!")
         return jsonify({"error": "Internal server error during token verification."}), 500
    except Exception as e:
         logger.error(f"Unexpected error during token verification: {e}", exc_info=True)
         return jsonify({"error": "An internal server error occurred during verification."}), 500
</file>

<file path="src/api/routes/customer_panel.py">
# src/api/routes/customer_panel.py (Continued)
# Defines API endpoints for accessing customer data and statistics.

from flask import Blueprint, request, jsonify, current_app
from src.services.customer_service import CustomerService # Import the specific service
from src.erp_integration.erp_person_service import ErpPersonService # Needed to instantiate service
from src.erp_integration import erp_auth_service # Need auth for ERP service
from src.api.decorators import login_required, customer_panel_access_required # Import decorators
from src.api.errors import ApiError, NotFoundError, ValidationError # Import custom errors
from src.utils.logger import logger

customer_panel_bp = Blueprint('customer_panel', __name__)

# Helper function to instantiate or get the CustomerService
# This could be improved with a proper dependency injection framework later
def _get_customer_service() -> CustomerService:
     erp_person_svc = ErpPersonService(erp_auth_service) # Use singleton ERP auth
     # Simple instantiation:
     return CustomerService(erp_person_svc)

@customer_panel_bp.route('/data', methods=['POST'])
@login_required
@customer_panel_access_required
def get_customer_data():
    """
    Fetches customer master data (Individual or Legal Entity) based on search criteria.
    ---
    tags: [Customer Panel]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              search_term:
                type: string
                description: "Customer Code, CPF (11 digits), or CNPJ (14 digits)"
                example: "12345"
              search_type:
                type: string
                description: "'PF' or 'PJ'. Required only if search_term is a Customer Code."
                example: "PF"
            required: [search_term]
    responses:
      200:
        description: Customer data found
        content:
          application/json:
            schema:
              # Define schema based on CustomerService._format_customer_data output
              type: object
              properties:
                 customer_type: {type: string, enum: [PF, PJ]}
                 code: {type: integer}
                 name: {type: string, description: "Name (PF) or Legal Name (PJ)"}
                 # ... other common and specific fields ...
      400:
        description: Bad request (Invalid JSON, missing fields, invalid search term format)
      401:
        description: Unauthorized
      403:
        description: Forbidden (User lacks permission)
      404:
        description: Customer not found
      500:
        description: Internal server error or ERP integration error
    """
    logger.info("Customer data request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    search_term = data.get('search_term')
    search_type = data.get('search_type') # Optional

    if not search_term:
        return jsonify({"error": "Field 'search_term' is required"}), 400

    try:
        customer_service = _get_customer_service()
        customer_details = customer_service.get_customer_details(str(search_term).strip(), search_type)
        return jsonify(customer_details), 200

    except ValidationError as e:
        logger.warning(f"Validation error fetching customer data: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Customer not found for search term '{search_term}': {e}")
        return jsonify({"error": str(e)}), 404
    except ApiError as e: # Catch specific internal/ERP errors
         logger.error(f"API error fetching customer data for '{search_term}': {e.message}", exc_info=False) # Don't need full stack for known API errors
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching customer data for '{search_term}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@customer_panel_bp.route('/statistics', methods=['GET'])
@login_required
@customer_panel_access_required
def get_customer_statistics():
    """
    Fetches financial statistics for a given customer code.
    ---
    tags: [Customer Panel]
    security:
      - bearerAuth: []
    parameters:
      - in: query
        name: customer_code
        schema:
          type: integer
        required: true
        description: The code of the customer.
    responses:
      200:
        description: Customer statistics found
        content:
          application/json:
            schema:
              # Define schema based on CustomerService._format_statistics output
              type: object
              properties:
                 average_delay_days: {type: integer, nullable: true}
                 # ... other statistics fields ...
      400:
        description: Bad request (Missing or invalid customer_code)
      401:
        description: Unauthorized
      403:
        description: Forbidden (User lacks permission)
      404:
        description: Statistics not found for the customer
      500:
        description: Internal server error or ERP integration error
    """
    logger.info("Customer statistics request received.")
    customer_code_str = request.args.get('customer_code')

    if not customer_code_str:
        return jsonify({"error": "Query parameter 'customer_code' is required"}), 400

    try:
        customer_code = int(customer_code_str)
    except (ValueError, TypeError):
        return jsonify({"error": "Query parameter 'customer_code' must be an integer"}), 400

    try:
        # Get current user details for permission checks/logic if needed
        current_user = request.current_user # Set by @login_required
        is_admin = current_user.permissions.is_admin if current_user and current_user.permissions else False

        customer_service = _get_customer_service()
        statistics = customer_service.get_customer_statistics(customer_code, is_admin)
        return jsonify(statistics), 200

    except NotFoundError as e:
        logger.warning(f"Statistics not found for customer code {customer_code}: {e}")
        return jsonify({"error": str(e)}), 404
    except ApiError as e: # Catch specific internal/ERP errors
         logger.error(f"API error fetching statistics for customer {customer_code}: {e.message}", exc_info=False)
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching statistics for customer {customer_code}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500
</file>

<file path="src/api/routes/fabrics.py">
# src/api/routes/fabrics.py
# Routes related to fabric information.

from flask import Blueprint, request, jsonify, current_app
from src.services.fabric_service import FabricService
from src.services.auth_service import AuthService
from src.api.decorators import login_required, fabrics_access_required
from src.api.errors import ApiError, NotFoundError, ServiceError
from src.utils.logger import logger

# --- Get Service Instances ---
# Helper functions to get services from app context
def _get_fabric_service() -> FabricService:
    service = current_app.config.get('fabric_service')
    if not service:
        logger.critical("FabricService not found in application config!")
        raise ServiceError("Fabric service is unavailable.", 503)
    return service

# --- Blueprint Definition ---
fabrics_bp = Blueprint('fabrics', __name__)

# --- Routes ---

@fabrics_bp.route('/balances', methods=['POST'])
@login_required
@fabrics_access_required
def get_fabric_balances():
    """
    Endpoint to get fabric balances, costs, and details.
    Accepts optional 'filter' and 'force_refresh' in JSON body.
    ---
    tags:
      - Fabrics
    security:
      - bearerAuth: []
    parameters:
      - in: body
        name: body
        schema:
          type: object
          properties:
            filter:
              type: string
              description: Optional text to filter fabrics by description/code (client-side).
              example: "JEANS"
            force_refresh:
              type: boolean
              description: If true, bypasses the cache and fetches fresh data.
              example: false
    responses:
      200:
        description: List of fabrics with balance, cost, and details.
        schema:
          type: object
          properties:
            fabrics:
              type: array
              items:
                type: object
                properties:
                  code:
                    type: integer
                  description:
                    type: string
                  balance:
                    type: integer
                  cost:
                    type: number
                    format: float
                    nullable: true
                  width:
                    type: number
                    format: float
                    nullable: true
                  grammage:
                    type: number
                    format: float
                    nullable: true
                  shrinkage:
                    type: number
                    format: float
                    nullable: true
            total_items:
               type: integer
      400:
        description: Invalid input.
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      404:
        description: No fabrics found.
      500:
        description: Internal server error or error fetching data from ERP.
      503:
        description: Service unavailable.
    """
    logger.info("Fabric balances request received.")
    data = request.get_json() or {}
    search_filter = data.get('filter')
    force_refresh = data.get('force_refresh', False)

    try:
        fabric_service = _get_fabric_service()
        fabric_list = fabric_service.get_fabrics(
            search_filter=search_filter,
            force_refresh=force_refresh
        )

        logger.info(f"Returning {len(fabric_list)} fabrics.")
        # Structure the response as expected by the frontend service
        return jsonify({
            "fabrics": fabric_list,
            "total_items": len(fabric_list) # Total items *after* filtering
        }), 200

    except NotFoundError as e:
        logger.warning(f"Fabric fetch failed: {e}")
        return jsonify({"error": str(e)}), 404
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error fetching fabrics: {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching fabrics: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred."}), 500


@fabrics_bp.route('/cache/clear', methods=['POST'])
@login_required
@fabrics_access_required # Or maybe admin_required? Check requirements.
def clear_fabric_cache():
    """
    Endpoint to manually clear the fabric data cache.
    ---
    tags:
      - Fabrics
    security:
      - bearerAuth: []
    responses:
      200:
        description: Cache cleared successfully.
        schema:
          type: object
          properties:
            message:
              type: string
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      500:
        description: Internal server error.
      503:
        description: Service unavailable.
    """
    logger.info(f"Request received to clear fabric cache by user '{request.current_user.username}'.")
    try:
        fabric_service = _get_fabric_service()
        fabric_service.clear_fabric_cache()
        return jsonify({"message": "Cache de tecidos limpo com sucesso."}), 200
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error clearing fabric cache: {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error clearing fabric cache: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while clearing the cache."}), 500

# --- Service Instantiation (Done in app factory) ---
# You need to ensure FabricService is instantiated and added to app.config['fabric_service']
# in src/app.py, similar to how auth_service is done.
</file>

<file path="src/api/routes/fiscal.py">
# src/api/routes/fiscal.py
# Defines API endpoints for the Fiscal module.

from typing import Any, Dict
from flask import Blueprint, request, jsonify, current_app, Response
import base64
from src.services.fiscal_service import FiscalService
from src.api.decorators import login_required, fiscal_access_required
from src.api.errors import ApiError, ErpIntegrationError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger
from src.config import config # For default fiscal page size

fiscal_bp = Blueprint('fiscal', __name__)

# Helper to get FiscalService instance
def _get_fiscal_service() -> FiscalService:
    service = current_app.config.get('fiscal_service')
    if not service:
        logger.critical("FiscalService not found in application config!")
        raise ServiceError("Fiscal service is unavailable.", 503)
    return service

@fiscal_bp.route('/invoices/search', methods=['POST'])
@login_required
@fiscal_access_required
def search_fiscal_invoices():
    """
    Searches for fiscal invoices based on provided filters.
    Handles pagination.
    ---
    tags: [Fiscal]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              page:
                type: integer
                description: "Page number (default: 1)"
                default: 1
              pageSize:
                type: integer
                description: f"Items per page (default: {config.FISCAL_PAGE_SIZE}, max: 100)"
                default: config.FISCAL_PAGE_SIZE
              # <<<--- MODIFIED: Use a single field for customer input --- >>>
              customer_code_cpf_cnpj:
                type: string
                description: "Customer Code, CPF (11 digits), or CNPJ (14 digits). Can be comma-separated for multiple values (only for codes or only for CPF/CNPJ, not mixed)."
                example: "389" # or "11122233344,55566677788899"
              # ----------------------------------------------------------
              invoice_number:
                type: string
                description: "Single number, comma-separated list, or range (e.g., 100-150)."
                example: "1001,1005"
              start_date:
                type: string
                format: date-time
                description: "Start issue date (ISO 8601 format, e.g., YYYY-MM-DD or YYYY-MM-DDTHH:mm:ss)."
                example: "2023-10-01"
              end_date:
                type: string
                format: date-time
                description: "End issue date (ISO 8601 format)."
                example: "2023-10-31T23:59:59"
              status:
                type: string
                description: "Comma-separated list of statuses (e.g., Authorized, Canceled)."
                example: "Authorized"
    responses:
      200:
        description: List of invoices found with pagination info.
        content:
          application/json:
            schema:
              type: object
              properties:
                items:
                  type: array
                  items:
                     $ref: '#/components/schemas/FormattedInvoiceListItem'
                page: { type: integer }
                pageSize: { type: integer }
                totalItems: { type: integer }
                totalPages: { type: integer }
      400:
        description: Bad request (Invalid filters or parameters).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      500:
        description: Internal server error or ERP integration error.
      503:
        description: Service unavailable.
    """
    logger.info("Search fiscal invoices request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
         return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Extract filters from request data
    filters = {}
    customer_input = data.get("customer_code_cpf_cnpj")
    invoice_number_input = data.get("invoice_number")
    start_date_input = data.get("start_date")
    end_date_input = data.get("end_date")
    status_input = data.get("status")

    # --- START: Intelligent Customer Filter Mapping ---
    if customer_input:
        customer_input_str = str(customer_input).strip()
        # Basic check: if it contains only digits and maybe commas
        is_potentially_numeric = all(c.isdigit() or c == ',' for c in customer_input_str.replace(" ", ""))

        if is_potentially_numeric:
             # Check length characteristics to distinguish code/list-of-codes from CPF/CNPJ
             codes = [c.strip() for c in customer_input_str.split(',') if c.strip()]
             # Heuristic: Assume codes are shorter than 11 digits, CPF/CNPJ are 11 or 14
             if all(len(code) < 11 for code in codes):
                 logger.debug(f"Treating customer input '{customer_input_str}' as customer_code")
                 filters["customer_code"] = customer_input_str # Pass comma-separated string to service
             elif all(len(code) == 11 or len(code) == 14 for code in codes):
                 logger.debug(f"Treating customer input '{customer_input_str}' as customer_cpf_cnpj")
                 filters["customer_cpf_cnpj"] = customer_input_str # Pass comma-separated string to service
             else:
                 # Ambiguous or mixed format
                 logger.warning(f"Ambiguous customer input format: '{customer_input_str}'. Could not determine if code(s) or CPF/CNPJ(s).")
                 # Return error or try one? Let's return an error for clarity.
                 return jsonify({"error": "Invalid format for 'customer_code_cpf_cnpj'. Provide only code(s) or only CPF/CNPJ(s), not mixed or invalid lengths."}), 400
        else:
             # Contains non-digits (excluding comma/space), definitely not code/CPF/CNPJ
             return jsonify({"error": "Invalid characters found in 'customer_code_cpf_cnpj'."}), 400
    # --- END: Intelligent Customer Filter Mapping ---


    # Add other filters if they exist
    if invoice_number_input:
        filters["invoice_number"] = invoice_number_input
    if start_date_input:
        filters["start_date"] = start_date_input
    if end_date_input:
        filters["end_date"] = end_date_input
    if status_input:
        filters["status"] = status_input

    # Extract pagination parameters with validation
    try:
        page = int(data.get('page', 1))
        page_size = int(data.get('pageSize', config.FISCAL_PAGE_SIZE))

        if page < 1:
            page = 1
        if page_size < 1:
            page_size = config.FISCAL_PAGE_SIZE # Fallback to default
        # Service layer will clamp page_size if > 100

    except (ValueError, TypeError):
         logger.warning(f"Invalid pagination parameters received: page={data.get('page')}, pageSize={data.get('pageSize')}")
         return jsonify({"error": "Invalid page or pageSize parameters. Must be integers."}), 400

    try:
        fiscal_service = _get_fiscal_service()
        # Pass the filters dict (now containing the *correct* key based on input)
        result: Dict[str, Any] = fiscal_service.search_invoices(filters, page, page_size)
        return jsonify(result), 200

    except ValidationError as e:
        logger.warning(f"Validation error searching invoices: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Unexpected NotFoundError during invoice search: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error searching invoices: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except ApiError as e:
        logger.error(f"API error searching invoices: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error searching invoices: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while searching invoices."}), 500


@fiscal_bp.route('/danfe/<string:access_key>', methods=['GET'])
@login_required
@fiscal_access_required
def generate_danfe(access_key: str):
    """
    Generates and returns the DANFE PDF for a given invoice access key.
    ---
    tags: [Fiscal]
    security:
      - bearerAuth: []
    parameters:
      - in: path
        name: access_key
        schema:
          type: string
          pattern: '^\d{44}$' # Regex for 44 digits
        required: true
        description: The 44-digit access key of the NF-e.
    responses:
      200:
        description: DANFE PDF content.
        content:
          application/pdf:
            schema:
              type: string
              format: binary
      400:
        description: Bad request (Invalid access key format).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      404:
        description: Invoice or DANFE not found for the given access key.
      500:
        description: Internal server error or ERP integration error.
      502:
        description: Error communicating with ERP during DANFE generation.
      503:
        description: Service unavailable.
    """
    logger.info(f"Generate DANFE request received for access key: ...{access_key[-6:]}")

    try:
        fiscal_service = _get_fiscal_service()
        pdf_bytes = fiscal_service.generate_danfe_pdf(access_key)

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'inline; filename="danfe_{access_key}.pdf"'
            }
        )

    except ValidationError as e:
        logger.warning(f"Validation error generating DANFE for key ...{access_key[-6:]}: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"DANFE/XML not found for key ...{access_key[-6:]}: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error generating DANFE for key ...{access_key[-6:]}: {e.message}", exc_info=True if e.status_code >= 500 else False)
        status_code = e.status_code if hasattr(e, 'status_code') and e.status_code else 500
        if isinstance(e.__cause__, ErpIntegrationError) and hasattr(e.__cause__, 'status_code'):
             status_code = e.__cause__.status_code
        return jsonify({"error": e.message}), status_code
    except ApiError as e:
        logger.error(f"API error generating DANFE: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error generating DANFE for key ...{access_key[-6:]}: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while generating the DANFE."}), 500


# Define Schema for OpenAPI (ensure it matches FormattedInvoiceListItem)
components = {
    "schemas": {
        "FormattedInvoiceListItem": {
            "type": "object",
            "properties": {
                "status": {"type": "string", "nullable": True},
                "recipient_name": {"type": "string", "nullable": True},
                "sales_order_code": {"type": "integer", "nullable": True},
                "invoice_number": {"type": "integer", "nullable": True},
                "invoice_series": {"type": "string", "nullable": True},
                "issue_date": {"type": "string", "format": "date-time", "nullable": True},
                "total_value": {"type": "number", "format": "float", "nullable": True},
                "total_quantity": {"type": "number", "format": "float", "nullable": True},
                "operation_name": {"type": "string", "nullable": True},
                "shipping_company_name": {"type": "string", "nullable": True},
                "access_key": {"type": "string", "nullable": True, "maxLength": 44, "minLength": 44}
            }
        }
    }
}
</file>

<file path="src/api/routes/observations.py">
# src/api/routes/observations.py
# Defines API endpoints for managing product observations using ORM.

from flask import Blueprint, request, jsonify, current_app

# Import Service
from src.services.observation_service import ObservationService

# Import ORM Model (apenas para type hints se necess√°rio, servi√ßo retorna ORM)
# from src.domain.observation import Observation

from src.api.decorators import login_required, products_access_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ForbiddenError, ServiceError, DatabaseError
from src.utils.logger import logger

observations_bp = Blueprint('observations', __name__)

# Helper para obter ObservationService
def _get_observation_service() -> ObservationService:
     service = current_app.config.get('observation_service')
     if not service:
          # Idealmente, a inje√ß√£o deve ser garantida no create_app
          logger.critical("ObservationService not found in application config!")
          raise ServiceError("Observation service is unavailable.", 503) # Usar ServiceError
     return service

@observations_bp.route('/product/<string:reference_code>', methods=['POST'])
@login_required
@products_access_required
def add_product_observation(reference_code: str):
    """Adds a new observation for a specific product reference code."""
    logger.info(f"Add observation request for reference: {reference_code}")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    observation_text = data.get('observation_text')

    if not observation_text:
        return jsonify({"error": "Field 'observation_text' is required"}), 400

    try:
        current_user = request.current_user
        observation_service = _get_observation_service()
        # Servi√ßo agora gerencia a sess√£o internamente
        new_observation = observation_service.add_observation(reference_code, observation_text, current_user)
        # Converter objeto ORM para dict
        return jsonify(new_observation.to_dict()), 201

    except ValidationError as e:
        logger.warning(f"Validation error adding observation for '{reference_code}': {e}")
        return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e: # Capturar erros do servi√ßo/DB
         logger.error(f"Service/DB error adding observation for '{reference_code}': {e}", exc_info=True)
         # Retornar 500 ou status espec√≠fico do ServiceError
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to add observation: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error adding observation for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/product/<string:reference_code>', methods=['GET'])
@login_required
@products_access_required
def get_product_observations(reference_code: str):
    """Retrieves observations for a specific product reference code."""
    logger.info(f"Get observations request for reference: {reference_code}")
    include_resolved_str = request.args.get('include_resolved', 'true').lower()
    include_resolved = include_resolved_str == 'true'

    try:
        observation_service = _get_observation_service()
        # Servi√ßo retorna lista de objetos ORM
        observations = observation_service.get_observations_for_product(reference_code, include_resolved)
        # Converter lista de objetos ORM para lista de dicts
        observations_data = [obs.to_dict() for obs in observations]
        return jsonify(observations_data), 200

    except ValidationError as e:
         logger.warning(f"Validation error getting observations for '{reference_code}': {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting observations for '{reference_code}': {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get observations: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting observations for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/product/<string:reference_code>/unresolved_count', methods=['GET'])
@login_required
@products_access_required
def get_product_unresolved_observations_count(reference_code: str):
    """Retrieves the count of unresolved observations for a specific product reference code."""
    logger.info(f"Get unresolved count request for reference: {reference_code}")
    try:
        observation_service = _get_observation_service()
        count = observation_service.get_unresolved_count(reference_code)
        return jsonify({"reference_code": reference_code, "unresolved_count": count}), 200

    except ValidationError as e:
         logger.warning(f"Validation error getting unresolved count for '{reference_code}': {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting unresolved count for '{reference_code}': {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get unresolved count: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting unresolved count for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/<int:observation_id>/resolve', methods=['PUT'])
@login_required
@products_access_required
def resolve_product_observation(observation_id: int):
    """Marks a specific observation as resolved."""
    logger.info(f"Resolve observation request for ID: {observation_id}")
    try:
        current_user = request.current_user
        observation_service = _get_observation_service()
        success = observation_service.resolve_observation(observation_id, current_user)

        if success:
            return jsonify({"message": f"Observation {observation_id} marked as resolved."}), 200
        else:
             # Servi√ßo pode retornar False se j√° estava resolvido ou n√£o encontrado
             # O servi√ßo agora levanta NotFoundError, ent√£o este 'else' pode indicar 'j√° resolvido'.
             logger.warning(f"Failed to mark observation {observation_id} as resolved (possibly already resolved).")
             # Manter 400 ou talvez um 200 com mensagem diferente? 400 indica que o estado n√£o mudou como pedido.
             return jsonify({"error": f"Observation {observation_id} could not be resolved (it might already be resolved)."}), 400

    except NotFoundError as e:
        logger.warning(f"Cannot resolve observation ID {observation_id}: Not found.")
        return jsonify({"error": str(e)}), 404
    except ValidationError as e:
         logger.warning(f"Validation error resolving observation {observation_id}: {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error resolving observation {observation_id}: {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to resolve observation: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error resolving observation {observation_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/pending_references', methods=['GET'])
@login_required
@products_access_required
def get_pending_references():
    """Retrieves references with pending observations."""
    logger.info("Get pending references request received.")
    try:
        observation_service = _get_observation_service()
        # Servi√ßo retorna lista de dicts j√° formatados pelo reposit√≥rio
        references = observation_service.get_references_with_pending_observations()
        return jsonify(references), 200
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting pending references: {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get pending references: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting pending references: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500
</file>

<file path="src/api/routes/products.py">
# src/api/routes/products.py
# Routes related to finished product information.

from flask import Blueprint, request, jsonify, current_app
from src.services.product_service import ProductService
from src.api.decorators import login_required, products_access_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger

# --- Get Service Instances ---
def _get_product_service() -> ProductService:
    service = current_app.config.get('product_service')
    if not service:
        logger.critical("ProductService not found in application config!")
        raise ServiceError("Product service is unavailable.", 503)
    return service

# --- Blueprint Definition ---
products_bp = Blueprint('products', __name__)

# --- Routes ---

@products_bp.route('/balance_matrix', methods=['POST'])
@login_required
@products_access_required
def get_product_balance_matrix():
    """
    Gets the product balance matrix for a given reference code and calculation mode.
    Also returns the raw product items used to build the matrix.
    ---
    tags:
      - Products
    security:
      - bearerAuth: []
    parameters:
      - in: body
        name: body
        required: true
        schema:
          type: object
          required:
            - reference_code
          properties:
            reference_code:
              type: string
              description: The product reference code.
              example: "1010"
            calculation_mode:
              type: string
              description: Balance calculation mode ('base', 'sales', 'production'). Defaults to 'base'.
              example: "sales"
              enum: ["base", "sales", "production"]
    responses:
      200:
        description: Product balance matrix and raw items.
        schema:
          # Define the expected response structure here (matching ProductService return)
          type: object
          properties:
             reference_code:
               type: string
             calculation_mode:
               type: string
             matrix:
               # Define matrix structure (simplified example)
               type: object
             product_items:
               # Define product items structure (simplified example)
               type: array
               items:
                 type: object
      400:
        description: Invalid input (e.g., missing reference code, invalid mode).
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      404:
        description: Product reference not found.
      500:
        description: Internal server error or error fetching data from ERP.
      503:
        description: Service unavailable.
    """
    data = request.get_json()
    if not data or not data.get('reference_code'):
        return jsonify({"error": "Campo 'reference_code' √© obrigat√≥rio."}), 400

    reference_code = str(data.get('reference_code')).strip().upper()
    calculation_mode = str(data.get('calculation_mode', 'base')).lower()

    logger.info(f"Balance matrix request: Ref={reference_code}, Mode={calculation_mode}")

    try:
        product_service = _get_product_service()
        # Call the updated service method
        result = product_service.get_product_balance_matrix_with_items(reference_code, calculation_mode)
        return jsonify(result), 200

    except (ValidationError, NotFoundError) as e:
        logger.warning(f"Product matrix request failed (Ref: {reference_code}): {e}")
        status = 400 if isinstance(e, ValidationError) else 404
        return jsonify({"error": str(e)}), status
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error fetching product matrix (Ref: {reference_code}): {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching product matrix (Ref: {reference_code}): {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred."}), 500
</file>

<file path="src/api/routes/users.py">
# src/api/routes/users.py
# Defines API endpoints for managing users (CRUD). Requires admin privileges.

from flask import Blueprint, request, jsonify, current_app
from src.domain.user import User, UserPermissions
from src.database.user_repository import UserRepository
from sqlalchemy.orm import Session
from src.database import get_db_session

from src.api.decorators import admin_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ForbiddenError, DatabaseError
from src.utils.logger import logger

from sqlalchemy.exc import SQLAlchemyError

users_bp = Blueprint('users', __name__)

# Helper para obter UserRepository (pode ser movido para um local central se repetido)
def _get_user_repository() -> UserRepository:
      # Tentar obter do contexto da app se injetado (boa pr√°tica)
      repo = current_app.config.get('user_repository')
      if repo:
           return repo
      else:
           # Fallback: criar inst√¢ncia (menos ideal para testes, mas funciona)
           from src.database import get_user_repository as get_repo_func
           logger.warning("UserRepository accessed via factory function in users route.")
           return get_repo_func()

@users_bp.route('', methods=['GET'])
@admin_required
def get_all_users():
    """Retrieves a list of all users. (Admin only)"""
    logger.info("Get all users request received.")
    try:
        # Obter sess√£o e chamar reposit√≥rio
        with get_db_session() as db:
            user_repo = _get_user_repository()
            users = user_repo.get_all(db) # Passar a sess√£o 'db'
        # Converter objetos ORM para dicts
        users_data = [user.to_dict(include_hash=False) for user in users]
        return jsonify({"users": users_data}), 200
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error retrieving all users: {e}", exc_info=True)
          # Usar ApiError ou erro espec√≠fico
          return jsonify({"error": "Failed to retrieve users due to database error."}), 500
    except Exception as e:
        logger.error(f"Error retrieving all users: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while retrieving users."}), 500


@users_bp.route('/<int:user_id>', methods=['GET'])
@admin_required
def get_user_by_id(user_id: int):
    """Retrieves a specific user by their ID. (Admin only)"""
    logger.info(f"Get user by ID request received for ID: {user_id}")
    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            user = user_repo.find_by_id(db, user_id) # Passar a sess√£o
        if not user:
            logger.warning(f"User with ID {user_id} not found.")
            raise NotFoundError(f"User with ID {user_id} not found.")

        # Converter objeto ORM para dict
        return jsonify(user.to_dict(include_hash=False)), 200
    except NotFoundError as e:
        return jsonify({"error": str(e)}), 404
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error retrieving user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error retrieving user."}), 500
    except Exception as e:
        logger.error(f"Error retrieving user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@users_bp.route('', methods=['POST'])
@admin_required
def create_user():
    """Creates a new user with specified permissions. (Admin only)"""
    logger.info("Create user request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()

    required = ['username', 'password', 'name']
    missing = [field for field in required if field not in data or not data[field]]
    if missing:
        logger.warning(f"Create user failed: Missing required fields: {missing}")
        return jsonify({"error": f"Missing required fields: {', '.join(missing)}"}), 400

    try:
        # Criar inst√¢ncia de UserPermissions a partir dos dados da API
        permissions = UserPermissions(
            is_admin=data.get('is_admin', False),
            can_access_products=data.get('can_access_products', False),
            can_access_fabrics=data.get('can_access_fabrics', False),
            can_access_customer_panel=data.get('can_access_customer_panel', False),
            can_access_fiscal=data.get('can_access_fiscal', False),
            can_access_accounts_receivable=data.get('can_access_accounts_receivable', False)
        )

        # Criar inst√¢ncia de User e associar permiss√µes
        user = User(
            username=data['username'],
            name=data['name'],
            email=data.get('email'),
            is_active=data.get('is_active', True),
            permissions=permissions # Associar o objeto de permiss√µes
        )
        # Definir a senha (o m√©todo set_password est√° no modelo User)
        user.set_password(data['password'])
        if not user.password_hash: # Verificar se o hash foi gerado
              raise ValidationError("Failed to process password.")

        # Usar sess√£o para adicionar ao banco
        with get_db_session() as db:
            user_repo = _get_user_repository()
            created_user = user_repo.add(db, user) # Passar sess√£o e objeto User

        logger.info(f"User '{created_user.username}' (ID: {created_user.id}) created successfully.")
        # Converter objeto ORM para dict
        return jsonify(created_user.to_dict(include_hash=False)), 201

    except (ValidationError, ValueError) as e: # Captura erros de valida√ß√£o ou duplicidade
        logger.warning(f"Validation error creating user: {e}")
        return jsonify({"error": str(e)}), 400
    except (DatabaseError, SQLAlchemyError) as e:
         logger.error(f"Database error creating user: {e}", exc_info=True)
         return jsonify({"error": "Database error creating user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error creating user: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while creating user."}), 500


@users_bp.route('/<int:user_id>', methods=['PUT'])
@admin_required
def update_user(user_id: int):
    """Updates an existing user's details and/or permissions. (Admin only)"""
    logger.info(f"Update user request received for ID: {user_id}")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not data:
          return jsonify({"error": "Request body cannot be empty for update."}), 400

    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            # Buscar o usu√°rio existente na sess√£o atual
            user = user_repo.find_by_id(db, user_id)
            if not user:
                raise NotFoundError(f"User with ID {user_id} not found.")

            # Atualizar campos do objeto User (a sess√£o rastreia as mudan√ßas)
            if 'name' in data: user.name = data['name']
            if 'email' in data: user.email = data['email']
            if 'is_active' in data: user.is_active = data['is_active']

            new_password = data.get('password')
            if new_password:
                logger.debug(f"Updating password for user ID: {user_id}")
                user.set_password(new_password)
                if not user.password_hash:
                     raise ValidationError("Failed to process new password.")

            # Atualizar permiss√µes (garantir que o objeto permissions existe)
            if not user.permissions:
                 logger.warning(f"User ID {user_id} found but missing permissions object during update. Creating default.")
                 user.permissions = UserPermissions() # Cria default associado

            # Atualizar campos do objeto UserPermissions
            user.permissions.is_admin = data.get('is_admin', user.permissions.is_admin)
            user.permissions.can_access_products = data.get('can_access_products', user.permissions.can_access_products)
            user.permissions.can_access_fabrics = data.get('can_access_fabrics', user.permissions.can_access_fabrics)
            user.permissions.can_access_customer_panel = data.get('can_access_customer_panel', user.permissions.can_access_customer_panel)
            user.permissions.can_access_fiscal = data.get('can_access_fiscal', user.permissions.can_access_fiscal)
            user.permissions.can_access_accounts_receivable = data.get('can_access_accounts_receivable', user.permissions.can_access_accounts_receivable)

            # Chamar o update do reposit√≥rio (que apenas faz flush opcionalmente)
            # O commit ser√° feito pelo get_db_session
            updated_user = user_repo.update(db, user) # Passa sess√£o e objeto modificado

        logger.info(f"User ID {user_id} update process completed.")
        # Retornar o usu√°rio atualizado convertido para dict
        return jsonify(updated_user.to_dict(include_hash=False)), 200

    except NotFoundError as e:
          return jsonify({"error": str(e)}), 404
    except (ValidationError, ValueError) as e: # Captura valida√ß√£o ou email duplicado
        logger.warning(f"Validation error updating user ID {user_id}: {e}")
        return jsonify({"error": str(e)}), 400
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error updating user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error updating user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error updating user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while updating user."}), 500


@users_bp.route('/<int:user_id>', methods=['DELETE'])
@admin_required
def delete_user(user_id: int):
    """Deletes a user by their ID. (Admin only)"""
    logger.info(f"Delete user request received for ID: {user_id}")
    current_user = request.current_user # Set by @admin_required -> @login_required

    if current_user.id == user_id:
        raise ForbiddenError("Cannot delete your own user account.")

    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            success = user_repo.delete(db, user_id) # Passar sess√£o

        if success:
            logger.info(f"User ID {user_id} deleted successfully.")
            return jsonify({"message": f"User ID {user_id} deleted successfully."}), 200
        else:
            # Se delete retornou False, significa que usu√°rio n√£o foi encontrado
            raise NotFoundError(f"User with ID {user_id} not found for deletion.")

    except ForbiddenError as e:
          return jsonify({"error": str(e)}), 403
    except NotFoundError as e:
        return jsonify({"error": str(e)}), 404
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error deleting user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error deleting user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error deleting user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while deleting user."}), 500
</file>

<file path="src/app.py">
# src/app.py
from flask import Flask, jsonify
from flask_cors import CORS
import atexit
import os
from sqlalchemy.exc import SQLAlchemyError

from src.config import Config
from src.api import register_blueprints
from src.api.errors import register_error_handlers, ConfigurationError, DatabaseError
from src.database import (
    get_db_session,
    init_sqlalchemy,
    dispose_sqlalchemy_engine,
)
from src.utils.logger import logger, configure_logger
from src.utils.system_monitor import start_resource_monitor, stop_resource_monitor

from src.database.user_repository import UserRepository
from src.database.observation_repository import ObservationRepository
from src.database.fiscal_repository import FiscalRepository

from src.services import (
    AuthService,
    CustomerService,
    FabricService,
    ObservationService,
    ProductService,
    FiscalService,
    AccountsReceivableService,
    FiscalSyncService
)
from src.services.fiscal_sync_service import (
    start_fiscal_sync_scheduler,
    stop_fiscal_sync_scheduler
)

from src.erp_integration import (
    erp_auth_service,
    ErpBalanceService,
    ErpCostService,
    ErpPersonService,
    ErpProductService,
    ErpFiscalService,
    ErpAccountsReceivableService
)

def create_app(config_object: Config) -> Flask:
    """
    Factory function to create and configure the Flask application with SQLAlchemy.

    Args:
        config_object: The configuration object for the application.

    Returns:
        The configured Flask application instance.
    """
    app = Flask("Connector-Backend")
    app.config.from_object(config_object)

    # --- Logging ---
    configure_logger(config_object.LOG_LEVEL)
    logger.info("Iniciando a aplica√ß√£o Flask para o Connector-Backend.")
    logger.info(f"Nome da aplica√ß√£o: {app.name}")
    logger.info(f"Modo de depura√ß√£o: {app.config.get('APP_DEBUG')}")

    # --- Secret Key Check ---
    if not app.config.get('SECRET_KEY') or app.config.get('SECRET_KEY') == 'default_secret_key_change_me_in_env':
            logger.critical("ALERTA CR√çTICO DE SEGURAN√áA: SECRET_KEY n√£o est√° definida ou est√° usando o valor padr√£o!")
            if not app.config.get('APP_DEBUG', False):
                raise ConfigurationError("SECRET_KEY deve ser configurada com um valor seguro e √∫nico em produ√ß√£o.")
            else:
                logger.warning("Usando SECRET_KEY padr√£o/insegura no modo de depura√ß√£o.")

    # --- CORS Configuration ---
    CORS(app, supports_credentials=True, resources={r"/api/*": {"origins": "*"}})
    logger.info("CORS configurado para permitir todas as origens (Atualizar para produ√ß√£o).")

    # --- Database Initialization (SQLAlchemy) ---
    db_engine = None
    try:
        db_uri = app.config.get('SQLALCHEMY_DATABASE_URI')
        if not db_uri:
             raise ConfigurationError("SQLALCHEMY_DATABASE_URI n√£o est√° configurado.")

        db_engine = init_sqlalchemy(db_uri)
        logger.info("Motor SQLAlchemy e f√°brica de sess√µes inicializados com sucesso.")

        atexit.register(dispose_sqlalchemy_engine)
        logger.debug("Registrado descarte do motor SQLAlchemy para sa√≠da da aplica√ß√£o.")

    except (DatabaseError, ConfigurationError, SQLAlchemyError) as db_init_err:
        logger.critical(f"Falha ao inicializar o banco de dados: {db_init_err}", exc_info=True)
        import sys
        sys.exit(1)
    except Exception as generic_db_err:
         logger.critical(f"Erro inesperado durante a inicializa√ß√£o do banco de dados: {generic_db_err}", exc_info=True)
         import sys
         sys.exit(1)

    # --- Dependency Injection (Service Instantiation) ---
    logger.info("Instanciando servi√ßos...")
    if not db_engine:
         logger.critical("Motor de banco de dados n√£o dispon√≠vel para instancia√ß√£o de servi√ßos.")
         import sys
         sys.exit(1)

    try:
        # --- Instanciar Reposit√≥rios Diretamente ---
        user_repo = UserRepository(db_engine)
        observation_repo = ObservationRepository(db_engine)
        fiscal_repo = FiscalRepository(db_engine)

        # Adicionar reposit√≥rios ao config da app
        app.config['user_repository'] = user_repo
        app.config['observation_repository'] = observation_repo
        app.config['fiscal_repository'] = fiscal_repo

        # ERP Integration Services
        erp_balance_svc = ErpBalanceService(erp_auth_service)
        erp_cost_svc = ErpCostService(erp_auth_service)
        erp_person_svc = ErpPersonService(erp_auth_service)
        erp_product_svc = ErpProductService(erp_auth_service)
        erp_fiscal_svc = ErpFiscalService(erp_auth_service)
        erp_ar_svc = ErpAccountsReceivableService(erp_auth_service)

        # Application Services
        auth_svc = AuthService(user_repo)
        customer_svc = CustomerService(erp_person_svc)
        fabric_svc = FabricService(erp_balance_svc, erp_cost_svc, erp_product_svc)
        observation_svc = ObservationService(observation_repo)
        product_svc = ProductService(erp_balance_svc)
        fiscal_svc = FiscalService(fiscal_repo, erp_fiscal_svc)
        ar_svc = AccountsReceivableService(erp_ar_svc, erp_person_svc)
        fiscal_sync_svc = FiscalSyncService(erp_fiscal_svc, fiscal_repo)

        # Store service instances in app config
        app.config['auth_service'] = auth_svc
        app.config['customer_service'] = customer_svc
        app.config['fabric_service'] = fabric_svc
        app.config['observation_service'] = observation_svc
        app.config['product_service'] = product_svc
        app.config['fiscal_service'] = fiscal_svc
        app.config['accounts_receivable_service'] = ar_svc
        app.config['fiscal_sync_service'] = fiscal_sync_svc

        logger.info("Servi√ßos instanciados e adicionados √† configura√ß√£o do aplicativo.")

    except Exception as service_init_err:
        logger.critical(f"Falha ao instanciar servi√ßos: {service_init_err}", exc_info=True)
        import sys
        sys.exit(1)

    # --- Register Blueprints (API Routes) ---
    register_blueprints(app)

    # --- Register Error Handlers ---
    register_error_handlers(app)

    # --- Resource Monitoring ---
    if not app.debug or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        start_resource_monitor(interval_seconds=300)
        atexit.register(stop_resource_monitor)

    # --- Start Background Schedulers ---
    if not app.debug or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        logger.info("Iniciando agendadores de tarefas em segundo plano...")
        start_fiscal_sync_scheduler(fiscal_sync_svc)
        atexit.register(stop_fiscal_sync_scheduler)
        logger.info("Agendador de sincroniza√ß√£o fiscal iniciado.")

    # --- Simple Health Check Endpoint ---
    @app.route('/health', methods=['GET'])
    def health_check():
        db_status = "ok"
        db_error = None
        try:
             with get_db_session() as db:
                 pass
        except Exception as e:
             logger.error(f"Verifica√ß√£o de sa√∫de da sess√£o do banco de dados falhou: {e}")
             db_status = "error"
             db_error = str(e)

        sync_running = FiscalSyncService._is_running

        return jsonify({
            "status": "ok",
            "database": db_status,
            "database_error": db_error if db_error else None,
            "sync_service_running": sync_running
        }), 200 if db_status == "ok" else 503

    logger.info("Aplica√ß√£o Connector-Backend configurada com sucesso.")
    return app
</file>

<file path="src/config/__init__.py">
# src/config/__init__.py
# Makes 'config' a package. Exports relevant items.

from .settings import config, Config, load_config

__all__ = ["config", "Config", "load_config"]
</file>

<file path="src/config/README.md">
# src/config

Este diret√≥rio cont√©m a configura√ß√£o da aplica√ß√£o.

## Arquivos

*   **`settings.py`**:
    *   Carrega vari√°veis de ambiente do arquivo `.env` na raiz do projeto usando `python-dotenv`.
    *   Define a classe `Config` (um `dataclass`) que agrupa todas as configura√ß√µes da aplica√ß√£o (Flask, API ERP, Banco de Dados).
    *   L√™ as vari√°veis de conex√£o do PostgreSQL (`POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`).
    *   Constr√≥i a `SQLALCHEMY_DATABASE_URI` usada pelo SQLAlchemy para conectar ao banco.
    *   Fornece valores padr√£o para configura√ß√µes caso n√£o sejam definidas no ambiente.
    *   Exporta uma inst√¢ncia singleton `config` da classe `Config`, que pode ser importada em outros m√≥dulos.
    *   Realiza valida√ß√µes b√°sicas (ex: n√≠vel de log).
*   **`README.md`**: Este arquivo.

## Uso

Importe a inst√¢ncia `config` de `src.config` para acessar as configura√ß√µes em qualquer lugar da aplica√ß√£o:

```python
from src.config import config

api_url = config.API_BASE_URL
debug_mode = config.APP_DEBUG
db_uri = config.SQLALCHEMY_DATABASE_URI # URI para SQLAlchemy
</file>

<file path="src/config/settings.py">
# src/config/settings.py
# Loads environment variables and defines the application configuration.

from dataclasses import dataclass, field
from typing import Optional
from dotenv import load_dotenv
import os
import logging
import sys
from urllib.parse import quote_plus # Para senhas na URL

# Determine the project root directory dynamically
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
dotenv_path = os.path.join(PROJECT_ROOT, '.env')
load_dotenv(dotenv_path=dotenv_path)
print(f"Loading .env file from: {dotenv_path}") # Debug print

@dataclass
class Config:
    """
    Application configuration loaded from environment variables.
    Provides type hints and default values.
    """
    # Flask Settings
    SECRET_KEY: str = field(default_factory=lambda: os.environ.get('SECRET_KEY', 'default_secret_key_change_me_in_env'))
    APP_HOST: str = field(default_factory=lambda: os.environ.get('APP_HOST', '0.0.0.0'))
    APP_PORT: int = field(default_factory=lambda: int(os.environ.get('APP_PORT', 5004)))
    APP_DEBUG: bool = field(default_factory=lambda: os.environ.get('APP_DEBUG', 'True').lower() == 'true')
    TOKEN_EXPIRATION_HOURS: int = field(default_factory=lambda: int(os.environ.get('TOKEN_EXPIRATION_HOURS', 24)))
    LOG_LEVEL: str = field(default_factory=lambda: os.environ.get('LOG_LEVEL', 'DEBUG').upper())

    # --- Database Settings ---
    DB_TYPE: str = field(default_factory=lambda: os.environ.get('DB_TYPE', 'POSTGRES').upper()) # Default to POSTGRES

    # PostgreSQL Specific Settings (read from .env)
    POSTGRES_HOST: str = field(default_factory=lambda: os.environ.get('POSTGRES_HOST', 'localhost'))
    POSTGRES_PORT: int = field(default_factory=lambda: int(os.environ.get('POSTGRES_PORT', 5432)))
    POSTGRES_USER: str = field(default_factory=lambda: os.environ.get('POSTGRES_USER', ''))
    POSTGRES_PASSWORD: str = field(default_factory=lambda: os.environ.get('POSTGRES_PASSWORD', ''))
    POSTGRES_DB: str = field(default_factory=lambda: os.environ.get('POSTGRES_DB', ''))

    # --- SQLAlchemy Database URL ---
    # Constructed based on the DB_TYPE and specific settings
    SQLALCHEMY_DATABASE_URI: Optional[str] = None

    # TOTVS ERP Company Code
    COMPANY_CODE: int = field(default_factory=lambda: int(os.environ.get('COMPANY_CODE', 1)))

    # TOTVS ERP API Integration Settings
    API_BASE_URL: str = field(default_factory=lambda: os.environ.get('API_BASE_URL', 'http://10.1.1.221:11980/api/totvsmoda'))
    PAGE_SIZE: int = field(default_factory=lambda: int(os.environ.get('PAGE_SIZE', 1000)))
    FISCAL_PAGE_SIZE: int = field(default_factory=lambda: min(int(os.environ.get('FISCAL_PAGE_SIZE', 50)), 100))
    MAX_RETRIES: int = field(default_factory=lambda: int(os.environ.get('MAX_RETRIES', 3)))

    # TOTVS ERP API Endpoints (relative to API_BASE_URL)
    BALANCES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('BALANCES_ENDPOINT', '/product/v2/balances/search'))
    COSTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('COSTS_ENDPOINT', '/product/v2/costs/search'))
    PRODUCTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('PRODUCTS_ENDPOINT', '/product/v2/products/search'))
    INDIVIDUALS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('INDIVIDUALS_ENDPOINT', '/person/v2/individuals/search'))
    LEGAL_ENTITIES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('LEGAL_ENTITIES_ENDPOINT', '/person/v2/legal-entities/search'))
    PERSON_STATS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('PERSON_STATS_ENDPOINT', '/person/v2/person-statistics'))
    TOKEN_ENDPOINT: str = field(default_factory=lambda: os.environ.get('TOKEN_ENDPOINT', '/authorization/v2/token'))
    ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT', '/accounts-receivable/v2/documents/search'))
    ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT', '/accounts-receivable/v2/bank-slip'))
    ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT', '/accounts-receivable/v2/payment-link'))
    FISCAL_INVOICES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_INVOICES_ENDPOINT', '/fiscal/v2/invoices/search'))
    FISCAL_XML_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_XML_ENDPOINT', '/fiscal/v2/xml-contents'))
    FISCAL_DANFE_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_DANFE_ENDPOINT', '/fiscal/v2/danfe-search'))

    # TOTVS ERP API Credentials
    API_USERNAME: str = field(default_factory=lambda: os.environ.get('API_USERNAME', ''))
    API_PASSWORD: str = field(default_factory=lambda: os.environ.get('API_PASSWORD', ''))
    CLIENT_ID: str = field(default_factory=lambda: os.environ.get('CLIENT_ID', 'kduapiv2'))
    CLIENT_SECRET: str = field(default_factory=lambda: os.environ.get('CLIENT_SECRET', ''))
    GRANT_TYPE: str = field(default_factory=lambda: os.environ.get('GRANT_TYPE', 'password'))

    def __post_init__(self):
        # Validate log level
        valid_levels = list(logging._nameToLevel.keys())
        if self.LOG_LEVEL not in valid_levels:
             print(f"Warning: Invalid LOG_LEVEL '{self.LOG_LEVEL}'. Valid levels: {valid_levels}. Defaulting to DEBUG.", file=sys.stderr)
             self.LOG_LEVEL = 'DEBUG'

        # --- Build SQLAlchemy Database URI ---
        if self.DB_TYPE == 'POSTGRES':
            if not all([self.POSTGRES_HOST, self.POSTGRES_USER, self.POSTGRES_PASSWORD, self.POSTGRES_DB]):
                print("Warning: Missing PostgreSQL connection details in environment variables. Database connection will likely fail.", file=sys.stderr)
                self.SQLALCHEMY_DATABASE_URI = None
            else:
                 # Use quote_plus for password in case it has special characters
                 encoded_password = quote_plus(self.POSTGRES_PASSWORD)
                 # Specify the driver (+psycopg)
                 self.SQLALCHEMY_DATABASE_URI = f"postgresql+psycopg://{self.POSTGRES_USER}:{encoded_password}@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"
        elif self.DB_TYPE == 'SQLITE':
             # Keep SQLite support if needed temporarily (requires DATABASE_PATH in .env)
             db_path = os.environ.get('DATABASE_PATH')
             if db_path:
                  abs_path = os.path.join(PROJECT_ROOT, db_path) if not os.path.isabs(db_path) else db_path
                  os.makedirs(os.path.dirname(abs_path), exist_ok=True)
                  self.SQLALCHEMY_DATABASE_URI = f"sqlite:///{abs_path}"
             else:
                  print("Warning: DB_TYPE is SQLITE but DATABASE_PATH is not set.", file=sys.stderr)
                  self.SQLALCHEMY_DATABASE_URI = None
        else:
             print(f"Warning: Unsupported DB_TYPE '{self.DB_TYPE}'. No database URI configured.", file=sys.stderr)
             self.SQLALCHEMY_DATABASE_URI = None

        # Validate Fiscal Page Size
        if self.FISCAL_PAGE_SIZE > 100:
            print(f"Warning: FISCAL_PAGE_SIZE ({self.FISCAL_PAGE_SIZE}) exceeds ERP limit of 100. Clamping to 100.", file=sys.stderr)
            self.FISCAL_PAGE_SIZE = 100
        elif self.FISCAL_PAGE_SIZE < 1:
            print(f"Warning: FISCAL_PAGE_SIZE ({self.FISCAL_PAGE_SIZE}) is invalid. Setting to default 50.", file=sys.stderr)
            self.FISCAL_PAGE_SIZE = 50

# Singleton instance, created by load_config
_config_instance: Optional[Config] = None

def load_config() -> Config:
    """Loads or returns the singleton Config instance."""
    global _config_instance
    if _config_instance is None:
        _config_instance = Config()
        # Log loaded config values (mask sensitive ones)
        print("--- Configuration Loaded ---")
        print(f"  APP_HOST: {_config_instance.APP_HOST}")
        print(f"  APP_PORT: {_config_instance.APP_PORT}")
        print(f"  APP_DEBUG: {_config_instance.APP_DEBUG}")
        print(f"  LOG_LEVEL: {_config_instance.LOG_LEVEL}")
        print(f"  DB_TYPE: {_config_instance.DB_TYPE}")
        # Mask password in logged URI
        db_uri_log = str(_config_instance.SQLALCHEMY_DATABASE_URI)
        if _config_instance.POSTGRES_PASSWORD:
             db_uri_log = db_uri_log.replace(quote_plus(_config_instance.POSTGRES_PASSWORD), '********')
        print(f"  SQLALCHEMY_DATABASE_URI: {db_uri_log}")
        print(f"  API_BASE_URL: {_config_instance.API_BASE_URL}")
        print(f"  API_USERNAME: {'*' * len(_config_instance.API_USERNAME) if _config_instance.API_USERNAME else 'Not Set'}")
        print(f"  COMPANY_CODE: {_config_instance.COMPANY_CODE}")
        print(f"  PAGE_SIZE (General): {_config_instance.PAGE_SIZE}")
        print(f"  FISCAL_PAGE_SIZE: {_config_instance.FISCAL_PAGE_SIZE}")
        print("--------------------------")
    return _config_instance

# Expose the singleton instance directly
config = load_config()

# Helper to get PROJECT_ROOT if needed elsewhere
def get_project_root() -> str:
    return PROJECT_ROOT
</file>

<file path="src/database/__init__.py">
# src/database/__init__.py
# Initializes SQLAlchemy components: Engine, SessionLocal, Base metadata.
# Uses local imports for logger/errors to prevent circular dependencies during Alembic runs.

import threading
from typing import Optional, Generator
from contextlib import contextmanager
from sqlalchemy import create_engine
from sqlalchemy.engine import Engine
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.exc import SQLAlchemyError

# Importar Base diretamente - ESSENCIAL para Alembic
from .base import Base
# N√ÉO importar logger, errors, ConfigurationError, SchemaManager aqui no topo

# --- SQLAlchemy Engine and Session Factory Globals ---
_sqla_engine: Optional[Engine] = None
_SessionLocalFactory: Optional[sessionmaker[Session]] = None
_engine_lock = threading.Lock()

# --- Fun√ß√£o de Inicializa√ß√£o do Engine e Session Factory ---
def init_sqlalchemy(database_uri: str, pool_size: int = 10, max_overflow: int = 20) -> Engine:
    """
    Initializes the SQLAlchemy engine, session factory, and database schema.
    Should be called once during application startup.
    Uses local imports for logger/errors.
    """
    # --- Importa√ß√µes locais ---
    from src.utils.logger import logger # Importa logger aqui
    from src.api.errors import DatabaseError, ConfigurationError # Importa errors aqui
    # -------------------------

    global _sqla_engine, _SessionLocalFactory
    with _engine_lock:
        if _sqla_engine and _SessionLocalFactory:
            logger.warning("SQLAlchemy engine and session factory already initialized.")
            return _sqla_engine

        if not database_uri:
            # Logger pode n√£o estar dispon√≠vel ainda se a config falhar aqui,
            # mas ConfigurationError ser√° levantado.
            # logger.critical("Database URI is not configured. Cannot initialize SQLAlchemy.")
            raise ConfigurationError("Database URI is missing in configuration.")

        logger.info(f"Initializing SQLAlchemy engine and session factory...")
        try:
            # 1. Create the Engine
            engine = create_engine(
                database_uri,
                pool_size=pool_size,
                max_overflow=max_overflow,
                pool_recycle=3600,
                echo=False
            )

            # 2. Test Connection
            try:
                with engine.connect() as connection:
                    logger.info("Database connection successful.")
            except SQLAlchemyError as conn_err:
                logger.critical(f"Database connection failed: {conn_err}", exc_info=True)
                raise DatabaseError(f"Failed to connect to the database: {conn_err}") from conn_err

            # 3. Create Session Factory (SessionLocal)
            _SessionLocalFactory = sessionmaker(
                autocommit=False, autoflush=False, bind=engine, expire_on_commit=False
            )
            logger.info("SQLAlchemy session factory (SessionLocal) created.")

            # 4. Initialize Schema (uses the engine)
            # --- Importar SchemaManager localmente ---
            from .schema_manager import SchemaManager
            # ---------------------------------------
            try:
                logger.info("Initializing database schema...")
                schema_manager = SchemaManager(engine)
                schema_manager.initialize_schema()
                logger.info("Database schema initialization complete.")
            except Exception as schema_err:
                logger.critical(f"Database schema initialization failed: {schema_err}", exc_info=True)
                engine.dispose()
                raise DatabaseError(f"Schema initialization failed: {schema_err}") from schema_err

            # Store the initialized engine
            _sqla_engine = engine
            logger.info("SQLAlchemy initialization complete.")
            return _sqla_engine

        except (DatabaseError, ConfigurationError) as e: # Capturar config error tb
             # Logger pode n√£o estar dispon√≠vel se falhar cedo
             print(f"ERROR: Database/Configuration error during SQLAlchemy initialization: {e}")
             raise
        except SQLAlchemyError as e:
             # Logger pode n√£o estar dispon√≠vel
             print(f"ERROR: SQLAlchemy error during initialization: {e}")
             logger.critical(f"SQLAlchemy engine/session factory initialization failed: {e}", exc_info=True)
             raise DatabaseError(f"SQLAlchemy initialization failed: {e}") from e
        except Exception as e:
             # Logger pode n√£o estar dispon√≠vel
             print(f"ERROR: Unexpected error during SQLAlchemy initialization: {e}")
             logger.critical(f"Unexpected error during SQLAlchemy initialization: {e}", exc_info=True)
             if 'engine' in locals() and engine: engine.dispose()
             raise DatabaseError(f"Unexpected error during database initialization: {e}") from e

# --- Fun√ß√£o para Obter uma Sess√£o (Gerenciador de Contexto) ---
@contextmanager
def get_db_session() -> Generator[Session, None, None]:
    """
    Dependency function/context manager to get a database session.
    Manages session lifecycle (commit, rollback, close).
    Uses local imports for logger/errors.
    """
    # --- Importa√ß√µes locais ---
    from src.utils.logger import logger # Importa logger aqui
    from src.api.errors import DatabaseError # Importa errors aqui
    # -------------------------

    if not _SessionLocalFactory:
        # Logger pode n√£o estar dispon√≠vel aqui se a inicializa√ß√£o falhou muito cedo
        # logger.critical("SessionLocal factory not initialized. Call init_sqlalchemy() first.")
        print("CRITICAL ERROR: Database session factory has not been initialized.")
        raise RuntimeError("Database session factory has not been initialized.")

    db: Optional[Session] = None
    try:
        db = _SessionLocalFactory()
        yield db
        db.commit()
        logger.debug("Database session committed successfully.")
    except SQLAlchemyError as sql_ex:
        logger.error(f"Database error occurred in session: {sql_ex}", exc_info=True)
        if db:
            db.rollback()
            logger.warning("Database session rolled back due to SQLAlchemyError.")
        raise DatabaseError(f"Database operation failed: {sql_ex}") from sql_ex
    except Exception as e:
        logger.error(f"Error occurred in database session: {e}", exc_info=True)
        if db:
            db.rollback()
            logger.warning("Database session rolled back due to exception.")
        raise
    finally:
        if db:
            db.close()
            logger.debug("Database session closed.")

# --- Fun√ß√£o de Desligamento do Engine ---
def dispose_sqlalchemy_engine():
    """Closes all connections in the engine's pool. Call during application shutdown."""
    # --- Importa√ß√µes locais ---
    from src.utils.logger import logger # Importa logger aqui
    # -------------------------

    global _sqla_engine, _SessionLocalFactory
    with _engine_lock:
        if _sqla_engine:
            logger.info("Disposing SQLAlchemy engine connection pool...")
            try:
                _sqla_engine.dispose()
                _sqla_engine = None
                _SessionLocalFactory = None
                logger.info("SQLAlchemy engine connection pool disposed.")
            except Exception as e:
                logger.error(f"Error disposing SQLAlchemy engine pool: {e}", exc_info=True)
        else:
            logger.debug("SQLAlchemy engine shutdown called, but engine already disposed or not initialized.")

# --- Itens Exportados Atualizados ---
# Somente fun√ß√µes e Base s√£o exportados
__all__ = [
    "init_sqlalchemy",
    "get_db_session",
    "dispose_sqlalchemy_engine",
    "Base", # Essencial
]
</file>

<file path="src/database/base_repository.py">
# src/database/base_repository.py
# Provides a simplified base class for ORM repositories.

from sqlalchemy.engine import Engine
from sqlalchemy.orm import sessionmaker, Session # Import Session stuff
from typing import Optional, Callable # Import Callable for SessionLocal type hint

from src.utils.logger import logger
from src.api.errors import DatabaseError

class BaseRepository:
    """
    Base class for data repositories using SQLAlchemy ORM Sessions.
    Stores the engine to potentially create sessions if needed,
    but individual methods should ideally receive a session.
    """

    def __init__(self, engine: Engine):
        """
        Initializes the BaseRepository.

        Args:
            engine: The SQLAlchemy Engine instance.
        """
        if not isinstance(engine, Engine):
             raise TypeError("engine must be an instance of sqlalchemy.engine.Engine")
        self.engine = engine
        # Criar a f√°brica de sess√µes localmente se n√£o for injetada globalmente?
        # Por simplicidade, vamos assumir que os reposit√≥rios filhos obter√£o
        # a sess√£o via get_db_session() ou inje√ß√£o.
        logger.debug(f"{self.__class__.__name__} initialized with SQLAlchemy engine: {engine.url.database}")

    # M√©todos _execute e _execute_transaction foram removidos.
    # Os reposit√≥rios filhos usar√£o a API da Sess√£o SQLAlchemy diretamente.
    # Ex: session.query(...), session.add(...), session.execute(select(...))

    # Poder√≠amos adicionar um helper para obter sess√£o aqui, mas √© melhor
    # gerenciar a sess√£o externamente (ex: com get_db_session).
    # def _get_session(self) -> Session:
    #     if not self._session_factory: # Precisaria da f√°brica aqui
    #         raise RuntimeError("Session factory not available in repository.")
    #     return self._session_factory()
</file>

<file path="src/database/base.py">
# src/database/base.py
# Define a base declarativa para os modelos SQLAlchemy ORM.

from sqlalchemy.orm import declarative_base
from sqlalchemy import MetaData

# Conven√ß√£o de nomenclatura para constraints (opcional, mas recomendado)
# Garante nomes consistentes para chaves prim√°rias, estrangeiras, √≠ndices, etc.
# Evita problemas com nomes muito longos ou colis√µes em alguns SGBDs.
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s"
}

# Cria uma inst√¢ncia de MetaData com a conven√ß√£o de nomenclatura
# O schema pode ser definido aqui se voc√™ usar schemas no PostgreSQL (ex: metadata=MetaData(schema="meu_schema"))
metadata = MetaData(naming_convention=convention)

# Cria a Base declarativa usando a metadata configurada
Base = declarative_base(metadata=metadata)

# Voc√™ pode adicionar aqui classes base customizadas com colunas comuns (id, created_at, etc.)
# se desejar, mas por enquanto manteremos simples.
# Exemplo:
# class BaseTimestampedModel(Base):
#     __abstract__ = True # N√£o cria tabela para esta classe
#     created_at: Mapped[datetime] = mapped_column(default=func.now())
#     updated_at: Mapped[datetime] = mapped_column(default=func.now(), onupdate=func.now())
</file>

<file path="src/database/fiscal_repository.py">
# src/database/fiscal_repository.py
# Handles database operations for Fiscal data using SQLAlchemy ORM.

import re # Importar regex para o range
from datetime import datetime, timezone, date, time # Adicionado timezone, date, time
from typing import List, Optional, Dict, Any, Tuple
from sqlalchemy import select, func, delete, update, and_, or_ # Importar and_, or_
from sqlalchemy.orm import Session, joinedload, selectinload, make_transient
from sqlalchemy.orm.exc import NoResultFound
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.fiscal_orm import (
    NotaFiscalOrm, NotaFiscalItemOrm, NotaFiscalItemProdutoOrm,
    NotaFiscalPagamentoOrm, NotaFiscalPedidoVendaOrm, NotaFiscalObservacaoOrm
)
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError
from src.utils.data_conversion import safe_float, safe_int, parse_optional_date, parse_optional_datetime, parse_optional_time

class FiscalRepository(BaseRepository):
    """
    Repository for managing Fiscal data (NotaFiscal and related entities) using ORM Sessions.
    Methods expect a Session object to be passed in.
    """

    # --- Upsert Logic ---
    def upsert_invoice(self, db: Session, invoice_data: Dict[str, Any]) -> Optional[NotaFiscalOrm]:
        """
        Creates or updates a Nota Fiscal and its related entities based on ERP data.
        Prioritizes lookup by (branch_code, invoice_sequence, invoice_date). Handles potential
        duplicates from ERP pagination by checking access_key if primary lookup fails.
        More robust handling of potential duplicates within the same session flush.

        Args:
            db: The SQLAlchemy Session.
            invoice_data: A dictionary representing a single invoice item from the ERP API response.

        Returns:
            The created or updated NotaFiscalOrm object, or None if essential data is missing or skipped.
        """
        if not isinstance(invoice_data, dict):
            logger.warning(f"Pulando upsert da nota fiscal: dados recebidos n√£o s√£o um dicion√°rio: {invoice_data}")
            return None

        branch_code = safe_int(invoice_data.get('branchCode'))
        invoice_sequence = safe_int(invoice_data.get('invoiceSequence'))
        invoice_code = safe_int(invoice_data.get('invoiceCode')) # Usado para logs e busca secund√°ria
        access_key = (invoice_data.get('eletronic') or {}).get('accessKey')
        invoice_date = parse_optional_date(invoice_data.get('invoiceDate')) # Adicionado invoice_date √† chave natural

        # Valida√ß√£o da chave natural prim√°ria
        if branch_code is None or invoice_sequence is None or invoice_date is None:
            logger.warning(f"Pulando upsert da nota fiscal: Faltando branchCode ({branch_code}), invoiceSequence ({invoice_sequence}) ou invoiceDate ({invoice_date}).")
            return None

        # --- Chave Natural Prim√°ria ---
        natural_key_filter = (
            NotaFiscalOrm.branch_code == branch_code,
            NotaFiscalOrm.invoice_sequence == invoice_sequence,
            NotaFiscalOrm.invoice_date == invoice_date
        )
        existing_invoice: Optional[NotaFiscalOrm] = None
        created_new = False

        try:
            # --- Busca Robusta ---
            # 1. Tentar buscar na sess√£o atual primeiro (caso j√° processado no batch)
            for obj in db.new: # Objetos a serem inseridos
                if (isinstance(obj, NotaFiscalOrm) and
                        obj.branch_code == branch_code and
                        obj.invoice_sequence == invoice_sequence and
                        obj.invoice_date == invoice_date):
                    existing_invoice = obj
                    logger.debug(f"Nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} j√° pendente para inser√ß√£o na sess√£o.")
                    break
            if not existing_invoice:
                 for obj in db.dirty: # Objetos a serem atualizados
                     if (isinstance(obj, NotaFiscalOrm) and
                            obj.branch_code == branch_code and
                            obj.invoice_sequence == invoice_sequence and
                            obj.invoice_date == invoice_date):
                          existing_invoice = obj
                          logger.debug(f"Nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} j√° pendente para atualiza√ß√£o na sess√£o.")
                          break

            # 2. Se n√£o estiver na sess√£o, buscar no banco pela chave natural
            if not existing_invoice:
                stmt_natural = select(NotaFiscalOrm).where(and_(*natural_key_filter))
                existing_invoice = db.scalars(stmt_natural).one_or_none()

            # 3. Se ainda n√£o encontrado E houver access_key, tentar por access_key no banco
            #    (Cobre casos de inconsist√™ncia na chave natural vs access_key ou erros anteriores)
            if not existing_invoice and access_key:
                stmt_access_key = select(NotaFiscalOrm).where(NotaFiscalOrm.access_key == access_key)
                invoice_by_key = db.scalars(stmt_access_key).one_or_none()
                if invoice_by_key:
                    logger.warning(f"Nota fiscal encontrada pela access_key '{access_key}' mas n√£o pela chave natural ({branch_code}/{invoice_sequence}/{invoice_date}). Usando registro existente encontrado pela chave.")
                    existing_invoice = invoice_by_key

            # --- Helper Function to Map Data ---
            def map_data_to_invoice(target: NotaFiscalOrm, data: Dict[str, Any]):
                eletronic_data = data.get('eletronic') or {}
                shipping_data = data.get('shippingCompany') or {}

                target.branch_cnpj = data.get('branchCnpj')
                target.person_code = safe_int(data.get('personCode'))
                target.person_name = data.get('personName')
                target.invoice_code = safe_int(data.get('invoiceCode'))
                target.serial_code = data.get('serialCode')
                target.invoice_status = data.get('invoiceStatus')
                target.access_key = eletronic_data.get('accessKey')
                target.electronic_invoice_status = eletronic_data.get('electronicInvoiceStatus')
                target.receipt = str(eletronic_data.get('receipt')) if eletronic_data.get('receipt') is not None else None
                target.receivement_date = parse_optional_datetime(eletronic_data.get('receivementDate'))
                target.disable_protocol = eletronic_data.get('disableProtocol')
                target.disable_date = parse_optional_datetime(eletronic_data.get('disableDate'))
                target.transaction_branch_code = safe_int(data.get('transactionBranchCode'))
                target.transaction_date = parse_optional_date(data.get('transactionDate'))
                target.transaction_code = safe_int(data.get('transactionCode'))
                target.inclusion_component_code = data.get('inclusionComponentCode')
                target.user_code = safe_int(data.get('userCode'))
                target.origin = data.get('origin')
                target.document_type = safe_int(data.get('documentType'))
                target.operation_type = data.get('operationType')
                target.operation_code = safe_int(data.get('operationCode'))
                target.operation_name = data.get('operatioName') # Potential typo in source data 'operatioName'?
                target.invoice_date = parse_optional_date(data.get('invoiceDate')) # J√° validado
                target.issue_date = parse_optional_date(data.get('issueDate'))
                target.release_date = parse_optional_date(data.get('releaseDate'))
                target.exit_time = parse_optional_time(data.get('exitTime'))
                target.lastchange_date = parse_optional_datetime(data.get('lastchangeDate'))
                target.payment_condition_code = safe_int(data.get('paymentConditionCode'))
                target.payment_condition_name = data.get('paymentConditionName')
                target.discount_percentage = safe_float(data.get('discountPercentage'))
                target.quantity = safe_float(data.get('quantity'))
                target.product_value = safe_float(data.get('productValue'))
                target.additional_value = safe_float(data.get('additionalValue'))
                target.shipping_value = safe_float(data.get('shippingValue'))
                target.insurance_value = safe_float(data.get('insuranceValue'))
                target.ipi_value = safe_float(data.get('ipiValue'))
                target.base_icms_value = safe_float(data.get('baseIcmsValue'))
                target.icms_value = safe_float(data.get('icmsValue'))
                target.icms_subst_value = safe_float(data.get('icmsSubStValue')) # Typo? 'icmsSubstValue'?
                target.total_value = safe_float(data.get('totalValue'))
                target.shipping_company_code = safe_int(shipping_data.get('shippingCompanyCode'))
                target.shipping_company_name = shipping_data.get('shippingCompanyName')
                target.freight_type = shipping_data.get('freightType') # Source had 'freitghtType'?
                target.freight_type_redispatch = shipping_data.get('freightTypeRedispatch') # Source had 'freitghtTypeRedispatch'?
                target.freight_value = safe_float(shipping_data.get('freightValue'))
                target.package_number = safe_int(shipping_data.get('packageNumber'))
                target.gross_weight = safe_float(shipping_data.get('grossWeight'))
                target.net_weight = safe_float(shipping_data.get('netWeight'))
                target.species = shipping_data.get('species')
                target.terminal_code = safe_int(data.get('terminalCode'))
                target.observation_nfe = data.get('observationNFE') # Campo de observa√ß√£o √∫nico

            # --- Atualizar ou Criar ---
            if existing_invoice:
                # --- ATUALIZA√á√ÉO ---
                new_last_change = parse_optional_datetime(invoice_data.get('lastchangeDate'))
                should_update = True
                if existing_invoice.lastchange_date and new_last_change:
                    # Normalizar para UTC ou comparar como naive (se ambos forem naive)
                    existing_ts = existing_invoice.lastchange_date
                    new_ts = new_last_change
                    if existing_ts.tzinfo and new_ts.tzinfo:
                         if new_ts.astimezone(timezone.utc) <= existing_ts.astimezone(timezone.utc):
                              should_update = False
                    elif not existing_ts.tzinfo and not new_ts.tzinfo:
                         if new_ts <= existing_ts:
                              should_update = False
                    else: # Mistura de naive e aware, assume que deve atualizar
                         logger.warning(f"Comparando timestamp naive e aware para NF {branch_code}/{invoice_sequence}/{invoice_date}. Atualizando por seguran√ßa.")

                if not should_update:
                     logger.debug(f"Pulando atualiza√ß√£o da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}, timestamp n√£o alterado ou mais antigo ({new_last_change}).")
                     return existing_invoice

                logger.debug(f"Atualizando nota fiscal existente ID {existing_invoice.id} ({branch_code}/{invoice_sequence}/{invoice_date})")
                invoice = existing_invoice
                map_data_to_invoice(invoice, invoice_data)
                # Limpar filhos ANTES de adicionar novos para evitar duplicatas
                invoice.items.clear()
                invoice.payments.clear()
                invoice.sales_orders.clear()
                invoice.observations.clear()
                # Flush pode ajudar a garantir que deletes ocorram antes de inserts se houver constraints
                # db.flush() # Descomente se necess√°rio, mas pode impactar performance
            else:
                 # --- CRIA√á√ÉO ---
                 logger.debug(f"Criando nova nota fiscal ({branch_code}/{invoice_sequence}/{invoice_date}, Chave: ...{access_key[-6:] if access_key else 'N/A'})")
                 # Checagem pr√©via por access_key (melhoria contra race condition/duplicidade)
                 if access_key:
                      stmt_check_key = select(NotaFiscalOrm.id).where(NotaFiscalOrm.access_key == access_key).limit(1)
                      key_already_exists = db.execute(stmt_check_key).scalar_one_or_none()
                      if key_already_exists:
                           logger.warning(f"Access_key duplicada '{access_key}' encontrada antes do INSERT para {branch_code}/{invoice_sequence}/{invoice_date}. Pulando este registro.")
                           return None # Pula esta nota

                 invoice = NotaFiscalOrm(branch_code=branch_code, invoice_sequence=invoice_sequence, invoice_date=invoice_date)
                 map_data_to_invoice(invoice, invoice_data)
                 db.add(invoice)
                 created_new = True # Marca que foi criado

            # --- Handle Children (Processar e associar ao 'invoice' correto) ---

            # Items and their Products
            items_list = invoice_data.get('items')
            if isinstance(items_list, list):
                for item_data in items_list:
                    if not isinstance(item_data, dict): continue
                    item_orm = NotaFiscalItemOrm(
                        nota_fiscal=invoice, # Associa√ß√£o feita aqui
                         sequence=safe_int(item_data.get('sequence')),
                         code=item_data.get('code'), name=item_data.get('name'),
                         ncm=item_data.get('ncm'), cfop=safe_int(item_data.get('cfop')),
                         measure_unit=item_data.get('measureUnit'), quantity=safe_float(item_data.get('quantity')),
                         gross_value=safe_float(item_data.get('grossValue')), discount_value=safe_float(item_data.get('discountValue')),
                         net_value=safe_float(item_data.get('netValue')), unit_gross_value=safe_float(item_data.get('unitGrossValue')),
                         unit_discount_value=safe_float(item_data.get('unitDiscountValue')), unit_net_value=safe_float(item_data.get('unitNetValue')),
                         additional_value=safe_float(item_data.get('additionalValue')), freight_value=safe_float(item_data.get('freightValue')),
                         insurance_value=safe_float(item_data.get('insuranceValue')), additional_item_information=item_data.get('additionalItemInformation')
                    )
                    # N√£o precisa de db.add(item_orm) por causa do cascade
                    products_list = item_data.get('products')
                    if isinstance(products_list, list):
                         for prod_data in products_list:
                              if not isinstance(prod_data, dict): continue
                              prod_orm = NotaFiscalItemProdutoOrm(
                                  item=item_orm, # Associa√ß√£o feita aqui
                                  product_code=safe_int(prod_data.get('productCode')), product_name=prod_data.get('productName'),
                                  dealer_code=safe_int(prod_data.get('dealerCode')), quantity=safe_float(prod_data.get('quantity')),
                                  unit_gross_value=safe_float(prod_data.get('unitGrossValue')), unit_discount_value=safe_float(prod_data.get('unitDiscountValue')),
                                  unit_net_value=safe_float(prod_data.get('unitNetValue')), gross_value=safe_float(prod_data.get('grossValue')),
                                  discount_value=safe_float(prod_data.get('discountValue')), net_value=safe_float(prod_data.get('netValue'))
                              )
                              # Associa√ß√£o via backref/relationship, n√£o precisa add
                              item_orm.item_products.append(prod_orm)
                    # Associa√ß√£o via backref/relationship
                    invoice.items.append(item_orm)

            # Payments
            payments_list = invoice_data.get('payments')
            if isinstance(payments_list, list):
                for payment_data in payments_list:
                    if not isinstance(payment_data, dict): continue
                    payment_orm = NotaFiscalPagamentoOrm(
                        nota_fiscal=invoice, # Associa√ß√£o
                        document_number=safe_int(payment_data.get('documentNumber')), expiration_date=parse_optional_datetime(payment_data.get('expirationDate')),
                        payment_value=safe_float(payment_data.get('paymentValue')), document_type_code=safe_int(payment_data.get('documentTypeCode')),
                        document_type=payment_data.get('documentType'), installment=safe_int(payment_data.get('installment')),
                        bearer_code=safe_int(payment_data.get('bearerCode')), bearer_name=payment_data.get('bearerName')
                    )
                    invoice.payments.append(payment_orm) # Associa√ß√£o

            # Sales Orders
            sales_order_list = invoice_data.get('salesOrder')
            if isinstance(sales_order_list, list):
                for order_data in sales_order_list:
                    if not isinstance(order_data, dict): continue
                    order_orm = NotaFiscalPedidoVendaOrm(
                        nota_fiscal=invoice, # Associa√ß√£o
                        branch_code=safe_int(order_data.get('branchCode')), order_code=safe_int(order_data.get('orderCode')),
                        customer_order_code=order_data.get('customerOrderCode')
                    )
                    invoice.sales_orders.append(order_orm) # Associa√ß√£o

            # Observations (observationNF list)
            observations_list = invoice_data.get('observationNF')
            if isinstance(observations_list, list):
                 for obs_data in observations_list:
                      if not isinstance(obs_data, dict): continue
                      obs_orm = NotaFiscalObservacaoOrm(
                          nota_fiscal=invoice, # Associa√ß√£o
                          observation=obs_data.get('observation'),
                          sequence=safe_int(obs_data.get('sequence'))
                      )
                      invoice.observations.append(obs_orm) # Associa√ß√£o


            # --- Flush Final ---
            # O flush aqui pode detectar UniqueViolations ANTES do commit do batch
            # db.flush() # Descomente se encontrar problemas de integridade complexos
            log_operation = "Criada" if created_new else "Atualizada"
            logger.debug(f"{log_operation} nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} na sess√£o. Commit pendente.")
            return invoice

        except IntegrityError as e:
            db.rollback() # Rollback da sess√£o atual para n√£o afetar o resto do batch
            logger.error(f"Erro de integridade do banco de dados durante upsert para nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            # Checar constraints espec√≠ficas se necess√°rio
            # if "uq_nota_fiscal_branch_sequence_date" in str(e.orig) or "ix_nota_fiscal_access_key" in str(e.orig):
            #      logger.warning(f"IntegrityError (chave duplicada?) para nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}. Pulando este registro.")
            #      return None # Pular este item
            # else:
                 # Outro erro de integridade, pode ser melhor propagar
            raise DatabaseError(f"Erro de integridade processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e
        except SQLAlchemyError as e:
            db.rollback() # Rollback da sess√£o atual
            logger.error(f"Erro de banco de dados durante upsert da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e
        except Exception as e:
            db.rollback() # Rollback da sess√£o atual
            logger.error(f"Erro inesperado durante upsert da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e


    # --- Get Latest Sync Timestamp ---
    def get_latest_sync_timestamp(self, db: Session) -> Optional[datetime]:
        """
        Finds the maximum 'lastchange_date' from the nota_fiscal table.
        """
        logger.debug("Consultando timestamp mais recente de sincroniza√ß√£o (max lastchange_date) na tabela nota_fiscal.")
        try:
            stmt = select(func.max(NotaFiscalOrm.lastchange_date))
            latest_timestamp = db.scalar(stmt)
            if latest_timestamp:
                 # Certificar que o timestamp retornado √© timezone-aware (UTC)
                 if latest_timestamp.tzinfo is None:
                      logger.warning(f"Timestamp {latest_timestamp} do DB √© naive, assumindo UTC.")
                      latest_timestamp = latest_timestamp.replace(tzinfo=timezone.utc)
                 else:
                      latest_timestamp = latest_timestamp.astimezone(timezone.utc)
                 logger.info(f"Timestamp mais recente de sincroniza√ß√£o encontrado: {latest_timestamp.isoformat()}")
            else:
                 logger.info("Nenhum timestamp anterior de sincroniza√ß√£o encontrado no banco de dados.")
            return latest_timestamp
        except SQLAlchemyError as e:
             logger.error(f"Erro de banco de dados ao obter timestamp mais recente de sincroniza√ß√£o: {e}", exc_info=True)
             return None # Retorna None para indicar falha ou aus√™ncia
        except Exception as e:
            logger.error(f"Erro inesperado ao obter timestamp mais recente de sincroniza√ß√£o: {e}", exc_info=True)
            return None # Retorna None


    # --- Find Invoices Local ---
    def find_invoices_local(self, db: Session, filters: Dict[str, Any], page: int, page_size: int) -> Tuple[List[NotaFiscalOrm], int]:
        """
        Searches for invoices in the LOCAL database based on provided filters.
        Args:
            db: The SQLAlchemy Session.
            filters: Dictionary of filter criteria mapped from API request.
            page: Page number (starting from 1).
            page_size: Number of items per page.
        Returns:
            A tuple containing: (list of NotaFiscalOrm objects, total_count).
        """
        logger.debug(f"Buscando notas fiscais locais com filtros: {filters}, P√°gina: {page}, TamanhoP√°gina: {page_size}")
        try:
            query = select(NotaFiscalOrm)
            applied_filters = [] # Para logar os filtros aplicados

            # --- Apply Filters ---

            # Filtro por Status (Chave API: 'status', Campo ORM: electronic_invoice_status)
            if 'status' in filters:
                status_input = filters['status']
                if status_input and isinstance(status_input, str):
                    # Divide por v√≠rgula, remove espa√ßos e converte para min√∫sculo
                    status_list_lower = [s.strip().lower() for s in status_input.split(',') if s.strip()]
                    if status_list_lower:
                        query = query.where(func.lower(NotaFiscalOrm.electronic_invoice_status).in_(status_list_lower))
                        applied_filters.append(f"status IN {status_list_lower}")

            # Filtro por Nome do Destinat√°rio (Chave API: 'recipient_name' - Manter se √∫til)
            if 'recipient_name' in filters:
                name_filter = filters['recipient_name']
                if name_filter and isinstance(name_filter, str):
                    query = query.where(NotaFiscalOrm.person_name.ilike(f"%{name_filter}%"))
                    applied_filters.append(f"recipient_name LIKE '%{name_filter}%'")

            # Filtro por N√∫mero da Nota Fiscal (Chave API: 'invoice_number', Campo ORM: invoice_code)
            if 'invoice_number' in filters:
                num_input = filters['invoice_number']
                if num_input and isinstance(num_input, str):
                    num_input = num_input.strip()
                    # 1. Checar por Range (ex: "100-150")
                    range_match = re.match(r'^(\d+)\s*-\s*(\d+)$', num_input)
                    if range_match:
                        start_num = safe_int(range_match.group(1))
                        end_num = safe_int(range_match.group(2))
                        if start_num is not None and end_num is not None and start_num <= end_num:
                            query = query.where(NotaFiscalOrm.invoice_code.between(start_num, end_num))
                            applied_filters.append(f"invoice_number BETWEEN {start_num} AND {end_num}")
                        else:
                            logger.warning(f"Range de n√∫mero de nota inv√°lido: '{num_input}'. Ignorando filtro.")
                    # 2. Checar por Lista (ex: "101, 105, 200")
                    elif ',' in num_input:
                        int_num_list = [safe_int(n.strip()) for n in num_input.split(',') if safe_int(n.strip()) is not None]
                        if int_num_list:
                            query = query.where(NotaFiscalOrm.invoice_code.in_(int_num_list))
                            applied_filters.append(f"invoice_number IN {int_num_list}")
                        else:
                             logger.warning(f"Lista de n√∫meros de nota inv√°lida ou vazia: '{num_input}'. Ignorando filtro.")
                    # 3. Assumir N√∫mero √önico
                    else:
                        single_num = safe_int(num_input)
                        if single_num is not None:
                            query = query.where(NotaFiscalOrm.invoice_code == single_num)
                            applied_filters.append(f"invoice_number == {single_num}")
                        else:
                             logger.warning(f"N√∫mero de nota inv√°lido: '{num_input}'. Ignorando filtro.")


            # Filtro por Chave de Acesso (Chave API: 'access_key')
            if 'access_key' in filters:
                 key = filters['access_key']
                 if key and isinstance(key, str) and len(key) == 44 and key.isdigit():
                      query = query.where(NotaFiscalOrm.access_key == key)
                      applied_filters.append(f"access_key == ...{key[-6:]}")
                 elif key:
                      logger.warning(f"Formato de chave de acesso inv√°lido no filtro: '{key}'. Ignorando.")


            # Filtro por C√≥digo do Cliente (Chave API interna: 'customer_code', Campo ORM: person_code)
            if 'customer_code' in filters:
                code_input = filters['customer_code']
                if code_input and isinstance(code_input, str):
                    # Tratar lista separada por v√≠rgula
                    code_list = [safe_int(c.strip()) for c in code_input.split(',') if safe_int(c.strip()) is not None]
                    if len(code_list) == 1:
                         query = query.where(NotaFiscalOrm.person_code == code_list[0])
                         applied_filters.append(f"person_code == {code_list[0]}")
                    elif len(code_list) > 1:
                         query = query.where(NotaFiscalOrm.person_code.in_(code_list))
                         applied_filters.append(f"person_code IN {code_list}")
                    else:
                        logger.warning(f"Lista de c√≥digos de cliente inv√°lida ou vazia: '{code_input}'. Ignorando filtro.")


            # Filtro por CPF/CNPJ do Cliente (Chave API interna: 'customer_cpf_cnpj')
            # !!! AJUSTE NECESS√ÅRIO QUANDO O JOIN COM A TABELA DE PESSOAS/CLIENTES FOR IMPLEMENTADO !!!
            if 'customer_cpf_cnpj' in filters:
                 cpf_cnpj_input = filters['customer_cpf_cnpj']
                 if cpf_cnpj_input and isinstance(cpf_cnpj_input, str):
                     cpf_cnpj_list = [doc.strip() for doc in cpf_cnpj_input.split(',') if doc.strip() and doc.isdigit() and (len(doc) == 11 or len(doc) == 14)]
                     if cpf_cnpj_list:
                          # --- Placeholder ---
                          # Substitua 'NotaFiscalOrm.branch_cnpj' pelo campo correto ap√≥s o JOIN com a tabela de Pessoas/Clientes
                          # Exemplo: Se houver um relacionamento 'person' em NotaFiscalOrm:
                          # from src.domain.person_orm import PersonOrm # Importar
                          # query = query.join(PersonOrm, NotaFiscalOrm.person_code == PersonOrm.code) # Exemplo de JOIN
                          # query = query.where(PersonOrm.cpf_cnpj.in_(cpf_cnpj_list)) # Exemplo de filtro no campo correto
                          logger.warning("Filtro por CPF/CNPJ ainda n√£o implementado com JOIN. Usando placeholder NotaFiscalOrm.branch_cnpj.")
                          query = query.where(NotaFiscalOrm.branch_cnpj.in_(cpf_cnpj_list)) # <<< AJUSTE ESTA LINHA FUTURAMENTE
                          applied_filters.append(f"branch_cnpj IN {cpf_cnpj_list} (Placeholder!)") # Ajuste o nome do campo no log tamb√©m
                          # --- Fim Placeholder ---
                     else:
                          logger.warning(f"Lista de CPF/CNPJ inv√°lida ou vazia: '{cpf_cnpj_input}'. Ignorando filtro.")


            # Filtro por Data de Emiss√£o (Chaves API: 'start_date', 'end_date', Campo ORM: issue_date)
            start_issue_date = parse_optional_date(filters.get('start_date')) # Simplificado, API s√≥ usa 'start_date' agora
            end_issue_date = parse_optional_date(filters.get('end_date'))     # Simplificado, API s√≥ usa 'end_date' agora
            if start_issue_date:
                 query = query.where(NotaFiscalOrm.issue_date >= start_issue_date)
                 applied_filters.append(f"issue_date >= {start_issue_date.isoformat()}")
            if end_issue_date:
                 # Para garantir que a data final seja inclusiva
                 query = query.where(NotaFiscalOrm.issue_date <= end_issue_date)
                 applied_filters.append(f"issue_date <= {end_issue_date.isoformat()}")


            # Log dos filtros efetivamente aplicados
            if applied_filters:
                logger.info(f"Filtros aplicados na consulta: {'; '.join(applied_filters)}")
            else:
                logger.info("Nenhum filtro espec√≠fico aplicado na consulta.")


            # --- Count Total Matching Items ---
            # Contar *depois* de aplicar todos os filtros WHERE
            count_query = select(func.count()).select_from(query.subquery())
            total_count = db.scalar(count_query) or 0
            logger.debug(f"Contagem total ANTES da pagina√ß√£o (com filtros): {total_count}")

            # --- Apply Ordering ---
            # Ordenar antes da pagina√ß√£o
            query = query.order_by(NotaFiscalOrm.issue_date.desc(), NotaFiscalOrm.invoice_code.desc())

            # --- Apply Pagination ---
            offset = (page - 1) * page_size
            query = query.limit(page_size).offset(offset)

            # --- Eager Loading ---
            # Carregar relacionamentos necess√°rios para a formata√ß√£o no FiscalService
            query = query.options(
                selectinload(NotaFiscalOrm.sales_orders) # Usado em _format_invoice_list_item
                # Adicione outros relacionamentos se forem usados na formata√ß√£o
            )

            # --- Execute Query ---
            results = db.scalars(query).all()

            logger.info(f"Busca local conclu√≠da. {len(results)} itens retornados para p√°gina {page}. Total de itens correspondentes: {total_count}.")
            return list(results), total_count

        except SQLAlchemyError as e:
            logger.error(f"Erro de banco de dados na busca de notas fiscais locais: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados durante busca de notas fiscais locais: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado na busca de notas fiscais locais: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado durante busca de notas fiscais locais: {e}") from e
</file>

<file path="src/database/observation_repository.py">
# src/database/observation_repository.py
# Handles database operations for Product Observations using SQLAlchemy ORM.

from datetime import datetime, timezone
from typing import List, Optional, Dict, Any
from sqlalchemy import select, func, delete, update # Import select, func, delete, update
from sqlalchemy.orm import Session # Import Session
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.observation import Observation # Import ORM model
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError

class ObservationRepository(BaseRepository):
    """
    Repository for managing Product Observations using SQLAlchemy ORM Sessions.
    Methods now expect a Session object to be passed in.
    """

    # O construtor ainda recebe Engine, mas n√£o o usaremos diretamente nos m√©todos ORM.
    # def __init__(self, engine: Engine):
    #     super().__init__(engine)
    #     logger.info("ObservationRepository initialized with SQLAlchemy engine (ready for ORM sessions).")


    def add(self, db: Session, observation: Observation) -> Observation:
        """Adds a new observation to the database using ORM Session."""
        if not observation.reference_code or not observation.observation_text or not observation.user:
             raise ValueError("Missing required fields (reference_code, observation_text, user).")

        logger.debug(f"ORM: Adding observation for ref '{observation.reference_code}' to session")
        try:
            # Define timestamp se n√£o estiver definido
            if observation.timestamp is None:
                 observation.timestamp = datetime.now(timezone.utc)

            db.add(observation)
            db.flush() # Para obter o ID gerado
            logger.info(f"ORM: Observation added to session (ID: {observation.id}) for ref: {observation.reference_code}. Commit pending.")
            # Commit √© tratado externamente
            return observation
        except IntegrityError as e: # Capturar erros de constraint se houver (improv√°vel aqui)
            db.rollback()
            logger.error(f"ORM: Database integrity error adding observation: {e}", exc_info=True)
            raise DatabaseError(f"Failed to add observation due to integrity constraint: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error adding observation: {e}", exc_info=True)
            raise DatabaseError(f"Failed to add observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error adding observation for ref '{observation.reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while adding observation: {e}") from e

    def find_by_id(self, db: Session, observation_id: int) -> Optional[Observation]:
        """Finds an observation by its ID using ORM Session."""
        logger.debug(f"ORM: Finding observation by ID {observation_id}")
        try:
            observation = db.get(Observation, observation_id)
            if observation:
                 logger.debug(f"ORM: Observation found by ID {observation_id}.")
            else:
                 logger.debug(f"ORM: Observation not found by ID {observation_id}.")
            return observation
        except SQLAlchemyError as e:
             logger.error(f"ORM: Database error finding observation by ID {observation_id}: {e}", exc_info=True)
             raise DatabaseError(f"Database error finding observation by ID: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Unexpected error finding observation by ID {observation_id}: {e}", exc_info=True)
             raise DatabaseError(f"Unexpected error finding observation by ID: {e}") from e


    def find_by_reference_code(self, db: Session, reference_code: str, include_resolved: bool = True) -> List[Observation]:
        """Finds observations for a reference code using ORM Session."""
        logger.debug(f"ORM: Finding obs for ref '{reference_code}' (resolved={include_resolved})")
        try:
            stmt = select(Observation).where(Observation.reference_code == reference_code)
            if not include_resolved:
                stmt = stmt.where(Observation.resolved == False)
            stmt = stmt.order_by(Observation.timestamp.desc())

            observations = db.scalars(stmt).all()
            logger.debug(f"ORM: Found {len(observations)} obs for ref '{reference_code}'.")
            return list(observations)
        except SQLAlchemyError as e:
             logger.error(f"ORM: Database error finding obs by ref '{reference_code}': {e}", exc_info=True)
             raise DatabaseError(f"Database error finding obs by ref: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Unexpected error finding obs by ref {reference_code}: {e}", exc_info=True)
             raise DatabaseError(f"Unexpected error finding obs by ref: {e}") from e

    def update(self, db: Session, observation_to_update: Observation) -> Observation:
        """Updates an existing observation using ORM Session."""
        if observation_to_update.id is None:
            raise ValueError("Cannot update observation without an ID.")

        logger.debug(f"ORM: Updating observation ID {observation_to_update.id} in session")
        try:
            # Se o objeto veio de fora da sess√£o, buscar primeiro ou usar merge.
            # Assumindo que o objeto j√° est√° na sess√£o ou ser√° gerenciado pelo chamador.
            db.flush() # Envia as altera√ß√µes pendentes (se houver) sem commitar
            logger.info(f"ORM: Observation ID {observation_to_update.id} marked for update. Commit pending.")
            # Commit √© externo
            return observation_to_update
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error updating observation ID {observation_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Failed to update observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error updating observation ID {observation_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while updating observation: {e}") from e


    def mark_as_resolved(self, db: Session, observation_id: int, resolved_by_user: str) -> bool:
        """Marks a specific observation as resolved using ORM Session."""
        logger.debug(f"ORM: Marking observation ID {observation_id} as resolved by '{resolved_by_user}'")
        try:
            observation = db.get(Observation, observation_id)
            if not observation:
                 logger.warning(f"ORM: Attempted to resolve non-existent observation ID {observation_id}.")
                 raise NotFoundError(f"Observation with ID {observation_id} not found.")

            if observation.resolved:
                 logger.warning(f"ORM: Observation ID {observation_id} was already resolved.")
                 return False # Indicar que nenhuma altera√ß√£o foi feita

            observation.resolved = True
            observation.resolved_user = resolved_by_user
            observation.resolved_timestamp = datetime.now(timezone.utc)
            db.flush() # Envia a altera√ß√£o
            logger.info(f"ORM: Observation ID {observation_id} marked as resolved in session. Commit pending.")
            # Commit √© externo
            return True
        except NotFoundError:
             raise # Re-raise not found error
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error marking obs ID {observation_id} as resolved: {e}", exc_info=True)
            raise DatabaseError(f"Failed to resolve observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error marking obs ID {observation_id} as resolved: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while resolving observation: {e}") from e

    def get_unresolved_count(self, db: Session, reference_code: str) -> int:
        """Gets the count of unresolved observations using ORM Session."""
        logger.debug(f"ORM: Getting unresolved count for ref '{reference_code}'")
        try:
            stmt = (
                select(func.count(Observation.id))
                .where(Observation.reference_code == reference_code)
                .where(Observation.resolved == False)
            )
            count = db.scalar(stmt)
            count = count if count is not None else 0
            logger.debug(f"ORM: Unresolved count for ref '{reference_code}': {count}")
            return count
        except SQLAlchemyError as e:
            logger.error(f"ORM: Failed get unresolved count for ref '{reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"Database error getting unresolved count: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Unexpected error getting unresolved count for ref '{reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"Unexpected error getting unresolved count: {e}") from e

    def get_references_with_pending(self, db: Session) -> List[Dict[str, Any]]:
        """Gets distinct references with the latest pending observation using ORM."""
        # Esta query √© um pouco mais complexa com ORM puro sem window functions diretas
        # Vamos manter a l√≥gica de subquery similar √† SQL original
        logger.debug("ORM: Getting references with pending observations")
        try:
            # Subquery para encontrar o timestamp mais recente n√£o resolvido por refer√™ncia
            subq = (
                select(
                    Observation.reference_code,
                    func.max(Observation.timestamp).label("max_timestamp")
                )
                .where(Observation.resolved == False)
                .group_by(Observation.reference_code)
                .subquery('latest_pending')
            )

            # Query principal para pegar os detalhes da observa√ß√£o mais recente
            stmt = (
                select(
                    Observation.reference_code,
                    Observation.user,
                    Observation.timestamp
                )
                .join(subq, (Observation.reference_code == subq.c.reference_code) & (Observation.timestamp == subq.c.max_timestamp))
                .where(Observation.resolved == False) # Garantir que ainda n√£o foi resolvido (caso haja duplicatas de timestamp)
                .order_by(Observation.timestamp.desc())
            )

            results = db.execute(stmt).mappings().all() # Executa e pega como dicion√°rios

            # Formata o resultado (converte datetime para isoformat)
            formatted_results = [
                 {
                      "reference_code": row["reference_code"],
                      "user": row["user"],
                      "timestamp": row["timestamp"].isoformat() if isinstance(row["timestamp"], datetime) else None
                 } for row in results
            ]

            logger.debug(f"ORM: Found {len(formatted_results)} references with pending observations.")
            return formatted_results
        except SQLAlchemyError as e:
            logger.error(f"ORM: Failed to get references with pending observations: {e}", exc_info=True)
            raise DatabaseError(f"Database error getting pending references: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Unexpected error getting pending references: {e}", exc_info=True)
            raise DatabaseError(f"Unexpected error getting pending references: {e}") from e

    def delete_by_id(self, db: Session, observation_id: int) -> bool:
        """Deletes an observation by its ID using ORM Session."""
        logger.debug(f"ORM: Deleting observation ID {observation_id}")
        try:
            observation = db.get(Observation, observation_id)
            if observation:
                db.delete(observation)
                db.flush()
                logger.info(f"ORM: Observation ID {observation_id} marked for deletion. Commit pending.")
                return True
            else:
                logger.warning(f"ORM: Attempted to delete observation ID {observation_id}, but it was not found.")
                return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error deleting obs ID {observation_id}: {e}", exc_info=True)
            raise DatabaseError(f"Failed to delete observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error deleting obs ID {observation_id}: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while deleting observation: {e}") from e
</file>

<file path="src/database/product_repository.py">
# src/database/product_repository.py
# Handles database operations related to products (if any beyond observations).

"""
NOTA: Atualmente, todas as opera√ß√µes de BD relacionadas ao produto parecem estar focadas em
'product_observations'. Elas s√£o manipuladas por `ObservationRepository`.

Se houvesse outras tabelas ou dados espec√≠ficos do produto para gerenciar localmente
(por exemplo, detalhes do produto em cache, metadados do produto local), este reposit√≥rio
lidaria com essas opera√ß√µes.

Este arquivo √© mantido como um espa√ßo reservado demonstrando a estrutura e a integra√ß√£o do SQLAlchemy.
"""

from sqlalchemy.engine import Engine
from .base_repository import BaseRepository
from src.utils.logger import logger
from typing import Optional

class ProductRepository(BaseRepository):
    """
    Reposit√≥rio para gerenciar dados de produtos no banco de dados local usando SQLAlchemy.
    Atualmente, a l√≥gica de observa√ß√£o est√° no ObservationRepository.
    """

    def __init__(self, engine: Engine):
        super().__init__(engine)
        logger.info("ProductRepository inicializado (Placeholder) com o engine do SQLAlchemy.")
    
    # Adicione m√©todos aqui conforme necess√°rio para opera√ß√µes espec√≠ficas de produtos no banco de dados
    # Exemplo:
    # def cache_product_details(self, product_data: dict):
    #     # L√≥gica para inserir/atualizar dados no cache usando self._execute
    #     pass
    #
    # def get_cached_product_details(self, product_code: int) -> Optional[dict]:
    #     # L√≥gica para buscar dados do cache usando self._execute
    #     pass
</file>

<file path="src/database/README.md">
# src/database

Este diret√≥rio cont√©m toda a l√≥gica relacionada √† intera√ß√£o com o banco de dados **PostgreSQL**, utilizando **SQLAlchemy ORM** e **Alembic** para gerenciamento de schema.

## Arquivos

*   **`__init__.py`**: Inicializa os componentes do SQLAlchemy (`Engine`, `sessionmaker` para criar `SessionLocal`) quando a aplica√ß√£o inicia, usando a URI do banco definida na configura√ß√£o. Fornece a fun√ß√£o `get_db_session` (um gerenciador de contexto) para obter e gerenciar sess√µes de banco de dados. **N√£o cont√©m mais as fun√ß√µes de f√°brica de reposit√≥rios nem a inicializa√ß√£o do SchemaManager aqui.**
*   **`base.py`**: Define a base declarativa (`Base`) do SQLAlchemy da qual todos os modelos ORM herdam. Tamb√©m configura metadados e conven√ß√µes de nomenclatura, que s√£o usados pelo Alembic.
*   **`base_repository.py`**: Define a classe `BaseRepository` simplificada, que serve como ponto de inicializa√ß√£o comum para reposit√≥rios, armazenando a `Engine`.
*   **`observation_repository.py`**: Define `ObservationRepository`, respons√°vel pelas opera√ß√µes CRUD relacionadas √†s observa√ß√µes de produto (`product_observations`) usando a API de Sess√£o do ORM.
*   **`product_repository.py`**: Placeholder para opera√ß√µes relacionadas a dados de *produtos* armazenados localmente.
*   **`schema_manager.py`**: Define `SchemaManager`, **agora com responsabilidade reduzida**. Sua fun√ß√£o principal √© garantir que as tabelas existam na **primeira inicializa√ß√£o** (usando `Base.metadata.create_all`) antes que o Alembic seja aplicado, e garantir dados iniciais essenciais (usu√°rio administrador). **N√ÉO √© mais respons√°vel por criar √≠ndices, constraints ou aplicar altera√ß√µes de schema (ALTER TABLE) - isso √© feito pelo Alembic.**
*   **`user_repository.py`**: Define `UserRepository`, respons√°vel pelas opera√ß√µes CRUD para as tabelas `users` e `user_permissions` usando a API de Sess√£o do ORM.
*   **`README.md`**: Este arquivo.

## Funcionamento com Alembic

1.  **Inicializa√ß√£o da App (`src/app.py`):**
    *   A fun√ß√£o `init_sqlalchemy()` deste pacote √© chamada. Ela cria a `Engine` global do SQLAlchemy e configura a f√°brica de sess√µes `SessionLocal`.
    *   O `SchemaManager` √© instanciado e `initialize_schema()` √© chamado. Ele executa `Base.metadata.create_all(engine)` (que cria tabelas que *n√£o* existem) e garante o usu√°rio admin.
2.  **Gerenciamento de Schema (Alembic):**
    *   **Fora da execu√ß√£o normal da aplica√ß√£o**, o desenvolvedor usa os comandos `alembic` para gerenciar o schema.
    *   `alembic revision --autogenerate`: Compara os modelos ORM (`Base.metadata`) com o banco de dados e gera um script de migra√ß√£o em `alembic/versions/`.
    *   `alembic upgrade head`: Aplica os scripts de migra√ß√£o pendentes ao banco de dados, efetivamente criando/alterando tabelas, colunas, √≠ndices, etc.
    *   Isso garante que as altera√ß√µes no schema sejam versionadas e aplicadas de forma consistente em diferentes ambientes (desenvolvimento, teste, produ√ß√£o).
3.  **Reposit√≥rios e Opera√ß√µes:** (Funcionamento permanece o mesmo)
    *   Os servi√ßos obt√™m inst√¢ncias dos reposit√≥rios.
    *   Para opera√ß√µes no banco, os servi√ßos usam `get_db_session()` para obter uma `Session`.
    *   A `Session` √© passada para os m√©todos do reposit√≥rio.
    *   Os reposit√≥rios usam a `Session` e a API ORM para interagir com o banco.
    *   O contexto `get_db_session()` gerencia commit/rollback/close.
4.  **Desligamento:** Na finaliza√ß√£o da aplica√ß√£o, `dispose_sqlalchemy_engine()` fecha o pool de conex√µes.

## Modelos de Dados

Os reposit√≥rios trabalham com os modelos ORM definidos em `src/domain` (ex: `User`, `Observation`), que herdam de `src/database/base.py::Base`. O Alembic usa esses mesmos modelos (`Base.metadata`) como a "verdade" sobre como o schema do banco de dados deve ser.
</file>

<file path="src/database/schema_manager.py">
# src/database/schema_manager.py
# Gerencia a cria√ß√£o inicial das tabelas do banco de dados e dados essenciais.

import bcrypt
import os
from datetime import datetime, timezone
from sqlalchemy.engine import Engine, Connection
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from sqlalchemy import text

from .base import Base
from src.utils.logger import logger
from src.api.errors import DatabaseError, ConfigurationError

DEFAULT_ADMIN_PASSWORD = 'admin'
try:
    from src.config import config
    DEFAULT_ADMIN_PASSWORD = os.environ.get('DEFAULT_ADMIN_PASSWORD', config.SECRET_KEY[:8] if config.SECRET_KEY else 'admin')
    if len(DEFAULT_ADMIN_PASSWORD) < 6:
        logger.warning("Senha padr√£o do admin √© muito curta, usando 'admin123' como alternativa.")
        DEFAULT_ADMIN_PASSWORD = 'admin123'
except (ImportError, ConfigurationError) as e:
    print(f"Aviso: N√£o foi poss√≠vel carregar a configura√ß√£o para senha do admin, usando '{DEFAULT_ADMIN_PASSWORD}'. Erro: {e}")

class SchemaManager:
    def __init__(self, engine: Engine):
        self.engine = engine
        logger.debug("SchemaManager inicializado com o engine do SQLAlchemy.")

    def initialize_schema(self):
        try:
            logger.info("Iniciando a cria√ß√£o do esquema do banco de dados...")
            Base.metadata.create_all(bind=self.engine)
            logger.info("Tabelas criadas/verificadas com sucesso.")

            with self.engine.connect() as connection:
                with connection.begin():
                    logger.debug("Verificando exist√™ncia do usu√°rio admin...")
                    self._ensure_admin_user_exists(connection)
                    logger.debug("Verifica√ß√£o do usu√°rio admin conclu√≠da.")

            logger.info("Esquema do banco de dados inicializado com sucesso.")

        except SQLAlchemyError as e:
            logger.critical(f"Falha na inicializa√ß√£o do esquema do banco de dados: {e}", exc_info=True)
            raise DatabaseError(f"Falha na inicializa√ß√£o do esquema: {e}") from e
        except Exception as e:
            logger.critical(f"Erro inesperado na inicializa√ß√£o do esquema: {e}", exc_info=True)
            raise DatabaseError(f"Falha na inicializa√ß√£o do esquema: {e}") from e

    def _ensure_admin_user_exists(self, connection: Connection):
        logger.debug("Verificando exist√™ncia do usu√°rio admin...")
        try:
            check_query = text("SELECT id FROM users WHERE LOWER(username) = LOWER(:username)")
            result = connection.execute(check_query, {'username': 'admin'})
            admin_user_row = result.fetchone()

            if not admin_user_row:
                logger.info("Usu√°rio admin n√£o encontrado. Criando...")
                password = DEFAULT_ADMIN_PASSWORD
                hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
                now_utc = datetime.now(timezone.utc)

                user_insert_query = text("""
                    INSERT INTO users (username, password_hash, name, email, created_at, is_active)
                    VALUES (:username, :password_hash, :name, :email, :created_at, :is_active)
                    RETURNING id
                """)
                user_result = connection.execute(user_insert_query, {
                    'username': 'admin', 'password_hash': hashed_password, 'name': 'Administrator',
                    'email': 'admin@example.com', 'created_at': now_utc, 'is_active': True
                })
                admin_id = user_result.scalar_one()
                logger.debug(f"Usu√°rio admin criado com ID: {admin_id}")

                perm_insert_query = text("""
                    INSERT INTO user_permissions
                    (user_id, is_admin, can_access_products, can_access_fabrics, can_access_customer_panel, can_access_fiscal, can_access_accounts_receivable)
                    VALUES (:user_id, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)
                """)
                connection.execute(perm_insert_query, {'user_id': admin_id})
                logger.info("Usu√°rio admin criado com permiss√µes totais.")
            else:
                admin_id = admin_user_row[0]
                logger.debug(f"Usu√°rio admin j√° existe (ID: {admin_id}). Verificando permiss√µes...")
                perm_upsert_query = text("""
                    INSERT INTO user_permissions (user_id, is_admin, can_access_products, can_access_fabrics, can_access_customer_panel, can_access_fiscal, can_access_accounts_receivable)
                    VALUES (:user_id, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)
                    ON CONFLICT (user_id) DO UPDATE SET
                        is_admin = EXCLUDED.is_admin,
                        can_access_products = EXCLUDED.can_access_products,
                        can_access_fabrics = EXCLUDED.can_access_fabrics,
                        can_access_customer_panel = EXCLUDED.can_access_customer_panel,
                        can_access_fiscal = EXCLUDED.can_access_fiscal,
                        can_access_accounts_receivable = EXCLUDED.can_access_accounts_receivable;
                """)
                connection.execute(perm_upsert_query, {'user_id': admin_id})
                logger.debug(f"Permiss√µes garantidas para o usu√°rio admin (ID: {admin_id}).")

        except IntegrityError as e:
            logger.warning(f"Falha ao criar/atualizar usu√°rio admin devido a restri√ß√£o de integridade: {e}")
        except SQLAlchemyError as e:
            logger.error(f"Erro SQLAlchemy ao garantir usu√°rio admin: {e}", exc_info=True)
            raise
        except Exception as e:
            logger.error(f"Erro inesperado ao garantir usu√°rio admin: {e}", exc_info=True)
            raise
</file>

<file path="src/database/user_repository.py">
# src/database/user_repository.py
# Gerencia opera√ß√µes de banco de dados relacionadas a Usu√°rios e Permiss√µes usando SQLAlchemy ORM.

from datetime import datetime, timezone
from typing import List, Optional, Dict, Any
from sqlalchemy import select, func, delete, update
from sqlalchemy.orm import Session, joinedload, selectinload
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.user import User, UserPermissions
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError

class UserRepository(BaseRepository):
    """
    Reposit√≥rio para gerenciar dados de Usu√°rio e Permiss√µes usando Sess√µes SQLAlchemy ORM.
    Os m√©todos agora esperam que um objeto Session seja passado.
    """

    def find_by_username(self, db: Session, username: str) -> Optional[User]:
        """
        Busca um usu√°rio ativo pelo nome de usu√°rio (case-insensitive) usando Sess√£o ORM.
        """
        logger.debug(f"ORM: Buscando usu√°rio ativo pelo username '{username}'")
        try:
            stmt = (
                select(User)
                .options(joinedload(User.permissions))
                .where(func.lower(User.username) == func.lower(username))
                .where(User.is_active == True)
            )
            user = db.scalars(stmt).first()

            if user:
                logger.debug(f"ORM: Usu√°rio encontrado pelo username '{username}': ID {user.id}")
            else:
                logger.debug(f"ORM: Usu√°rio ativo n√£o encontrado pelo username '{username}'.")
            return user
        except SQLAlchemyError as e:
            logger.error(f"ORM: Erro de banco de dados ao buscar usu√°rio pelo username '{username}': {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados ao buscar usu√°rio pelo username: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Erro inesperado ao buscar usu√°rio pelo username '{username}': {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado ao buscar usu√°rio pelo username: {e}") from e

    def find_by_id(self, db: Session, user_id: int) -> Optional[User]:
        """Busca um usu√°rio pelo ID usando Sess√£o ORM (independente do status ativo)."""
        logger.debug(f"ORM: Buscando usu√°rio pelo ID {user_id}")
        try:
            user = db.get(User, user_id, options=[joinedload(User.permissions)])
            if user:
                 logger.debug(f"ORM: Usu√°rio encontrado pelo ID {user_id}.")
                 if user.permissions is None:
                      logger.warning(f"ORM: Usu√°rio ID {user_id} encontrado, mas relacionamento permissions √© None. Inconsist√™ncia de dados?")
            else:
                 logger.debug(f"ORM: Usu√°rio n√£o encontrado pelo ID {user_id}.")
            return user
        except SQLAlchemyError as e:
            logger.error(f"ORM: Erro de banco de dados ao buscar usu√°rio pelo ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados ao buscar usu√°rio pelo ID: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Erro inesperado ao buscar usu√°rio pelo ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado ao buscar usu√°rio pelo ID: {e}") from e

    def get_all(self, db: Session) -> List[User]:
        """Recupera todos os usu√°rios do banco de dados usando Sess√£o ORM."""
        logger.debug("ORM: Recuperando todos os usu√°rios")
        try:
            stmt = select(User).options(joinedload(User.permissions)).order_by(User.username)
            users = db.scalars(stmt).all()
            logger.debug(f"ORM: Recuperados {len(users)} usu√°rios do banco de dados.")
            return list(users)
        except SQLAlchemyError as e:
             logger.error(f"ORM: Erro de banco de dados ao recuperar todos os usu√°rios: {e}", exc_info=True)
             raise DatabaseError(f"Erro de banco de dados ao recuperar todos os usu√°rios: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Erro inesperado ao recuperar todos os usu√°rios: {e}", exc_info=True)
             raise DatabaseError(f"Erro inesperado ao recuperar todos os usu√°rios: {e}") from e

    def add(self, db: Session, user: User) -> User:
        """Adiciona um novo usu√°rio e suas permiss√µes usando Sess√£o ORM."""
        if not user.username or not user.password_hash or not user.name:
             raise ValueError("Campos obrigat√≥rios faltando (username, password_hash, name) para Usu√°rio.")
        if user.permissions is None:
             logger.warning(f"Objeto User para '{user.username}' est√° sem objeto UserPermissions associado. Criando padr√£o.")
             user.permissions = UserPermissions()

        logger.debug(f"ORM: Adicionando usu√°rio '{user.username}' √† sess√£o")
        try:
            if user.created_at is None:
                user.created_at = datetime.now(timezone.utc)

            db.add(user)
            db.flush()
            logger.info(f"ORM: Usu√°rio '{user.username}' adicionado √† sess√£o (ID: {user.id}, Perm ID: {getattr(user.permissions, 'id', None)}). Commit pendente.")
            return user
        except IntegrityError as e:
            db.rollback()
            logger.warning(f"ORM: Erro de integridade do banco de dados ao adicionar usu√°rio '{user.username}': {e}")
            error_info = str(e.orig).lower() if e.orig else str(e).lower()
            if "users_username_key" in error_info or "unique constraint" in error_info and "username" in error_info:
                 raise ValueError(f"Username '{user.username}' j√° existe.")
            if "users_email_key" in error_info or "unique constraint" in error_info and "email" in error_info and user.email:
                 raise ValueError(f"Email '{user.email}' j√° existe.")
            raise DatabaseError(f"Falha ao adicionar usu√°rio devido a restri√ß√£o de integridade: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao adicionar usu√°rio '{user.username}': {e}", exc_info=True)
            raise DatabaseError(f"Falha ao adicionar usu√°rio: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao adicionar usu√°rio '{user.username}': {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao adicionar usu√°rio: {e}") from e


    def update(self, db: Session, user_to_update: User) -> User:
        """Atualiza um usu√°rio existente e suas permiss√µes usando Sess√£o ORM."""
        if user_to_update.id is None:
            raise ValueError("N√£o √© poss√≠vel atualizar usu√°rio sem um ID.")
        if not user_to_update.password_hash:
             raise ValueError("Hash de senha n√£o pode estar vazio para atualiza√ß√£o.")

        logger.debug(f"ORM: Atualizando usu√°rio ID {user_to_update.id} na sess√£o")
        try:
            db.flush()
            logger.info(f"ORM: Usu√°rio ID {user_to_update.id} marcado para atualiza√ß√£o na sess√£o. Commit pendente.")
            return user_to_update
        except IntegrityError as e:
            db.rollback()
            logger.warning(f"ORM: Erro de integridade do banco de dados ao atualizar usu√°rio ID {user_to_update.id}: {e}")
            error_info = str(e.orig).lower() if e.orig else str(e).lower()
            if "users_email_key" in error_info or "unique constraint" in error_info and "email" in error_info:
                 raise ValueError(f"Email '{user_to_update.email}' j√° est√° em uso por outro usu√°rio.")
            raise DatabaseError(f"Falha ao atualizar usu√°rio devido a restri√ß√£o de integridade: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao atualizar usu√°rio ID {user_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Falha ao atualizar usu√°rio: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao atualizar usu√°rio ID {user_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao atualizar usu√°rio: {e}") from e

    def delete(self, db: Session, user_id: int) -> bool:
        """Exclui um usu√°rio pelo ID usando Sess√£o ORM."""
        logger.debug(f"ORM: Excluindo usu√°rio ID {user_id}")
        try:
            user = db.get(User, user_id)
            if user:
                db.delete(user)
                db.flush()
                logger.info(f"ORM: Usu√°rio ID {user_id} marcado para exclus√£o na sess√£o. Commit pendente.")
                return True
            else:
                logger.warning(f"ORM: Tentativa de excluir usu√°rio ID {user_id}, mas usu√°rio n√£o foi encontrado.")
                return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao excluir usu√°rio ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Falha ao excluir usu√°rio: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao excluir usu√°rio ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao excluir usu√°rio: {e}") from e

    def update_last_login(self, db: Session, user_id: int) -> bool:
        """Atualiza o timestamp de √∫ltimo login para um usu√°rio usando Sess√£o ORM."""
        logger.debug(f"ORM: Atualizando √∫ltimo login para usu√°rio ID {user_id}")
        try:
            user = db.get(User, user_id)
            if user:
                user.last_login = datetime.now(timezone.utc)
                db.flush()
                logger.debug(f"ORM: √öltimo login do Usu√°rio ID {user_id} marcado para atualiza√ß√£o. Commit pendente.")
                return True
            else:
                 logger.warning(f"ORM: Falha ao atualizar √∫ltimo login para usu√°rio ID {user_id} (usu√°rio n√£o encontrado).")
                 return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Falha ao atualizar √∫ltimo login para usu√°rio ID {user_id}: {e}", exc_info=True)
            return False
        except Exception as e:
             db.rollback()
             logger.error(f"ORM: Erro inesperado ao atualizar √∫ltimo login para usu√°rio ID {user_id}: {e}", exc_info=True)
             return False
</file>

<file path="src/domain/__init__.py">
# src/domain/__init__.py
# Makes 'domain' a package. Exports domain models.

# ORM Models (j√° convertidos ou ser√£o nos pr√≥ximos passos)
from .user import User, UserPermissions
from .observation import Observation

# Dataclasses (ainda n√£o convertidos para ORM, se aplic√°vel)
# Se converter todos para ORM, remova os imports espec√≠ficos de dataclasses
# que foram substitu√≠dos.
from .balance import Balance, ProductItem, ProductResponse
from .cost import Cost, ProductCost, CostResponse
from .fabric_details import FabricDetailsItem, FabricDetailValue
from .person import Address, Phone, Email, IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from .fiscal import FormattedInvoiceListItem, InvoiceXmlOutDto, DanfeRequestModel, DanfeResponseModel
from .accounts_receivable import (
    DocumentChangeModel, DocumentFilterModel, DocumentRequestModel, DocumentModel,
    DocumentResponseModel, BankSlipRequestModel, AccountsReceivableTomasResponseModel,
    FormattedReceivableListItem, CalculatedValuesModel, InvoiceDataModel
)


# Mantemos todos os exports por enquanto. Se um modelo for *completamente*
# substitu√≠do e n√£o for mais usado como Dataclass em nenhum lugar,
# pode ser removido daqui. No entanto, √© seguro manter todos.
__all__ = [
    # ORM Models
    "User", "UserPermissions",
    "Observation",

    # Dataclasses (Potencialmente a serem convertidos ou usados como DTOs)
    "Balance", "ProductItem", "ProductResponse",
    "Cost", "ProductCost", "CostResponse",
    "FabricDetailsItem", "FabricDetailValue",
    "Address", "Phone", "Email", "IndividualDataModel", "LegalEntityDataModel", "PersonStatisticsResponseModel",
    "FormattedInvoiceListItem", "InvoiceXmlOutDto", "DanfeRequestModel", "DanfeResponseModel",
    "DocumentChangeModel", "DocumentFilterModel", "DocumentRequestModel", "DocumentModel",
    "DocumentResponseModel", "BankSlipRequestModel", "AccountsReceivableTomasResponseModel",
    "FormattedReceivableListItem", "CalculatedValuesModel", "InvoiceDataModel"
]
</file>

<file path="src/domain/accounts_receivable.py">
# src/domain/accounts_receivable.py
# Defines data models related to Accounts Receivable operations based on ERP API.

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from src.utils.logger import logger

# --- Models based on AccountsReceivable.json components/schemas ---

@dataclass(frozen=True)
class DocumentChangeModel:
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    in_check: Optional[bool] = None # API says boolean, not nullable? Check usage. Defaulting to None safety.

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentChangeModel']:
        if not data: return None
        return cls(
            start_date=data.get('startDate'),
            end_date=data.get('endDate'),
            in_check=data.get('inCheck')
        )

    def to_dict(self) -> Dict[str, Any]:
        d = {}
        if self.start_date is not None: d['startDate'] = self.start_date
        if self.end_date is not None: d['endDate'] = self.end_date
        if self.in_check is not None: d['inCheck'] = self.in_check
        return d

@dataclass(frozen=True)
class DocumentFilterModel:
    change: Optional[DocumentChangeModel] = None
    branch_code_list: Optional[List[int]] = field(default_factory=list)
    customer_code_list: Optional[List[int]] = field(default_factory=list)
    customer_cpf_cnpj_list: Optional[List[str]] = field(default_factory=list)
    start_expired_date: Optional[str] = None
    end_expired_date: Optional[str] = None
    start_payment_date: Optional[str] = None
    end_payment_date: Optional[str] = None
    start_issue_date: Optional[str] = None
    end_issue_date: Optional[str] = None
    start_credit_date: Optional[str] = None
    end_credit_date: Optional[str] = None
    status_list: Optional[List[int]] = field(default_factory=list)
    document_type_list: Optional[List[int]] = field(default_factory=list)
    billing_type_list: Optional[List[int]] = field(default_factory=list)
    discharge_type_list: Optional[List[int]] = field(default_factory=list)
    charge_type_list: Optional[List[int]] = field(default_factory=list)
    has_open_invoices: Optional[bool] = None
    receivable_code_list: Optional[List[float]] = field(default_factory=list) # API uses number/double
    our_number_list: Optional[List[float]] = field(default_factory=list) # API uses number/double
    commissioned_code: Optional[int] = None
    commissioned_cpf_cnpj: Optional[str] = None
    closing_code_commission: Optional[int] = None
    closing_company_commission: Optional[int] = None
    closing_date_commission: Optional[str] = None
    closing_commissioned_code: Optional[int] = None
    closing_commissioned_cpf_cnpj: Optional[str] = None

    # No from_dict needed, service layer builds this for the request
    def to_dict(self) -> Dict[str, Any]:
        d = {}
        if self.change: d['change'] = self.change.to_dict()
        if self.branch_code_list: d['branchCodeList'] = self.branch_code_list
        if self.customer_code_list: d['customerCodeList'] = self.customer_code_list
        if self.customer_cpf_cnpj_list: d['customerCpfCnpjList'] = self.customer_cpf_cnpj_list
        if self.start_expired_date: d['startExpiredDate'] = self.start_expired_date
        if self.end_expired_date: d['endExpiredDate'] = self.end_expired_date
        if self.start_payment_date: d['startPaymentDate'] = self.start_payment_date
        if self.end_payment_date: d['endPaymentDate'] = self.end_payment_date
        if self.start_issue_date: d['startIssueDate'] = self.start_issue_date
        if self.end_issue_date: d['endIssueDate'] = self.end_issue_date
        if self.start_credit_date: d['startCreditDate'] = self.start_credit_date
        if self.end_credit_date: d['endCreditDate'] = self.end_credit_date
        if self.status_list: d['statusList'] = self.status_list
        if self.document_type_list: d['documentTypeList'] = self.document_type_list
        if self.billing_type_list: d['billingTypeList'] = self.billing_type_list
        if self.discharge_type_list: d['dischargeTypeList'] = self.discharge_type_list
        if self.charge_type_list: d['chargeTypeList'] = self.charge_type_list
        if self.has_open_invoices is not None: d['hasOpenInvoices'] = self.has_open_invoices
        if self.receivable_code_list: d['receivableCodeList'] = self.receivable_code_list
        if self.our_number_list: d['ourNumberList'] = self.our_number_list
        if self.commissioned_code: d['commissionedCode'] = self.commissioned_code
        if self.commissioned_cpf_cnpj: d['commissionedCpfCnpj'] = self.commissioned_cpf_cnpj
        if self.closing_code_commission: d['closingCodeCommission'] = self.closing_code_commission
        if self.closing_company_commission: d['closingCompanyCommission'] = self.closing_company_commission
        if self.closing_date_commission: d['closingDateCommission'] = self.closing_date_commission
        if self.closing_commissioned_code: d['closingCommissionedCode'] = self.closing_commissioned_code
        if self.closing_commissioned_cpf_cnpj: d['closingCommissionedCpfCnpj'] = self.closing_commissioned_cpf_cnpj
        return d


@dataclass(frozen=True)
class DocumentRequestModel:
    filter: Optional[DocumentFilterModel] = None
    expand: Optional[str] = None
    order: Optional[str] = None
    page: int = 1
    page_size: int = 100

    # No from_dict needed, service layer builds this
    def to_dict(self) -> Dict[str, Any]:
        d = {
            "page": self.page,
            "pageSize": self.page_size,
        }
        if self.filter: d['filter'] = self.filter.to_dict()
        if self.expand: d['expand'] = self.expand
        if self.order: d['order'] = self.order
        return d

@dataclass(frozen=True)
class CalculatedValuesModel:
    days_late: Optional[int] = None
    increase_value: Optional[float] = None
    interest_value: Optional[float] = None
    fine_value: Optional[float] = None
    discount_value: Optional[float] = None
    corrected_value: Optional[float] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['CalculatedValuesModel']:
        if not data: return None
        return cls(
            days_late=data.get('daysLate'),
            increase_value=data.get('increaseValue'),
            interest_value=data.get('interestValue'),
            fine_value=data.get('fineValue'),
            discount_value=data.get('discountValue'),
            corrected_value=data.get('correctedValue')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__ # Simple mapping

# Define CheckInstallmentModel, InvoiceDataModel, CommissionDataModel similarly if needed
# For brevity, we'll focus on the main DocumentModel and the formatted output
@dataclass(frozen=True)
class InvoiceDataModel: # Placeholder - add fields as needed
    invoice_code: Optional[int] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['InvoiceDataModel']:
        if not data: return None
        return cls(invoice_code=data.get('invoiceCode'))

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__

@dataclass(frozen=True)
class DocumentModel:
    # Core Fields
    branch_code: Optional[int] = None
    customer_code: Optional[int] = None
    customer_cpf_cnpj: Optional[str] = None
    receivable_code: Optional[int] = None # API uses int64
    installment_code: Optional[int] = None
    max_change_filter_date: Optional[str] = None
    expired_date: Optional[str] = None
    payment_date: Optional[str] = None
    issue_date: Optional[str] = None
    settlement_branch_code: Optional[int] = None
    settlement_date: Optional[str] = None
    settlement_sequence: Optional[int] = None
    status: Optional[int] = None
    document_type: Optional[int] = None
    billing_type: Optional[int] = None
    discharge_type: Optional[int] = None
    charge_type: Optional[int] = None
    origin_installment: Optional[int] = None
    bearer_code: Optional[int] = None
    bearer_name: Optional[str] = None
    installment_value: Optional[float] = None
    paid_value: Optional[float] = None
    net_value: Optional[float] = None
    discount_value: Optional[float] = None
    rebate_value: Optional[float] = None
    interest_value: Optional[float] = None # Distinct from calculated_values.interest_value
    assessment_value: Optional[float] = None # Distinct from calculated_values.fine_value
    bar_code: Optional[str] = None
    digitable_line: Optional[str] = None
    our_number: Optional[int] = None # API uses int64
    dac_our_number: Optional[str] = None
    qr_code_pix: Optional[str] = None
    discharge_user: Optional[int] = None
    registration_user: Optional[int] = None
    # Expanded Fields (optional based on 'expand' parameter)
    calculated_values: Optional[CalculatedValuesModel] = None
    check: Optional[Dict[str, Any]] = None # Simplified for now
    invoice: Optional[List[InvoiceDataModel]] = field(default_factory=list)
    commissions: Optional[List[Dict[str, Any]]] = field(default_factory=list) # Simplified

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentModel']:
        if not data: return None

        calculated_values = CalculatedValuesModel.from_dict(data.get('calculatedValues'))
        invoices_raw = data.get('invoice', [])
        invoices = [InvoiceDataModel.from_dict(inv) for inv in invoices_raw if inv] if isinstance(invoices_raw, list) else []
        invoices = [inv for inv in invoices if inv is not None] # Filter out Nones


        return cls(
            branch_code=data.get('branchCode'),
            customer_code=data.get('customerCode'),
            customer_cpf_cnpj=data.get('customerCpfCnpj'),
            receivable_code=data.get('receivableCode'),
            installment_code=data.get('installmentCode'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            expired_date=data.get('expiredDate'),
            payment_date=data.get('paymentDate'),
            issue_date=data.get('issueDate'),
            settlement_branch_code=data.get('settlementBranchCode'),
            settlement_date=data.get('settlementDate'),
            settlement_sequence=data.get('settlementSequence'),
            status=data.get('status'),
            document_type=data.get('documentType'),
            billing_type=data.get('billingType'),
            discharge_type=data.get('dischargeType'),
            charge_type=data.get('chargeType'),
            origin_installment=data.get('originInstallment'),
            bearer_code=data.get('bearerCode'),
            bearer_name=data.get('bearerName'),
            installment_value=data.get('installmentValue'),
            paid_value=data.get('paidValue'),
            net_value=data.get('netValue'),
            discount_value=data.get('discountValue'),
            rebate_value=data.get('rebateValue'),
            interest_value=data.get('interestValue'),
            assessment_value=data.get('assessmentValue'),
            bar_code=data.get('barCode'),
            digitable_line=data.get('digitableLine'),
            our_number=data.get('ourNumber'),
            dac_our_number=data.get('dacOurNumber'),
            qr_code_pix=data.get('qrCodePix'),
            discharge_user=data.get('dischargeUser'),
            registration_user=data.get('registrationUser'),
            calculated_values=calculated_values,
            check=data.get('check'), # Keep as dict for now
            invoice=invoices,
            commissions=data.get('commissions') # Keep as list of dicts
        )

    def to_dict(self) -> Dict[str, Any]:
        d = self.__dict__.copy()
        if self.calculated_values: d['calculated_values'] = self.calculated_values.to_dict()
        if self.invoice: d['invoice'] = [inv.to_dict() for inv in self.invoice]
        # check and commissions kept as dicts/list of dicts
        return d


@dataclass(frozen=True)
class DocumentResponseModel:
    count: int = 0
    total_pages: int = 0
    has_next: bool = False
    total_items: int = 0
    items: List[DocumentModel] = field(default_factory=list)

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentResponseModel']:
        if not data: return None
        items_raw = data.get('items', [])
        items = [DocumentModel.from_dict(item) for item in items_raw if item] if isinstance(items_raw, list) else []
        items = [item for item in items if item is not None]

        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "count": self.count,
            "totalPages": self.total_pages,
            "hasNext": self.has_next,
            "totalItems": self.total_items,
            "items": [item.to_dict() for item in self.items]
        }

@dataclass(frozen=True)
class BankSlipRequestModel:
    branch_code: int
    customer_code: int
    receivable_code: int # API int64
    installment_number: int
    customer_cpf_cnpj: Optional[str] = None # Keep this field in the model

    def to_dict(self) -> Dict[str, Any]:
        d = {
            "branchCode": self.branch_code,
            "customerCode": self.customer_code, # Always include customerCode
            "receivableCode": self.receivable_code,
            "installmentNumber": self.installment_number,
        }
        # Only add customerCpfCnpj if customerCode is somehow missing (shouldn't happen with current validation)
        # OR if the API strictly requires *only one*, then we never add CpfCnpj here.
        # Let's enforce sending only customerCode as requested.
        # if not self.customer_code and self.customer_cpf_cnpj:
        #     d['customerCpfCnpj'] = self.customer_cpf_cnpj
        # Since customerCode is required, we simply don't add customerCpfCnpj to the dict being sent to ERP.
        return d

@dataclass(frozen=True)
class AccountsReceivableTomasResponseModel:
    content: Optional[str] = None
    uniface_response_status: Optional[str] = None
    uniface_message: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['AccountsReceivableTomasResponseModel']:
        if not data: return None
        return cls(
            content=data.get('content'),
            uniface_response_status=data.get('unifaceResponseStatus'),
            uniface_message=data.get('unifaceMessage')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__


# --- Formatted output model for the /search endpoint ---
@dataclass(frozen=True)
class FormattedReceivableListItem:
    customer_code: Optional[int] = None
    customer_cpf_cnpj: Optional[str] = None
    customer_name: Optional[str] = None # Enriched field
    invoice_number: Optional[int] = None # From nested invoice -> invoiceCode
    document_number: Optional[int] = None # receivableCode
    installment_number: Optional[int] = None # installmentCode
    bearer_name: Optional[str] = None
    issue_date: Optional[str] = None
    expired_date: Optional[str] = None
    days_late: Optional[int] = None # From calculated_values
    payment_date: Optional[str] = None
    value_original: Optional[float] = None # installmentValue
    value_increase: Optional[float] = None # Combined calculated values
    value_rebate: Optional[float] = None # Combined rebate/discount values
    value_paid: Optional[float] = None # paidValue
    value_corrected: Optional[float] = None # From calculated_values
    status: Optional[int] = None
    document_type: Optional[int] = None
    billing_type: Optional[int] = None
    discharge_type: Optional[int] = None
    charge_type: Optional[int] = None

    # No from_dict needed, built in service layer
    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__
</file>

<file path="src/domain/balance.py">
# src/domain/balance.py
# Defines data models related to product balances from the ERP.

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from src.utils.logger import logger # Use the application's configured logger

@dataclass(frozen=True)
class Balance:
    """
    Represents a single balance entry for a product variant. Immutable.

    Corresponds to an item within the 'balances' list in the ERP API response.
    """
    branch_code: int
    stock_code: int
    stock_description: str
    stock: int = 0
    sales_order: int = 0
    input_transaction: int = 0
    output_transaction: int = 0
    production_order_progress: int = 0
    production_order_wait_lib: int = 0
    stock_temp: Optional[int] = None
    production_planning: Optional[int] = None
    purchase_order: Optional[int] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Balance object to a dictionary."""
        return self.__dict__ # Dataclasses provide __dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Balance':
        """Creates a Balance object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for Balance.from_dict: {type(data)}")
            raise ValueError("Invalid data format for Balance")
        return cls(
            branch_code=data.get('branchCode', 0),
            stock_code=data.get('stockCode', 0),
            stock_description=data.get('stockDescription', ''),
            stock=data.get('stock', 0),
            sales_order=data.get('salesOrder', 0),
            input_transaction=data.get('inputTransaction', 0),
            output_transaction=data.get('outputTransaction', 0),
            production_order_progress=data.get('productionOrderProgress', 0),
            production_order_wait_lib=data.get('productionOrderWaitLib', 0),
            stock_temp=data.get('stockTemp'),
            production_planning=data.get('productionPlanning'),
            purchase_order=data.get('purchaseOrder')
        )

@dataclass(frozen=True)
class ProductItem:
    """
    Represents a product variant (SKU) with its details and balances. Immutable.

    Corresponds to an item within the 'items' list in the ERP API balance response.
    """
    product_code: int
    product_name: str
    product_sku: str
    reference_code: str
    color_code: str
    color_name: str
    size_name: str
    balances: List[Balance] = field(default_factory=list)
    locations: Optional[List[Any]] = None # Type hint could be more specific if structure is known
    max_change_filter_date: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductItem object to a dictionary."""
        return {
            **self.__dict__, # Get base attributes
            'balances': [b.to_dict() for b in self.balances] # Convert nested balances
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductItem':
        """Creates a ProductItem object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductItem.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductItem")

        balances_data = data.get('balances', [])
        if not isinstance(balances_data, list):
             logger.warning(f"Invalid 'balances' format in ProductItem data for product {data.get('productCode')}. Expected list, got {type(balances_data)}.")
             balances = []
        else:
             balances = [Balance.from_dict(b_data) for b_data in balances_data if isinstance(b_data, dict)]

        return cls(
            product_code=data.get('productCode', 0),
            product_name=data.get('productName', ''),
            product_sku=data.get('productSku', ''),
            reference_code=data.get('referenceCode', ''),
            color_code=data.get('colorCode', ''),
            color_name=data.get('colorName', ''),
            size_name=data.get('sizeName', ''),
            balances=balances,
            locations=data.get('locations'),
            max_change_filter_date=data.get('maxChangeFilterDate')
        )

    # --- Balance Calculation Methods ---
    # These methods assume the relevant balance data is in the *first* Balance object
    # in the balances list, which seems to be the pattern in the original code.
    # Consider adding checks or making this assumption explicit.

    def _get_primary_balance(self) -> Optional[Balance]:
        """Helper to get the primary balance object (first in the list)."""
        if self.balances:
            return self.balances[0]
        logger.warning(f"ProductItem {self.product_code} has no balance data.")
        return None

    def calculate_base_balance(self) -> int:
        """Calculates base balance: stock + input - output."""
        balance = self._get_primary_balance()
        if balance:
            return balance.stock + balance.input_transaction - balance.output_transaction
        return 0

    def calculate_sales_balance(self) -> int:
        """Calculates balance considering sales orders: base_balance - sales_order."""
        balance = self._get_primary_balance()
        if balance:
            return self.calculate_base_balance() - balance.sales_order
        return 0

    def calculate_production_balance(self) -> int:
        """Calculates balance considering sales and production: base_balance - sales + production."""
        balance = self._get_primary_balance()
        if balance:
            return (self.calculate_base_balance() - balance.sales_order +
                    balance.production_order_progress + balance.production_order_wait_lib)
        return 0

    def get_balance_for_mode(self, mode: str) -> int:
        """
        Returns the calculated balance based on the specified mode.

        Args:
            mode: Calculation mode ('base', 'sales', 'production').

        Returns:
            The calculated balance value.

        Raises:
            ValueError: If the mode is unrecognized.
        """
        if mode == 'base':
            return self.calculate_base_balance()
        elif mode == 'sales':
            return self.calculate_sales_balance()
        elif mode == 'production':
            return self.calculate_production_balance()
        else:
            logger.error(f"Unrecognized balance calculation mode: {mode}")
            raise ValueError(f"Unrecognized balance calculation mode: {mode}")


@dataclass(frozen=True)
class ProductResponse:
    """
    Represents the overall structure of the balance API response. Immutable.
    """
    count: int
    total_pages: int
    has_next: bool
    total_items: int
    items: List[ProductItem] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductResponse object to a dictionary."""
        return {
             **self.__dict__,
            'items': [item.to_dict() for item in self.items]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductResponse':
        """
        Creates a ProductResponse object from the raw API response dictionary.

        Args:
            data: The dictionary parsed from the API JSON response.

        Returns:
            A ProductResponse object.

        Raises:
            ValueError: If the input data is not a dictionary or has invalid format.
        """
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductResponse.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductResponse")

        items_data = data.get('items', [])
        if not isinstance(items_data, list):
            logger.warning(f"Invalid 'items' format in ProductResponse data. Expected list, got {type(items_data)}.")
            items = []
        else:
            items = []
            for item_data in items_data:
                 if isinstance(item_data, dict):
                     try:
                         items.append(ProductItem.from_dict(item_data))
                     except ValueError as e:
                          logger.error(f"Skipping invalid item in ProductResponse: {e} - Data: {item_data}")
                 else:
                     logger.warning(f"Skipping non-dict item in ProductResponse items list: {item_data}")


        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )
</file>

<file path="src/domain/cost.py">
# src/domain/cost.py
# Defines data models related to product costs from the ERP.

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from src.utils.logger import logger # Use the application's configured logger

@dataclass(frozen=True)
class Cost:
    """
    Represents a single cost entry for a product variant. Immutable.

    Corresponds to an item within the 'costs' list in the ERP API response.
    """
    branch_code: int
    cost_code: int
    cost_name: str
    cost: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Cost object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Cost':
        """Creates a Cost object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for Cost.from_dict: {type(data)}")
            raise ValueError("Invalid data format for Cost")
        return cls(
            branch_code=data.get('branchCode', 0),
            cost_code=data.get('costCode', 0),
            cost_name=data.get('costName', ''),
            cost=data.get('cost', 0.0) # Ensure float conversion if necessary
        )

@dataclass(frozen=True)
class ProductCost:
    """
    Represents a product variant (SKU) with its details and costs. Immutable.

    Corresponds to an item within the 'items' list in the ERP API cost response.
    """
    product_code: int
    product_name: str
    product_sku: str
    reference_code: str
    color_code: str
    color_name: str
    size_name: str
    costs: List[Cost] = field(default_factory=list)
    max_change_filter_date: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductCost object to a dictionary."""
        return {
            **self.__dict__,
            'costs': [c.to_dict() for c in self.costs]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductCost':
        """Creates a ProductCost object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductCost.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductCost")

        costs_data = data.get('costs', [])
        if not isinstance(costs_data, list):
            logger.warning(f"Invalid 'costs' format in ProductCost data for product {data.get('productCode')}. Expected list, got {type(costs_data)}.")
            costs = []
        else:
            costs = [Cost.from_dict(c_data) for c_data in costs_data if isinstance(c_data, dict)]

        return cls(
            product_code=data.get('productCode', 0),
            product_name=data.get('productName', ''),
            product_sku=data.get('productSku', ''),
            reference_code=data.get('referenceCode', ''),
            color_code=data.get('colorCode', ''),
            color_name=data.get('colorName', ''),
            size_name=data.get('sizeName', ''),
            costs=costs,
            max_change_filter_date=data.get('maxChangeFilterDate')
        )

    def get_primary_cost_value(self) -> float:
        """
        Returns the value of the primary cost (first in the list).

        Returns:
            Cost value (float) or 0.0 if no costs are available.
        """
        if self.costs:
            return self.costs[0].cost
        logger.warning(f"ProductCost {self.product_code} has no cost data.")
        return 0.0

@dataclass(frozen=True)
class CostResponse:
    """
    Represents the overall structure of the cost API response. Immutable.
    """
    count: int
    total_pages: int
    has_next: bool
    total_items: int
    items: List[ProductCost] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the CostResponse object to a dictionary."""
        return {
             **self.__dict__,
            'items': [item.to_dict() for item in self.items]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CostResponse':
        """
        Creates a CostResponse object from the raw API response dictionary.

        Args:
            data: The dictionary parsed from the API JSON response.

        Returns:
            A CostResponse object.

        Raises:
            ValueError: If the input data is not a dictionary or has invalid format.
        """
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for CostResponse.from_dict: {type(data)}")
            raise ValueError("Invalid data format for CostResponse")

        items_data = data.get('items', [])
        if not isinstance(items_data, list):
             logger.warning(f"Invalid 'items' format in CostResponse data. Expected list, got {type(items_data)}.")
             items = []
        else:
            items = []
            for item_data in items_data:
                 if isinstance(item_data, dict):
                      try:
                          items.append(ProductCost.from_dict(item_data))
                      except ValueError as e:
                           logger.error(f"Skipping invalid item in CostResponse: {e} - Data: {item_data}")
                 else:
                      logger.warning(f"Skipping non-dict item in CostResponse items list: {item_data}")

        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )
</file>

<file path="src/domain/fabric_details.py">
# src/domain/fabric_details.py
# Defines data models related to fabric-specific details (width, grammage, etc.) from the ERP.
# Renamed from original product_model.py for clarity.

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from src.utils.logger import logger

@dataclass(frozen=True)
class FabricDetailValue:
    """
    Represents a single additional field value for a fabric. Immutable.

    Corresponds to an item in the 'additionalFields' list in the ERP Product API response.
    """
    code: int # Field code (e.g., 1=Width, 2=Grammage, 3=Shrinkage)
    name: str # Field name (provided by ERP)
    value: Any # Field value (can be string, number, etc.)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FabricDetailValue object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['FabricDetailValue']:
        """Creates a FabricDetailValue from a dictionary, returns None if invalid."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for FabricDetailValue.from_dict: {type(data)}")
            return None
        try:
            # Basic validation
            code = int(data.get('code'))
            name = str(data.get('name', ''))
            value = data.get('value') # Keep original type for flexibility
            return cls(code=code, name=name, value=value)
        except (TypeError, ValueError, KeyError) as e:
            logger.error(f"Error creating FabricDetailValue from dict: {e}. Data: {data}")
            return None


@dataclass(frozen=True)
class FabricDetailsItem:
    """
    Represents a fabric product with its specific details (width, grammage, shrinkage). Immutable.

    Derived from the ERP Product API response, focusing on relevant additional fields.
    """
    product_code: int
    width: Optional[float] = None      # Largura (Code 1)
    grammage: Optional[float] = None   # Gramatura (Code 2)
    shrinkage: Optional[float] = None  # Encolhimento (Code 3)
    # Add other relevant fields if needed from the base product data
    # product_name: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FabricDetailsItem object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_product_api_item(cls, item_data: Dict[str, Any]) -> Optional['FabricDetailsItem']:
        """
        Creates a FabricDetailsItem from a single item dictionary from the ERP Product API response.

        Args:
            item_data: Dictionary representing one product item from the ERP API.

        Returns:
            A FabricDetailsItem object or None if essential data is missing or invalid.
        """
        if not isinstance(item_data, dict):
            logger.warning(f"Invalid item_data type for FabricDetailsItem: {type(item_data)}")
            return None

        product_code = item_data.get('productCode')
        if not product_code:
            logger.warning("Skipping item in FabricDetailsItem creation: missing productCode.")
            return None

        additional_fields_data = item_data.get('additionalFields', [])
        if not isinstance(additional_fields_data, list):
            logger.warning(f"Invalid 'additionalFields' format for product {product_code}. Expected list.")
            additional_fields_data = []

        width = None
        grammage = None
        shrinkage = None

        for field_data in additional_fields_data:
            field_obj = FabricDetailValue.from_dict(field_data)
            if field_obj and field_obj.value is not None: # Check if value exists
                try:
                    if field_obj.code == 1:  # Largura
                        width = float(field_obj.value)
                    elif field_obj.code == 2:  # Gramatura
                        grammage = float(field_obj.value)
                    elif field_obj.code == 3:  # Encolhimento
                        shrinkage = float(field_obj.value)
                except (ValueError, TypeError) as e:
                    logger.warning(f"Could not convert fabric detail value for product {product_code}, field code {field_obj.code}. Value: '{field_obj.value}', Error: {e}")

        return cls(
            product_code=product_code,
            width=width,
            grammage=grammage,
            shrinkage=shrinkage
            # product_name=item_data.get('productName') # Optionally include name
        )

# Note: The overall Product Response structure for the /products/search endpoint
# is similar to Balance/Cost responses, but might have slightly different fields.
# If needed, a dedicated FabricDetailsResponse dataclass could be created,
# similar to ProductResponse or CostResponse. For now, the erp_product_service
# might just return a list of FabricDetailsItem.
</file>

<file path="src/domain/fiscal_orm.py">
# src/domain/fiscal_orm.py
# Define os modelos ORM para as tabelas Fiscais usando SQLAlchemy.

from datetime import datetime, date, time # Importar tipos necess√°rios
from typing import Optional, List, Dict, Any # Importar tipos necess√°rios
from sqlalchemy import (
    Integer, String, Text, Boolean, DateTime, Date, Time, Numeric, ForeignKey, func
)
from sqlalchemy.orm import relationship, Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP, VARCHAR, NUMERIC # Tipos espec√≠ficos PG

# Importar Base
from src.database.base import Base
from src.utils.logger import logger

# --- Tabela Principal: Nota Fiscal ---
class NotaFiscalOrm(Base):
    __tablename__ = 'nota_fiscal'

    # Chave Prim√°ria Composta (ou usar um ID √∫nico se preferir?)
    # Usar sequence parece mais robusto como PK se branchCode puder repetir.
    # Vamos usar um ID autoincremento por simplicidade e indexar a chave natural.
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    branch_code: Mapped[int] = mapped_column(Integer, nullable=False, index=True) # FK para 'empresas' (futuro)
    invoice_sequence: Mapped[int] = mapped_column(Integer, nullable=False, index=True)

    # --- Chave Natural (para busca/unicidade) ---
    # unique constraint para (branch_code, invoice_sequence) pode ser adicionado via Alembic
    # __table_args__ = (UniqueConstraint('branch_code', 'invoice_sequence', name='uq_nota_fiscal_branch_sequence'),)

    # --- Dados da Empresa/Pessoa ---
    branch_cnpj: Mapped[Optional[str]] = mapped_column(VARCHAR(14))
    person_code: Mapped[Optional[int]] = mapped_column(Integer, index=True) # FK para 'pessoas' (futuro)
    person_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Identifica√ß√£o da Nota ---
    invoice_code: Mapped[Optional[int]] = mapped_column(Integer, index=True) # N√∫mero da NF-e
    serial_code: Mapped[Optional[str]] = mapped_column(VARCHAR(5)) # S√©rie
    invoice_status: Mapped[Optional[str]] = mapped_column(VARCHAR(20)) # Issued, Canceled, etc.
    access_key: Mapped[Optional[str]] = mapped_column(VARCHAR(44), unique=True, index=True) # Chave de Acesso (pode ser PK?)
    electronic_invoice_status: Mapped[Optional[str]] = mapped_column(VARCHAR(30)) # Authorized, Canceled, Denied
    receipt: Mapped[Optional[str]] = mapped_column(Text) # Protocolo/Recibo (pode ser longo?)
    receivement_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True)) # Data autoriza√ß√£o
    disable_protocol: Mapped[Optional[str]] = mapped_column(Text)
    disable_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))

    # --- Dados da Transa√ß√£o/Opera√ß√£o ---
    transaction_branch_code: Mapped[Optional[int]] = mapped_column(Integer)
    transaction_date: Mapped[Optional[date]] = mapped_column(Date)
    transaction_code: Mapped[Optional[int]] = mapped_column(Integer)
    inclusion_component_code: Mapped[Optional[str]] = mapped_column(VARCHAR(30))
    user_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'usuarios' (futuro)
    origin: Mapped[Optional[str]] = mapped_column(VARCHAR(20)) # Own, ThirdParty
    document_type: Mapped[Optional[int]] = mapped_column(Integer) # 55, 65
    operation_type: Mapped[Optional[str]] = mapped_column(VARCHAR(10)) # Input, Output
    operation_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'operacoes' (futuro)
    operation_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Datas e Horas ---
    invoice_date: Mapped[Optional[date]] = mapped_column(Date) # Data de movimento
    issue_date: Mapped[Optional[date]] = mapped_column(Date, index=True) # Data de emiss√£o
    release_date: Mapped[Optional[date]] = mapped_column(Date) # Data de lan√ßamento
    exit_time: Mapped[Optional[time]] = mapped_column(Time) # Hora de sa√≠da
    lastchange_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True), index=True) # Ultima altera√ß√£o ERP

    # --- Valores Totais ---
    # Usar NUMERIC para valores monet√°rios
    payment_condition_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'cond_pagamento' (futuro)
    payment_condition_name: Mapped[Optional[str]] = mapped_column(Text)
    discount_percentage: Mapped[Optional[float]] = mapped_column(NUMERIC(10, 4)) # Ajustar precis√£o/escala
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4)) # Ajustar precis√£o/escala
    product_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2)) # Ajustar precis√£o/escala
    additional_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    shipping_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    insurance_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    ipi_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    base_icms_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    icms_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    icms_subst_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    total_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))

    # --- Dados de Frete ---
    shipping_company_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'pessoas' (futuro)
    shipping_company_name: Mapped[Optional[str]] = mapped_column(Text)
    freight_type: Mapped[Optional[str]] = mapped_column(VARCHAR(50)) # CIF, FOB, etc.
    freight_type_redispatch: Mapped[Optional[str]] = mapped_column(VARCHAR(50))
    freight_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    package_number: Mapped[Optional[int]] = mapped_column(Integer)
    gross_weight: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 3)) # Ajustar precis√£o/escala
    net_weight: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 3))
    species: Mapped[Optional[str]] = mapped_column(VARCHAR(50))

    # --- Outros ---
    terminal_code: Mapped[Optional[int]] = mapped_column(Integer)
    observation_nfe: Mapped[Optional[str]] = mapped_column(Text) # Campo √∫nico de obs NFE

    # Timestamps locais
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=func.now(), nullable=False)
    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=func.now(), onupdate=func.now(), nullable=False)

    # --- Relacionamentos (um-para-muitos) ---
    items: Mapped[List["NotaFiscalItemOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    payments: Mapped[List["NotaFiscalPagamentoOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    sales_orders: Mapped[List["NotaFiscalPedidoVendaOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    observations: Mapped[List["NotaFiscalObservacaoOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")

    def __repr__(self):
        return f"<NotaFiscalOrm(id={self.id}, branch={self.branch_code}, seq={self.invoice_sequence}, num={self.invoice_code}, key=...{str(self.access_key)[-6:] if self.access_key else 'N/A'})>"


# --- Tabela de Itens da Nota Fiscal ---
class NotaFiscalItemOrm(Base):
    __tablename__ = 'nota_fiscal_item'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    sequence: Mapped[int] = mapped_column(Integer, nullable=False)
    code: Mapped[Optional[str]] = mapped_column(Text) # C√≥digo fiscal do produto
    name: Mapped[Optional[str]] = mapped_column(Text)
    ncm: Mapped[Optional[str]] = mapped_column(VARCHAR(12))
    cfop: Mapped[Optional[int]] = mapped_column(Integer)
    measure_unit: Mapped[Optional[str]] = mapped_column(VARCHAR(6))
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4))
    gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    unit_gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6)) # Mais casas decimais para unit√°rio
    unit_discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    additional_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    freight_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    insurance_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    additional_item_information: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="items")

    # --- Relacionamento (um-para-muitos para produtos do item) ---
    item_products: Mapped[List["NotaFiscalItemProdutoOrm"]] = relationship(back_populates="item", cascade="all, delete-orphan", lazy="select")

    def __repr__(self):
        return f"<NotaFiscalItemOrm(id={self.id}, nf_id={self.nota_fiscal_id}, seq={self.sequence})>"


# --- Tabela de Produtos do Item da Nota Fiscal ---
class NotaFiscalItemProdutoOrm(Base):
    __tablename__ = 'nota_fiscal_item_produto'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    item_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal_item.id', ondelete='CASCADE'), index=True)

    product_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'produtos' (futuro)
    product_name: Mapped[Optional[str]] = mapped_column(Text)
    dealer_code: Mapped[Optional[int]] = mapped_column(Integer)
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4))
    unit_gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))

    # --- Relacionamento (muitos-para-um) ---
    item: Mapped["NotaFiscalItemOrm"] = relationship(back_populates="item_products")

    def __repr__(self):
        return f"<NotaFiscalItemProdutoOrm(id={self.id}, item_id={self.item_id}, product_code={self.product_code})>"


# --- Tabela de Pagamentos da Nota Fiscal ---
class NotaFiscalPagamentoOrm(Base):
    __tablename__ = 'nota_fiscal_pagamento'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    document_number: Mapped[Optional[int]] = mapped_column(Integer)
    expiration_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))
    payment_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    document_type_code: Mapped[Optional[int]] = mapped_column(Integer)
    document_type: Mapped[Optional[str]] = mapped_column(VARCHAR(50))
    installment: Mapped[Optional[int]] = mapped_column(Integer)
    bearer_code: Mapped[Optional[int]] = mapped_column(Integer)
    bearer_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="payments")

    def __repr__(self):
        return f"<NotaFiscalPagamentoOrm(id={self.id}, nf_id={self.nota_fiscal_id}, installment={self.installment})>"


# --- Tabela de Pedidos de Venda da Nota Fiscal ---
class NotaFiscalPedidoVendaOrm(Base):
    __tablename__ = 'nota_fiscal_pedido_venda'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    branch_code: Mapped[Optional[int]] = mapped_column(Integer)
    order_code: Mapped[Optional[int]] = mapped_column(Integer, index=True)
    customer_order_code: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="sales_orders")

    def __repr__(self):
        return f"<NotaFiscalPedidoVendaOrm(id={self.id}, nf_id={self.nota_fiscal_id}, order_code={self.order_code})>"


# --- Tabela de Observa√ß√µes da Nota Fiscal ---
class NotaFiscalObservacaoOrm(Base):
    __tablename__ = 'nota_fiscal_observacao'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    observation: Mapped[Optional[str]] = mapped_column(Text)
    sequence: Mapped[Optional[int]] = mapped_column(Integer)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="observations")

    def __repr__(self):
        return f"<NotaFiscalObservacaoOrm(id={self.id}, nf_id={self.nota_fiscal_id}, seq={self.sequence})>"
</file>

<file path="src/domain/fiscal.py">
# src/domain/fiscal.py
# Defines data models related to Fiscal module operations (DANFE, XML, Invoice List).

from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
from src.utils.logger import logger

@dataclass(frozen=True)
class FormattedInvoiceListItem:
    """Represents essential data for an invoice in a list view, formatted for API response."""
    status: Optional[str] = None        # Mapped from electronicInvoiceStatus
    recipient_name: Optional[str] = None # Mapped from personName
    sales_order_code: Optional[int] = None     # Mapped from salesOrder -> orderCode
    invoice_number: Optional[int] = None   # Mapped from invoiceCode
    invoice_series: Optional[str] = None    # Mapped from serialCode
    issue_date: Optional[str] = None     # Mapped from eletronic -> receivementDate or issueDate
    total_value: Optional[float] = None  # Mapped from totalValue
    total_quantity: Optional[float] = None     # Mapped from quantity
    operation_name: Optional[str] = None # Mapped from operatioName
    shipping_company_name: Optional[str] = None # Mapped from shippingCompany -> shippingCompanyName
    access_key: Optional[str] = None     # Mapped from eletronic -> accessKey

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FormattedInvoiceListItem object to a dictionary."""
        return self.__dict__


@dataclass(frozen=True)
class InvoiceXmlOutDto:
    """
    Represents the response from the GET /xml-contents/{accessKey} endpoint. Immutable.
    Corresponds to the InvoiceXmlOutDto schema.
    """
    processing_type: Optional[str] = None # Maps to ElectronicInvoiceStatusType enum
    main_invoice_xml: Optional[str] = None # Base64 encoded XML
    cancel_invoice_xml: Optional[str] = None # Base64 encoded XML

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['InvoiceXmlOutDto']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for InvoiceXmlOutDto.from_dict: {type(data)}")
            return None
        return cls(
            processing_type=data.get('processingType'),
            main_invoice_xml=data.get('mainInvoiceXml'),
            cancel_invoice_xml=data.get('cancelInvoiceXml')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__

@dataclass(frozen=True)
class DanfeRequestModel:
    """
    Represents the request body for the POST /danfe-search endpoint. Immutable.
    Corresponds to the DanfeRequestModel schema.
    """
    main_invoice_xml: str # Base64 encoded XML - marked as required in swagger
    nfe_document_type: Optional[int] = None # Maps to NfeDocumentType enum (1=Normal, 2=Simplified)

    def to_dict(self) -> Dict[str, Any]:
        # Return only non-None fields to match typical API expectations
        d = {"mainInvoiceXml": self.main_invoice_xml}
        if self.nfe_document_type is not None:
            d["nfeDocumentType"] = self.nfe_document_type
        return d

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['DanfeRequestModel']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for DanfeRequestModel.from_dict: {type(data)}")
            return None
        main_xml = data.get('mainInvoiceXml')
        if not main_xml:
            logger.warning("Missing required 'mainInvoiceXml' for DanfeRequestModel.")
            return None
        return cls(
            main_invoice_xml=main_xml,
            nfe_document_type=data.get('nfeDocumentType')
        )

@dataclass(frozen=True)
class DanfeResponseModel:
    """
    Represents the response from the POST /danfe-search endpoint. Immutable.
    Corresponds to the DanfeResponseModel schema.
    """
    danfe_pdf_base64: Optional[str] = None # Base64 encoded PDF

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['DanfeResponseModel']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for DanfeResponseModel.from_dict: {type(data)}")
            return None
        # Adjust key based on testing if needed (e.g., if API returns 'pdfBase64')
        return cls(
            danfe_pdf_base64=data.get('danfePdfBase64')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__
</file>

<file path="src/domain/observation.py">
# src/domain/observation.py
# Define o modelo ORM para Product Observations usando SQLAlchemy.

from datetime import datetime, timezone
from typing import Optional, Dict, Any
from sqlalchemy import (
    Column, Integer, String, Boolean, DateTime, Text, func # Import func if using database default timestamps
)
from sqlalchemy.orm import Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP # Importar tipo espec√≠fico do PG

# Importar Base
from src.database.base import Base
from src.utils.logger import logger

class Observation(Base):
    """
    Representa uma observa√ß√£o de produto como modelo ORM.
    """
    __tablename__ = 'product_observations'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    # Usar Text para c√≥digos/textos potencialmente longos
    reference_code: Mapped[str] = mapped_column(Text, nullable=False, index=True)
    observation_text: Mapped[str] = mapped_column("observation", Text, nullable=False) # Mapeia para coluna 'observation' existente
    # Coluna "user" precisa de aspas se for palavra reservada, mas SQLAlchemy pode lidar com isso.
    # Se o nome do atributo no Python for diferente, use mapped_column("user", ...)
    user: Mapped[str] = mapped_column(Text, nullable=False)
    # Usar TIMESTAMP(timezone=True) para PostgreSQL, com default via Python/SQLAlchemy
    timestamp: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=lambda: datetime.now(timezone.utc), nullable=False)
    resolved: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False, index=True)
    resolved_user: Mapped[Optional[str]] = mapped_column(Text)
    resolved_timestamp: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))

    def to_dict(self) -> Dict[str, Any]:
        """Converte o objeto Observation para um dicion√°rio."""
        return {
            'id': self.id,
            'reference_code': self.reference_code,
            # Retorna o nome do atributo python 'observation_text'
            'observation_text': self.observation_text,
            'user': self.user,
            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
            'resolved': self.resolved,
            'resolved_user': self.resolved_user,
            'resolved_timestamp': self.resolved_timestamp.isoformat() if self.resolved_timestamp else None,
        }

    # @classmethod from_dict n√£o √© necess√°rio para ORM, o SQLAlchemy cuida disso.

    def __repr__(self):
        return f"<Observation(id={self.id}, ref='{self.reference_code}', resolved={self.resolved})>"
</file>

<file path="src/domain/person.py">
# src/domain/person.py
# Defines data models related to Person data (Individuals, Legal Entities) from the ERP.

from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from src.utils.logger import logger

@dataclass(frozen=True)
class Address:
    """Represents a person's address details. Immutable."""
    sequence_code: Optional[int] = None
    address_type_code: Optional[int] = None
    address_type: Optional[str] = None
    public_place: Optional[str] = None
    address: Optional[str] = None
    address_number: Optional[str] = None # API might return string
    complement: Optional[str] = None
    neighborhood: Optional[str] = None
    ibge_city_code: Optional[int] = None
    city_name: Optional[str] = None
    state_abbreviation: Optional[str] = None
    cep: Optional[str] = None
    bcb_country_code: Optional[int] = None
    country_name: Optional[str] = None
    post_office_box: Optional[str] = None # API might return string
    reference: Optional[str] = None
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Address']:
        """Creates an Address object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for Address.from_dict: {type(data)}")
            return None
        # Use .get with default None for Optional fields
        return cls(
            sequence_code=data.get('sequenceCode'),
            address_type_code=data.get('addressTypeCode'),
            address_type=data.get('addressType'),
            public_place=data.get('publicPlace'),
            address=data.get('address'),
            address_number=str(data['addressNumber']) if data.get('addressNumber') is not None else None,
            complement=data.get('complement'),
            neighborhood=data.get('neighborhood'),
            ibge_city_code=data.get('ibgeCityCode'),
            city_name=data.get('cityName'),
            state_abbreviation=data.get('stateAbbreviation'),
            cep=data.get('cep'),
            bcb_country_code=data.get('bcbCountryCode'),
            country_name=data.get('countryName'),
            post_office_box=str(data['postOfficeBox']) if data.get('postOfficeBox') is not None else None,
            reference=data.get('reference'),
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Address object to a dictionary."""
        return self.__dict__

@dataclass(frozen=True)
class Phone:
    """Represents a person's phone number details. Immutable."""
    sequence: Optional[int] = None
    type_code: Optional[int] = None
    type_name: Optional[str] = None
    number: Optional[str] = None
    branch_line: Optional[str] = None # API might return string
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Phone']:
        """Creates a Phone object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for Phone.from_dict: {type(data)}")
             return None
        # Note the inconsistent capitalization in the original 'Sequence'
        return cls(
            sequence=data.get('Sequence') or data.get('sequence'), # Handle both cases
            type_code=data.get('typeCode'),
            type_name=data.get('typeName'),
            number=data.get('number'),
            branch_line=str(data['branchLine']) if data.get('branchLine') is not None else None,
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Phone object to a dictionary."""
        return self.__dict__

@dataclass(frozen=True)
class Email:
    """Represents a person's email address details. Immutable."""
    sequence: Optional[int] = None
    type_code: Optional[int] = None
    type_name: Optional[str] = None
    email: Optional[str] = None
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Email']:
        """Creates an Email object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for Email.from_dict: {type(data)}")
            return None
        return cls(
            sequence=data.get('sequence'),
            type_code=data.get('typeCode'),
            type_name=data.get('typeName'),
            email=data.get('email'),
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Email object to a dictionary."""
        return self.__dict__


@dataclass(frozen=True)
class IndividualDataModel:
    """Represents data for an individual (Pessoa F√≠sica). Immutable."""
    code: int
    cpf: str
    is_inactive: bool
    name: str
    rg: Optional[str] = None
    rg_federal_agency: Optional[str] = None
    birth_date: Optional[str] = None # Keep as string from API? Or parse to date? Keep str for now.
    branch_insert_code: Optional[int] = None
    addresses: List[Address] = field(default_factory=list)
    phones: List[Phone] = field(default_factory=list)
    emails: List[Email] = field(default_factory=list)
    is_customer: Optional[bool] = None
    is_supplier: Optional[bool] = None
    is_employee: Optional[bool] = None
    employee_status: Optional[str] = None
    customer_status: Optional[str] = None
    insert_date: Optional[str] = None # Keep as string
    # --- Other fields from original model (add as needed) ---
    marital_status: Optional[str] = None
    gender: Optional[str] = None
    # ctps: Optional[int] = None # Example of omitted fields, add back if needed
    # ... many other fields ...
    max_change_filter_date: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['IndividualDataModel']:
        """Creates an IndividualDataModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for IndividualDataModel.from_dict: {type(data)}")
             return None

        code = data.get('code')
        cpf = data.get('cpf')
        name = data.get('name')

        if not code or not cpf or not name:
             logger.warning(f"Missing essential data (code, cpf, name) for IndividualDataModel: {data.get('code')}")
             return None

        # Process nested lists safely
        addresses_data = data.get('addresses', [])
        phones_data = data.get('phones', [])
        emails_data = data.get('emails', [])

        addresses = [Address.from_dict(addr) for addr in addresses_data if isinstance(addr, dict)]
        addresses = [addr for addr in addresses if addr is not None] # Filter out None results
        phones = [Phone.from_dict(phone) for phone in phones_data if isinstance(phone, dict)]
        phones = [phone for phone in phones if phone is not None]
        emails = [Email.from_dict(email) for email in emails_data if isinstance(email, dict)]
        emails = [email for email in emails if email is not None]

        return cls(
            code=code,
            cpf=cpf,
            is_inactive=data.get('isInactive', False),
            name=name,
            rg=data.get('rg'),
            rg_federal_agency=data.get('rgFederalAgency'),
            birth_date=data.get('birthDate'),
            branch_insert_code=data.get('branchInsertCode'),
            addresses=addresses,
            phones=phones,
            emails=emails,
            is_customer=data.get('isCustomer'),
            is_supplier=data.get('isSupplier'),
            is_employee=data.get('isEmployee'),
            employee_status=data.get('employeeStatus'),
            customer_status=data.get('customerStatus'),
            insert_date=data.get('insertDate'),
            marital_status=data.get('maritalStatus'),
            gender=data.get('gender'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            # Add other fields here if needed
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the IndividualDataModel object to a dictionary."""
        return {
             **self.__dict__,
            'addresses': [a.to_dict() for a in self.addresses],
            'phones': [p.to_dict() for p in self.phones],
            'emails': [e.to_dict() for e in self.emails],
        }

@dataclass(frozen=True)
class LegalEntityDataModel:
    """Represents data for a legal entity (Pessoa Jur√≠dica). Immutable."""
    # --- Fields WITHOUT defaults first ---
    code: int
    cnpj: str
    is_inactive: bool
    name: str # Raz√£o Social

    # --- Fields WITH defaults ---
    branch_insert_code: Optional[int] = None # API schema says required, but play safe
    fantasy_name: Optional[str] = None
    uf: Optional[str] = None
    number_state_registration: Optional[str] = None
    date_foundation: Optional[str] = None # Keep as string
    share_capital: Optional[float] = None
    addresses: List[Address] = field(default_factory=list)
    phones: List[Phone] = field(default_factory=list)
    emails: List[Email] = field(default_factory=list)
    insert_date: Optional[str] = None # Keep as string
    max_change_filter_date: Optional[str] = None
    is_customer: Optional[bool] = None
    is_supplier: Optional[bool] = None
    is_representative: Optional[bool] = None
    customer_status: Optional[str] = None
    # ... add other fields with defaults here ...


    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['LegalEntityDataModel']:
        """Creates a LegalEntityDataModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for LegalEntityDataModel.from_dict: {type(data)}")
             return None

        # Essential fields
        code = data.get('code')
        cnpj = data.get('cnpj')
        name = data.get('name') # Raz√£o Social
        is_inactive=data.get('isInactive', False) # Default to False if missing

        if code is None or cnpj is None or name is None:
             logger.warning(f"Missing essential data (code, cnpj, name) for LegalEntityDataModel: {data.get('code')}")
             return None

        # Process nested lists safely
        addresses_data = data.get('addresses', [])
        phones_data = data.get('phones', [])
        emails_data = data.get('emails', [])

        addresses = [Address.from_dict(addr) for addr in addresses_data if isinstance(addr, dict)]
        addresses = [addr for addr in addresses if addr is not None]
        phones = [Phone.from_dict(phone) for phone in phones_data if isinstance(phone, dict)]
        phones = [phone for phone in phones if phone is not None]
        emails = [Email.from_dict(email) for email in emails_data if isinstance(email, dict)]
        emails = [email for email in emails if email is not None]

        return cls(
            # Non-default args first
            code=code,
            cnpj=cnpj,
            is_inactive=is_inactive,
            name=name,
            # Default args next
            branch_insert_code=data.get('branchInsertCode'),
            fantasy_name=data.get('fantasyName'),
            uf=data.get('uf'),
            number_state_registration=data.get('numberStateRegistration'),
            date_foundation=data.get('dateFoundation'),
            share_capital=data.get('shareCapital'),
            addresses=addresses,
            phones=phones,
            emails=emails,
            insert_date=data.get('insertDate'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            is_customer=data.get('isCustomer'),
            is_supplier=data.get('isSupplier'),
            is_representative=data.get('isRepresentative'),
            customer_status=data.get('customerStatus'),
            # Add other fields here if needed
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the LegalEntityDataModel object to a dictionary."""
        return {
             **self.__dict__,
            'addresses': [a.to_dict() for a in self.addresses],
            'phones': [p.to_dict() for p in self.phones],
            'emails': [e.to_dict() for e in self.emails],
        }


@dataclass(frozen=True)
class PersonStatisticsResponseModel:
    """Represents customer statistics data from the ERP API. Immutable."""
    average_delay: Optional[int] = None
    maximum_delay: Optional[int] = None
    purchase_quantity: Optional[int] = None
    total_purchase_value: Optional[float] = None
    average_purchase_value: Optional[float] = None
    biggest_purchase_date: Optional[str] = None # Keep as string
    biggest_purchase_value: Optional[float] = None
    first_purchase_date: Optional[str] = None # Keep as string
    first_purchase_value: Optional[float] = None
    last_purchase_value: Optional[float] = None
    last_purchase_date: Optional[str] = None # Keep as string
    total_installments_paid: Optional[float] = None
    quantity_installments_paid: Optional[int] = None
    average_value_installments_paid: Optional[float] = None
    total_installments_delayed: Optional[float] = None
    quantity_installments_delayed: Optional[int] = None
    average_installment_delay: Optional[float] = None
    total_installments_open: Optional[float] = None
    quantity_installments_open: Optional[int] = None
    average_installments_open: Optional[float] = None
    last_invoice_paid_value: Optional[float] = None
    last_invoice_paid_date: Optional[str] = None # Keep as string

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['PersonStatisticsResponseModel']:
        """Creates a PersonStatisticsResponseModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for PersonStatisticsResponseModel.from_dict: {type(data)}")
            return None
        # Directly map fields, relying on dataclass defaults for missing keys
        # Add type checks/conversions if API types are unreliable
        try:
            return cls(
                average_delay=data.get('averageDelay'),
                maximum_delay=data.get('maximumDelay'),
                purchase_quantity=data.get('purchaseQuantity'),
                total_purchase_value=data.get('totalPurchaseValue'),
                average_purchase_value=data.get('averagePurchaseValue'),
                biggest_purchase_date=data.get('biggestPurchaseDate'),
                biggest_purchase_value=data.get('biggestPurchaseValue'),
                first_purchase_date=data.get('firstPurchaseDate'),
                first_purchase_value=data.get('firstPurchaseValue'),
                last_purchase_value=data.get('lastPurchaseValue'),
                last_purchase_date=data.get('lastPurchaseDate'),
                total_installments_paid=data.get('totalInstallmentsPaid'),
                quantity_installments_paid=data.get('quantityInstallmentsPaid'),
                average_value_installments_paid=data.get('averageValueInstallmentsPaid'),
                total_installments_delayed=data.get('totalInstallmentsDelayed'),
                quantity_installments_delayed=data.get('quantityInstallmentsDelayed'),
                average_installment_delay=data.get('averageInstallmentDelay'),
                total_installments_open=data.get('totalInstallmentsOpen'),
                quantity_installments_open=data.get('quantityInstallmentsOpen'),
                average_installments_open=data.get('averageInstallmentsOpen'),
                last_invoice_paid_value=data.get('lastInvoicePaidValue'),
                last_invoice_paid_date=data.get('lastInvoicePaidDate')
            )
        except (TypeError, ValueError) as e:
            logger.error(f"Error creating PersonStatisticsResponseModel from dict: {e}. Data: {data}", exc_info=True)
            return None # Return None if data types are wrong

    def to_dict(self) -> Dict[str, Any]:
        """Converts the PersonStatisticsResponseModel object to a dictionary."""
        return self.__dict__
</file>

<file path="src/domain/README.md">
# src/domain

Este diret√≥rio cont√©m os modelos de dados da aplica√ß√£o. Eles representam as estruturas de dados manipuladas pela aplica√ß√£o, incluindo tanto os modelos ORM para o banco de dados local quanto Dataclasses para representar dados vindos do ERP ou usados como DTOs (Data Transfer Objects).

## Arquivos

*   **Modelos ORM (SQLAlchemy):**
    *   `user.py`: Define os modelos ORM `User` e `UserPermissions` mapeados para as tabelas do banco de dados local. Herdam de `src.database.base.Base`.
    *   `observation.py`: Define o modelo ORM `Observation` mapeado para a tabela `product_observations`. Herda de `src.database.base.Base`.
*   **Dataclasses (DTOs / Modelos ERP):**
    *   `accounts_receivable.py`: Define modelos Dataclass para dados de Contas a Receber do ERP (ex: `DocumentModel`, `BankSlipRequestModel`, `FormattedReceivableListItem`).
    *   `balance.py`: Define `Balance`, `ProductItem`, `ProductResponse` (Dataclasses) para dados de saldo do ERP.
    *   `cost.py`: Define `Cost`, `ProductCost`, `CostResponse` (Dataclasses) para dados de custo do ERP.
    *   `fabric_details.py`: Define `FabricDetailValue`, `FabricDetailsItem` (Dataclasses) para detalhes espec√≠ficos de tecidos (largura, gramatura, etc.) do ERP.
    *   `fiscal.py`: Define modelos Dataclass para opera√ß√µes do m√≥dulo Fiscal (ex: `FormattedInvoiceListItem`, `InvoiceXmlOutDto`, `DanfeResponseModel`).
    *   `person.py`: Define `Address`, `Phone`, `Email`, `IndividualDataModel`, `LegalEntityDataModel`, `PersonStatisticsResponseModel` (Dataclasses) para dados de pessoa (PF/PJ) do ERP.
*   **Outros:**
    *   `__init__.py`: Exporta todos os modelos (ORM e Dataclasses) para f√°cil importa√ß√£o.
    *   `README.md`: Este arquivo.

## Padr√µes

*   **Modelos ORM:**
    *   Implementados como classes Python que herdam de `src.database.base.Base`.
    *   Usam `Mapped` e `mapped_column` do SQLAlchemy 2.0 para definir atributos e mapeamento de colunas.
    *   Definem relacionamentos usando `relationship`.
    *   Podem conter m√©todos de l√≥gica de neg√≥cio relacionados ao pr√≥prio modelo (ex: `User.verify_password`).
    *   Incluem um m√©todo `to_dict()` para facilitar a serializa√ß√£o para JSON na camada da API.
*   **Dataclasses:**
    *   Usados para representar estruturas de dados que *n√£o* s√£o mapeadas diretamente para tabelas do banco local (principalmente dados do ERP ou DTOs espec√≠ficos da API).
    *   Geralmente `frozen=True` (imut√°veis) para dados vindos de fontes externas.
    *   Incluem m√©todos `from_dict` (ou similar) para criar inst√¢ncias a partir de respostas de API e `to_dict` para serializa√ß√£o.
*   **Type Hinting:** Tipos s√£o definidos para todos os atributos.
*   **Valida√ß√£o:** A valida√ß√£o nos m√©todos `from_dict` de Dataclasses √© b√°sica. Valida√ß√µes mais complexas podem residir nos servi√ßos. Modelos ORM dependem das constraints do banco e valida√ß√µes na camada de servi√ßo antes da persist√™ncia.
</file>

<file path="src/domain/user.py">
# src/domain/user.py
from datetime import datetime, timezone
import bcrypt
from typing import Optional, Dict, Any, TYPE_CHECKING
from sqlalchemy import (
    Column, Integer, String, Boolean, DateTime, ForeignKey, func, Text
)
from sqlalchemy.orm import relationship, Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP

from src.database.base import Base
from src.utils.logger import logger

if TYPE_CHECKING:
    pass

class UserPermissions(Base):
    """
    Representa as permiss√µes ORM associadas a um usu√°rio.
    """
    __tablename__ = 'user_permissions'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    user_id: Mapped[int] = mapped_column(ForeignKey('users.id', ondelete='CASCADE'), unique=True, nullable=False, index=True)

    is_admin: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_products: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_fabrics: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_customer_panel: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_fiscal: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_accounts_receivable: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)

    user: Mapped["User"] = relationship(back_populates="permissions")

    def to_dict(self) -> Dict[str, Any]:
        """Converte o objeto UserPermissions para um dicion√°rio."""
        return {
            'id': self.id,
            'user_id': self.user_id,
            'is_admin': self.is_admin,
            'can_access_products': self.can_access_products,
            'can_access_fabrics': self.can_access_fabrics,
            'can_access_customer_panel': self.can_access_customer_panel,
            'can_access_fiscal': self.can_access_fiscal,
            'can_access_accounts_receivable': self.can_access_accounts_receivable,
        }

    def __repr__(self):
        return f"<UserPermissions(id={self.id}, user_id={self.user_id}, is_admin={self.is_admin})>"

class User(Base):
    """
    Representa um usu√°rio da aplica√ß√£o como modelo ORM.
    """
    __tablename__ = 'users'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    username: Mapped[str] = mapped_column(Text, unique=True, nullable=False, index=True)
    password_hash: Mapped[str] = mapped_column(Text, nullable=False)
    name: Mapped[str] = mapped_column(Text, nullable=False)
    email: Mapped[Optional[str]] = mapped_column(Text, unique=True, index=True)
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=lambda: datetime.now(timezone.utc), nullable=False)
    last_login: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))
    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)

    permissions: Mapped["UserPermissions"] = relationship(
        "UserPermissions",
        back_populates="user",
        cascade="all, delete-orphan",
        uselist=False,
        lazy="joined"
    )

    def set_password(self, password: str):
        """Hashes the given password and sets the password_hash."""
        if not password:
            self.password_hash = ""
            logger.warning(f"Tentativa de definir senha vazia para usu√°rio {self.username}")
            return
        try:
            salt = bcrypt.gensalt()
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            self.password_hash = hashed.decode('utf-8')
        except Exception as e:
            logger.error(f"Erro ao fazer hash da senha para usu√°rio {self.username}: {e}")
            self.password_hash = ""

    def verify_password(self, password: str) -> bool:
        """Verifies the given password against the stored hash."""
        if not self.password_hash or not password:
            logger.debug(f"Verifica√ß√£o de senha falhou para usu√°rio {self.username}: Hash ou senha fornecida ausente.")
            return False
        try:
            hash_bytes = self.password_hash.encode('utf-8')
            result = bcrypt.checkpw(password.encode('utf-8'), hash_bytes)
            logger.debug(f"Resultado da verifica√ß√£o de senha para usu√°rio {self.username}: {result}")
            return result
        except ValueError as e:
             logger.error(f"Erro ao verificar senha para usu√°rio {self.username}: {e}. Poss√≠vel valor de hash corrompido: '{self.password_hash[:10]}...'")
             return False
        except Exception as e:
            logger.error(f"Erro inesperado ao verificar senha para usu√°rio {self.username}: {e}")
            return False

    def update_last_login(self):
        """Sets the last_login timestamp to the current time UTC."""
        self.last_login = datetime.now(timezone.utc)

    def to_dict(self, include_hash: bool = False) -> Dict[str, Any]:
        """
        Converts the User object to a dictionary.
        Args:
            include_hash: Whether to include the password_hash in the output. Defaults to False.
        Returns:
            Dictionary representation of the user.
        """
        data = {
            'id': self.id,
            'username': self.username,
            'name': self.name,
            'email': self.email,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'last_login': self.last_login.isoformat() if self.last_login else None,
            'is_active': self.is_active,
            'permissions': self.permissions.to_dict() if self.permissions else None
        }
        if include_hash:
            data['password_hash'] = self.password_hash
        return data

    def __repr__(self):
        perm_id = getattr(self.permissions, 'id', None)
        return f"<User(id={self.id}, username='{self.username}', perm_id={perm_id})>"
</file>

<file path="src/erp_integration/__init__.py">
# src/erp_integration/__init__.py
# Makes 'erp_integration' a package. Exports ERP service classes.

from .erp_auth_service import ErpAuthService
from .erp_balance_service import ErpBalanceService
from .erp_cost_service import ErpCostService
from .erp_person_service import ErpPersonService
from .erp_product_service import ErpProductService
from .erp_fiscal_service import ErpFiscalService
from .erp_accounts_receivable_service import ErpAccountsReceivableService # Added Accounts Receivable service

# Instantiate singleton for ERP Auth if desired, as it's likely stateless
# and used by other ERP services.
erp_auth_service = ErpAuthService()

# Other services might be instantiated here or passed the auth service instance
# when they are created (dependency injection).

__all__ = [
    "ErpAuthService",
    "erp_auth_service", # Export instance too
    "ErpBalanceService",
    "ErpCostService",
    "ErpPersonService",
    "ErpProductService",
    "ErpFiscalService",
    "ErpAccountsReceivableService", # Added to exports
]
</file>

<file path="src/erp_integration/erp_accounts_receivable_service.py">
# src/erp_integration/erp_accounts_receivable_service.py
# Fetches Accounts Receivable data from the TOTVS ERP API.

import requests
from typing import Optional, Dict, Any
from src.config import config
# Import domain models if needed for type hints, but methods return raw dicts
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError

class ErpAccountsReceivableService:
    """
    Service to interact with the ERP's Accounts Receivable endpoints.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpAccountsReceivableService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        self.documents_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT}"
        self.bank_slip_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT}"
        # self.payment_link_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT}" # If needed later
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE
        logger.info("ErpAccountsReceivableService initialized.")

    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None) -> Dict[str, Any]:
        """Internal helper to make requests, handling auth and retries."""
        # This can be copied/adapted from ErpPersonService or ErpFiscalService
        # Ensure it handles POST correctly and specific error cases for this API
        attempt = 0
        last_exception: Optional[Exception] = None

        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP AR API: {method} {url}")
            response = None
            status_code = None
            response_text_snippet = "N/A"

            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                }

                timeout = 45 # Slightly longer timeout might be needed

                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=timeout)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=timeout)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                status_code = response.status_code
                try:
                    response_text_snippet = response.text[:1000] if response.text else "(Empty Body)"
                except Exception as read_err:
                    response_text_snippet = f"(Error reading response body: {read_err})"

                logger.debug(f"ERP AR Response Status: {status_code}, Body Snippet: {response_text_snippet}")

                # Check specific AR error patterns if necessary (e.g., 400 with DomainNotificationMessage)
                # The Swagger shows 400 for Bad Request, 200 for Success. No explicit 404 mentioned for search/boleto.
                # If a 400 contains useful info in DomainNotificationMessage, parse it?
                if status_code == 400:
                    error_detail = response_text_snippet # Default error detail
                    try:
                        error_json = response.json()
                        if isinstance(error_json, dict):
                           msg = error_json.get('message') or error_json.get('Message') # Check common keys
                           det_msg = error_json.get('detailedMessage') or error_json.get('DetailedMessage')
                           error_detail = f"{msg or 'Bad Request'} ({det_msg or response_text_snippet})"
                    except requests.exceptions.JSONDecodeError:
                        pass # Stick with the text snippet
                    logger.warning(f"ERP AR API returned 400 Bad Request for {method} {url}. Detail: {error_detail}")
                    # Map 400 to ErpIntegrationError for now, service layer might interpret further
                    raise ErpIntegrationError(f"ERP AR API returned Bad Request (400): {error_detail}")


                if status_code == 401 and attempt <= self.max_retries:
                     logger.warning(f"ERP AR API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                     self.erp_auth_service.invalidate_token()
                     last_exception = requests.exceptions.HTTPError(f"401 Client Error: Unauthorized for url: {url}", response=response)
                     continue # Retry

                # Raise other HTTP errors (>= 400, excluding 400/401 handled above)
                response.raise_for_status()

                # Handle cases where API returns 200 but empty body or non-JSON
                try:
                     resp_json = response.json()
                     if not resp_json and method.upper() != "GET": # Allow empty response for GET maybe, but not POST results
                          logger.warning(f"Received empty successful response (2xx) from ERP AR API: {method} {url}")
                          # Treat as error for POST requests expecting data
                          raise ErpIntegrationError(f"Received empty successful response from ERP AR API: {method} {url}")
                     return resp_json
                except requests.exceptions.JSONDecodeError as json_err:
                     logger.error(f"Failed to decode JSON response from {method} {url}. Status: {status_code}, Error: {json_err}. Response: {response_text_snippet}")
                     raise ErpIntegrationError(f"Received non-JSON response from ERP AR API: {json_err}") from json_err

            except requests.exceptions.HTTPError as e:
                 # Catches errors raised by raise_for_status (excluding 400/401 retry)
                 logger.error(f"HTTP error {status_code} from ERP AR API ({method} {url}): {e}. Response: {response_text_snippet}", exc_info=False)
                 last_exception = ErpIntegrationError(f"ERP AR API request failed with status {status_code}: {response_text_snippet}")
                 break # Break loop for non-retryable HTTP errors

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP AR API ({method} {url}): {e}", exc_info=True)
                 last_exception = ErpIntegrationError(f"Network error connecting to ERP AR API: {e}")
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying AR API call after network error (Attempt {attempt}).")
                      continue # Retry on network errors
                 else:
                      break # Exhausted retries

            except ErpIntegrationError as e: # Catch 400 errors raised above
                 last_exception = e
                 raise e # Re-raise immediately

            except Exception as e:
                 logger.error(f"Unexpected error during ERP AR API request ({method} {url}): {e}", exc_info=True)
                 error_msg = f"Unexpected error during ERP AR API request: {e}"
                 if response:
                      error_msg += f" | Response Status: {status_code}, Response Snippet: {response_text_snippet}"
                 last_exception = ErpIntegrationError(error_msg)
                 break

        # If loop finishes due to exhausted retries or non-retryable error
        log_message = f"Failed ERP AR API request after {attempt} attempts: {method} {url}. LastError: {last_exception}"
        logger.error(log_message)
        if isinstance(last_exception, ErpIntegrationError):
            raise last_exception
        elif isinstance(last_exception, Exception):
            raise ErpIntegrationError(log_message) from last_exception
        else:
             raise ErpIntegrationError(f"Exhausted retries or failed for ERP AR API request: {method} {url}")


    def search_documents(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Calls the ERP endpoint to search for accounts receivable documents."""
        logger.debug(f"Calling ERP AR documents search with payload: {payload}")
        # Note: _make_request returns the parsed dictionary directly
        return self._make_request(self.documents_url, method="POST", json_payload=payload)

    def get_bank_slip(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Calls the ERP endpoint to generate a bank slip (boleto)."""
        logger.debug(f"Calling ERP AR bank slip generation with payload: {payload}")
        # Note: _make_request returns the parsed dictionary directly
        return self._make_request(self.bank_slip_url, method="POST", json_payload=payload)
</file>

<file path="src/erp_integration/erp_auth_service.py">
# src/erp_integration/erp_auth_service.py
# Handles authentication with the TOTVS ERP API to obtain Bearer tokens.

import time
import requests
from typing import Optional, Dict, Any
from threading import Lock
from src.config import config # Import app configuration
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Use custom error

class ErpAuthService:
    """
    Manages authentication with the ERP API (TOTVS) using OAuth Password Grant.
    Handles token acquisition, caching, expiration, and renewal.
    Designed as a thread-safe singleton.
    """
    _instance = None
    _lock = Lock()
    _token_lock = Lock() # Separate lock specifically for token refresh logic

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(ErpAuthService, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        """Initializes the ErpAuthService (called only once due to Singleton)."""
        if self._initialized:
            return
        with self._lock:
            if self._initialized:
                 return

            self._access_token: Optional[str] = None
            self._expires_at: float = 0 # Store expiration time as timestamp
            # Construct full URLs from config
            self.auth_url = f"{config.API_BASE_URL.rstrip('/')}{config.TOKEN_ENDPOINT}"
            self.client_id = config.CLIENT_ID
            self.client_secret = config.CLIENT_SECRET
            self.username = config.API_USERNAME
            self.password = config.API_PASSWORD
            self.grant_type = config.GRANT_TYPE

            if not self.username or not self.password:
                 logger.warning("ERP API username or password not configured. Authentication will likely fail.")
            if not self.client_id: # Client secret might be optional depending on grant type
                 logger.warning("ERP API client_id not configured.")

            self._initialized = True
            logger.info(f"ErpAuthService initialized for URL: {self.auth_url}")

    def get_token(self) -> str:
        """
        Returns a valid Bearer token for accessing the ERP API.
        Handles token expiration and renewal automatically. Thread-safe.

        Returns:
            A valid access token string.

        Raises:
            ErpIntegrationError: If unable to obtain or refresh the token.
        """
        with self._token_lock: # Ensure only one thread refreshes the token at a time
            # Check expiry with a safety margin (e.g., 60 seconds)
            # time.time() is generally preferred over time.monotonic() for expiration checks
            # as it relates to wall-clock time, which 'exp' usually represents.
            safety_margin = 60
            if not self._access_token or time.time() >= (self._expires_at - safety_margin):
                logger.info("ERP token missing or expired/near expiry. Refreshing...")
                try:
                    self._refresh_token()
                except Exception as e:
                    # Log the error from _refresh_token and re-raise specific type
                    logger.critical(f"Failed to refresh ERP token: {e}", exc_info=True)
                    raise ErpIntegrationError("Failed to obtain/refresh ERP API token.") from e

            if not self._access_token:
                 # This should not happen if _refresh_token succeeds, but handle defensively
                 logger.error("Access token is still None after refresh attempt.")
                 raise ErpIntegrationError("Failed to obtain ERP API token after refresh.")

            return self._access_token

    def invalidate_token(self):
        """Forces the token to be refreshed on the next call to get_token()."""
        with self._token_lock:
            logger.info("Invalidating stored ERP token.")
            self._access_token = None
            self._expires_at = 0

    def _refresh_token(self):
        """
        Internal method to request a new token from the ERP's authorization endpoint.
        This method is called internally by get_token() when needed.
        Assumes _token_lock is held by the caller.
        """
        auth_data = {
            'username': self.username,
            'password': self.password,
            'client_id': self.client_id,
            'grant_type': self.grant_type
        }
        # Add client_secret only if it's provided (some grant types might not require it)
        if self.client_secret:
            auth_data['client_secret'] = self.client_secret

        logger.debug(f"Requesting new ERP token from {self.auth_url}")
        try:
            response = requests.post(
                self.auth_url,
                data=auth_data, # Use data for application/x-www-form-urlencoded
                timeout=15 # Increased timeout for auth requests
            )
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

            token_data = response.json()

            if 'access_token' not in token_data:
                 logger.error(f"ERP Auth response missing 'access_token'. Response: {token_data}")
                 raise ErpIntegrationError("Received invalid token response from ERP.")

            self._access_token = token_data['access_token']
            expires_in = token_data.get('expires_in', 3600) # Default to 1 hour if missing
            try:
                 # Calculate expiration time based on 'expires_in'
                 self._expires_at = time.time() + int(expires_in)
            except (ValueError, TypeError):
                 logger.warning(f"Invalid 'expires_in' value received: {expires_in}. Defaulting to 1 hour.")
                 self._expires_at = time.time() + 3600

            logger.info(f"Successfully refreshed ERP token. Expires in approx {expires_in} seconds.")
            # Log partial token for debugging if needed, but be careful
            # logger.debug(f"New token: {self._access_token[:10]}...{self._access_token[-10:]}")

        except requests.exceptions.RequestException as e:
            logger.error(f"Network error during ERP token refresh request to {self.auth_url}: {e}", exc_info=True)
            # Invalidate potentially stale token on network error
            self._access_token = None
            self._expires_at = 0
            raise ErpIntegrationError(f"Network error contacting ERP auth server: {e}") from e
        except Exception as e:
             logger.error(f"Unexpected error during ERP token refresh: {e}", exc_info=True)
             # Invalidate potentially stale token on any error
             self._access_token = None
             self._expires_at = 0
             # Include response text in error if available
             err_msg = f"Unexpected error refreshing ERP token: {e}"
             if 'response' in locals() and hasattr(response, 'text'):
                  err_msg += f" | Response: {response.text[:500]}" # Limit response length
             raise ErpIntegrationError(err_msg) from e
</file>

<file path="src/erp_integration/erp_balance_service.py">
# src/erp_integration/erp_balance_service.py
# Fetches product balance data from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.balance import ProductResponse, ProductItem # Domain models
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpBalanceService:
    """
    Service to interact with the ERP's product balance endpoint.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpBalanceService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.BALANCES_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpBalanceService initialized for URL: {self.api_url}")

    def get_balances(self,
                     reference_code_list: Optional[List[str]] = None,
                     is_fabric: bool = False) -> List[ProductItem]:
        """
        Retrieves product balances from the ERP, handling pagination.

        Args:
            reference_code_list: Optional list of reference codes to filter by (only for finished products).
            is_fabric: If True, applies filters for raw materials (fabrics).
                       If False, applies filters for finished products.

        Returns:
            A list of ProductItem objects containing balance data.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_items: List[ProductItem] = []
        current_page = 1
        has_next = True

        log_prefix = "fabrics" if is_fabric else f"products (Refs: {reference_code_list or 'All'})"
        logger.info(f"Starting ERP balance fetch for {log_prefix}.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for {log_prefix} balances...")
            try:
                payload = self._build_request_payload(current_page, reference_code_list, is_fabric)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid response data for page {current_page}. Aborting fetch.")
                    # Should this be an error? Depends on API contract. Assume empty list is valid.
                    break # Stop pagination if response is weird

                # Parse response using domain model
                product_response = ProductResponse.from_dict(response_data)
                page_items = product_response.items
                all_items.extend(page_items)

                has_next = product_response.has_next
                total_pages = product_response.total_pages
                logger.debug(f"Fetched page {current_page}/{total_pages or '?'}. Items: {len(page_items)}. HasNext: {has_next}")

                current_page += 1

                # Safety break: Avoid infinite loops if hasNext is always true
                if current_page > (total_pages + 5) and total_pages > 0: # Allow a few extra pages just in case
                     logger.warning(f"Potential infinite loop detected in balance pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500: # Absolute safety limit
                     logger.warning(f"Reached absolute page limit (500) for balance fetch. Stopping.")
                     break


            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for {log_prefix} balances: {e}", exc_info=True)
                 # Re-raise the specific error
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for {log_prefix} balances: {e}", exc_info=True)
                 # Wrap in generic ERP error
                 raise ErpIntegrationError(f"Unexpected error during balance fetch: {e}") from e

        logger.info(f"Finished ERP balance fetch for {log_prefix}. Total items retrieved: {len(all_items)}")
        return all_items

    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Makes the actual HTTP request to the ERP API, handling retries and auth.

        Args:
            payload: The request body (dictionary).

        Returns:
            The JSON response dictionary from the API.

        Raises:
            ErpIntegrationError: If the request fails after retries.
        """
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP balance API.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    # Add other headers if required by ERP
                }

                response = requests.post(
                    self.api_url,
                    json=payload,
                    headers=headers,
                    timeout=30 # Adjust timeout as needed
                )
                response.raise_for_status() # Raise HTTPError for 4xx/5xx
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 # Check for 401 Unauthorized specifically for token refresh
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP API returned 401 Unauthorized (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      # Optional: Add a small delay before retrying?
                      # time.sleep(0.5)
                      continue # Go to next attempt loop
                 else:
                      # For other HTTP errors or if retries exhausted
                      response_text = e.response.text[:500] # Limit response text length
                      logger.error(f"HTTP error {status_code} from ERP balance API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 # Includes connection errors, timeouts, etc.
                 logger.error(f"Network error connecting to ERP balance API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying after network error (Attempt {attempt}).")
                      # Optional: Add delay before retry
                      # time.sleep(1)
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP API after {attempt} attempts: {e}") from e
            # except Exception as e: # Catch other potential errors like JSONDecodeError
            #      logger.error(f"Unexpected error during ERP API request: {e}", exc_info=True)
            #      # Should we retry on unexpected errors? Maybe not.
            #      raise ErpIntegrationError(f"Unexpected error during ERP API request: {e}") from e

        # Should not be reached if loop logic is correct, but as fallback:
        logger.error("Exhausted retries for ERP balance API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP balance API.")


    def _build_request_payload(self, page: int, reference_code_list: Optional[List[str]], is_fabric: bool) -> Dict[str, Any]:
        """Constructs the JSON payload for the balance API request."""

        # Common parts
        base_payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "colorCode,productSize", # Consistent ordering
             "filter": {
                 "branchInfo": {
                     "branchCode": self.company_code,
                     "isActive": True,
                     # Specific flags based on product type
                 }
             },
             "option": {
                 "balances": [
                     {
                         "branchCode": self.company_code,
                         "stockCodeList": [1], # Always use stock code 1 (FISICO)? Verify requirement.
                         # Specific flags based on product type
                     }
                 ]
             }
        }

        # Type-specific adjustments
        if is_fabric:
             # Filters for Raw Materials / Tecidos
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": False,
                 "isRawMaterial": True,
                 "isBulkMaterial": False, # Assuming fabrics aren't bulk
                 "isOwnProduction": False,
             })
             # Fabric-specific classifications (Example based on original code)
             base_payload["filter"]["classifications"] = [
                 {"type": 4000, "codeList": ["001"]}, # Example: Tipo = Mat√©ria Prima
                 {"type": 4001, "codeList": ["001", "002", "003"]} # Example: Subtipo = Tecido Plano, Malha, etc.
             ]
             # Balance options for fabrics (don't need sales/production orders?)
             base_payload["option"]["balances"][0].update({
                 "isSalesOrder": False, # Typically no sales orders for raw materials?
                 "isTransaction": True, # Inputs/Outputs
                 "isProductionOrder": False, # Typically no production orders *for* raw materials?
             })
        else:
             # Filters for Finished Products
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": True,
                 "isRawMaterial": False,
                 "isBulkMaterial": False,
                 "isOwnProduction": True, # Assuming finished goods are own production
             })
             # Add reference code filter if provided
             if reference_code_list:
                  base_payload["filter"]["referenceCodeList"] = reference_code_list
             # Balance options for finished products
             base_payload["option"]["balances"][0].update({
                 "isSalesOrder": True, # Include sales orders
                 "isTransaction": True, # Inputs/Outputs
                 "isProductionOrder": True, # Include production orders
             })

        logger.debug(f"Generated ERP balance payload: {base_payload}")
        return base_payload
</file>

<file path="src/erp_integration/erp_cost_service.py">
# src/erp_integration/erp_cost_service.py
# Fetches product cost data from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.cost import CostResponse, ProductCost # Domain models
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpCostService:
    """
    Service to interact with the ERP's product cost endpoint.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpCostService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.COSTS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpCostService initialized for URL: {self.api_url}")

    def get_costs(self,
                  reference_code_list: Optional[List[str]] = None,
                  is_fabric: bool = False) -> List[ProductCost]:
        """
        Retrieves product costs from the ERP, handling pagination.

        Args:
            reference_code_list: Optional list of reference codes to filter by.
            is_fabric: If True, applies filters for raw materials (fabrics).
                       If False, applies filters for finished products.

        Returns:
            A list of ProductCost objects containing cost data.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_items: List[ProductCost] = []
        current_page = 1
        has_next = True

        log_prefix = "fabrics" if is_fabric else f"products (Refs: {reference_code_list or 'All'})"
        logger.info(f"Starting ERP cost fetch for {log_prefix}.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for {log_prefix} costs...")
            try:
                payload = self._build_request_payload(current_page, reference_code_list, is_fabric)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid cost response data for page {current_page}. Aborting fetch.")
                    break

                cost_response = CostResponse.from_dict(response_data)
                page_items = cost_response.items
                all_items.extend(page_items)

                has_next = cost_response.has_next
                total_pages = cost_response.total_pages
                logger.debug(f"Fetched cost page {current_page}/{total_pages or '?'}. Items: {len(page_items)}. HasNext: {has_next}")

                current_page += 1

                # Safety break
                if current_page > (total_pages + 5) and total_pages > 0:
                     logger.warning(f"Potential infinite loop detected in cost pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500:
                     logger.warning(f"Reached absolute page limit (500) for cost fetch. Stopping.")
                     break


            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for {log_prefix} costs: {e}", exc_info=True)
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for {log_prefix} costs: {e}", exc_info=True)
                 raise ErpIntegrationError(f"Unexpected error during cost fetch: {e}") from e

        logger.info(f"Finished ERP cost fetch for {log_prefix}. Total items retrieved: {len(all_items)}")
        return all_items


    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Makes the HTTP request to the ERP API, handling retries and auth."""
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP cost API.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                }
                response = requests.post(self.api_url, json=payload, headers=headers, timeout=30)
                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Cost API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP cost API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP cost API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP cost API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying cost API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP cost API after {attempt} attempts: {e}") from e

        logger.error("Exhausted retries for ERP cost API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP cost API.")


    def _build_request_payload(self, page: int, reference_code_list: Optional[List[str]], is_fabric: bool) -> Dict[str, Any]:
        """Constructs the JSON payload for the cost API request."""

        base_payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "colorCode,productSize", # Or relevant order for costs
             "filter": {
                 "branchInfo": {
                     "branchCode": self.company_code,
                     "isActive": True,
                 }
             },
             "option": {
                 # Specify which cost codes are needed
                 "costs": [{"branchCode": self.company_code, "costCodeList": [2]}] # Example: Cost Code 2 = Custo Reposi√ß√£o? Verify.
             }
        }

        if is_fabric:
             # Filters for Raw Materials / Tecidos
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": False,
                 "isRawMaterial": True,
                 "isBulkMaterial": False,
                 "isOwnProduction": False,
             })
             base_payload["filter"]["classifications"] = [
                 {"type": 4000, "codeList": ["001"]},
                 {"type": 4001, "codeList": ["001", "002", "003"]}
             ]
        else:
             # Filters for Finished Products
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": True,
                 "isRawMaterial": False,
                 "isBulkMaterial": False,
                 "isOwnProduction": True,
             })
             if reference_code_list:
                  base_payload["filter"]["referenceCodeList"] = reference_code_list

        logger.debug(f"Generated ERP cost payload: {base_payload}")
        return base_payload
</file>

<file path="src/erp_integration/erp_fiscal_service.py">
# src/erp_integration/erp_fiscal_service.py
# Fetches Fiscal data (Invoices) raw data from the TOTVS ERP API, focusing on sync needs.

import requests
from typing import Optional, List, Dict, Any
from src.config import config
# N√£o precisa mais de modelos de dom√≠nio aqui, retorna dicion√°rio bruto
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError # Custom errors

# Define the specific page size limit for this endpoint
ERP_FISCAL_PAGE_SIZE = 100 # ERP Limit

class ErpFiscalService:
    """
    Service to interact with the ERP's Fiscal endpoints, primarily focused on
    fetching raw invoice data for synchronization purposes.
    Handles direct communication, authentication, and basic error handling.
    Pagination logic is handled by the caller (e.g., FiscalSyncService).
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpFiscalService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        # Somente a URL de busca √© necess√°ria aqui para sync
        self.invoices_search_url = f"{self.base_url}{config.FISCAL_INVOICES_ENDPOINT}"
        self.xml_content_url_template = f"{self.base_url}{config.FISCAL_XML_ENDPOINT}/{{accessKey}}"
        self.danfe_search_url = f"{self.base_url}{config.FISCAL_DANFE_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE # Pode ser necess√°rio para headers/filtros default
        logger.info("ErpFiscalService initialized (Refactored for Raw Data Fetch).")


    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None, stream: bool = False) -> requests.Response:
        """
        Internal helper to make requests to the Fiscal API, handling auth and retries.
        Returns the raw Response object.
        (This method remains largely the same as before, focusing on robust request execution)
        """
        attempt = 0
        last_exception: Optional[Exception] = None
        response: Optional[requests.Response] = None

        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP Fiscal API: {method} {url}")
            response = None
            status_code = None
            response_text_snippet = "N/A"

            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    "Accept": "application/json" if not stream else "*/*"
                    # Adicionar headers de empresa se a API TOTVS exigir
                    # "CompanyCode": str(self.company_code),
                    #"BranchCode": str(self.company_code),
                }

                timeout = 60 if stream else 45 # Increased timeout slightly

                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=timeout, stream=stream)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=timeout, stream=stream)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                status_code = response.status_code
                try:
                    response_text_snippet = response.text[:1000] if response.text else "(Empty Body)"
                except Exception as read_err:
                    response_text_snippet = f"(Error reading response body: {read_err})"

                logger.debug(f"ERP Response Status: {status_code}, Body Snippet: {response_text_snippet}")

                if status_code == 404:
                     logger.warning(f"ERP Fiscal API returned 404 Not Found for {method} {url}. Params/Payload: {params or json_payload}")
                     raise ErpNotFoundError(f"Resource not found in ERP for request {method} {url}.")

                if status_code == 401 and attempt <= self.max_retries:
                     logger.warning(f"ERP Fiscal API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                     self.erp_auth_service.invalidate_token()
                     last_exception = requests.exceptions.HTTPError(f"401 Client Error: Unauthorized for url: {url}", response=response)
                     continue # Retry

                # Check specific error patterns if needed (e.g., 400 with specific messages)
                if status_code == 400:
                    error_detail = response_text_snippet # Default
                    try:
                        error_json = response.json()
                        if isinstance(error_json, dict):
                           msg = error_json.get('message') or error_json.get('Message')
                           det_msg = error_json.get('detailedMessage') or error_json.get('DetailedMessage')
                           error_detail = f"{msg or 'Bad Request'} ({det_msg or response_text_snippet})"
                    except requests.exceptions.JSONDecodeError:
                        pass # Stick with the text snippet
                    logger.warning(f"ERP Fiscal API returned 400 Bad Request for {method} {url}. Detail: {error_detail}")
                    # Raise specific error that sync service might handle differently
                    raise ErpIntegrationError(f"ERP API returned Bad Request (400): {error_detail}", status_code=400)


                response.raise_for_status() # Raise other HTTP errors

                # Success
                return response

            except requests.exceptions.HTTPError as e:
                 logger.error(f"HTTP error {status_code} from ERP Fiscal API ({method} {url}): {e}. Response: {response_text_snippet}", exc_info=False)
                 last_exception = ErpIntegrationError(f"ERP Fiscal API request failed with status {status_code}: {response_text_snippet}", status_code=status_code)
                 break

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP Fiscal API ({method} {url}): {e}", exc_info=True)
                 last_exception = ErpIntegrationError(f"Network error connecting to ERP Fiscal API: {e}")
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying Fiscal API call after network error (Attempt {attempt}).")
                      continue # Retry
                 else:
                      break # Exhausted retries

            except ErpNotFoundError as e:
                 last_exception = e
                 raise e # Re-raise specific 404

            except ErpIntegrationError as e: # Catch 400 error raised above
                 last_exception = e
                 raise e # Re-raise

            except Exception as e:
                 logger.error(f"Unexpected error during ERP Fiscal API request ({method} {url}): {e}", exc_info=True)
                 error_msg = f"Unexpected error during ERP Fiscal API request: {e}"
                 if response:
                      error_msg += f" | Response Status: {status_code}, Response Snippet: {response_text_snippet}"
                 last_exception = ErpIntegrationError(error_msg)
                 break # Don't retry unexpected errors

        # If loop finishes
        log_message = f"Failed ERP Fiscal API request after {attempt} attempts: {method} {url}. LastError: {last_exception}"
        logger.error(log_message)
        if isinstance(last_exception, (ErpIntegrationError, ErpNotFoundError)):
            raise last_exception
        elif isinstance(last_exception, Exception):
            raise ErpIntegrationError(log_message) from last_exception
        else:
             raise ErpIntegrationError(f"Exhausted retries or failed for ERP Fiscal API request: {method} {url}")


    # --- Fetch Raw Data for a SINGLE Page ---
    def fetch_invoices_page(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Fetches a single page of raw invoice data from the ERP based on the payload.
        Handles JSON decoding and basic response validation.

        Args:
            payload: The full request payload for the ERP's /invoices/search endpoint,
                     including filter, expand, order, page, and pageSize.

        Returns:
            The raw JSON response dictionary from the ERP for the requested page.

        Raises:
            ErpIntegrationError: If the API call fails, returns non-JSON, or invalid structure.
            ErpNotFoundError: If the API returns 404 (though less likely for search).
        """
        logger.debug(f"Fetching raw ERP invoices page {payload.get('page')} with payload.")
        # Payload details are not logged here for brevity, but could be if needed
        # logger.debug(f"Payload: {payload}")

        try:
            response = self._make_request(self.invoices_search_url, method="POST", json_payload=payload)

            # Decode JSON response
            try:
                response_data = response.json()
            except requests.exceptions.JSONDecodeError as json_err:
                logger.error(f"Failed to decode JSON response for invoice fetch page {payload.get('page')}. Status: {response.status_code}, Error: {json_err}. Response Text: {response.text[:500]}")
                raise ErpIntegrationError(f"Received non-JSON response from ERP invoice search: {json_err}") from json_err

            # Basic validation of the expected structure
            if not isinstance(response_data, dict) or 'items' not in response_data or 'hasNext' not in response_data:
                logger.error(f"Invalid response structure received from ERP invoice search: {response_data}")
                raise ErpIntegrationError("Invalid response structure received from ERP invoice search.")

            logger.debug(f"Successfully fetched raw data for page {payload.get('page')}. Items: {len(response_data.get('items', []))}, HasNext: {response_data.get('hasNext')}")
            return response_data # Return the full raw dictionary

        except (ErpNotFoundError, ErpIntegrationError) as e:
             # Logged in _make_request, just re-raise
             raise e
        except Exception as e:
             logger.error(f"Unexpected error in fetch_invoices_page ERP call: {e}", exc_info=True)
             raise ErpIntegrationError(f"Unexpected error during ERP raw invoice fetch: {e}") from e

    # --- Methods for DANFE/XML (remain mostly the same as they fetch specific items) ---
    def get_xml_content_raw(self, access_key: str) -> Dict[str, Any]:
        """Gets the raw XML content response for a given access key."""
        logger.debug(f"Fetching raw ERP XML content for access key: ...{access_key[-6:]}")
        url = self.xml_content_url_template.format(accessKey=access_key)
        try:
            response = self._make_request(url, method="GET")
            try:
                 return response.json() # Return raw dict
            except requests.exceptions.JSONDecodeError as json_err:
                 logger.error(f"Failed to decode JSON for XML key ...{access_key[-6:]}. Status: {response.status_code}, Text: {response.text[:500]}")
                 raise ErpIntegrationError(f"Received non-JSON from ERP XML content: {json_err}") from json_err
        except (ErpNotFoundError, ErpIntegrationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Unexpected error fetching raw XML for key ...{access_key[-6:]}: {e}", exc_info=True)
            raise ErpIntegrationError(f"Unexpected error getting raw XML content: {e}") from e

    def get_danfe_from_xml_raw(self, xml_base64: str) -> Dict[str, Any]:
        """Requests the DANFE PDF raw response using the invoice XML."""
        logger.debug(f"Requesting raw DANFE response from ERP using provided XML...")
        # Create payload directly here or use a simple dict
        payload = {"mainInvoiceXml": xml_base64} # Add nfeDocumentType if needed
        try:
            response = self._make_request(self.danfe_search_url, method="POST", json_payload=payload)
            try:
                 return response.json() # Return raw dict
            except requests.exceptions.JSONDecodeError as json_err:
                 logger.error(f"Failed to decode JSON response for DANFE generation. Status: {response.status_code}, Text: {response.text[:500]}")
                 raise ErpIntegrationError(f"Received non-JSON response from ERP DANFE generation: {json_err}") from json_err
        except (ErpNotFoundError, ErpIntegrationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Unexpected error generating raw DANFE response: {e}", exc_info=True)
            raise ErpIntegrationError(f"Unexpected error generating raw DANFE response: {e}") from e
</file>

<file path="src/erp_integration/erp_person_service.py">
# src/erp_integration/erp_person_service.py
# Fetches Person (Individual, Legal Entity, Statistics) data from the TOTVS ERP API.

import requests
from typing import Optional, List, Dict, Any, Union
from src.config import config
from src.domain.person import IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError # Custom errors

class ErpPersonService:
    """
    Service to interact with the ERP's Person related endpoints.
    Handles fetching individuals, legal entities, and statistics.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpPersonService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        # Construct full URLs for endpoints
        self.individuals_url = f"{self.base_url}{config.INDIVIDUALS_ENDPOINT}"
        self.legal_entities_url = f"{self.base_url}{config.LEGAL_ENTITIES_ENDPOINT}"
        self.stats_url = f"{self.base_url}{config.PERSON_STATS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE
        logger.info("ErpPersonService initialized.")

    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Internal helper to make requests to the Person API, handling auth and retries.

        Args:
            url: The full URL for the API endpoint.
            method: HTTP method ("GET" or "POST").
            params: Dictionary of query parameters for GET requests.
            json_payload: Dictionary payload for POST requests.

        Returns:
            The JSON response dictionary.

        Raises:
            ErpIntegrationError: If the request fails after retries.
            ErpNotFoundError: If the API returns a 404 status.
        """
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP Person API: {method} {url}")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    # Add company code header if required by API - Check TOTVS docs
                    # "CompanyCode": str(self.company_code),
                    # "BranchCode": str(self.company_code), # Might be needed
                }

                response: requests.Response
                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=20)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=20)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                # Check for 404 specifically before raise_for_status
                if response.status_code == 404:
                     logger.warning(f"ERP Person API returned 404 Not Found for {method} {url}. Params/Payload: {params or json_payload}")
                     # Map 404 to a specific custom exception
                     raise ErpNotFoundError("Resource not found in ERP.")

                response.raise_for_status() # Raise HTTPError for other 4xx/5xx
                # Handle cases where API returns 200 but empty body or non-JSON
                try:
                     return response.json()
                except requests.exceptions.JSONDecodeError:
                     logger.error(f"Failed to decode JSON response from {method} {url}. Status: {response.status_code}, Response: {response.text[:200]}")
                     raise ErpIntegrationError("Received non-JSON response from ERP Person API.")


            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Person API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      # ErpNotFoundError is handled above
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP Person API ({method} {url}): {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP Person API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP Person API ({method} {url}): {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying Person API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP Person API after {attempt} attempts: {e}") from e

        logger.error(f"Exhausted retries for ERP Person API request: {method} {url}")
        raise ErpIntegrationError(f"Exhausted retries trying to reach ERP Person API: {method} {url}")

    def _search_person(self, url: str, filter_payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Helper to perform a search and return the first item found, or None."""
        payload = {
            "filter": filter_payload,
            "expand": "phones,addresses,emails", # Request nested details
            "page": 1,
            "pageSize": 1 # Only need the first match
        }
        try:
            response_data = self._make_request(url, method="POST", json_payload=payload)
            items = response_data.get('items', [])
            if items and isinstance(items, list):
                logger.debug(f"Found person item in ERP search at {url} with filter {filter_payload}.")
                return items[0] # Return the first item dictionary
            else:
                 logger.debug(f"No items found in ERP search at {url} with filter {filter_payload}.")
                 return None
        except ErpNotFoundError:
             logger.debug(f"ERP search returned 404 (Not Found) for filter {filter_payload} at {url}.")
             return None # Treat ERP 404 as None found
        # Let other ErpIntegrationErrors propagate up


    # --- Public Methods ---

    def get_individual_by_code(self, code: int) -> Optional[IndividualDataModel]:
        """Fetches an individual from ERP by their code."""
        logger.debug(f"Searching ERP for individual by code: {code}")
        item_dict = self._search_person(self.individuals_url, {"personCodeList": [code]})
        if item_dict:
             return IndividualDataModel.from_dict(item_dict)
        return None

    def get_legal_entity_by_code(self, code: int) -> Optional[LegalEntityDataModel]:
        """Fetches a legal entity from ERP by their code."""
        logger.debug(f"Searching ERP for legal entity by code: {code}")
        item_dict = self._search_person(self.legal_entities_url, {"personCodeList": [code]})
        if item_dict:
             return LegalEntityDataModel.from_dict(item_dict)
        return None

    def get_individual_by_cpf(self, cpf: str) -> Optional[IndividualDataModel]:
        """Fetches an individual from ERP by their CPF."""
        logger.debug(f"Searching ERP for individual by CPF: {cpf[-4:]}") # Log last 4 digits
        item_dict = self._search_person(self.individuals_url, {"cpfList": [cpf]})
        if item_dict:
             return IndividualDataModel.from_dict(item_dict)
        return None

    def get_legal_entity_by_cnpj(self, cnpj: str) -> Optional[LegalEntityDataModel]:
        """Fetches a legal entity from ERP by their CNPJ."""
        logger.debug(f"Searching ERP for legal entity by CNPJ: {cnpj[-4:]}") # Log last 4 digits
        item_dict = self._search_person(self.legal_entities_url, {"cnpjList": [cnpj]})
        if item_dict:
             return LegalEntityDataModel.from_dict(item_dict)
        return None

    def get_customer_statistics(self, customer_code: int, is_admin: bool) -> Optional[PersonStatisticsResponseModel]:
        """Fetches customer statistics from the ERP."""
        # Determine BranchCode based on admin status (as per original logic)
        # TODO: Clarify requirement - should non-admins see stats only for their branch?
        branch_code = 1 if is_admin else self.company_code # Assuming 1 is a default/global branch for admin
        logger.debug(f"Fetching ERP statistics for customer code: {customer_code}, Branch: {branch_code}")

        params = {
            "CustomerCode": customer_code,
            "BranchCode": branch_code
        }
        try:
            response_data = self._make_request(self.stats_url, method="GET", params=params)
            if response_data: # Ensure response is not empty
                return PersonStatisticsResponseModel.from_dict(response_data)
            else:
                 logger.warning(f"Received empty response for statistics for customer {customer_code}.")
                 return None # Or raise ErpNotFoundError? Treat empty as not found for now.
        except ErpNotFoundError:
             logger.warning(f"ERP statistics not found (404) for customer code: {customer_code}")
             return None # Map ERP 404 to None result
</file>

<file path="src/erp_integration/erp_product_service.py">
# src/erp_integration/erp_product_service.py
# Fetches generic product data (like fabric details) from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.fabric_details import FabricDetailsItem # Domain model for results
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpProductService:
    """
    Service to interact with the ERP's generic product endpoint,
    used here specifically to fetch fabric details (width, grammage, etc.).
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpProductService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.PRODUCTS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpProductService initialized for URL: {self.api_url}")

    def get_fabric_details(self) -> Dict[int, FabricDetailsItem]:
        """
        Retrieves product details relevant to fabrics (width, grammage, shrinkage)
        from the ERP, handling pagination.

        Returns:
            A dictionary mapping product_code (int) to FabricDetailsItem objects.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_details: Dict[int, FabricDetailsItem] = {}
        current_page = 1
        has_next = True

        logger.info("Starting ERP fabric details fetch.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for fabric details...")
            try:
                payload = self._build_request_payload(current_page)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid product details response data for page {current_page}. Aborting fetch.")
                    break

                items_data = response_data.get('items', [])
                if not isinstance(items_data, list):
                     logger.warning(f"Invalid 'items' format in product details response page {current_page}. Expected list.")
                     items_data = []

                processed_count = 0
                for item_dict in items_data:
                     if isinstance(item_dict, dict):
                          details_item = FabricDetailsItem.from_product_api_item(item_dict)
                          if details_item:
                               all_details[details_item.product_code] = details_item
                               processed_count += 1
                     else:
                          logger.warning(f"Skipping non-dict item in product details response: {item_dict}")


                has_next = response_data.get('hasNext', False)
                total_pages = response_data.get('totalPages', 0)
                logger.debug(f"Fetched product details page {current_page}/{total_pages or '?'}. Processed Items: {processed_count}. HasNext: {has_next}")

                current_page += 1

                # Safety break
                if current_page > (total_pages + 5) and total_pages > 0:
                     logger.warning(f"Potential infinite loop detected in product details pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500:
                     logger.warning(f"Reached absolute page limit (500) for product details fetch. Stopping.")
                     break

            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for fabric details: {e}", exc_info=True)
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for fabric details: {e}", exc_info=True)
                 raise ErpIntegrationError(f"Unexpected error during fabric details fetch: {e}") from e

        logger.info(f"Finished ERP fabric details fetch. Total items retrieved: {len(all_details)}")
        return all_details

    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Makes the HTTP request to the ERP API, handling retries and auth."""
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP product API for details.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                }
                response = requests.post(self.api_url, json=payload, headers=headers, timeout=30)
                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Product API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP product API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP product API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP product API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying product API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP product API after {attempt} attempts: {e}") from e

        logger.error("Exhausted retries for ERP product API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP product API.")


    def _build_request_payload(self, page: int) -> Dict[str, Any]:
        """Constructs the JSON payload for the product details API request (fabric specific)."""

        # Payload specifically to get fabric details (width, grammage, shrinkage)
        payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "productCode", # Order by product code
            "expand": "additionalFields", # Crucial: Expand to get the details
            "filter": {
                "branchInfo": {
                    "branchCode": self.company_code,
                    "isActive": True,
                    # Filters specific to fabrics (raw materials)
                    "isFinishedProduct": False,
                    "isRawMaterial": True,
                    "isBulkMaterial": False,
                    "isOwnProduction": False,
                },
                # Fabric-specific classifications (same as in balance/cost)
                "classifications": [
                    {"type": 4000, "codeList": ["001"]},
                    {"type": 4001, "codeList": ["001", "002", "003"]}
                ]
            },
            "option": {
                # Specify which additional fields are needed by code
                "additionalFields": [
                    {"codeList": [1, 2, 3]}  # 1=Width, 2=Grammage, 3=Shrinkage
                ],
                 # Optionally include branch info code if needed, but might not be necessary if filtering by it
                 "branchInfoCode": self.company_code,
            }
        }

        logger.debug(f"Generated ERP product details payload: {payload}")
        return payload
</file>

<file path="src/erp_integration/README.md">
# src/erp_integration

Este diret√≥rio cont√©m a camada respons√°vel por toda a comunica√ß√£o com a API externa do ERP TOTVS. O objetivo √© isolar a complexidade da integra√ß√£o com o ERP do resto da aplica√ß√£o.

## Arquivos

*   **`erp_accounts_receivable_service.py`**: Respons√°vel por buscar dados de documentos de contas a receber e solicitar gera√ß√£o de boletos via API do ERP.
*   **`erp_auth_service.py`**: Gerencia a autentica√ß√£o com a API do ERP, obtendo e renovando os tokens de acesso (Bearer tokens) necess√°rios para as demais chamadas. Implementado como um Singleton thread-safe.
*   **`erp_balance_service.py`**: Respons√°vel por buscar dados de saldo de produtos (acabados ou mat√©rias-primas) do endpoint `/product/v2/balances/search` do ERP.
*   **`erp_cost_service.py`**: Respons√°vel por buscar dados de custo de produtos do endpoint `/product/v2/costs/search` do ERP.
*   **`erp_person_service.py`**: Respons√°vel por buscar dados de pessoas (PF/PJ) e estat√≠sticas dos endpoints `/person/v2/*` do ERP.
*   **`erp_product_service.py`**: Respons√°vel por buscar dados gen√©ricos de produtos do endpoint `/product/v2/products/search` do ERP, usado especificamente aqui para obter detalhes adicionais de tecidos (largura, gramatura, etc.).
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Encapsular os detalhes da comunica√ß√£o com a API do ERP (URLs, payloads, headers).
*   Utilizar o `ErpAuthService` para obter tokens de autentica√ß√£o v√°lidos.
*   Realizar chamadas HTTP (GET/POST) para os endpoints espec√≠ficos do ERP.
*   Implementar l√≥gica de retentativas (`MAX_RETRIES`) em caso de falhas de rede ou erros espec√≠ficos (como 401 para token expirado).
*   Tratar erros de comunica√ß√£o com o ERP e lan√ßar exce√ß√µes espec√≠ficas (`ErpIntegrationError`, `ErpNotFoundError`) para a camada de servi√ßo (`src/services`).
*   Mapear as respostas JSON do ERP para os modelos de dom√≠nio definidos em `src/domain` (ex: `ProductItem`, `CostResponse`, `IndividualDataModel`, `DocumentResponseModel`).
*   Gerenciar a pagina√ß√£o das APIs do ERP, buscando todas as p√°ginas necess√°rias para retornar um conjunto completo de dados quando aplic√°vel.

## Intera√ß√µes

*   **Camada de Servi√ßo (`src/services`)**: Os servi√ßos de neg√≥cio utilizam os servi√ßos desta camada para obter dados do ERP.
*   **Configura√ß√£o (`src/config`)**: Utiliza as configura√ß√µes definidas em `settings.py` (URLs, credenciais, c√≥digos, etc.).
*   **Dom√≠nio (`src/domain`)**: Recebe dados brutos do ERP e os transforma nos objetos de dom√≠nio definidos.
*   **API Errors (`src/api/errors`)**: Lan√ßa exce√ß√µes customizadas definidas neste pacote em caso de erros espec√≠ficos do ERP.
*   **Utils (`src/utils`)**: Utiliza o `logger` para registrar informa√ß√µes e erros.
</file>

<file path="src/services/__init__.py">
# src/services/__init__.py
# Makes 'services' a package. Exports service classes.

from .auth_service import AuthService
from .customer_service import CustomerService
from .fabric_service import FabricService
from .observation_service import ObservationService
from .product_service import ProductService
from .fiscal_service import FiscalService
from .accounts_receivable_service import AccountsReceivableService
from .fiscal_sync_service import FiscalSyncService # <<<--- ADDED

# Optionally initialize instances here if they are stateless singletons
# and don't require request context or specific configurations per request.
# However, it's often better to instantiate them in the app factory or inject them.

# Example (if needed, but prefer instantiation in app factory):
# auth_service_instance = AuthService(...)
# observation_service_instance = ObservationService(...)

__all__ = [
    "AuthService",
    "CustomerService",
    "FabricService",
    "ObservationService",
    "ProductService",
    "FiscalService",
    "AccountsReceivableService",
    "FiscalSyncService", # <<<--- ADDED
]
</file>

<file path="src/services/accounts_receivable_service.py">
# src/services/accounts_receivable_service.py
# Cont√©m a l√≥gica de neg√≥cios para o m√≥dulo de Contas a Receber.

import base64
from datetime import datetime, date
from typing import Dict, Any, List, Optional, Tuple, Set, Union
from src.erp_integration.erp_accounts_receivable_service import ErpAccountsReceivableService
from src.erp_integration.erp_person_service import ErpPersonService
from src.domain.accounts_receivable import (
    DocumentChangeModel, DocumentRequestModel, DocumentFilterModel, DocumentModel, DocumentResponseModel,
    BankSlipRequestModel, AccountsReceivableTomasResponseModel, FormattedReceivableListItem,
    CalculatedValuesModel, InvoiceDataModel
)
from src.domain.person import IndividualDataModel, LegalEntityDataModel
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError, ValidationError, ErpIntegrationError
from src.config import config
from src.utils.pdf_utils import decode_base64_to_bytes

class AccountsReceivableService:
    """
    Camada de servi√ßo para lidar com opera√ß√µes de Contas a Receber.
    """
    def __init__(self,
                 erp_ar_service: ErpAccountsReceivableService,
                 erp_person_service: ErpPersonService):
        self.erp_ar_service = erp_ar_service
        self.erp_person_service = erp_person_service
        logger.info("AccountsReceivableService inicializado.")

    def _parse_and_validate_filters(self, raw_filters: Optional[Dict[str, Any]]) -> Optional[DocumentFilterModel]:
        """Analisa o dicion√°rio de filtros brutos no DocumentFilterModel, realizando valida√ß√£o."""
        if not raw_filters or not isinstance(raw_filters, dict):
            return None

        filter_args: Dict[str, Any] = {}

        try:
            list_int_keys = {
                'branchCodeList': 'branch_code_list', 'customerCodeList': 'customer_code_list',
                'statusList': 'status_list', 'documentTypeList': 'document_type_list',
                'billingTypeList': 'billing_type_list', 'dischargeTypeList': 'discharge_type_list',
                'chargeTypeList': 'charge_type_list'
            }
            for raw_key, model_key in list_int_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, int) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de inteiros.")
                    if value:
                        filter_args[model_key] = value

            list_str_keys = {'customerCpfCnpjList': 'customer_cpf_cnpj_list'}
            for raw_key, model_key in list_str_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, str) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de strings.")
                    if value:
                        filter_args[model_key] = value

            list_float_keys = {'receivableCodeList': 'receivable_code_list', 'ourNumberList': 'our_number_list'}
            for raw_key, model_key in list_float_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, (int, float)) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de n√∫meros.")
                    if value:
                        filter_args[model_key] = [float(x) for x in value]

            date_keys = {
                'startExpiredDate': 'start_expired_date', 'endExpiredDate': 'end_expired_date',
                'startPaymentDate': 'start_payment_date', 'endPaymentDate': 'end_payment_date',
                'startIssueDate': 'start_issue_date', 'endIssueDate': 'end_issue_date',
                'startCreditDate': 'start_credit_date', 'endCreditDate': 'end_credit_date',
                'closingDateCommission': 'closing_date_commission'
            }
            for raw_key, model_key in date_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    try:
                        datetime.fromisoformat(str(value).replace('Z', '+00:00'))
                        filter_args[model_key] = str(value)
                    except (ValueError, TypeError):
                         raise ValidationError(f"Formato de data inv√°lido para o filtro '{raw_key}': {value}. Use ISO 8601.")

            bool_keys = {'hasOpenInvoices': 'has_open_invoices'}
            for raw_key, model_key in bool_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, bool):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser um booleano (true/false).")
                    filter_args[model_key] = value

            simple_int_keys = {
                'commissionedCode': 'commissioned_code', 'closingCodeCommission': 'closing_code_commission',
                'closingCompanyCommission': 'closing_company_commission', 'closingCommissionedCode': 'closing_commissioned_code'
            }
            for raw_key, model_key in simple_int_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, int): raise ValidationError(f"Filtro '{raw_key}' deve ser um inteiro.")
                    filter_args[model_key] = value

            simple_str_keys = {
                'commissionedCpfCnpj': 'commissioned_cpf_cnpj', 'closingCommissionedCpfCnpj': 'closing_commissioned_cpf_cnpj'
            }
            for raw_key, model_key in simple_str_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, str): raise ValidationError(f"Filtro '{raw_key}' deve ser uma string.")
                    filter_args[model_key] = value

            change_data = raw_filters.get('change')
            if change_data is not None:
                if not isinstance(change_data, dict):
                    raise ValidationError("Filtro 'change' deve ser um objeto.")
                change_model = DocumentChangeModel.from_dict(change_data)
                if change_model:
                    filter_args['change'] = change_model #

            # --- Instanciar o dataclass congelado UMA VEZ com todos os args ---
            if not filter_args:
                return None

            parsed = DocumentFilterModel(**filter_args)
            logger.debug(f"Filtros analisados: {parsed.to_dict()}")
            return parsed

        except ValidationError:
            raise
        except Exception as e:
            logger.error(f"Erro ao analisar filtros: {e}", exc_info=True)
            raise ValidationError(f"Formato de filtro inv√°lido: {e}")


    def _fetch_customer_names(self, documents: List[DocumentModel]) -> Dict[int, str]:
        """Busca nomes para clientes √∫nicos presentes na lista de documentos."""
        customer_ids: Set[int] = set()
        for doc in documents:
            if doc.customer_code:
                customer_ids.add(doc.customer_code)

        if not customer_ids:
            return {}

        logger.debug(f"Buscando nomes para {len(customer_ids)} c√≥digos de cliente √∫nicos.")
        names_map: Dict[int, str] = {}
        # Otimiza√ß√£o Potencial: Requisi√ß√£o em lote para a API de Pessoas, se suportado.
        # Por enquanto, busca um por um. Considere adicionar cache aqui (n√≠vel de requisi√ß√£o ou mais longo).
        for code in customer_ids:
            name = "Nome N√£o Encontrado"
            try:
                person: Optional[Union[LegalEntityDataModel, IndividualDataModel]] = \
                    self.erp_person_service.get_legal_entity_by_code(code)
                if person:
                    name = person.name # Razao Social
                else:
                    person = self.erp_person_service.get_individual_by_code(code)
                    if person:
                        name = person.name

                names_map[code] = name

            except ErpIntegrationError as e:
                 logger.warning(f"Falha ao buscar nome para o c√≥digo de cliente {code}: {e.message}")
            except Exception as e:
                 logger.error(f"Erro inesperado ao buscar nome para o c√≥digo de cliente {code}: {e}", exc_info=True)

        logger.debug(f"Nomes buscados para {len(names_map)} clientes.")
        return names_map

    def _format_receivable_list_item(self, doc: DocumentModel, customer_names: Dict[int, str]) -> FormattedReceivableListItem:
        """Formata um √∫nico DocumentModel, aplicando l√≥gica condicional para valores calculados."""

        # Obter n√∫mero da nota fiscal
        invoice_number = None
        if doc.invoice and doc.invoice[0]:
             invoice_number = doc.invoice[0].invoice_code

        # Obter nome do cliente
        cust_name = customer_names.get(doc.customer_code, "Nome Indispon√≠vel") if doc.customer_code else "Cliente Inv√°lido"

        # --- Determinar Status do T√≠tulo ---
        is_paid = doc.discharge_type != 0 or doc.payment_date is not None
        is_overdue = False
        current_date = date.today() # Usa date para compara√ß√£o com expired_date

        if doc.expired_date and not is_paid:
            try:
                # Extrai apenas a parte da data para compara√ß√£o
                expired_dt = datetime.fromisoformat(doc.expired_date.split('T')[0]).date()
                is_overdue = expired_dt < current_date
            except (ValueError, TypeError):
                logger.warning(f"N√£o foi poss√≠vel analisar expired_date: {doc.expired_date} para o doc {doc.receivable_code}/{doc.installment_code}")

        # --- Inicializar valores formatados ---
        days_late = None
        value_corrected = None
        increase = 0.0
        rebate = 0.0
        calc_vals: Optional[CalculatedValuesModel] = doc.calculated_values # Mant√©m refer√™ncia

        # --- Aplicar L√≥gica Condicional baseada no Status ---
        # Usar valores calculados (calculateValue) se o t√≠tulo estiver aberto E vencido
        use_calculated_for_current = is_overdue and calc_vals is not None

        if use_calculated_for_current:
            # *** Usa calculateValue para t√≠tulos Abertos e Vencidos ***
            logger.debug(f"Doc {doc.receivable_code}/{doc.installment_code}: Usando calculateValue (Atualmente Vencido)")
            days_late = calc_vals.days_late
            value_corrected = calc_vals.corrected_value
            # Combina acr√©scimo/juros/multa de calculateValue
            increase = (calc_vals.increase_value or 0.0) + \
                       (calc_vals.interest_value or 0.0) + \
                       (calc_vals.fine_value or 0.0)
            # Usa desconto do contexto de calculateValue
            rebate = (calc_vals.discount_value or 0.0)

        else:
            # *** Usa campos diretos para t√≠tulos Pagos ou Ainda N√£o Vencidos ***
            logger.debug(f"Doc {doc.receivable_code}/{doc.installment_code}: Usando campos diretos (Pago ou N√£o Vencido)")
            # days_late e value_corrected permanecem None
            # Usa juros/acr√©scimos hist√≥ricos registrados no pr√≥prio documento
            increase = (doc.interest_value or 0.0) + (doc.assessment_value or 0.0)
            # Usa abatimento/desconto hist√≥ricos registrados no pr√≥prio documento
            rebate = (doc.rebate_value or 0.0) + (doc.discount_value or 0.0)

        # --- Formatar acr√©scimo/abatimento final (mostrar nulo se zero) ---
        value_increase = increase if increase > 0 else None
        value_rebate = rebate if rebate > 0 else None


        # --- Instanciar FormattedReceivableListItem ---
        return FormattedReceivableListItem(
            customer_code=doc.customer_code,
            customer_cpf_cnpj=doc.customer_cpf_cnpj,
            customer_name=cust_name,
            invoice_number=invoice_number,
            document_number=doc.receivable_code,
            installment_number=doc.installment_code,
            bearer_name=doc.bearer_name,
            issue_date=doc.issue_date,
            expired_date=doc.expired_date,
            payment_date=doc.payment_date,
            value_original=doc.installment_value,
            value_paid=doc.paid_value,
            # --- Usar valores calculados condicionalmente ---
            days_late=days_late,
            value_increase=value_increase,
            value_rebate=value_rebate,
            value_corrected=value_corrected,
            # --- Mapear outros campos ---
            status=doc.status,
            document_type=doc.document_type,
            billing_type=doc.billing_type,
            discharge_type=doc.discharge_type,
            charge_type=doc.charge_type
        )

    def search_receivables(self, raw_filters: Optional[Dict[str, Any]], page: int, page_size: int, expand: Optional[str], order: Optional[str]) -> Dict[str, Any]:
        """
        Busca por documentos de contas a receber, aplica filtro de filial padr√£o,
        enriquece com nomes de clientes e formata os resultados.
        """
        logger.info(f"Buscando contas a receber. P√°gina: {page}, Tamanho: {page_size}, Filtros: {raw_filters is not None}, Expandir: {expand}, Ordem: {order}")

        if page < 1: page = 1
        if page_size < 1 or page_size > 100:
             logger.warning(f"Ajustando tamanho da p√°gina de {page_size} para 100 (limite da API).")
             page_size = 100

        # Sempre expandir calculateValue e invoice para os campos necess√°rios
        expand_list = set(item.strip() for item in expand.split(',') if item.strip()) if expand else set()
        expand_list.add("calculateValue")
        expand_list.add("invoice")
        final_expand_str = ",".join(sorted(list(expand_list)))

        try:
            # 1. Analisar e Validar Filtros do Usu√°rio
            parsed_user_filters = self._parse_and_validate_filters(raw_filters)

            # 2. *** Garantir que o Filtro de C√≥digo da Filial Esteja Presente ***
            filter_for_request: DocumentFilterModel
            default_branch = [config.COMPANY_CODE] # Usa c√≥digo da empresa da config

            if parsed_user_filters is None:
                # Nenhum filtro fornecido pelo usu√°rio, cria filtro apenas com filial padr√£o
                logger.debug("Nenhum filtro de usu√°rio fornecido. Aplicando filtro de filial padr√£o.")
                filter_for_request = DocumentFilterModel(branch_code_list=default_branch)
            elif not parsed_user_filters.branch_code_list:
                # Usu√°rio forneceu filtros, mas n√£o branchCodeList. Adiciona filial padr√£o.
                logger.debug("Filtros de usu√°rio fornecidos sem branchCodeList. Adicionando filtro de filial padr√£o.")
                # Como DocumentFilterModel √© congelado, cria um novo mesclando
                # Importante: to_dict() retorna chaves em camelCase (formato API), mas precisamos de snake_case para o modelo
                filter_dict = parsed_user_filters.to_dict()

                # Convertendo de volta para snake_case para o DocumentFilterModel
                filter_args = {}
                # Mapeamentos de camelCase para snake_case (necess√°rio para reconstruir o modelo)
                all_keys_map = {
                     'branchCodeList': 'branch_code_list', 'customerCodeList': 'customer_code_list',
                     'statusList': 'status_list', 'documentTypeList': 'document_type_list',
                     'billingTypeList': 'billing_type_list', 'dischargeTypeList': 'discharge_type_list',
                     'chargeTypeList': 'charge_type_list',
                     'customerCpfCnpjList': 'customer_cpf_cnpj_list',
                     'receivableCodeList': 'receivable_code_list', 'ourNumberList': 'our_number_list',
                     'startExpiredDate': 'start_expired_date', 'endExpiredDate': 'end_expired_date',
                     'startPaymentDate': 'start_payment_date', 'endPaymentDate': 'end_payment_date',
                     'startIssueDate': 'start_issue_date', 'endIssueDate': 'end_issue_date',
                     'startCreditDate': 'start_credit_date', 'endCreditDate': 'end_credit_date',
                     'closingDateCommission': 'closing_date_commission',
                     'hasOpenInvoices': 'has_open_invoices',
                     'commissionedCode': 'commissioned_code', 'closingCodeCommission': 'closing_code_commission',
                     'closingCompanyCommission': 'closing_company_commission', 'closingCommissionedCode': 'closing_commissioned_code',
                     'commissionedCpfCnpj': 'commissioned_cpf_cnpj', 'closingCommissionedCpfCnpj': 'closing_commissioned_cpf_cnpj'
                 }

                for camel_key, snake_key in all_keys_map.items():
                    if camel_key in filter_dict:
                        filter_args[snake_key] = filter_dict[camel_key]

                # Tratar a chave 'change' separadamente, pois √© um objeto
                if 'change' in filter_dict and filter_dict['change']:
                    filter_args['change'] = DocumentChangeModel.from_dict(filter_dict['change'])
                filter_args['branch_code_list'] = default_branch
                filter_for_request = DocumentFilterModel(**filter_args)
            else:
                logger.debug("Usu√°rio forneceu branchCodeList nos filtros.")
                filter_for_request = parsed_user_filters

            # 3. Preparar Payload da Requisi√ß√£o ERP usando o filtro garantido
            request_payload = DocumentRequestModel(
                filter=filter_for_request,
                expand=final_expand_str,
                order=order,
                page=page,
                page_size=page_size
            )

            # 4. Chamar Servi√ßo ERP
            erp_response_dict = self.erp_ar_service.search_documents(request_payload.to_dict())

            # 5. Analisar Resposta ERP
            erp_response = DocumentResponseModel.from_dict(erp_response_dict)
            if not erp_response:
                raise ServiceError("Falha ao analisar a resposta do ERP para a busca de contas a receber.")

            # 6. Buscar Nomes dos Clientes
            customer_names = self._fetch_customer_names(erp_response.items)

            # 7. Formatar Resultados
            formatted_items = [self._format_receivable_list_item(doc, customer_names) for doc in erp_response.items]

            # 8. Construir Resposta Final da API
            result = {
                "items": [item.to_dict() for item in formatted_items],
                "page": page,
                "pageSize": page_size,
                "totalItems": erp_response.total_items,
                "totalPages": erp_response.total_pages,
                "hasNext": erp_response.has_next
            }
            logger.info(f"Buscou e formatou com sucesso {len(formatted_items)} contas a receber para a p√°gina {page}. Total: {erp_response.total_items}")
            return result

        except (ValidationError, NotFoundError) as e:
            logger.warning(f"Busca de contas a receber falhou: {e}")
            raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integra√ß√£o com o ERP durante a busca de contas a receber: {e}", exc_info=False)
             raise ServiceError(f"Falha ao comunicar com o ERP para a busca de contas a receber: {e.message}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar contas a receber: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao buscar contas a receber: {e}") from e

    def generate_boleto_pdf(self, request_data: Dict[str, Any]) -> bytes:
        """
        Gera o PDF do Boleto Banc√°rio para uma parcela espec√≠fica de contas a receber.
        """
        logger.info(f"Requisi√ß√£o para gerar PDF do boleto recebida: {request_data}")

        required = ['branchCode', 'customerCode', 'receivableCode', 'installmentNumber']
        missing = [field for field in required if field not in request_data]
        if missing:
            raise ValidationError(f"Campos obrigat√≥rios ausentes para gera√ß√£o do boleto: {', '.join(missing)}")

        try:
            boleto_request = BankSlipRequestModel(
                branch_code=int(request_data['branchCode']),
                customer_code=int(request_data['customerCode']),
                receivable_code=int(request_data['receivableCode']),
                installment_number=int(request_data['installmentNumber']),
                customer_cpf_cnpj=request_data.get('customerCpfCnpj')
            )
        except (ValueError, TypeError) as e:
            raise ValidationError(f"Tipo de dado inv√°lido nos par√¢metros da requisi√ß√£o do boleto: {e}")


        try:
            # 1. Chamar Servi√ßo ERP
            erp_response_dict = self.erp_ar_service.get_bank_slip(boleto_request.to_dict())

            # 2. Analisar Resposta ERP
            tomas_response = AccountsReceivableTomasResponseModel.from_dict(erp_response_dict)
            if not tomas_response:
                 raise ServiceError("Falha ao analisar a resposta do ERP para a gera√ß√£o do boleto.")

            status_lower = tomas_response.uniface_response_status.lower() if tomas_response.uniface_response_status else ""
            if tomas_response.uniface_response_status and status_lower not in ('ok', 'success'):
                 err_msg = tomas_response.uniface_message or "Erro desconhecido do Uniface"
                 logger.error(f"Gera√ß√£o do boleto falhou no Uniface. Status: {tomas_response.uniface_response_status}, Mensagem: {err_msg}")
                 raise ServiceError(f"Gera√ß√£o do boleto falhou no ERP ({tomas_response.uniface_response_status}): {err_msg}")

            # 3. Extrair Conte√∫do Base64
            pdf_base64 = tomas_response.content
            if not pdf_base64:
                logger.error("Resposta do ERP para gera√ß√£o do boleto est√° sem o 'content' (PDF Base64). Status foi: %s", tomas_response.uniface_response_status)
                raise NotFoundError("O PDF do boleto n√£o p√¥de ser gerado pelo ERP (conte√∫do ausente).")

            # 4. Decodificar Base64 para Bytes
            pdf_bytes = decode_base64_to_bytes(pdf_base64)
            logger.info("PDF do Boleto gerado e decodificado com sucesso.")
            return pdf_bytes

        except (ValidationError, NotFoundError) as e:
            logger.warning(f"Gera√ß√£o do boleto falhou: {e}")
            raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integra√ß√£o com o ERP durante a gera√ß√£o do boleto: {e}", exc_info=False)
             raise ServiceError(f"Falha na comunica√ß√£o com o ERP durante a gera√ß√£o do boleto: {e.message}") from e
        except ServiceError as e:
             raise e
        except Exception as e:
            logger.error(f"Erro inesperado ao gerar PDF do boleto: {e}", exc_info=True)
            if isinstance(e, ServiceError):
                raise
            else:
                raise ServiceError(f"Ocorreu um erro inesperado ao gerar o boleto: {e}") from e
</file>

<file path="src/services/auth_service.py">
# src/services/auth_service.py
# Handles user authentication, token generation/verification, and current user retrieval.

import jwt
from datetime import datetime, timedelta, timezone
from flask import current_app, request, session
from typing import Tuple, Optional, Dict, Any

from src.domain.user import User
from src.database.user_repository import UserRepository
from src.database import get_db_session

from src.utils.logger import logger
from src.api.errors import AuthenticationError, InvalidTokenError, ExpiredTokenError, DatabaseError, ConfigurationError

class AuthService:
    """
    Service layer for user authentication and authorization token management using ORM.
    """

    def __init__(self, user_repository: UserRepository):
        """
        Initializes the AuthService.

        Args:
            user_repository: Instance of UserRepository.
        """
        self.user_repository = user_repository
        logger.info("AuthService initialized (ORM).")

    def login(self, username: str, password: str) -> Tuple[str, Dict[str, Any]]:
        """
        Authenticates a user, updates last login, and generates a JWT token.
        Uses a database session.

        Args:
            username: The user's username.
            password: The user's password.

        Returns:
            A tuple containing: (jwt_token, user_data_dict).

        Raises:
            AuthenticationError: If login fails due to invalid credentials or inactive user.
            DatabaseError: If a database issue occurs during user lookup or update.
        """
        logger.debug(f"Tentando login para usu√°rio: {username}")

        try:
            with get_db_session() as db:
                user = self.user_repository.find_by_username(db, username)

                if not user:
                    logger.warning(f"Login falhou: Usu√°rio '{username}' n√£o encontrado ou inativo.")
                    raise AuthenticationError("Invalid username or password.")

                if not user.is_active:
                    logger.warning(f"Login falhou: Usu√°rio '{username}' est√° inativo.")
                    raise AuthenticationError("User account is inactive.")

                if not user.verify_password(password):
                    logger.warning(f"Login falhou: Senha incorreta para usu√°rio '{username}'.")
                    raise AuthenticationError("Invalid username or password.")

                self.user_repository.update_last_login(db, user.id)

                logger.info(f"Login bem-sucedido para usu√°rio '{username}' (ID: {user.id}). Gerando token.")
                token = self._generate_token(user)

                user_data = user.to_dict(include_hash=False)

                session['token'] = token

                return token, user_data

        except (AuthenticationError, DatabaseError):
            raise
        except Exception as e:
            logger.error(f"Erro durante processamento p√≥s-login para usu√°rio '{username}': {e}", exc_info=True)
            raise AuthenticationError("Login process failed after authentication.") from e


    def _generate_token(self, user: User) -> str:
        """Generates a JWT token for the given user."""
        if not user or user.id is None:
            logger.error(f"N√£o √© poss√≠vel gerar token: Objeto de usu√°rio inv√°lido fornecido. Usu√°rio: {user}")
            raise ValueError("Valid user object with ID required to generate token.")

        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
             logger.critical("Chave Secreta JWT n√£o est√° configurada!")
             raise ConfigurationError("JWT Secret Key is missing.")

        expiration_hours = current_app.config.get('TOKEN_EXPIRATION_HOURS', 24)
        expiration_time = datetime.now(timezone.utc) + timedelta(hours=expiration_hours)

        perms_payload = {}
        if user.permissions:
             perms_payload = {
                  'adm': user.permissions.is_admin,
                  'prod': user.permissions.can_access_products,
                  'fab': user.permissions.can_access_fabrics,
                  'cust': user.permissions.can_access_customer_panel,
                  'fisc': user.permissions.can_access_fiscal,
                  'ar': user.permissions.can_access_accounts_receivable,
             }

        payload = {
            'user_id': user.id,
            'username': user.username,
            'perms': perms_payload,
            'exp': expiration_time,
            'iat': datetime.now(timezone.utc)
        }
        logger.debug(f"Gerando token JWT para usu√°rio {user.id} com payload: {payload}")
        try:
            token = jwt.encode(payload, secret_key, algorithm='HS256')
            return token
        except Exception as e:
            logger.error(f"Falha ao codificar token JWT: {e}", exc_info=True)
            raise RuntimeError("Failed to generate authentication token.") from e

    def verify_token(self, token: str) -> Dict[str, Any]:
        """
        Verifies a JWT token and returns its payload.
        """
        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
             logger.critical("Chave Secreta JWT n√£o est√° configurada!")
             raise ConfigurationError("JWT Secret Key is missing.")

        try:
            payload = jwt.decode(
                token,
                secret_key,
                algorithms=['HS256']
            )
            logger.debug(f"Token verificado com sucesso para user_id: {payload.get('user_id')}")
            return payload
        except jwt.ExpiredSignatureError:
            logger.warning(f"Verifica√ß√£o de token falhou: Token expirado. Token: {token[:10]}...")
            raise ExpiredTokenError("Authentication token has expired.")
        except jwt.InvalidTokenError as e:
            logger.warning(f"Verifica√ß√£o de token falhou: Token inv√°lido. Erro: {e}. Token: {token[:10]}...")
            raise InvalidTokenError(f"Invalid authentication token: {e}")
        except Exception as e:
            logger.error(f"Erro inesperado durante verifica√ß√£o de token: {e}", exc_info=True)
            raise InvalidTokenError(f"Token verification failed due to an unexpected error: {e}")

    def get_current_user_from_request(self) -> Optional[User]:
        """
        Retrieves the currently authenticated user based on the token
        found in the request headers or session, using a database session.

        Returns:
            The User object if authenticated and active, otherwise None.
        """
        token = None
        auth_header = request.headers.get('Authorization')
        if auth_header and auth_header.startswith('Bearer '):
            token = auth_header.split(' ')[1]
        else:
            token = session.get('token')

        if not token:
            logger.debug("Nenhum token de autentica√ß√£o encontrado no cabe√ßalho da requisi√ß√£o ou na sess√£o.")
            return None

        try:
            payload = self.verify_token(token)
            user_id = payload.get('user_id')
            if not user_id:
                 logger.warning("Payload de token inv√°lido: 'user_id' ausente.")
                 return None

            with get_db_session() as db:
                user = self.user_repository.find_by_id(db, user_id)

                if not user:
                    logger.warning(f"Token v√°lido, mas usu√°rio com ID {user_id} n√£o encontrado no banco de dados.")
                    return None
                if not user.is_active:
                    logger.warning(f"Token v√°lido, mas usu√°rio {user.username} (ID: {user_id}) est√° inativo.")
                    return None

                logger.debug(f"Usu√°rio autenticado recuperado: {user.username} (ID: {user.id})")
                return user

        except (ExpiredTokenError, InvalidTokenError) as e:
            logger.debug(f"Verifica√ß√£o de token falhou ao obter usu√°rio atual: {e}")
            if 'token' in session: session.pop('token')
            return None
        except DatabaseError as e:
            logger.error(f"Erro de banco de dados ao recuperar usu√°rio atual (ID: {user_id}): {e}", exc_info=True)
            return None
        except Exception as e:
             logger.error(f"Erro inesperado ao recuperar usu√°rio atual: {e}", exc_info=True)
             return None

    def logout(self):
         """Logs out the current user by clearing the session token."""
         if 'token' in session:
              session.pop('token')
              logger.info("Usu√°rio deslogado, token de sess√£o removido.")
              return True
         logger.debug("Logout chamado mas nenhum token de sess√£o encontrado.")
         return False
</file>

<file path="src/services/customer_service.py">
from typing import Optional, Dict, Any, Union, List
from src.domain.person import IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from src.erp_integration.erp_person_service import ErpPersonService
from src.utils.logger import logger
from src.api.errors import NotFoundError, ServiceError, ValidationError

class CustomerService:
    def __init__(self, erp_person_service: ErpPersonService):
        self.erp_person_service = erp_person_service
        logger.info("CustomerService inicializado.")

    def get_customer_details(self, search_term: str, search_type: Optional[str] = None) -> Dict[str, Any]:
        logger.debug(f"Buscando detalhes do cliente para: '{search_term}', tipo: {search_type}")
        search_term = str(search_term).strip()
        customer_data: Optional[Union[IndividualDataModel, LegalEntityDataModel]] = None
        customer_type: str = ""

        try:
            if search_term.isdigit() and len(search_term) <= 9:
                if not search_type or search_type.upper() not in ("PF", "PJ"):
                    raise ValidationError("O campo 'search_type' ('PF' ou 'PJ') √© obrigat√≥rio ao buscar por c√≥digo.")
                customer_type = search_type.upper()
                customer_code = int(search_term)
                if customer_type == "PF":
                    customer_data = self.erp_person_service.get_individual_by_code(customer_code)
                else:
                    customer_data = self.erp_person_service.get_legal_entity_by_code(customer_code)

            elif len(search_term) == 11 and search_term.isdigit():
                customer_type = "PF"
                customer_data = self.erp_person_service.get_individual_by_cpf(search_term)
            elif len(search_term) == 14 and search_term.isdigit():
                customer_type = "PJ"
                customer_data = self.erp_person_service.get_legal_entity_by_cnpj(search_term)
            else:
                raise ValidationError("Formato inv√°lido para 'search_term'. Deve ser C√≥digo (com tipo 'PF'/'PJ'), CPF (11 d√≠gitos) ou CNPJ (14 d√≠gitos).")

            if not customer_data:
                logger.warning(f"Cliente n√£o encontrado para: '{search_term}', tipo: {search_type}")
                raise NotFoundError("Cliente n√£o encontrado.")

            formatted_response = self._format_customer_data(customer_data, customer_type)
            logger.info(f"Detalhes do cliente obtidos com sucesso: {customer_data.code}")
            return formatted_response

        except (NotFoundError, ValidationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Erro ao buscar detalhes do cliente '{search_term}': {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar detalhes do cliente: {e}") from e

    def get_customer_statistics(self, customer_code: int, is_admin: bool) -> Dict[str, Any]:
        logger.debug(f"Buscando estat√≠sticas para o cliente: {customer_code}")
        try:
            statistics_data = self.erp_person_service.get_customer_statistics(customer_code, is_admin)

            if not statistics_data:
                logger.warning(f"Estat√≠sticas n√£o encontradas para o cliente: {customer_code}")
                raise NotFoundError(f"Estat√≠sticas n√£o encontradas para o cliente {customer_code}.")

            formatted_statistics = self._format_statistics(statistics_data)
            logger.info(f"Estat√≠sticas do cliente obtidas com sucesso: {customer_code}")
            return formatted_statistics

        except NotFoundError:
            raise
        except Exception as e:
            logger.error(f"Erro ao buscar estat√≠sticas do cliente {customer_code}: {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar estat√≠sticas do cliente: {e}") from e

    def _format_customer_data(self, customer: Union[IndividualDataModel, LegalEntityDataModel], customer_type: str) -> Dict[str, Any]:
        common_data = {
            "code": customer.code,
            "status": "Inativo" if customer.is_inactive else "Ativo",
            "registered_at": customer.insert_date,
            "address": self._format_address(customer.addresses),
            "phones": self._format_phones(customer.phones),
            "emails": self._format_emails(customer.emails),
            "is_customer": getattr(customer, 'is_customer', None),
            "is_supplier": getattr(customer, 'is_supplier', None),
        }

        if customer_type == "PF" and isinstance(customer, IndividualDataModel):
            return {**common_data, "customer_type": "PF", "name": customer.name, "cpf": customer.cpf, "rg": customer.rg, "rg_issuer": customer.rg_federal_agency, "birth_date": customer.birth_date, "is_employee": customer.is_employee, "registered_by_branch": customer.branch_insert_code}
        elif customer_type == "PJ" and isinstance(customer, LegalEntityDataModel):
            return {**common_data, "customer_type": "PJ", "legal_name": customer.name, "trade_name": customer.fantasy_name, "cnpj": customer.cnpj, "state_registration": customer.number_state_registration, "state_registration_uf": customer.uf, "foundation_date": customer.date_foundation, "share_capital": customer.share_capital, "is_representative": customer.is_representative}
        else:
            logger.error(f"Inconsist√™ncia entre tipo '{customer_type}' e tipo de dados '{type(customer)}'")
            raise ServiceError("Erro interno ao formatar os dados do cliente.")

    def _format_address(self, addresses: List[Any]) -> Optional[Dict[str, Any]]:
        if not addresses:
            return None
        valid_addresses = [addr for addr in addresses if addr is not None]
        if not valid_addresses:
            return None
        default_address = next((addr for addr in valid_addresses if addr.is_default), None)
        address_to_format = default_address or valid_addresses[0]
        street = f"{address_to_format.public_place or ''} {address_to_format.address or ''}".strip()
        return {"street": street or None, "number": address_to_format.address_number, "neighborhood": address_to_format.neighborhood, "city": address_to_format.city_name, "state": address_to_format.state_abbreviation, "zip_code": address_to_format.cep, "type": address_to_format.address_type, "complement": address_to_format.complement, "reference": address_to_format.reference}

    def _format_phones(self, phones: List[Any]) -> List[Dict[str, Any]]:
        return [{"number": phone.number, "type": phone.type_name, "is_default": phone.is_default} for phone in phones if phone and hasattr(phone, 'number')]

    def _format_emails(self, emails: List[Any]) -> List[Dict[str, Any]]:
        return [{"email": email.email, "type": email.type_name, "is_default": email.is_default} for email in emails if email and hasattr(email, 'email')]

    def _format_statistics(self, statistics: PersonStatisticsResponseModel) -> Dict[str, Any]:
        return {"average_delay_days": statistics.average_delay, "max_delay_days": statistics.maximum_delay, "total_overdue_value": statistics.total_installments_delayed, "overdue_installments_count": statistics.quantity_installments_delayed, "total_purchases_count": statistics.purchase_quantity, "total_purchases_value": statistics.total_purchase_value, "average_purchase_value": statistics.average_purchase_value}
</file>

<file path="src/services/fabric_service.py">
import time
from typing import List, Dict, Any, Optional
from cachetools import TTLCache, cached

from src.domain.balance import ProductItem as BalanceItem # Alias para clareza
from src.domain.cost import ProductCost
from src.domain.fabric_details import FabricDetailsItem
from src.erp_integration.erp_balance_service import ErpBalanceService
from src.erp_integration.erp_cost_service import ErpCostService
from src.erp_integration.erp_product_service import ErpProductService # Para detalhes do tecido
from src.utils.fabric_list_builder import build_fabric_list, filter_fabric_list # Importar construtores
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError

# Configura√ß√£o do cache: TTL de 10 minutos, m√°ximo de 10 entradas
# Observa√ß√£o: Este cache √© espec√≠fico para a inst√¢ncia. Se v√°rias inst√¢ncias forem executadas, os caches s√£o separados.
fabric_data_cache = TTLCache(maxsize=10, ttl=600) # 600 segundos = 10 minutos

# Fun√ß√£o auxiliar para gera√ß√£o de chave de cache (lida com filtro None)
def _get_cache_key(search_filter: Optional[str]) -> str:
    return f"filter:{search_filter or '_NONE_'}"

class FabricService:
    """
    Camada de servi√ßo para opera√ß√µes relacionadas a tecidos (mat√©ria-prima).
    Busca dados no ERP, combina e fornece listas formatadas com cache.
    """
    def __init__(self,
                 erp_balance_service: ErpBalanceService,
                 erp_cost_service: ErpCostService,
                 erp_product_service: ErpProductService):
        self.erp_balance_service = erp_balance_service
        self.erp_cost_service = erp_cost_service
        self.erp_product_service = erp_product_service # Injeta servi√ßo de produtos para detalhes
        logger.info("FabricService inicializado.")

    def clear_fabric_cache(self):
        """Limpa o cache de dados de tecidos."""
        logger.info("Limpando o cache de dados de tecidos.")
        fabric_data_cache.clear()

    def get_fabrics(self, search_filter: Optional[str] = None, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """
        Recupera uma lista de tecidos (mat√©rias-primas) com saldo, custo e detalhes,
        usando cache e opcionalmente filtrada por um termo de pesquisa.

        Args:
            search_filter: Texto para filtrar tecidos pela descri√ß√£o (case-insensitive).
                           O filtro ocorre AP√ìS a busca e cacheamento.
            force_refresh: Se True, ignora o cache e busca dados frescos.

        Returns:
            Uma lista de dicion√°rios, cada um representando um tecido com seus dados.

        Raises:
            ServiceError: Se ocorrer um erro na recupera√ß√£o ou processamento dos dados.
            NotFoundError: Se nenhum tecido for encontrado no ERP.
        """
        cache_key = _get_cache_key(search_filter) # Usa o filtro na chave do cache
        log_prefix = f"tecidos (Filtro: '{search_filter or 'Nenhum'}', For√ßar: {force_refresh})"
        logger.info(f"Buscando {log_prefix}...")

        if not force_refresh and cache_key in fabric_data_cache:
            logger.info(f"Cache encontrado para chave '{cache_key}'. Retornando dados em cache.")
            return list(fabric_data_cache[cache_key])

        logger.info(f"Cache ausente ou force_refresh=True para chave '{cache_key}'. Buscando dados do ERP.")
        try:
            full_fabric_list_unfiltered = self._fetch_and_build_fabrics()
            unfiltered_cache_key = _get_cache_key(None)
            fabric_data_cache[unfiltered_cache_key] = full_fabric_list_unfiltered
            logger.info(f"Armazenados {len(full_fabric_list_unfiltered)} tecidos no cache com chave '{unfiltered_cache_key}'.")

            if search_filter:
                logger.debug(f"Aplicando filtro no cliente: '{search_filter}'")
                filtered_list = filter_fabric_list(full_fabric_list_unfiltered, search_filter)
                logger.info(f"Lista de tecidos filtrada de {len(full_fabric_list_unfiltered)} para {len(filtered_list)} itens.")
                return filtered_list
            else:
                return full_fabric_list_unfiltered

        except NotFoundError:
            logger.warning(f"Nenhum tecido encontrado no ERP para {log_prefix}.")
            raise
        except Exception as e:
            logger.error(f"Erro ao recuperar {log_prefix}: {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar a lista de tecidos: {e}") from e

    def _fetch_and_build_fabrics(self) -> List[Dict[str, Any]]:
        """M√©todo interno para buscar dados do ERP e construir a lista de tecidos."""
        logger.debug("Buscando saldos de tecidos no ERP...")
        fabric_balances: List[BalanceItem] = self.erp_balance_service.get_balances(is_fabric=True)
        logger.debug(f"Obtidos {len(fabric_balances)} itens de saldo para tecidos.")

        if not fabric_balances:
            raise NotFoundError("Nenhum tecido encontrado no sistema ERP.")

        logger.debug("Buscando custos de tecidos no ERP...")
        fabric_costs: List[ProductCost] = self.erp_cost_service.get_costs(is_fabric=True)
        logger.debug(f"Obtidos {len(fabric_costs)} itens de custo para tecidos.")

        logger.debug("Buscando detalhes dos tecidos (largura, gramatura, etc.) no ERP...")
        fabric_details_map: Dict[int, FabricDetailsItem] = self.erp_product_service.get_fabric_details()
        logger.debug(f"Obtidos detalhes de {len(fabric_details_map)} tecidos.")

        logger.debug("Construindo lista de tecidos...")
        full_fabric_list = build_fabric_list(fabric_balances, fabric_costs, fabric_details_map)
        logger.debug(f"Lista de tecidos constru√≠da com {len(full_fabric_list)} itens.")

        return full_fabric_list
</file>

<file path="src/services/fiscal_service.py">
# src/services/fiscal_service.py
# Cont√©m l√≥gica de neg√≥cio para o m√≥dulo Fiscal, agora lendo do DB local e gerando DANFE via ERP.

import base64
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple

# --- Servi√ßos ERP (Necess√°rio para DANFE/XML) ---
from src.erp_integration.erp_fiscal_service import ErpFiscalService

# --- Reposit√≥rio Local e Session Manager ---
from src.database import get_db_session
from src.database.fiscal_repository import FiscalRepository

# --- Modelos ORM e DTOs ---
from src.domain.fiscal_orm import NotaFiscalOrm
from src.domain.fiscal import (
    FormattedInvoiceListItem, InvoiceXmlOutDto, DanfeResponseModel
)

# --- Utilit√°rios e Erros ---
from src.utils.logger import logger
from src.utils.pdf_utils import decode_base64_to_bytes
from src.api.errors import ErpIntegrationError, ServiceError, NotFoundError, ValidationError, DatabaseError
from src.config import config
from sqlalchemy.exc import SQLAlchemyError

# P√°gina√ß√£o padr√£o para busca local
LOCAL_FISCAL_PAGE_SIZE = 50

class FiscalService:
    """
    Service layer for handling fiscal operations.
    - Searches invoices from the LOCAL database (synced from ERP).
    - Generates DANFE PDF by fetching necessary data from ERP.
    """
    def __init__(self, fiscal_repository: FiscalRepository, erp_fiscal_service: ErpFiscalService):
        """
        Initializes the FiscalService.

        Args:
            fiscal_repository: Repository for accessing local fiscal data (ORM).
            erp_fiscal_service: Service for interacting with ERP for DANFE/XML.
        """
        self.fiscal_repository = fiscal_repository
        self.erp_fiscal_service = erp_fiscal_service
        logger.info("Servi√ßo Fiscal inicializado (usando DB local para busca).")

    # --- Search Invoices (Local Database) ---
    def search_invoices(self, filters: Dict[str, Any], page: int = 1, page_size: int = LOCAL_FISCAL_PAGE_SIZE) -> Dict[str, Any]:
        """
        Searches for invoices in the LOCAL database based on filters and formats the results.

        Args:
            filters: Dictionary of filter criteria (keys should ideally match NotaFiscalOrm attributes or be mapped).
            page: Page number (starting from 1).
            page_size: Number of items per page.

        Returns:
            A dictionary containing the paginated list of formatted invoices.

        Raises:
            ValidationError: If filter validation fails (implementation needed).
            DatabaseError: If a database error occurs.
            ServiceError: For unexpected errors.
        """
        logger.info(f"Buscando notas fiscais no banco local com filtros: {filters}, P√°gina: {page}, Itens por p√°gina: {page_size}")

        # Clamp page size (optional, based on preference for local search)
        if page_size < 1: page_size = LOCAL_FISCAL_PAGE_SIZE

        validated_filters = filters

        try:
            with get_db_session() as db:
                # Use the local repository search method
                invoice_orms, total_count = self.fiscal_repository.find_invoices_local(
                    db, validated_filters, page, page_size
                )

            # Format the ORM results into the desired API structure
            formatted_items = [self._format_invoice_list_item(orm) for orm in invoice_orms]

            total_pages = (total_count + page_size - 1) // page_size if page_size > 0 else 0

            result = {
                "items": formatted_items,
                "page": page,
                "pageSize": page_size,
                "totalItems": total_count,
                "totalPages": total_pages
            }
            logger.info(f"Busca conclu√≠da com sucesso. Encontrados {len(formatted_items)} notas fiscais para p√°gina {page}. Total de Itens: {total_count}")
            return result

        except ValidationError as e:
             logger.warning(f"Falha na valida√ß√£o dos filtros durante busca de notas fiscais: {e}")
             raise e
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Erro de banco de dados durante busca de notas fiscais: {e}", exc_info=True)
            raise DatabaseError("Falha ao recuperar notas fiscais do banco de dados local.") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar ou processar notas fiscais locais: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado durante a busca de notas fiscais: {e}") from e

    def _format_invoice_list_item(self, nf_orm: NotaFiscalOrm) -> Dict[str, Any]:
        """Formats a NotaFiscalOrm object into the desired list structure."""
        if not nf_orm:
            return {}

        # Get sales order code (handle potential absence of relationship data)
        sales_order_code = None
        try:
            if nf_orm.sales_orders and nf_orm.sales_orders[0]:
                 sales_order_code = nf_orm.sales_orders[0].order_code
        except Exception as rel_err:
            logger.warning(f"N√£o foi poss√≠vel acessar rela√ß√£o sales_orders para NF {nf_orm.id}: {rel_err}")

        # Use the FormattedInvoiceListItem dataclass for structure and conversion
        formatted = FormattedInvoiceListItem(
            status=nf_orm.electronic_invoice_status,
            recipient_name=nf_orm.person_name,
            sales_order_code=sales_order_code,
            invoice_number=nf_orm.invoice_code,
            invoice_series=nf_orm.serial_code,
            issue_date=nf_orm.issue_date.isoformat() if nf_orm.issue_date else (nf_orm.invoice_date.isoformat() if nf_orm.invoice_date else None),
            total_value=float(nf_orm.total_value) if nf_orm.total_value is not None else None,
            total_quantity=float(nf_orm.quantity) if nf_orm.quantity is not None else None,
            operation_name=nf_orm.operation_name,
            shipping_company_name=nf_orm.shipping_company_name,
            access_key=nf_orm.access_key
        )
        return formatted.to_dict()

    # --- DANFE Generation (Still relies on ERP) ---
    def generate_danfe_pdf(self, access_key: str) -> bytes:
        """
        Generates the DANFE PDF for a given invoice access key by fetching data from ERP.
        """
        if not access_key or len(access_key) != 44 or not access_key.isdigit():
             raise ValidationError("Formato de chave de acesso inv√°lido. Deve conter 44 d√≠gitos.")

        logger.info(f"Gerando DANFE via ERP para chave de acesso: ...{access_key[-6:]}")
        try:
            # 1. Get XML Content (Raw) from ERP Service
            logger.debug(f"Etapa 1: Buscando XML do ERP para chave ...{access_key[-6:]}")
            xml_raw_dict = self.erp_fiscal_service.get_xml_content_raw(access_key)

            # Parse raw dict using DTO
            xml_dto = InvoiceXmlOutDto.from_dict(xml_raw_dict)
            if not xml_dto or not xml_dto.main_invoice_xml:
                 logger.error(f"Falha ao interpretar resposta do XML ou campo mainInvoiceXml ausente. Dados brutos: {xml_raw_dict}")
                 raise ServiceError(f"Conte√∫do XML inv√°lido ou ausente recebido do ERP para chave ...{access_key[-6:]}.")
            main_xml_base64 = xml_dto.main_invoice_xml
            logger.debug(f"Etapa 1: XML principal obtido com sucesso (Tamanho Base64: {len(main_xml_base64)}).")

            # 2. Get DANFE from XML (Raw) using ERP Service
            logger.debug(f"Etapa 2: Solicitando DANFE do ERP usando XML obtido...")
            danfe_raw_dict = self.erp_fiscal_service.get_danfe_from_xml_raw(main_xml_base64)

            # Parse raw dict using DTO
            danfe_dto = DanfeResponseModel.from_dict(danfe_raw_dict)
            if not danfe_dto or not danfe_dto.danfe_pdf_base64:
                 logger.error(f"Falha ao interpretar resposta do DANFE ou campo danfePdfBase64 ausente. Dados brutos: {danfe_raw_dict}")
                 raise ServiceError("DANFE PDF inv√°lido ou ausente recebido do ERP.")
            pdf_base64 = danfe_dto.danfe_pdf_base64
            logger.debug(f"Etapa 2: DANFE PDF recebido e interpretado com sucesso (Tamanho Base64: {len(pdf_base64)}).")

            # 3. Decode Base64 to PDF bytes
            try:
                pdf_bytes = decode_base64_to_bytes(pdf_base64)
                logger.info(f"DANFE PDF gerado e decodificado com sucesso para chave ...{access_key[-6:]}.")
                return pdf_bytes
            except (ValueError, TypeError, RuntimeError) as decode_err:
                logger.error(f"Falha ao decodificar Base64 do DANFE PDF: {decode_err}", exc_info=True)
                raise ServiceError("Falha ao decodificar o PDF DANFE gerado.")

        except (NotFoundError, ValidationError) as e:
             logger.warning(f"Gera√ß√£o de DANFE falhou para chave ...{access_key[-6:]}: {e}")
             raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integra√ß√£o com ERP durante gera√ß√£o de DANFE para chave ...{access_key[-6:]}: {e}", exc_info=False)
             status_code = e.status_code if hasattr(e, 'status_code') else 502
             raise ServiceError(f"Falha na comunica√ß√£o com o ERP durante gera√ß√£o de DANFE: {e.message}", status_code=status_code) from e
        except ServiceError as e:
             logger.error(f"Erro de servi√ßo durante gera√ß√£o de DANFE para chave ...{access_key[-6:]}: {e}", exc_info=True)
             raise e
        except Exception as e:
            logger.error(f"Erro inesperado ao gerar DANFE para chave de acesso ...{access_key[-6:]}: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado durante a gera√ß√£o do DANFE: {e}") from e
</file>

<file path="src/services/fiscal_sync_service.py">
# src/services/fiscal_sync_service.py
# Service responsible for synchronizing fiscal invoice data from ERP to local DB.

import threading
import time
from datetime import datetime, timedelta, timezone
from typing import Optional, List, Dict, Any

from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from src.database import get_db_session
from src.database.fiscal_repository import FiscalRepository
from src.erp_integration.erp_fiscal_service import ErpFiscalService, ERP_FISCAL_PAGE_SIZE
from src.utils.logger import logger
from src.api.errors import ServiceError, DatabaseError, ErpIntegrationError
from src.config import config

# --- Constants for Sync Logic ---
INITIAL_SYNC_START_YEAR = 2010
SYNC_INTERVAL_MINUTES = 5
MAX_INVOICES_PER_TRANSACTION = 500

class FiscalSyncService:
    """
    Orchestrates the synchronization of fiscal invoices from the ERP
    to the local database. Handles initial bulk load in chunks and incremental updates.
    """
    _lock = threading.Lock()
    _is_running = False

    def __init__(self, erp_fiscal_service: ErpFiscalService, fiscal_repository: FiscalRepository):
        self.erp_fiscal_service = erp_fiscal_service
        self.fiscal_repository = fiscal_repository
        self.company_code = config.COMPANY_CODE
        logger.info("Servi√ßo de sincroniza√ß√£o fiscal inicializado.")

    def _get_last_sync_time(self) -> Optional[datetime]:
        """Fetches the latest 'lastchange_date' from the local database."""
        try:
            with get_db_session() as db:
                return self.fiscal_repository.get_latest_sync_timestamp(db)
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao obter timestamp da √∫ltima sincroniza√ß√£o: {e}. Usando l√≥gica de sincroniza√ß√£o inicial.", exc_info=True)
            return None

    def run_sync(self, full_sync: bool = False):
        """
        Executes the synchronization process. Prevents concurrent runs.
        """
        if FiscalSyncService._is_running:
             logger.warning("Sincroniza√ß√£o fiscal j√° est√° em execu√ß√£o. Ignorando esta chamada.")
             return

        with FiscalSyncService._lock:
             if FiscalSyncService._is_running:
                  logger.warning("Sincroniza√ß√£o fiscal obteve o lock mas j√° est√° em execu√ß√£o. Ignorando.")
                  return
             FiscalSyncService._is_running = True
             logger.info(f"[CICLO IN√çCIO] Iniciando ciclo de sincroniza√ß√£o fiscal (Sincroniza√ß√£o Completa: {full_sync}).")

        try:
            start_time_cycle = time.monotonic()
            total_processed_cycle = 0
            perform_initial_sync_logic = False

            if full_sync:
                logger.info("Sincroniza√ß√£o completa solicitada pelo par√¢metro.")
                perform_initial_sync_logic = True
            else:
                logger.info("Verificando timestamp da √∫ltima sincroniza√ß√£o para modo incremental...")
                last_sync_time = self._get_last_sync_time()

                if last_sync_time is None:
                    logger.info("Nenhuma sincroniza√ß√£o anterior encontrada. Realizando sincroniza√ß√£o inicial.")
                    perform_initial_sync_logic = True
                else:
                    # --- Incremental Sync Logic ---
                    start_date_inc = last_sync_time - timedelta(minutes=10)
                    end_date_inc = datetime.now(timezone.utc)
                    logger.info(f"Executando sincroniza√ß√£o incremental de {start_date_inc.date()} at√© {end_date_inc.date()}")
                    try:
                        total_processed_cycle = self._sync_time_range(start_date_inc, end_date_inc)
                        logger.info(f"Sincroniza√ß√£o incremental conclu√≠da. Processadas: {total_processed_cycle} notas fiscais.")
                    except Exception as e:
                         logger.error(f"Falha na sincroniza√ß√£o incremental: {e}", exc_info=True)
                         raise

            # --- Initial Sync Logic (if needed) ---
            if perform_initial_sync_logic:
                logger.info("Iniciando processo de sincroniza√ß√£o inicial em blocos de 6 meses.")
                try:
                    total_processed_cycle = self._perform_initial_sync_in_chunks()
                    logger.info(f"Processo de sincroniza√ß√£o inicial conclu√≠do. Total processado: {total_processed_cycle} notas fiscais")
                except Exception as e:
                    logger.error(f"Falha no processo de sincroniza√ß√£o inicial: {e}", exc_info=True)
                    raise

            elapsed_time_cycle = time.monotonic() - start_time_cycle
            elapsed_str = self._format_time_duration(elapsed_time_cycle)
            logger.info(f"[CICLO FIM] Ciclo de sincroniza√ß√£o fiscal conclu√≠do com sucesso em {elapsed_str}. Processadas: {total_processed_cycle} notas fiscais.")

        except Exception as cycle_error:
             elapsed_time_cycle = time.monotonic() - start_time_cycle
             elapsed_str = self._format_time_duration(elapsed_time_cycle)
             logger.error(f"[CICLO ERRO] Ciclo de sincroniza√ß√£o fiscal falhou ap√≥s {elapsed_str}: {cycle_error}", exc_info=True)
        finally:
            with FiscalSyncService._lock:
                FiscalSyncService._is_running = False

    def _format_time_duration(self, seconds: float) -> str:
        """Formata dura√ß√£o de tempo em formato leg√≠vel."""
        if seconds < 60:
            return f"{seconds:.2f} segundos"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.2f} minutos ({seconds:.2f} segundos)"
        else:
            hours = seconds / 3600
            minutes = (seconds % 3600) / 60
            return f"{hours:.2f} horas ({minutes:.2f} minutos)"

    def _perform_initial_sync_in_chunks(self) -> int:
        """
        Performs the initial data synchronization by fetching data in 6-month chunks
        and estimates remaining time.
        """
        total_processed_initial = 0
        start_year = INITIAL_SYNC_START_YEAR
        current_time = datetime.now(timezone.utc)
        end_year = current_time.year

        # --- C√°lculo da Estimativa ---
        total_chunks = (end_year - start_year + 1) * 2
        chunks_processed = 0
        start_time_initial_sync = time.monotonic()

        for year in range(start_year, end_year + 1):
            logger.info(f"--- Processando sincroniza√ß√£o inicial para o ano {year} ---")

            for half in [1, 2]:
                if year == end_year and half == 2 and current_time.month <= 6:
                     logger.info(f"Data atual est√° no primeiro semestre de {year}. Pulando segundo semestre.")
                     continue

                start_chunk, end_chunk = self._get_chunk_dates(year, half)
                effective_end_chunk = min(end_chunk, current_time)

                if start_chunk >= effective_end_chunk:
                    logger.info(f"Pulando bloco S{half}-{year} pois a data de in√≠cio n√£o √© anterior √† data de fim.")
                    continue

                # --- Log de In√≠cio do Chunk com Estimativa ---
                chunks_processed += 1
                avg_time_per_chunk = (time.monotonic() - start_time_initial_sync) / chunks_processed if chunks_processed > 0 else 0
                remaining_chunks = total_chunks - chunks_processed
                estimated_remaining_time = avg_time_per_chunk * remaining_chunks if avg_time_per_chunk > 0 else 0
                estimated_total_time = avg_time_per_chunk * total_chunks if avg_time_per_chunk > 0 else 0

                # Formata√ß√£o mais clara das estimativas
                est_rem_str = self._format_time_duration(estimated_remaining_time) if estimated_remaining_time > 0 else "Calculando..."
                est_tot_str = self._format_time_duration(estimated_total_time) if estimated_total_time > 0 else "Calculando..."

                logger.info(f"""
[ESTIMATIVA]
Sincronizando bloco S{half}-{year} ({start_chunk.date()} at√© {effective_end_chunk.date()})
Progresso: Bloco {chunks_processed}/{total_chunks} ({(chunks_processed/total_chunks*100):.1f}%)
Tempo restante estimado: {est_rem_str}
Tempo total estimado: {est_tot_str}
[FIM ESTIMATIVA]""")

                start_time_chunk = time.monotonic()
                try:
                    processed_in_chunk = self._sync_time_range(start_chunk, effective_end_chunk)
                    total_processed_initial += processed_in_chunk
                    elapsed_chunk = time.monotonic() - start_time_chunk
                    elapsed_str = self._format_time_duration(elapsed_chunk)
                    logger.info(f"Conclu√≠do bloco S{half}-{year} em {elapsed_str}. Processadas: {processed_in_chunk} notas fiscais")
                except Exception as e:
                    logger.error(f"Erro sincronizando bloco S{half}-{year} ({start_chunk.date()} at√© {effective_end_chunk.date()}): {e}. Interrompendo sincroniza√ß√£o inicial.")
                    raise

        logger.info("Processamento de blocos da sincroniza√ß√£o inicial conclu√≠do.")
        return total_processed_initial

    def _get_chunk_dates(self, year: int, half: int) -> tuple[datetime, datetime]:
        """Calculates start and end dates for a 6-month chunk."""
        if half == 1:
            start_date = datetime(year, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
            end_date = datetime(year, 6, 30, 23, 59, 59, 999999, tzinfo=timezone.utc)
        elif half == 2:
            start_date = datetime(year, 7, 1, 0, 0, 0, tzinfo=timezone.utc)
            end_date = datetime(year, 12, 31, 23, 59, 59, 999999, tzinfo=timezone.utc)
        else:
            raise ValueError("Semestre inv√°lido especificado")
        return start_date, end_date


    def _sync_time_range(self, start_date: datetime, end_date: datetime) -> int:
        """
        Fetches and processes invoices within a specific time range based on 'lastchangeDate'.
        Manages ERP pagination and commits data in batches. Returns the number of processed items.
        """
        current_page = 1
        has_next = True
        processed_count_range = 0
        invoices_in_batch = 0
        db: Optional[Session] = None
        db_context = None

        try:
            while has_next:
                logger.debug(f"Buscando p√°gina {current_page} do ERP para per√≠odo {start_date.date()} at√© {end_date.date()}...")

                filter_payload = {
                    "change": {
                        "startDate": start_date.isoformat(timespec='milliseconds'),
                        "endDate": end_date.isoformat(timespec='milliseconds')
                    },
                    "branchCodeList": [self.company_code],
                    "origin": "Own",
                    "documentTypeCodeList": [55]
                }
                erp_request_payload = {
                    "filter": filter_payload,
                    "expand": "shippingCompany, salesOrder, eletronic, items, payments, observationNF, observationNFE",
                    "order": "lastchangeDate",
                    "page": current_page,
                    "pageSize": ERP_FISCAL_PAGE_SIZE
                }

                erp_response = self.erp_fiscal_service.fetch_invoices_page(erp_request_payload)
                items = erp_response.get('items', [])
                has_next = erp_response.get('hasNext', False)
                
                if items:
                     logger.info(f"P√°gina {current_page} do ERP: Recebidas {len(items)} notas fiscais. Pr√≥xima={has_next}")
                elif has_next:
                     logger.debug(f"P√°gina {current_page} do ERP: Recebidas 0 notas fiscais. Pr√≥xima={has_next}")

                if not items and not has_next:
                    logger.debug(f"N√£o h√° mais notas fiscais no ERP para a p√°gina {current_page} e per√≠odo.")
                    break

                if not items:
                     current_page += 1
                     continue

                # --- Process Batch ---
                if db is None:
                    db_context = get_db_session()
                    db = db_context.__enter__()

                for invoice_data in items:
                    if not isinstance(invoice_data, dict): continue
                    upserted = self.fiscal_repository.upsert_invoice(db, invoice_data)
                    if upserted:
                        processed_count_range += 1
                        invoices_in_batch += 1

                    if invoices_in_batch >= MAX_INVOICES_PER_TRANSACTION:
                        logger.info(f"Confirmando lote de {invoices_in_batch} notas fiscais (Per√≠odo {start_date.date()}-{end_date.date()}, P√°gina ~{current_page})...")
                        db.commit()
                        logger.info("Lote confirmado com sucesso.")
                        invoices_in_batch = 0

                current_page += 1

        except Exception as e:
             logger.error(f"Erro durante sincroniza√ß√£o de per√≠odo ({start_date.date()} at√© {end_date.date()}): {e}", exc_info=True)
             if db: db.rollback()
             raise
        finally:
            if db_context:
                try:
                    if db and invoices_in_batch > 0:
                        logger.info(f"Confirmando lote final de {invoices_in_batch} notas fiscais para per√≠odo {start_date.date()}-{end_date.date()}.")
                        db.commit()
                        logger.info("Lote final confirmado.")
                    db_context.__exit__(None, None, None)
                except Exception as final_err:
                    logger.error(f"Erro durante confirma√ß√£o/fechamento final para sincroniza√ß√£o de per√≠odo: {final_err}", exc_info=True)
                    try:
                         if db: db.rollback()
                         db_context.__exit__(type(final_err), final_err, final_err.__traceback__)
                    except:
                          pass

        logger.info(f"Sincroniza√ß√£o conclu√≠da para per√≠odo {start_date.isoformat()} at√© {end_date.isoformat()}. Processadas/Atualizadas: {processed_count_range}")
        return processed_count_range


# --- Background Task Setup ---
_sync_thread: Optional[threading.Thread] = None
_stop_sync_event = threading.Event()

def _fiscal_sync_task(sync_service: FiscalSyncService, initial_delay_sec: int, interval_min: int):
    """The actual function run by the background thread."""
    logger.info(f"Tarefa de sincroniza√ß√£o fiscal em background iniciada. Atraso inicial: {initial_delay_sec}s, Intervalo: {interval_min}min.")
    first_run = True
    while not _stop_sync_event.is_set():
        if first_run:
            logger.info(f"Aguardando {initial_delay_sec}s antes da primeira execu√ß√£o de sincroniza√ß√£o fiscal...")
            wait_time = initial_delay_sec
            first_run = False
        else:
            wait_time = interval_min * 60

        interrupted = _stop_sync_event.wait(timeout=wait_time)
        if interrupted:
             logger.info("Tarefa de sincroniza√ß√£o fiscal interrompida pelo evento de parada durante espera.")
             break

        logger.info("Tarefa de sincroniza√ß√£o fiscal iniciando ciclo de trabalho...")
        try:
            sync_service.run_sync(full_sync=False)
        except Exception as e:
            logger.error(f"Erro n√£o tratado durante ciclo de sincroniza√ß√£o fiscal agendado: {e}", exc_info=True)

        logger.info(f"Ciclo de trabalho de sincroniza√ß√£o fiscal finalizado. Aguardando pr√≥ximo gatilho ({interval_min} min)...")

    logger.info("Tarefa de sincroniza√ß√£o fiscal em background finalizada.")

def start_fiscal_sync_scheduler(sync_service: FiscalSyncService, initial_delay_sec: int = 30, interval_min: int = SYNC_INTERVAL_MINUTES):
    global _sync_thread
    if _sync_thread is None or not _sync_thread.is_alive():
        _stop_sync_event.clear()
        _sync_thread = threading.Thread(
            target=_fiscal_sync_task,
            args=(sync_service, initial_delay_sec, interval_min),
            daemon=True
        )
        _sync_thread.start()
        logger.info("Thread do agendador de sincroniza√ß√£o fiscal iniciada.")
    else:
        logger.warning("Thread do agendador de sincroniza√ß√£o fiscal j√° est√° em execu√ß√£o.")

def stop_fiscal_sync_scheduler():
    global _sync_thread
    if _sync_thread and _sync_thread.is_alive():
        logger.info("Parando thread do agendador de sincroniza√ß√£o fiscal...")
        _stop_sync_event.set()
        _sync_thread.join(timeout=10)
        if _sync_thread.is_alive():
            logger.warning("Thread do agendador de sincroniza√ß√£o fiscal n√£o parou adequadamente ap√≥s 10s.")
        _sync_thread = None
    else:
        logger.info("Thread do agendador de sincroniza√ß√£o fiscal n√£o est√° em execu√ß√£o ou j√° foi parada.")
</file>

<file path="src/services/observation_service.py">
# src/services/observation_service.py
# Contains business logic related to managing product observations using ORM.

from typing import List, Dict, Any
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from src.database import get_db_session
from src.database.observation_repository import ObservationRepository
from src.domain.observation import Observation
from src.domain.user import User
from src.utils.logger import logger
from src.api.errors import NotFoundError, ServiceError, ValidationError, ForbiddenError, DatabaseError
from sqlalchemy.exc import SQLAlchemyError

class ObservationService:
    """
    Camada de servi√ßo para gerenciamento de observa√ß√µes de produtos usando ORM Sessions.
    """

    def __init__(self, observation_repository: ObservationRepository):
        self.observation_repository = observation_repository
        logger.info("ObservationService inicializado (ORM).")

    def add_observation(self, reference_code: str, observation_text: str, user: User) -> Observation:
        """Adiciona uma nova observa√ß√£o para um c√≥digo de refer√™ncia de produto usando ORM."""
        if not reference_code or not observation_text:
            raise ValidationError("O c√≥digo de refer√™ncia e o texto da observa√ß√£o n√£o podem estar vazios.")
        if not user or not user.username:
            raise ValidationError("Informa√ß√µes de usu√°rio v√°lidas s√£o necess√°rias para adicionar uma observa√ß√£o.")

        logger.info(f"Usu√°rio '{user.username}' adicionando observa√ß√£o para refer√™ncia '{reference_code}'.")

        observation = Observation(
            reference_code=reference_code,
            observation_text=observation_text,
            user=user.username,
            timestamp=datetime.now(timezone.utc)
        )

        try:
            with get_db_session() as db:
                created_observation = self.observation_repository.add(db, observation)
            logger.info(f"Observa√ß√£o (ID: {created_observation.id}) adicionada com sucesso para refer√™ncia '{reference_code}'.")
            return created_observation
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao adicionar observa√ß√£o para refer√™ncia '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"N√£o foi poss√≠vel adicionar a observa√ß√£o: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao adicionar observa√ß√£o: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao adicionar a observa√ß√£o: {e}") from e

    def get_observations_for_product(self, reference_code: str, include_resolved: bool = True) -> List[Observation]:
        """Recupera observa√ß√µes para um c√≥digo de refer√™ncia de produto espec√≠fico usando ORM."""
        if not reference_code:
            raise ValidationError("O c√≥digo de refer√™ncia n√£o pode estar vazio.")

        logger.debug(f"Buscando observa√ß√µes para refer√™ncia '{reference_code}' (include_resolved={include_resolved}).")
        try:
            with get_db_session() as db:
                observations = self.observation_repository.find_by_reference_code(db, reference_code, include_resolved)
            logger.debug(f"Encontradas {len(observations)} observa√ß√µes para refer√™ncia '{reference_code}'.")
            return observations
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao recuperar observa√ß√µes para refer√™ncia '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"N√£o foi poss√≠vel recuperar as observa√ß√µes: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao recuperar observa√ß√µes: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao recuperar as observa√ß√µes: {e}") from e

    def resolve_observation(self, observation_id: int, resolving_user: User) -> bool:
        """Marca uma observa√ß√£o como resolvida usando ORM."""
        if not resolving_user or not resolving_user.username:
            raise ValidationError("Informa√ß√µes de usu√°rio v√°lidas s√£o necess√°rias para resolver uma observa√ß√£o.")

        logger.info(f"Usu√°rio '{resolving_user.username}' tentando resolver observa√ß√£o ID: {observation_id}.")
        try:
            with get_db_session() as db:
                success = self.observation_repository.mark_as_resolved(db, observation_id, resolving_user.username)
            if success:
                logger.info(f"Observa√ß√£o ID: {observation_id} resolvida com sucesso por '{resolving_user.username}'.")
            else:
                logger.warning(f"Observa√ß√£o ID: {observation_id} n√£o p√¥de ser marcada como resolvida.")
            return success
        except NotFoundError:
            logger.warning(f"Tentativa de resolver observa√ß√£o ID: {observation_id} falhou: N√£o encontrada.")
            raise
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao resolver observa√ß√£o ID {observation_id}: {e}", exc_info=True)
            raise ServiceError(f"N√£o foi poss√≠vel resolver a observa√ß√£o: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao resolver observa√ß√£o: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao resolver a observa√ß√£o: {e}") from e

    def get_unresolved_count(self, reference_code: str) -> int:
        """Obt√©m a contagem de observa√ß√µes n√£o resolvidas para um c√≥digo de refer√™ncia de produto usando ORM."""
        if not reference_code:
            raise ValidationError("O c√≥digo de refer√™ncia n√£o pode estar vazio.")

        logger.debug(f"Obtendo contagem de observa√ß√µes n√£o resolvidas para refer√™ncia '{reference_code}'.")
        try:
            with get_db_session() as db:
                count = self.observation_repository.get_unresolved_count(db, reference_code)
            logger.debug(f"Contagem de n√£o resolvidas para refer√™ncia '{reference_code}': {count}.")
            return count
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao obter contagem de observa√ß√µes n√£o resolvidas para refer√™ncia '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"N√£o foi poss√≠vel obter a contagem de observa√ß√µes n√£o resolvidas: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao obter contagem de n√£o resolvidas: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao obter a contagem de observa√ß√µes n√£o resolvidas: {e}") from e

    def get_references_with_pending_observations(self) -> List[Dict[str, Any]]:
        """Recupera refer√™ncias com observa√ß√µes pendentes usando ORM."""
        logger.debug("Buscando refer√™ncias com observa√ß√µes pendentes.")
        try:
            with get_db_session() as db:
                references = self.observation_repository.get_references_with_pending(db)
            logger.debug(f"Encontradas {len(references)} refer√™ncias com observa√ß√µes pendentes.")
            return references
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao recuperar refer√™ncias com observa√ß√µes pendentes: {e}", exc_info=True)
            raise ServiceError(f"N√£o foi poss√≠vel recuperar as refer√™ncias com observa√ß√µes pendentes: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar refer√™ncias pendentes: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao buscar refer√™ncias com observa√ß√µes pendentes: {e}") from e
</file>

<file path="src/services/product_service.py">
from typing import List, Dict, Any
from src.domain.balance import ProductItem
from src.erp_integration.erp_balance_service import ErpBalanceService
from src.utils.matrix_builder import build_product_matrix
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError, ValidationError

class ProductService:
    """
    Camada de servi√ßo para opera√ß√µes relacionadas a produtos acabados, principalmente informa√ß√µes de saldo.
    """
    def __init__(self, erp_balance_service: ErpBalanceService):
        self.erp_balance_service = erp_balance_service
        logger.info("ProductService inicializado.")

    def get_product_balance_matrix_with_items(self, reference_code: str, calculation_mode: str = 'base') -> Dict[str, Any]:
        """
            Recupera dados de saldo de produto para um c√≥digo de refer√™ncia do ERP,
            formata-os em uma estrutura de matriz (cor x tamanho) e inclui os itens brutos.

            Argumentos:
            reference_code: O c√≥digo de refer√™ncia do produto a ser consultado.
            computation_mode: O modo de c√°lculo de saldo ('base', 'sales', 'production').

            Retorna:
            Um dicion√°rio contendo:
            {
            "reference_code": str,
            "calculation_mode": str,
            "matrix": Dict[str, Any], # A estrutura de matriz de build_product_matrix
            "product_items": List[Dict[str, Any]] # Dados brutos de ProductItem como dicts
            }

            Gera:
            ValidationError: Se os par√¢metros de entrada forem inv√°lidos.
            NotFoundError: Se nenhum produto for encontrado para o c√≥digo de refer√™ncia.
            ServiceError: Se ocorrer um erro durante a comunica√ß√£o do ERP ou o processamento de dados.
        """
        if not reference_code:
            raise ValidationError("O c√≥digo de refer√™ncia do produto n√£o pode estar vazio.")
        if calculation_mode not in ['base', 'sales', 'production']:
            raise ValidationError(f"Modo de c√°lculo inv√°lido: '{calculation_mode}'. Modos v√°lidos: 'base', 'sales', 'production'.")

        logger.info(f"Buscando matriz de saldo e itens para refer√™ncia '{reference_code}', modo '{calculation_mode}'.")

        try:
            logger.debug(f"Chamando servi√ßo de saldo do ERP para c√≥digo de refer√™ncia: {reference_code}")
            product_items: List[ProductItem] = self.erp_balance_service.get_balances(
                reference_code_list=[reference_code],
                is_fabric=False
            )

            if not product_items:
                logger.warning(f"Nenhum item de produto encontrado no ERP para c√≥digo de refer√™ncia: {reference_code}")
                raise NotFoundError(f"Nenhum produto encontrado para o c√≥digo de refer√™ncia '{reference_code}'.")

            logger.debug(f"Encontrados {len(product_items)} itens de produto para refer√™ncia '{reference_code}'. Construindo matriz...")
            matrix_data = build_product_matrix(product_items, calculation_mode)
            logger.info(f"Matriz de saldo constru√≠da com sucesso para refer√™ncia '{reference_code}'.")

            product_items_dict = [item.to_dict() for item in product_items]

            response_data = {
                "reference_code": reference_code,
                "calculation_mode": calculation_mode,
                "matrix": matrix_data,
                "product_items": product_items_dict
            }
            return response_data

        except (NotFoundError, ValidationError) as e:
             raise e
        except Exception as e:
            logger.error(f"Erro ao obter matriz de saldo do produto para '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar matriz de saldo do produto: {e}") from e
</file>

<file path="src/services/README.md">
# src/services

Este diret√≥rio cont√©m a camada de l√≥gica de neg√≥cio da aplica√ß√£o. Os servi√ßos orquestram as opera√ß√µes, coordenando chamadas para a camada de integra√ß√£o com o ERP (`src/erp_integration`) e a camada de acesso ao banco de dados (`src/database`), aplicando regras de neg√≥cio e gerenciando o ciclo de vida das sess√µes de banco de dados para opera√ß√µes que o exigem.

## Arquivos

*   **`accounts_receivable_service.py`**: L√≥gica para buscar, filtrar, enriquecer e formatar documentos de contas a receber, al√©m de gerar boletos. Utiliza `ErpAccountsReceivableService` e `ErpPersonService`.
*   **`auth_service.py`**: L√≥gica para autentica√ß√£o de usu√°rios (login, gera√ß√£o/verifica√ß√£o de token JWT). Utiliza `UserRepository` e gerencia a sess√£o de banco de dados (`get_db_session`) para buscar usu√°rios e atualizar o √∫ltimo login.
*   **`customer_service.py`**: L√≥gica para buscar e formatar dados de clientes (PF/PJ) e estat√≠sticas. Utiliza `ErpPersonService`.
*   **`fabric_service.py`**: L√≥gica para obter a lista de tecidos, combinando dados de saldo, custo e detalhes. Utiliza `ErpBalanceService`, `ErpCostService`, `ErpProductService` e `utils`.
*   **`fiscal_service.py`**: L√≥gica para buscar notas fiscais e gerar DANFE. Utiliza `ErpFiscalService`.
*   **`observation_service.py`**: L√≥gica de neg√≥cio para gerenciar observa√ß√µes de produto (adicionar, buscar, resolver, contar). Utiliza `ObservationRepository` e gerencia a sess√£o de banco de dados (`get_db_session`) para todas as opera√ß√µes no banco.
*   **`product_service.py`**: L√≥gica para obter informa√ß√µes de produtos acabados (matriz de saldo). Utiliza `ErpBalanceService` e `utils`.
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Implementar os casos de uso da aplica√ß√£o.
*   Validar dados de entrada.
*   Coordenar intera√ß√µes entre diferentes fontes de dados (ERP e banco de dados local).
*   Aplicar regras de neg√≥cio.
*   **Gerenciar Sess√µes de Banco de Dados:** Para opera√ß√µes que modificam ou leem dados do banco local (ex: login, gerenciamento de observa√ß√µes, CRUD de usu√°rios), os servi√ßos utilizam o gerenciador de contexto `get_db_session()` para obter uma `Session` SQLAlchemy e pass√°-la aos m√©todos do reposit√≥rio correspondente. A sess√£o garante a atomicidade das opera√ß√µes (commit/rollback).
*   Formatar dados para serem retornados pela camada da API (convertendo objetos ORM em dicion√°rios quando necess√°rio).
*   Lan√ßar exce√ß√µes espec√≠ficas (`ValidationError`, `NotFoundError`, `ServiceError`, `DatabaseError`) para serem tratadas pela camada da API.

## Intera√ß√µes

*   **Camada da API (`src/api`)**: Chama os m√©todos dos servi√ßos.
*   **Camada de Integra√ß√£o ERP (`src/erp_integration`)**: Os servi√ßos utilizam os servi√ßos de integra√ß√£o para interagir com o ERP.
*   **Camada de Banco de Dados (`src/database`)**:
    *   Obt√©m inst√¢ncias dos reposit√≥rios (`UserRepository`, `ObservationRepository`) via fun√ß√µes f√°brica (`get_user_repository`, etc.).
    *   Utiliza `get_db_session()` para obter e gerenciar sess√µes SQLAlchemy.
    *   Passa a `Session` ativa para os m√©todos dos reposit√≥rios que precisam interagir com o banco.
*   **Dom√≠nio (`src/domain`)**: Os servi√ßos manipulam os objetos de dom√≠nio (modelos ORM e Dataclasses).
</file>

<file path="src/utils/__init__.py">
# src/utils/__init__.py

from .logger import logger
from .matrix_builder import build_product_matrix
from .fabric_list_builder import build_fabric_list, filter_fabric_list
from .system_monitor import log_system_resources, start_resource_monitor
from .pdf_utils import decode_base64_to_bytes

__all__ = [
    "logger",
    "build_product_matrix",
    "build_fabric_list",
    "filter_fabric_list",
    "log_system_resources",
    "start_resource_monitor",
    "decode_base64_to_bytes",
]
</file>

<file path="src/utils/data_conversion.py">
# src/utils/data_conversion.py
from datetime import datetime, date, time, timezone
from typing import Any, Optional, Union
from .logger import logger
import sys

def safe_int(value: Any) -> Optional[int]:
    """Converte um valor para inteiro de forma segura, retornando None em caso de falha."""
    if value is None:
        return None
    try:
        if isinstance(value, float) and value.is_integer():
            return int(value)
        if isinstance(value, str):
            try:
                float_val = float(value)
                if float_val.is_integer():
                    return int(float_val)
            except ValueError:
                pass 
        return int(value)
    except (ValueError, TypeError) as e:
        logger.debug(f"N√£o foi poss√≠vel converter o valor '{value}' (tipo: {type(value)}) para inteiro: {e}")
        return None

def safe_float(value: Any) -> Optional[float]:
    """Converte um valor para float de forma segura, retornando None em caso de falha."""
    if value is None:
        return None
    try:
        return float(value)
    except (ValueError, TypeError) as e:
        logger.debug(f"N√£o foi poss√≠vel converter o valor '{value}' (tipo: {type(value)}) para float: {e}")
        return None

def parse_optional_datetime(value: Optional[str]) -> Optional[datetime]:
    """Converte uma string ISO 8601 para um objeto datetime com fuso hor√°rio UTC, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        dt_str = value.replace('Z', '+00:00')
        formatos = [
            "%Y-%m-%dT%H:%M:%S.%f%z",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S.%f",
            "%Y-%m-%dT%H:%M:%S",
        ]
        parsed_dt = None
        for fmt in formatos:
            try:
                parsed_dt = datetime.strptime(dt_str, fmt)
                break
            except ValueError:
                continue

        if parsed_dt is None:
            parsed_dt = datetime.fromisoformat(dt_str)

        if parsed_dt.tzinfo is None:
            parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
        else:
            parsed_dt = parsed_dt.astimezone(timezone.utc)

        return parsed_dt
    except (ValueError, TypeError) as e:
        logger.warning(f"N√£o foi poss√≠vel converter '{value}' para datetime: {e}")
        return None

def parse_optional_date(value: Optional[str]) -> Optional[date]:
    """Converte uma string (YYYY-MM-DD) para um objeto date, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        date_str = value.split('T')[0]
        return date.fromisoformat(date_str)
    except (ValueError, TypeError) as e:
        logger.warning(f"N√£o foi poss√≠vel converter '{value}' para date: {e}")
        return None

def parse_optional_time(value: Optional[str]) -> Optional[time]:
    """Converte uma string (HH:MM:SS ou HH:MM:SS.ffffff) para um objeto time, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        time_str = value.split('T')[-1].split('+')[0].split('-')[0].split('Z')[0]
        formatos = ["%H:%M:%S.%f", "%H:%M:%S"]
        parsed_time = None
        for fmt in formatos:
            try:
                dt_obj = datetime.strptime(time_str, fmt)
                parsed_time = dt_obj.time()
                break
            except ValueError:
                continue
        if parsed_time is None:
            raise ValueError("Formato de hora n√£o reconhecido")
        return parsed_time
    except (ValueError, TypeError, IndexError) as e:
        logger.warning(f"N√£o foi poss√≠vel converter '{value}' para time: {e}")
        return None
</file>

<file path="src/utils/fabric_list_builder.py">
from typing import List, Dict, Any, Optional, TYPE_CHECKING
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.domain.balance import ProductItem as BalanceItem
    from src.domain.cost import ProductCost
    from src.domain.fabric_details import FabricDetailsItem

def build_fabric_list(
    balances: List['BalanceItem'],
    costs: List['ProductCost'],
    details: Dict[int, 'FabricDetailsItem']
) -> List[Dict[str, Any]]:
    """
    Constr√≥i uma lista de tecidos combinando dados de saldo, custo e detalhes.
    """
    from src.domain.balance import ProductItem as BalanceItem
    from src.domain.cost import ProductCost
    from src.domain.fabric_details import FabricDetailsItem

    logger.debug(f"Construindo lista de tecidos com {len(balances)} itens de saldo, {len(costs)} itens de custo, {len(details)} itens de detalhes.")

    cost_map: Dict[int, ProductCost] = {cost.product_code: cost for cost in costs if isinstance(cost, ProductCost)}
    fabric_list: List[Dict[str, Any]] = []
    processed_codes = set()

    for balance_item in balances:
        if not isinstance(balance_item, BalanceItem) or balance_item.product_code in processed_codes:
            continue

        product_code = balance_item.product_code
        processed_codes.add(product_code)

        # Calcular saldo
        fabric_balance = 0
        if balance_item.balances:
            try:
                fabric_balance = balance_item.calculate_base_balance()
            except Exception as e:
                logger.error(f"Erro ao calcular saldo do tecido {product_code}: {e}")
        else:
            logger.warning(f"Tecido {product_code} n√£o possui entradas de saldo.")

        # Obter custo
        cost_value: Optional[float] = None
        cost_item = cost_map.get(product_code)
        if cost_item:
            try:
                cost_value = cost_item.get_primary_cost_value()
            except Exception as e:
                logger.error(f"Erro ao obter custo do tecido {product_code}: {e}")
        else:
            logger.debug(f"Nenhum dado de custo encontrado para o tecido {product_code}.")

        # Obter detalhes
        details_item = details.get(product_code)
        width, grammage, shrinkage = None, None, None
        if isinstance(details_item, FabricDetailsItem):
            width = details_item.width
            grammage = details_item.grammage
            shrinkage = details_item.shrinkage
        elif details_item is not None:
            logger.warning(f"Detalhes encontrados para tecido {product_code}, mas o tipo est√° incorreto: {type(details_item)}")

        fabric_dict = {
            "code": product_code,
            "description": balance_item.product_name or "N/A",
            "balance": fabric_balance,
            "cost": cost_value,
            "width": width,
            "grammage": grammage,
            "shrinkage": shrinkage
        }
        fabric_list.append(fabric_dict)

    balance_codes = {b.product_code for b in balances if isinstance(b, BalanceItem)}
    cost_only_codes = set(cost_map.keys()) - balance_codes
    details_only_codes = set(details.keys()) - balance_codes

    if cost_only_codes:
        logger.warning(f"Custos encontrados para {len(cost_only_codes)} c√≥digos de produto n√£o presentes nos saldos: {list(cost_only_codes)[:10]}...")
    if details_only_codes:
        logger.warning(f"Detalhes encontrados para {len(details_only_codes)} c√≥digos de produto n√£o presentes nos saldos: {list(details_only_codes)[:10]}...")

    logger.info(f"Lista de tecidos constru√≠da com {len(fabric_list)} itens √∫nicos.")
    return fabric_list

def filter_fabric_list(
    fabric_list: List[Dict[str, Any]],
    search_text: Optional[str]
) -> List[Dict[str, Any]]:
    """
    Filtra a lista de tecidos com base no texto de pesquisa no campo 'description'.
    """
    if not search_text:
        logger.debug("Nenhum filtro de pesquisa fornecido para a lista de tecidos.")
        return fabric_list

    search_lower = search_text.lower()
    logger.debug(f"Filtrando lista de tecidos ({len(fabric_list)} itens) com o texto: '{search_text}'")

    filtered_list = [
        item for item in fabric_list
        if isinstance(item.get("description"), str) and search_lower in item["description"].lower()
    ]

    logger.info(f"Lista de tecidos filtrada para {len(filtered_list)} itens.")
    return filtered_list
</file>

<file path="src/utils/logger.py">
import logging
import os
import sys
import traceback
from datetime import datetime
from concurrent_log_handler import ConcurrentRotatingFileHandler
from typing import Optional

# --- Configura√ß√£o ---
LOG_DIRECTORY = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "logs")
LOG_FILENAME_BASE = "app.log"  # Nome base do arquivo de log
LOG_LEVEL_DEFAULT = "DEBUG"  # N√≠vel de log padr√£o
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d | %(funcName)s] - %(message)s'
LOG_MAX_BYTES = 10 * 1024 * 1024  # 10 MB
LOG_BACKUP_COUNT = 10

class Logger:
    """Encapsula a configura√ß√£o do logger usando ConcurrentRotatingFileHandler."""
    _instance = None
    _logger = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(Logger, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, name: str = "SaldoAPI", log_level: Optional[str] = None):
        if self._initialized:
            return

        # Determinar n√≠vel de log
        level_str = log_level
        if level_str is None:
            try:
                from src.config import config  # Importa√ß√£o atrasada para evitar depend√™ncias circulares
                level_str = config.LOG_LEVEL
            except ImportError:
                level_str = LOG_LEVEL_DEFAULT
        level_str = level_str.upper()

        numeric_level = getattr(logging, level_str, None)
        if not isinstance(numeric_level, int):
            print(f"Aviso: N√≠vel de log inv√°lido '{level_str}'. Usando DEBUG por padr√£o.", file=sys.stderr)
            numeric_level = logging.DEBUG
            level_str = "DEBUG"

        self._logger = logging.getLogger(name)
        self._logger.setLevel(numeric_level)

        if not self._logger.handlers:
            formatter = logging.Formatter(LOG_FORMAT)

            # Console
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(formatter)
            self._logger.addHandler(console_handler)

            # Arquivo (ConcurrentRotatingFileHandler)
            try:
                os.makedirs(LOG_DIRECTORY, exist_ok=True)
                log_file_path = os.path.join(LOG_DIRECTORY, LOG_FILENAME_BASE)

                file_handler = ConcurrentRotatingFileHandler(
                    filename=log_file_path,
                    mode='a',
                    maxBytes=LOG_MAX_BYTES,
                    backupCount=LOG_BACKUP_COUNT,
                    encoding='utf-8',
                )
                file_handler.setFormatter(formatter)
                self._logger.addHandler(file_handler)
                print(f"Log configurado (ConcurrentRotatingFileHandler). N√≠vel: {level_str}. Arquivo: {log_file_path}")
            except Exception as e:
                print(f"Erro ao configurar log de arquivo: {e}", file=sys.stderr)

        self._initialized = True

    def get_logger(self) -> logging.Logger:
        """Retorna a inst√¢ncia do logger configurado."""
        if not self._logger:
            raise RuntimeError("Logger n√£o foi inicializado.")
        return self._logger

# Inst√¢ncia global do logger
logger_instance = Logger()
logger = logger_instance.get_logger()

def configure_logger(level: str):
    """Reconfigura o n√≠vel global do logger."""
    global logger_instance, logger
    logger_instance = Logger(log_level=level)
    logger = logger_instance.get_logger()
</file>

<file path="src/utils/matrix_builder.py">
# src/utils/matrix_builder.py
import re
from typing import List, Dict, Any, Tuple, Set, Optional, TYPE_CHECKING
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.domain.balance import ProductItem

def build_product_matrix(products: List['ProductItem'], calculation_mode: str = 'base') -> Dict[str, Any]:
    from src.domain.balance import ProductItem

    if not products:
        logger.warning("build_product_matrix chamado com lista de produtos vazia.")
        return {"colors": [], "sizes": [], "values": {}, "totals": {"base_balance": 0, "sales_orders": 0, "in_production": 0}}

    if calculation_mode not in ['base', 'sales', 'production']:
        raise ValueError(f"Modo de c√°lculo inv√°lido: {calculation_mode}")

    logger.debug(f"Construindo matriz para {len(products)} itens de produto, modo '{calculation_mode}'.")

    color_set: Set[Tuple[str, str]] = set()
    size_set: Set[str] = set()
    product_map: Dict[Tuple[str, str], ProductItem] = {}

    for p in products:
        if not p or not p.color_code or not p.size_name:
            logger.warning(f"Ignorando ProductItem inv√°lido na constru√ß√£o da matriz: {p}")
            continue
        if not isinstance(p, ProductItem):
            logger.warning(f"Ignorando item com tipo inesperado {type(p)} na constru√ß√£o da matriz.")
            continue
        color_set.add((p.color_code, p.color_name or p.color_code))
        size_set.add(p.size_name)
        product_map[(p.color_code, p.size_name)] = p

    sorted_colors = sorted(list(color_set), key=lambda c: c[0])
    sorted_sizes = _smart_sort_sizes(list(size_set))

    matrix: Dict[str, Any] = {
        "colors": [{"code": code, "name": name} for code, name in sorted_colors],
        "sizes": sorted_sizes,
        "values": {}
    }

    for color_code, color_name in sorted_colors:
        matrix["values"][color_code] = {}
        for size_name in sorted_sizes:
            product = product_map.get((color_code, size_name))
            value = 0
            status = "critical"
            product_code_for_cell: Optional[int] = None

            if product:
                try:
                    value = product.get_balance_for_mode(calculation_mode)
                    status = _determine_status(value)
                    product_code_for_cell = product.product_code
                except ValueError as e:
                    logger.error(f"Erro ao calcular saldo para {product.product_code}: {e}")
                    status = "error"
                except Exception as e:
                    logger.error(f"Erro inesperado ao processar produto {product.product_code}: {e}", exc_info=True)
                    status = "error"
            else:
                logger.debug(f"Nenhuma variante de produto encontrada para Cor={color_code}, Tamanho={size_name}.")

            matrix["values"][color_code][size_name] = {
                "value": value,
                "status": status,
                "product_code": product_code_for_cell
            }

    matrix["totals"] = _calculate_totals(products)
    logger.debug("Constru√ß√£o da matriz conclu√≠da.")
    return matrix

def _calculate_totals(products: List['ProductItem']) -> Dict[str, int]:
    from src.domain.balance import ProductItem

    total_base_balance = 0
    total_sales_orders = 0
    total_in_production = 0

    for product in products:
        if not isinstance(product, ProductItem):
            logger.warning(f"Ignorando item com tipo inesperado {type(product)} no c√°lculo dos totais.")
            continue

        if product.balances:
            total_base_balance += product.calculate_base_balance()
            primary_balance = product._get_primary_balance()
            if primary_balance:
                total_sales_orders += primary_balance.sales_order
                total_in_production += (primary_balance.production_order_progress + primary_balance.production_order_wait_lib)
        else:
            logger.warning(f"Produto {product.product_code} inclu√≠do no c√°lculo dos totais, mas sem dados de saldo.")

    return {
        "base_balance": total_base_balance,
        "sales_orders": total_sales_orders,
        "in_production": total_in_production
    }

def _smart_sort_sizes(sizes: List[str]) -> List[str]:
    def sort_key(size: str) -> Tuple[int, int, str]:
        size_upper = size.upper()
        order_map = {"RN": 0, "BB": 1, "PP": 10, "P": 20, "M": 30, "G": 40, "GG": 50, "XG": 60, "EG": 70, "EGG": 80, "UN": 999, "UNICO": 999}
        if size_upper in order_map:
            return (1, order_map[size_upper], size_upper)
        if size_upper.isdigit():
            return (2, int(size_upper), size_upper)
        match_lead_num = re.match(r'(\d+)\s*(.*)', size_upper)
        if match_lead_num:
            return (3, int(match_lead_num.group(1)), size_upper)
        return (9999, 0, size_upper)

    try:
        return sorted(sizes, key=sort_key)
    except Exception as e:
        logger.error(f"Erro ao ordenar tamanhos: {e}. Usando ordena√ß√£o alfanum√©rica padr√£o.", exc_info=True)
        return sorted(sizes)

def _determine_status(value: int) -> str:
    if value <= 0:
        return "critical"
    elif value < 10:
        return "low"
    else:
        return "sufficient"
</file>

<file path="src/utils/pdf_utils.py">
# src/utils/pdf_utils.py
import base64
import binascii
from .logger import logger

def decode_base64_to_bytes(base64_string: str) -> bytes:
    """
    Decodifica uma string Base64 em bytes.

    Args:
        base64_string: A string codificada em Base64.

    Returns:
        Os bytes decodificados.

    Raises:
        ValueError: Se a string de entrada estiver vazia.
        TypeError: Se a entrada n√£o for uma string.
        binascii.Error: Se a string Base64 for inv√°lida ou corrompida.
    """
    if not base64_string:
        raise ValueError("A string Base64 de entrada n√£o pode ser vazia.")
    if not isinstance(base64_string, str):
        raise TypeError("A entrada deve ser uma string.")

    try:
        decoded_bytes = base64.b64decode(base64_string, validate=True)
        logger.debug(f"Base64 decodificado com sucesso (tamanho: {len(base64_string)}) para bytes (tamanho: {len(decoded_bytes)}).")
        return decoded_bytes
    except binascii.Error as e:
        logger.error(f"Falha ao decodificar a string Base64: {e}", exc_info=True)
        raise ValueError(f"String Base64 inv√°lida fornecida: {e}") from e
    except Exception as e:
        logger.error(f"Erro inesperado durante a decodifica√ß√£o Base64: {e}", exc_info=True)
        raise RuntimeError("Ocorreu um erro inesperado durante a decodifica√ß√£o Base64.") from e
</file>

<file path="src/utils/README.md">
# src/utils

Este diret√≥rio cont√©m m√≥dulos utilit√°rios que fornecem funcionalidades de suporte usadas em v√°rias partes da aplica√ß√£o, mas que n√£o se encaixam diretamente na l√≥gica de neg√≥cio principal, acesso a dados ou integra√ß√£o ERP.

## Arquivos

*   **`fabric_list_builder.py`**: Cont√©m as fun√ß√µes `build_fabric_list` e `filter_fabric_list`. A primeira combina dados de saldo, custo e detalhes de tecidos em uma lista formatada. A segunda filtra essa lista com base em um texto de busca.
*   **`logger.py`**: Configura o logger da aplica√ß√£o (usando o m√≥dulo `logging` do Python). Define o formato, n√≠vel e handlers (console e arquivo rotativo) para os logs. Exporta a inst√¢ncia `logger` configurada para ser usada em toda a aplica√ß√£o.
*   **`matrix_builder.py`**: Cont√©m a fun√ß√£o `build_product_matrix` que transforma uma lista de dados de saldo de produto (obtida do ERP) em uma estrutura de matriz (cor x tamanho) para exibi√ß√£o no frontend. Inclui l√≥gica para ordena√ß√£o inteligente de tamanhos e c√°lculo de totais.
*   **`pdf_utils.py`**: Fornece fun√ß√µes utilit√°rias para manipula√ß√£o de dados PDF, como decodificar strings Base64 para bytes.
*   **`system_monitor.py`**: Fornece fun√ß√µes (`log_system_resources`, `start_resource_monitor`, `stop_resource_monitor`) para registrar periodicamente o uso de recursos do sistema (mem√≥ria, CPU, threads) pela aplica√ß√£o. √ötil para monitoramento e diagn√≥stico de performance.
*   **`README.md`**: Este arquivo.

## Uso

Importe as fun√ß√µes ou a inst√¢ncia `logger` diretamente destes m√≥dulos onde for necess√°rio.

```python
# Exemplo de uso do logger
from src.utils.logger import logger
logger.info("Esta √© uma mensagem informativa.")
logger.error("Ocorreu um erro.", exc_info=True)

# Exemplo de uso do matrix_builder (em um servi√ßo, por exemplo)
from src.utils.matrix_builder import build_product_matrix
from src.domain.balance import ProductItem # Assuming product_items is List[ProductItem]
matrix_data = build_product_matrix(product_items, 'sales')

# Exemplo de uso do pdf_utils (em um servi√ßo, por exemplo)
from src.utils.pdf_utils import decode_base64_to_bytes
pdf_bytes = decode_base64_to_bytes(base64_pdf_string) # <<< ADDED

# Exemplo de uso do system_monitor (na inicializa√ß√£o da app, por exemplo)
from src.utils.system_monitor import start_resource_monitor
start_resource_monitor() # Inicia o monitoramento em background
</file>

<file path="src/utils/system_monitor.py">
# src/utils/system_monitor.py
import os
import psutil
import threading
import time
from typing import Optional
from .logger import logger

_monitor_thread: Optional[threading.Thread] = None
_stop_monitor = threading.Event()

def log_system_resources():
    """Registra informa√ß√µes sobre o uso atual de recursos do sistema (Mem√≥ria, CPU, Threads, etc.)."""
    try:
        process = psutil.Process(os.getpid())

        memoria_info = process.memory_info()
        mem_mb = memoria_info.rss / (1024 * 1024)
        logger.info(f"Uso de Recursos - Mem√≥ria (RSS): {mem_mb:.2f} MB")

        cpu_percent = process.cpu_percent(interval=0.1)
        logger.info(f"Uso de Recursos - CPU: {cpu_percent:.2f}%")

        threads = process.num_threads()
        logger.info(f"Uso de Recursos - Threads: {threads}")

        try:
            arquivos_abertos = len(process.open_files())
            logger.info(f"Uso de Recursos - Arquivos Abertos: {arquivos_abertos}")
        except (psutil.AccessDenied, NotImplementedError, Exception) as e:
            logger.debug(f"N√£o foi poss√≠vel obter a contagem de arquivos abertos: {type(e).__name__}")

        try:
            conexoes = len(process.connections(kind='inet'))
            logger.info(f"Uso de Recursos - Conex√µes de Rede (inet): {conexoes}")
        except (psutil.AccessDenied, NotImplementedError, Exception) as e:
            logger.debug(f"N√£o foi poss√≠vel obter a contagem de conex√µes de rede: {type(e).__name__}")

    except psutil.NoSuchProcess:
        logger.warning("N√£o foi poss√≠vel obter informa√ß√µes do processo para monitoramento de recursos (processo finalizado?).")
    except Exception as e:
        logger.error(f"Erro ao registrar uso de recursos do sistema: {e}", exc_info=True)

def _monitor_task(interval_seconds: int = 300):
    """Tarefa em segundo plano que registra recursos periodicamente."""
    logger.info(f"Iniciando monitoramento peri√≥dico de recursos (Intervalo: {interval_seconds}s)")
    while not _stop_monitor.is_set():
        log_system_resources()
        _stop_monitor.wait(timeout=interval_seconds)
    logger.info("Monitoramento peri√≥dico de recursos finalizado.")

def start_resource_monitor(interval_seconds: int = 300):
    """
    Inicia a thread em segundo plano para monitoramento peri√≥dico de recursos.
    Garante que apenas um monitor esteja em execu√ß√£o.
    
    Args:
        interval_seconds: Intervalo de tempo entre logs de recursos (em segundos). Padr√£o: 5 minutos.
    """
    global _monitor_thread
    if _monitor_thread is None or not _monitor_thread.is_alive():
        _stop_monitor.clear()
        _monitor_thread = threading.Thread(target=_monitor_task, args=(interval_seconds,), daemon=True)
        _monitor_thread.start()
    else:
        logger.debug("Thread de monitoramento de recursos j√° est√° em execu√ß√£o.")

def stop_resource_monitor():
    """Envia sinal para a thread de monitoramento em segundo plano parar."""
    global _monitor_thread
    if _monitor_thread and _monitor_thread.is_alive():
        logger.info("Parando a thread de monitoramento de recursos...")
        _stop_monitor.set()
        _monitor_thread.join(timeout=5)
        if _monitor_thread.is_alive():
            logger.warning("A thread de monitoramento de recursos n√£o parou corretamente.")
        _monitor_thread = None
    else:
        logger.debug("Thread de monitoramento de recursos n√£o est√° em execu√ß√£o ou j√° foi parada.")
</file>

</files>
