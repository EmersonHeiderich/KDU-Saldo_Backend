This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.gitignore
AccountsReceivable.json
alembic.ini
alembic/env.py
alembic/README
alembic/script.py.mako
alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py
alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py
alembic/versions/75de064288e5_adiciona_tabelas_iniciais.py
alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py
backend_structure.md
README.md
requirements.txt
run.py
src/__init__.py
src/api/__init__.py
src/api/decorators.py
src/api/errors.py
src/api/README.md
src/api/routes/__init__.py
src/api/routes/accounts_receivable.py
src/api/routes/auth.py
src/api/routes/customer_panel.py
src/api/routes/fabrics.py
src/api/routes/fiscal.py
src/api/routes/observations.py
src/api/routes/products.py
src/api/routes/users.py
src/app.py
src/config/__init__.py
src/config/README.md
src/config/settings.py
src/database/__init__.py
src/database/base_repository.py
src/database/base.py
src/database/fiscal_repository.py
src/database/observation_repository.py
src/database/product_repository.py
src/database/README.md
src/database/schema_manager.py
src/database/user_repository.py
src/domain/__init__.py
src/domain/accounts_receivable.py
src/domain/balance.py
src/domain/cost.py
src/domain/fabric_details.py
src/domain/fiscal_orm.py
src/domain/fiscal.py
src/domain/observation.py
src/domain/person.py
src/domain/README.md
src/domain/user.py
src/erp_integration/__init__.py
src/erp_integration/erp_accounts_receivable_service.py
src/erp_integration/erp_auth_service.py
src/erp_integration/erp_balance_service.py
src/erp_integration/erp_cost_service.py
src/erp_integration/erp_fiscal_service.py
src/erp_integration/erp_person_service.py
src/erp_integration/erp_product_service.py
src/erp_integration/README.md
src/services/__init__.py
src/services/accounts_receivable_service.py
src/services/auth_service.py
src/services/customer_service.py
src/services/fabric_service.py
src/services/fiscal_service.py
src/services/fiscal_sync_service.py
src/services/observation_service.py
src/services/product_service.py
src/services/README.md
src/utils/__init__.py
src/utils/data_conversion.py
src/utils/fabric_list_builder.py
src/utils/logger.py
src/utils/matrix_builder.py
src/utils/pdf_utils.py
src/utils/README.md
src/utils/system_monitor.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
# .gitignore
# Specifies intentionally untracked files that Git should ignore.

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
# Usually these files are created by pyinstaller, if you plan to use it
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/  # Flask instance folder
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# PEP 582; used by PDM, Flit and potentially other tools
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rove concepts
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static analysis results
.pytype/

# Cython debug symbols
cython_debug/

# VS Code settings
.vscode/

# Local database files (if named differently than standard Django/Flask)
# Example:
database/app.db
database/app.db-shm
database/app.db-wal
*.db
# database/app.db-journal # Add specific DB files if not covered by .env path

# Logs directory (defined in logger.py)
logs/

# Temporary files
*.tmp
*.bak
*~
</file>

<file path="AccountsReceivable.json">
{
    "openapi": "3.0.1",
    "info": {
      "title": "API Accounts Receivable",
      "description": "TOTVS.Moda API Swagger Surface",
      "contact": {
        "name": "TOTVS.Moda Atendimento",
        "url": "https://totvssuporte.zendesk.com",
        "email": "atendimentova@totvs.com.br"
      },
      "license": {
        "name": "TOTVS",
        "url": "https://www.totvs.com/"
      },
      "version": "2.8.18"
    },
    "paths": {
      "/api/totvsmoda/accounts-receivable/v2/documents/search": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Obter dados de documentos de contas a receber.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/DocumentRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DocumentResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      },
      "/api/totvsmoda/accounts-receivable/v2/bank-slip": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Retorna o Base64 do Boleto Bancário.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/BankSlipRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/AccountsReceivableTomasResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      },
      "/api/totvsmoda/accounts-receivable/v2/payment-link": {
        "post": {
          "tags": [
            "AccountsReceivable"
          ],
          "summary": "Retorna o Link de Pagamento (PIX) da Fatura.",
          "requestBody": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              },
              "text/json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              },
              "application/*+json": {
                "schema": {
                  "$ref": "#/components/schemas/PaymentLinkRequestModel"
                }
              }
            }
          },
          "responses": {
            "200": {
              "description": "Success",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/AccountsReceivableTomasResponseModel"
                  }
                }
              }
            },
            "400": {
              "description": "Bad Request",
              "content": {
                "application/json": {
                  "schema": {
                    "$ref": "#/components/schemas/DomainNotificationMessage"
                  }
                }
              }
            }
          }
        }
      }
    },
    "components": {
      "schemas": {
        "AccountsReceivableTomasResponseModel": {
          "type": "object",
          "properties": {
            "content": {
              "type": "string",
              "description": "Conteúdo retornado na execução do Tomas.",
              "nullable": true
            },
            "unifaceResponseStatus": {
              "type": "string",
              "description": "Status da resposta da requisição do Tomas no Uniface.",
              "nullable": true
            },
            "unifaceMessage": {
              "type": "string",
              "description": "Mensagem de retorno do Uniface.",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "BankSlipRequestModel": {
          "required": [
            "branchCode",
            "customerCode",
            "installmentNumber",
            "receivableCode"
          ],
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "Código de empresa. Campo \"Empresa\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 4 caracteres.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "Código do cliente. Campo \"Cliente\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres.\u003Cbr\u003ENão pode ser informado junto com customerCpfCnpj, mas um deles deverá ser informado.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "Cpf/Cnpj do cliente. Campo \"Cpf/Cnpj\" do componente PESFM010.\r\n\u003Cbr\u003ETamanho máximo de 14 caracteres, informar apenas números.\u003Cbr\u003ENão pode ser informado junto com customerCode, mas um deles deverá ser informado.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "Código da fatura do cliente. Campo \"Fatura\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 10 caracteres.",
              "format": "int64"
            },
            "installmentNumber": {
              "type": "integer",
              "description": "Número da parcela da fatura do cliente. Campo \"Parcela\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 3 caracteres.",
              "format": "int32"
            }
          },
          "additionalProperties": false
        },
        "CalculatedValuesModel": {
          "type": "object",
          "properties": {
            "daysLate": {
              "type": "integer",
              "description": "Dias de atraso.",
              "format": "int32",
              "nullable": true
            },
            "increaseValue": {
              "type": "number",
              "description": "Valor de acréscimo.",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "description": "Valor de juros/mora.",
              "format": "double",
              "nullable": true
            },
            "fineValue": {
              "type": "number",
              "description": "Valor da multa",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "description": "Valor total dos descontos",
              "format": "double",
              "nullable": true
            },
            "correctedValue": {
              "type": "number",
              "description": "Valor corridigo.",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Valores calculados para títulos vencidos conforme a taxa de juros/multa do título."
        },
        "CheckInstallmentModel": {
          "type": "object",
          "properties": {
            "checkBand": {
              "type": "string",
              "description": "Número da banda do cheque. Campo \"Banda magnética\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            },
            "checkReturnDate1": {
              "type": "string",
              "description": "Data de devolução do primeiro retorno do cheque. Campo \"Data devolução 1\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode1": {
              "type": "integer",
              "description": "Código do motivo de devolução do primeiro retorno do cheque. Campo \"Motivo devolução 1\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription1": {
              "type": "string",
              "description": "Descrição do motivo de devolução do primeiro retorno do cheque. Campo \"Motivo devolução 1\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            },
            "checkReturnDate2": {
              "type": "string",
              "description": "Data de devolução do segundo retorno do cheque. Campo \"Data devolução 2\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode2": {
              "type": "integer",
              "description": "Código do motivo de devolução do segundo retorno do cheque. Campo \"Motivo devolução 2\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription2": {
              "type": "string",
              "description": "Descrição do motivo de devolução do segundo retorno do cheque. Campo \"Motivo devolução 2\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            },
            "checkReturnDate3": {
              "type": "string",
              "description": "Data de devolução do terceiro retorno do cheque. Campo \"Data devolução 3\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "date-time",
              "nullable": true
            },
            "reasonForReturnCode3": {
              "type": "integer",
              "description": "Código do motivo de devolução do terceiro retorno do cheque. Campo \"Motivo devolução 3\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "reasonForReturnDescription3": {
              "type": "string",
              "description": "Descrição do motivo de devolução do terceiro retorno do cheque. Campo \"Motivo devolução 3\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            },
            "bankNumber": {
              "type": "integer",
              "description": "Número do banco do cheque. Campo \"Banco\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "agencyNumber": {
              "type": "integer",
              "description": "Número da agência do banco do cheque.. Campo \"Agência\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "checkNumber": {
              "type": "integer",
              "description": "Número sequncial do cheque. Campo \"Número cheque\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "format": "int32",
              "nullable": true
            },
            "account": {
              "type": "string",
              "description": "Número da conta do cliente do cheque. Campo \"Conta\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            },
            "checkThirdName": {
              "type": "string",
              "description": "Nome do titular do cheque de terceiro. Campo \"Titular chq. terceiro\" do frame \"Informação do cheque\" do componente FCRFM002(FCRFM001 -\u003E Botão informação cheque)",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Lista de cheque da fatura."
        },
        "CommissionDataModel": {
          "type": "object",
          "properties": {
            "commissionedCode": {
              "type": "integer",
              "description": "Código do comissionado. Campo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres",
              "format": "int32"
            },
            "commissionedCpfCnpj": {
              "type": "string",
              "description": "CPF ou CNPJ do comissionado vinculado à pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 14 caracteres",
              "nullable": true
            },
            "typeCode": {
              "type": "integer",
              "description": "Código do tipo comissionado do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 3 caracteres",
              "format": "int32"
            },
            "typeDescription": {
              "type": "string",
              "description": "Descrição do tipo comissionado do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 30 caracteres",
              "nullable": true
            },
            "status": {
              "type": "integer",
              "description": "Situação da comissão. Campo \"Situação\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003E0 Normal\u003Cbr\u003E1 Excluida\u003Cbr\u003E2 Transferida\u003Cbr\u003E3 Transferida recebimento\u003Cbr\u003E4 Trocado comissionado\u003Cbr\u003E5 Responsabilidade\u003Cbr\u003E6 Abatida por exportação\u003Cbr\u003E9 Cancelada",
              "format": "int32"
            },
            "percentageBilling": {
              "type": "number",
              "description": "Percentual de comissão de faturamento. Campo \"% Faturamento\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo: 3 números inteiros com 6 casas decimais.",
              "format": "double"
            },
            "valueBilling": {
              "type": "number",
              "description": "Valor de comissão de faturamento. Campo \"Vl. comis. fat.\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo: 12 caracteres mais 2 caracteres para casas decimais.",
              "format": "double"
            },
            "isPaidBilling": {
              "type": "boolean",
              "description": "Se a comissão de faturamento está paga. Campo Pago do bloco \"Comissionado\" do componente FCRFM001."
            },
            "percentageReceived": {
              "type": "number",
              "description": "Percentual de comissão de recebimento. Campo \"% Recebimento\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo: 3 números inteiros com 6 casas decimais.",
              "format": "double"
            },
            "valueReceived": {
              "type": "number",
              "description": "Valor de comissão de recebimento. Campo \"Vl. comis. rec.\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo: 12 caracteres mais 2 caracteres para casas decimais.",
              "format": "double"
            },
            "isPaidReceived": {
              "type": "boolean",
              "description": "Se a comissão de recebimento está paga. Campo Pago do bloco \"Comissionado\" do componente FCRFM001."
            },
            "rebateValue": {
              "type": "number",
              "description": "Valor de abatimento que incide na comissão. Frame Comissão - Campo Abatimento - Valor - do componente COMFC008 -\u003E \"Detalhe\"  COMFD008.",
              "format": "double",
              "nullable": true
            },
            "paymentCompany": {
              "type": "integer",
              "description": "Se a comissão está paga. Código da empresa do fechamento da comissão. Frame Fechamento - Campo Emp. - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 4 caracteres",
              "format": "int32",
              "nullable": true
            },
            "paymentDateReceived": {
              "type": "string",
              "description": "Se a comissão de recebimento está paga. Data do fechamento do recebimento da comissão. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.",
              "format": "date-time",
              "nullable": true
            },
            "paymentCodeReceived": {
              "type": "number",
              "description": "Se a comissão de recebimento está paga. Número do fechamento do recebimento da comissão. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres",
              "format": "double",
              "nullable": true
            },
            "paymentDateBilling": {
              "type": "string",
              "description": "Se a comissão de faturamento está paga. Data do fechamento do pagamento da comissão. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.",
              "format": "date-time",
              "nullable": true
            },
            "paymentCodeBilling": {
              "type": "number",
              "description": "Se a comissão de faturamento está paga. Número do fechamento do pagamento  da comissão. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Lista de comissão relacionado a fatura."
        },
        "DocumentChangeModel": {
          "type": "object",
          "properties": {
            "startDate": {
              "type": "string",
              "description": "Data/hora inicial de alteração.",
              "format": "date-time",
              "nullable": true
            },
            "endDate": {
              "type": "string",
              "description": "Data/hora final de alteração.",
              "format": "date-time",
              "nullable": true
            },
            "inCheck": {
              "type": "boolean",
              "description": "Houve alteração de cheque."
            }
          },
          "additionalProperties": false
        },
        "DocumentFilterModel": {
          "type": "object",
          "properties": {
            "change": {
              "$ref": "#/components/schemas/DocumentChangeModel"
            },
            "branchCodeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Lista de código empresa. Campo \"Código\" do componente GERFM009.",
              "nullable": true
            },
            "customerCodeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Lista de código de cliente. Campo \"Código\" do componente PESFM010.",
              "nullable": true
            },
            "customerCpfCnpjList": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Lista de código CPF/CNPJ de cliente. Campo \"Número CPF\" ou \"Número CNPJ\" do componente PESFM010.",
              "nullable": true
            },
            "startExpiredDate": {
              "type": "string",
              "description": "Filtro inicial de data de vencimento da fatura. Campo \"Data.vencto\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endExpiredDate": {
              "type": "string",
              "description": "Filtro final de data de vencimento da fatura. Campo \"Data.vencto\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "startPaymentDate": {
              "type": "string",
              "description": "Filtro inicial de data de baixa da fatura. Campo \"Data liquidação\" do componente FCRFM001 botão \"Informação baixa\".",
              "format": "date-time",
              "nullable": true
            },
            "endPaymentDate": {
              "type": "string",
              "description": "Filtro final de data de baixa da fatura. Campo \"Data liquidação\" do componente FCRFM001 botão \"Informação baixa\".",
              "format": "date-time",
              "nullable": true
            },
            "startIssueDate": {
              "type": "string",
              "description": "Filtro inicial de data de emissão da fatura. Campo \"Dt.emissão\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endIssueDate": {
              "type": "string",
              "description": "Filtro final de data de emissão da fatura. Campo \"Dt.emissão\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "startCreditDate": {
              "type": "string",
              "description": "Filtro inicial de data de liquidação da fatura. Campo \"Emp./Dt.Crédito/Nr.Liq\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "endCreditDate": {
              "type": "string",
              "description": "Filtro final de data de liquidação da fatura. Campo \"Emp./Dt.Crédito/Nr.Liq\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "statusList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": " Filtro de Tipo de situação. Campo \"Situação\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o código númerico referente ao tipo de situação \u003Cbr\u003E 1 - Normal \u003Cbr\u003E 2 - Devolvido \u003Cbr\u003E 3 - Cancelado \u003Cbr\u003E 4 - Quebrada ",
              "nullable": true
            },
            "documentTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de documento. Campo \"Tipo documento\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o código númerico referente ao tipo de documento \u003Cbr\u003E 1 - fatura  \u003Cbr\u003E 2 - cheque  \u003Cbr\u003E 3 - dinheiro  \u003Cbr\u003E 4 - cartão de crédito  \u003Cbr\u003E 5 - cartão de débito  \u003Cbr\u003E 6 - nota débeito \u003Cbr\u003E 7 - TEF  \u003Cbr\u003E 8 - cheque TEF  \u003Cbr\u003E 9 - Toco  \u003Cbr\u003E 10 - Adiantamento(saida cx.)  \u003Cbr\u003E 11 - desconto financeiro \u003Cbr\u003E 12 - DOFINI   \u003Cbr\u003E 13 - vale  \u003Cbr\u003E 14 - nota promissoria  \u003Cbr\u003E 15 - cheque garantido  \u003Cbr\u003E 16 - TED/DOC  \u003Cbr\u003E 17 - pré-autorização TEF  \u003Cbr\u003E 18 - cheque presente  \u003Cbr\u003E 19 - TEF/TECBAN - BANRISUL \u003Cbr\u003E 20 - CREDEV  \u003Cbr\u003E 21 - cartão próprio  \u003Cbr\u003E 22 - TEF/HYPERCARD  \u003Cbr\u003E 23 - Bônus desconto \u003Cbr\u003E 25 - voucher  \u003Cbr\u003E 26 - PIX  \u003Cbr\u003E 27 - PicPay  \u003Cbr\u003E 28 - ame  \u003Cbr\u003E 29 - Mercado pago  \u003Cbr\u003E 30 - Marketplace \u003Cbr\u003E 50 - Outro documento ",
              "nullable": true
            },
            "billingTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de faturamento. Campo \"Tipo faturamento\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o código númerico referente ao tipo de faturamento \u003Cbr\u003E 1 - Venda à vista \u003Cbr\u003E 2 - Venda a prazo \u003Cbr\u003E 3 - Recebimento à vista \u003Cbr\u003E 4 - Recebimento a prazo \u003Cbr\u003E 5 - Juro \u003Cbr\u003E 6 - Adiantamento(entrada cx) \u003Cbr\u003E 7 - Dev. adiantamento \u003Cbr\u003E 8 - Tarifa \u003Cbr\u003E 9 - Outra despesa \u003Cbr\u003E 10 - Emprestimo \u003Cbr\u003E 11 - Troca Cheque Por Dinheiro \u003Cbr\u003E 12 - Renegociação de titulo \u003Cbr\u003E 13 - Cobrança cartão \u003Cbr\u003E 14 - Cheque devolvido \u003Cbr\u003E 15 - Compra cheque presente \u003Cbr\u003E 16 - Prestação conta agencia \u003Cbr\u003E 17 - Via exportação \u003Cbr\u003E 18 - Agrupamento de Fatura \u003Cbr\u003E 19 - Vale/adiant. funcionário \u003Cbr\u003E 20 - Locação \u003Cbr\u003E 21 - Cheque presente \u003Cbr\u003E 22 - Recebimento fatura terceiro \u003Cbr\u003E 23 - Cessão direito/crédito \u003Cbr\u003E 24 - Compra para terceiros \u003Cbr\u003E 25 - serviço \u003Cbr\u003E 26 - Titulo terceiros \u003Cbr\u003E 27 - Correção monetária \u003Cbr\u003E 30 - Correio \u003Cbr\u003E 31 - Transferencia de divida \u003Cbr\u003E 32 - Quebra \u003Cbr\u003E 33 - Endosso central de guias \u003Cbr\u003E 34 - Fatura central de guias \u003Cbr\u003E 35 - Condominio \u003Cbr\u003E 36 - Fechamento de Convênio \u003Cbr\u003E 37 - Rateio de despesas \u003Cbr\u003E 38 - Rareio de receitas \u003Cbr\u003E 39 - Pgto duplicata entre empresas \u003Cbr\u003E 40 - Receb faturas entre empresas \u003Cbr\u003E 41 - Receb Chq Pres de outra empresa \u003Cbr\u003E 42 - Transf. saldo entre empresas ",
              "nullable": true
            },
            "dischargeTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de baixa. Campo \"Tipo baixa\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o código númerico referente ao tipo de baixa \u003Cbr\u003E 0 - Título não baixado\u003Cbr\u003E 1 - Via recebimento\u003Cbr\u003E 2 - Baixa para depósito\u003Cbr\u003E 3 - Agrupamento de fatura\u003Cbr\u003E 4 - Devolução de adiant.\u003Cbr\u003E 5 - - Deb. conta (comis., folha)\u003Cbr\u003E 6 - Automática (outro proc)\u003Cbr\u003E 7 - Via banco\u003Cbr\u003E 8 - Baixa para desconto\u003Cbr\u003E 9 - Baixa por renegociação\u003Cbr\u003E 10 - Via faturamento\u003Cbr\u003E 11 - Recebimento de garantia\u003Cbr\u003E 12 - Baixa por conta bancária\u003Cbr\u003E 13 - Baixa na conta representante\u003Cbr\u003E 14 - Baixa por recálculo de cartão\u003Cbr\u003E 15 - Baixa por central de operação\u003Cbr\u003E 16 - Isentado\u003Cbr\u003E 17 - Baixa por abatimento total\u003Cbr\u003E 18 - Baixa título descontado\u003Cbr\u003E 19 - Baixa transferência dívida\u003Cbr\u003E 20 - Baixa por extrato eletronico\u003Cbr\u003E 21 - Baixa por prorrogação\u003Cbr\u003E 22 - Baixa por exportação\u003Cbr\u003E 23 - Baixa por vendor\u003Cbr\u003E 24 - Baixa fatura de funcionário\u003Cbr\u003E 25 - Baixa fatura sócio\u003Cbr\u003E 26 - Baixa adiantamento futuro\u003Cbr\u003E 27 - Baixa CREDEV futuro\u003Cbr\u003E 28 - Baixa título endossado\u003Cbr\u003E 29 - Desconto em comissão\u003Cbr\u003E 30 - Baixa acerto loja\u003Cbr\u003E 31 - Baixa cartão com credev\u003Cbr\u003E 32 - Baixa por Quebra\u003Cbr\u003E 33 - Baixa cobrança terceirizada\u003Cbr\u003E 34 - Baixa por retirada de cobrança terceirizada\u003Cbr\u003E 35 - Boleto e-commerce\u003Cbr\u003E 36 - Baixa por título de terceiros\u003Cbr\u003E 37 - Fechamento de Convênio\u003Cbr\u003E 38 - Acerto entre empresas\u003Cbr\u003E 39 - Baixa adiant. operadora\u003Cbr\u003E 40 - Depósito e-commerce\u003Cbr\u003E 41 - Transferência online e-commerce\u003Cbr\u003E 50 - Outra baixa",
              "nullable": true
            },
            "chargeTypeList": {
              "type": "array",
              "items": {
                "type": "integer",
                "format": "int32"
              },
              "description": "Filtro de Tipo de cobança. Campo \"Tipo cobrança\" do componente \"FCRFM001\"\r\n\u003Cbr\u003E Neste filtro deve ser informado o código númerico referente ao tipo de cobrança \u003Cbr\u003E 0 - Não está em cobrança \u003Cbr\u003E 1 - Simples \u003Cbr\u003E 2 - Descontada \u003Cbr\u003E 3 - Caucionada \u003Cbr\u003E 4 - Vinculada \u003Cbr\u003E 5 - Sem registro \u003Cbr\u003E 6 - Vendor \u003Cbr\u003E 8 - Protestado \u003Cbr\u003E 9 - Custódia \u003Cbr\u003E 11 - Retirado para renegociação \u003Cbr\u003E 12 - Fora de negociação \u003Cbr\u003E 13 - Endossado \u003Cbr\u003E 14 - Operadora de crédito \u003Cbr\u003E 15 - Em cartório \u003Cbr\u003E 16 - Cobrança na loja/empresa \u003Cbr\u003E 17 - Aguardando recebimento \u003Cbr\u003E 18 - Direto para boleto \u003Cbr\u003E 19 - Abatimento total \u003Cbr\u003E 20 - Custodia chq recusado \u003Cbr\u003E 21 - Custodia chq baixa/retirada \u003Cbr\u003E 22 - Custodia chq devolucao \u003Cbr\u003E 23 - Desconto chq recusado \u003Cbr\u003E 24 - Desconto chq baixa/retirada \u003Cbr\u003E 25 - Desconto chq devolucao \u003Cbr\u003E 26 - Cobrança terceirizada \u003Cbr\u003E 27 - SCPC \u003Cbr\u003E 28 - Exportação \u003Cbr\u003E 29 - Cessão direito/crédito \u003Cbr\u003E 30 - Compra para terceiros \u003Cbr\u003E 31 - Convênio \u003Cbr\u003E 32 - Cobrança judicial \u003Cbr\u003E 33 - Negativado \u003Cbr\u003E 34 - Sustado em cartório \u003Cbr\u003E 35 - Protesto cancelado \u003Cbr\u003E 36 - Disponível para cartório \u003Cbr\u003E 51 - Reserva cob. simples \u003Cbr\u003E 52 - Reserva cob. desc. fat. \u003Cbr\u003E 53 - Reserva cob. desc. chq. \u003Cbr\u003E 54 - Reserva cob. caucionada \u003Cbr\u003E 56 - Reserva cob. vinculada \u003Cbr\u003E 59 - Reserva cob. vendor \u003Cbr\u003E 60 - Reserva cob. custódia \u003Cbr\u003E 70 - Reserva para endosso \u003Cbr\u003E 80 - Reserva cheque \u003Cbr\u003E 85 - Reserva desconto custódia \u003Cbr\u003E 90 - Reserva desconto compror \u003Cbr\u003E 98 - Perdas \u003Cbr\u003E 99 - PDD - Fundo Perdido ",
              "nullable": true
            },
            "hasOpenInvoices": {
              "type": "boolean",
              "description": "Indica filtro de fatura em aberto",
              "nullable": true
            },
            "receivableCodeList": {
              "type": "array",
              "items": {
                "type": "number",
                "format": "double"
              },
              "description": "Lista de código de fatura. Campo \"Fatura\" do frame \"Fatura\" do componente FCRFM001.",
              "nullable": true
            },
            "ourNumberList": {
              "type": "array",
              "items": {
                "type": "number",
                "format": "double"
              },
              "description": "Lista de \"Nosso número\" referente a parcela da fatura. Campo \"Nosso número\" do frame \"Parcela\" do componente FCRFM001.",
              "nullable": true
            },
            "commissionedCode": {
              "type": "integer",
              "description": "Filtro pelo Código do comissionado. Campo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres\u003Cbr\u003ENão deve ser informado junto com o CommissionedCpfCnpj",
              "format": "int32",
              "nullable": true
            },
            "commissionedCpfCnpj": {
              "type": "string",
              "description": "Filtro pelo CPF ou CNPJ do comissionado vinculado à pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comissionado\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 14 caracteres\u003Cbr\u003ENão deve ser informado junto com o CommissionedCode",
              "nullable": true
            },
            "closingCodeCommission": {
              "type": "integer",
              "description": "Se a comissão está paga. Filtro pelo Número do fechamento da comissão. Frame Fechamento - Campo Fechamento - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres\u003Cbr\u003EAo informar obrigatório também informar o ClosingCompanyCommission e ClosingDateCommission",
              "format": "int32",
              "nullable": true
            },
            "closingCompanyCommission": {
              "type": "integer",
              "description": "Se a comissão está paga. Filtro pelo Código da empresa do fechamento da comissão. Frame Fechamento - Campo Emp. - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 4 caracteres\u003Cbr\u003EAo informar obrigatório também informar o ClosingCodeCommission e ClosingDateCommission",
              "format": "int32",
              "nullable": true
            },
            "closingDateCommission": {
              "type": "string",
              "description": "Se a comissão está paga. Filtro pela Data do fechamento da comissão. Frame Fechamento - Campo Data - do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003EAo informar obrigatório também informar o ClosingCompanyCommission e ClosingCodeCommission",
              "format": "date-time",
              "nullable": true
            },
            "closingCommissionedCode": {
              "type": "integer",
              "description": "Filtro pelo código do comissionado do fechamento de comissão. Campo \"Comissionado\" do bloco \"Comissão\" do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres\u003Cbr\u003ENão deve ser informado junto com o ClosingCommissionedCpfCnpj",
              "format": "int32",
              "nullable": true
            },
            "closingCommissionedCpfCnpj": {
              "type": "string",
              "description": "Filtro pelo CPF ou CNPJ do comissionado vinculado à pessoa do comissionado cadastrada no componente PESFM010.\r\nCampo \"Comissionado\" do bloco \"Comissão\" do componente COMFC008 -\u003E \"Detalhe\" COMFD008.\r\n\u003Cbr\u003ETamanho máximo de 14 caracteres\u003Cbr\u003ENão deve ser informado junto com o ClosingCommissionedCode",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentModel": {
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "Código da empresa da fatura. Campo \"Empresa\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "Código do cliente da fatura. Campo \"Cliente\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "CPF/CNPJ do cliente. Campo \"Número CPF\" ou \"Número CNPJ\" do componente PESFM010.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "Código da fatura. Campo \"Fatura\" do frame \"Fatura\" do componente FCRFM001.",
              "format": "int64"
            },
            "installmentCode": {
              "type": "integer",
              "description": "Código da parcela fatura. Campo \"Parcela\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32"
            },
            "maxChangeFilterDate": {
              "type": "string",
              "description": "Maior data de alteração dentro do filtro de intervalo de data. Campo populado apenas quando os campos \"filter.change.startDate\" e \"filter.change.endDate\" são informados.",
              "format": "date-time",
              "nullable": true
            },
            "expiredDate": {
              "type": "string",
              "description": "Data de vencimento parcela da fatura. Campo \"Data vencto.\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "paymentDate": {
              "type": "string",
              "description": "Data de pagamento da parcela da fatura. Campo \"Oper./Pagamento\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "issueDate": {
              "type": "string",
              "description": "Data de emissão da parcela da fatura. Campo \"Dt. emissão\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "settlementBranchCode": {
              "type": "integer",
              "description": "Empresa da liquidação da parcela da fatura. Campo \"Emp/Dt. crédito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "settlementDate": {
              "type": "string",
              "description": "Data de crédito da parcela da fatura. Campo \"Emp/Dt. crédito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "date-time",
              "nullable": true
            },
            "settlementSequence": {
              "type": "integer",
              "description": "Nr. da liquidação da parcela da fatura. Campo \"Emp/Dt. crédito/Nr. liq\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "status": {
              "$ref": "#/components/schemas/ReceivableStatusType"
            },
            "documentType": {
              "$ref": "#/components/schemas/DocumentTypeSearchAvailable"
            },
            "billingType": {
              "$ref": "#/components/schemas/ReceivableBillingType"
            },
            "dischargeType": {
              "$ref": "#/components/schemas/ReceivableDischargeType"
            },
            "chargeType": {
              "$ref": "#/components/schemas/ReceivableChargeType"
            },
            "originInstallment": {
              "type": "integer",
              "description": "Parcela origem relacionado a parcela. Campo \"Parcela origem\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "bearerCode": {
              "type": "integer",
              "description": "Código do portador da parcela da fatura. Campo \"Portador\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "bearerName": {
              "type": "string",
              "description": "Nome do portador da parcela da fatura. Campo \"Portador\" do frame \"Parcela\" do componente FCRFM001.",
              "nullable": true
            },
            "installmentValue": {
              "type": "number",
              "description": "Valor da parcela da fatura. Campo \"Valor\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "paidValue": {
              "type": "number",
              "description": "Valor pago da parcela da fatura. Campo \"Vl. pago\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "netValue": {
              "type": "number",
              "description": "Valor líquido da parcela da fatura. Campo \"Valor líquido\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "description": "Valor de desconto da parcela da fatura. Campo \"Valor desconto\" do frame \"Valor dedução\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "rebateValue": {
              "type": "number",
              "description": "Valor de abatimento da parcela da fatura. Campo \"Valor abatimento\" do frame \"Valor dedução\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "description": "Valor de juros da parcela da fatura. Campo \"Valor juro\" do frame \"Valor acréscimo\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "assessmentValue": {
              "type": "number",
              "description": "Valor de multa da parcela da fatura. Campo \"Valor multa\" do frame \"Valor acréscimo\" do componente FCRFM001.",
              "format": "double",
              "nullable": true
            },
            "barCode": {
              "type": "string",
              "description": "Imagem do código de barras da parcela da fatura. Imagem do código de barras do boleto impresso pelo componente FCRFP098.",
              "nullable": true
            },
            "digitableLine": {
              "type": "string",
              "description": "Linha digitável da parcela da fatura. Código da linha digitável do boleto impresso pelo componente FCRFP098.",
              "nullable": true
            },
            "ourNumber": {
              "type": "integer",
              "description": "Nosso número da parcela da fatura. Campo \"Nosso número\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int64",
              "nullable": true
            },
            "dacOurNumber": {
              "type": "string",
              "description": "DAC nosso número da parcela da fatura. Campo \"Nosso número\" do frame \"Valor acréscimo\" do componente FCRFM001.",
              "nullable": true
            },
            "qrCodePix": {
              "type": "string",
              "description": "Link de pagamento para PIX. Campo \"link\" do conteúdo do retorno da geração do PIX no componente GERFC014.",
              "nullable": true
            },
            "dischargeUser": {
              "type": "integer",
              "description": "Operador de baixa da parcela da fatura. Campo \"Oper./Pagamento\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32",
              "nullable": true
            },
            "registrationUser": {
              "type": "integer",
              "description": "Operador de cadastro da parcela da fatura. Campo \"Oper./Inclusão\" do frame \"Parcela\" do componente FCRFM001.",
              "format": "int32"
            },
            "calculatedValues": {
              "$ref": "#/components/schemas/CalculatedValuesModel"
            },
            "check": {
              "$ref": "#/components/schemas/CheckInstallmentModel"
            },
            "invoice": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/InvoiceDataModel"
              },
              "nullable": true
            },
            "commissions": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/CommissionDataModel"
              },
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentRequestModel": {
          "type": "object",
          "properties": {
            "filter": {
              "$ref": "#/components/schemas/DocumentFilterModel"
            },
            "expand": {
              "type": "string",
              "description": "Lista de grupo de dados para expansão separados por  \",\".\r\n\u003Cbr\u003EAs seguintes expressões são suportadas: \"check\", \"invoice\", \"commissioneds\", \"calculateValue\".\u003Cbr\u003EEx.: \"expand\": \"check,invoice,commissioneds,calculateValue\".",
              "nullable": true
            },
            "order": {
              "type": "string",
              "description": " Lista de campos para ordenação separados por \",\". Para ordenação descendente utilizar o caracter \"-\".\r\n As seguintes expressões são suportadas: \"branchCode\", \"customerCode\",\"customerCpfCnpj\", \"receivableCode\", \"installmentCode\" e \"maxChangeFilterDate\"\r\nEx.: \"order\": \"-customerCode,maxChangeFilterDate\"",
              "nullable": true
            },
            "page": {
              "type": "integer",
              "description": "Número da página. Página inicial é 1.",
              "format": "int32"
            },
            "pageSize": {
              "type": "integer",
              "description": "Quantidade de itens por página. Valor padrão é 100. Valor máximo é 100.",
              "format": "int32"
            }
          },
          "additionalProperties": false
        },
        "DocumentResponseModel": {
          "type": "object",
          "properties": {
            "count": {
              "type": "integer",
              "format": "int32"
            },
            "totalPages": {
              "type": "integer",
              "format": "int32"
            },
            "hasNext": {
              "type": "boolean"
            },
            "totalItems": {
              "type": "integer",
              "format": "int32"
            },
            "items": {
              "type": "array",
              "items": {
                "$ref": "#/components/schemas/DocumentModel"
              },
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "DocumentTypeSearchAvailable": {
          "enum": [
            "Invoice",
            "Check",
            "Cash",
            "CreditCard",
            "DebitCard",
            "DebitNote"
          ],
          "type": "integer",
          "description": "tipo de documento das faturas. Campo \"Tipo documento\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Fatura\u003Cbr\u003E2 - Cheque\u003Cbr\u003E3 - Dinheiro\u003Cbr\u003E4 - Cartão de crédito\u003Cbr\u003E5 - Cartão de débito\u003Cbr\u003E6 - Nota de débito\u003Cbr\u003E Somente será realizado consulta para as tipagens acima",
          "format": "int32"
        },
        "DomainNotificationMessage": {
          "type": "object",
          "properties": {
            "code": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            },
            "message": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            },
            "detailedMessage": {
              "type": "string",
              "nullable": true,
              "readOnly": true
            }
          },
          "additionalProperties": false
        },
        "InvoiceDataModel": {
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "Código da empresa. Campo \"Empresa\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32"
            },
            "invoiceSequence": {
              "type": "integer",
              "description": "Código sequencial da nota fiscal. Campo \"Fatura\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32"
            },
            "invoiceDate": {
              "type": "string",
              "description": "Data de movimento da nota fiscal. Campo \"Data fatura\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "date-time"
            },
            "invoiceCode": {
              "type": "integer",
              "description": "Número da nota fiscal. Primeiro campo \"Nota fiscal\" do componente FISFL030 -\u003E \"F12 na Nota fiscal\".",
              "format": "int32",
              "nullable": true
            }
          },
          "additionalProperties": false,
          "description": "Documento fiscal."
        },
        "PaymentLinkRequestModel": {
          "required": [
            "branchCode",
            "customerCode",
            "installmentNumber",
            "receivableCode"
          ],
          "type": "object",
          "properties": {
            "branchCode": {
              "type": "integer",
              "description": "Código de empresa. Campo \"Empresa\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 4 caracteres.",
              "format": "int32"
            },
            "customerCode": {
              "type": "integer",
              "description": "Código do cliente. Campo \"Cliente\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 9 caracteres.\u003Cbr\u003ENão pode ser informado junto com customerCpfCnpj, mas um deles deverá ser informado.",
              "format": "int32"
            },
            "customerCpfCnpj": {
              "type": "string",
              "description": "Cpf/Cnpj do cliente. Campo \"Cpf/Cnpj\" do componente PESFM010.\r\n\u003Cbr\u003ETamanho máximo de 14 caracteres, informar apenas números.\u003Cbr\u003ENão pode ser informado junto com customerCode, mas um deles deverá ser informado.",
              "nullable": true
            },
            "receivableCode": {
              "type": "integer",
              "description": "Código da fatura do cliente. Campo \"Fatura\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 10 caracteres.",
              "format": "int64"
            },
            "installmentNumber": {
              "type": "integer",
              "description": "Número da parcela da fatura do cliente. Campo \"Parcela\" do componente FCRFM001.\r\n\u003Cbr\u003ETamanho máximo de 3 caracteres.",
              "format": "int32"
            },
            "daysLate": {
              "type": "integer",
              "format": "int32",
              "nullable": true
            },
            "increaseValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "discountValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "fineValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "interestValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            },
            "correctedValue": {
              "type": "number",
              "format": "double",
              "nullable": true
            }
          },
          "additionalProperties": false
        },
        "ReceivableBillingType": {
          "enum": [
            "CashSale",
            "InstallmentSale",
            "CashReceivable",
            "InstallmentReceivable",
            "Interest",
            "Advance",
            "AdvanceReturn",
            "Tariff",
            "OtherExpense",
            "Loan",
            "ExchangeCheckForCash",
            "TitleRenegotiation",
            "ChargeCard",
            "CheckReturned",
            "PurchaseCheckCurrent",
            "AccountabilityAgency",
            "ViaExport",
            "InvoiceGrouping",
            "EmployeeVoucherAdvance",
            "Location",
            "CheckCurrent",
            "ReceiptInvoiceOthers",
            "RightAssignmentCredit",
            "PurchaseForOthers",
            "Service",
            "OtherTitle",
            "MonetaryCorrection",
            "PostOffice",
            "DebitTransfer",
            "Break",
            "EndorsementCentralGuides",
            "InvoiceCentralGuides",
            "Condominium",
            "AgreementClosing",
            "ApportionmentCosts",
            "ApportionmentRevenue",
            "PaymentDuplicateBetweenCompanies",
            "ReceivingInvoicesBetweenCompanies",
            "ReceivesCheckCurrentFromAnotherCompany",
            "BalanceTransferBetweenCompanies"
          ],
          "type": "integer",
          "description": "tipo de faturamento das faturas. Campo \"Tipo faturamento\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Venda à vista\u003Cbr\u003E2 - Venda a prazo\u003Cbr\u003E3 - Recebimento à vista\u003Cbr\u003E4 - Recebimento a prazo\u003Cbr\u003E5 - Juro\u003Cbr\u003E6 - Adiantamento (entrada cx.)\u003Cbr\u003E7 - Dev.adiantamento\u003Cbr\u003E8 - Tarifa\u003Cbr\u003E9 - Outra despesa\u003Cbr\u003E10 - Emprestimo\u003Cbr\u003E11 - Troca cheque por Dinheiro\u003Cbr\u003E12 - Renegociação de título\u003Cbr\u003E13 - Cobrança cartão\u003Cbr\u003E14 - Cheque devolvido\u003Cbr\u003E15 - Compra cheque presente\u003Cbr\u003E16 - Prestacao conta agencia\u003Cbr\u003E17 - Via exportacao\u003Cbr\u003E18 - Agrupamento de Fatura\u003Cbr\u003E19 - Vale/adiant. funcionário\u003Cbr\u003E20 - Locação\u003Cbr\u003E21 - Cheque presente\u003Cbr\u003E22 - Recebimento fatura terceiro\u003Cbr\u003E23 - Cessão direito/crédito\u003Cbr\u003E24 - Compra para terceiros\u003Cbr\u003E25 - Serviço\u003Cbr\u003E26 - Título de terceiros\u003Cbr\u003E27 - Correção monetária\u003Cbr\u003E30 - Correio\u003Cbr\u003E31 - Transferência de dívida\u003Cbr\u003E32 - Quebra\u003Cbr\u003E33 - Endosso central de guias\u003Cbr\u003E34 - Fatura central de guias\u003Cbr\u003E35 - Condomínio\u003Cbr\u003E36 - Fechamento de Convênio\u003Cbr\u003E37 - Rateio de despesas\u003Cbr\u003E38 - Rateio de receitas\u003Cbr\u003E39 - Pgto duplicata entre empresas\u003Cbr\u003E40 - Receb faturas entre empresas\u003Cbr\u003E41 - Receb Chq Pres de outra empresa\u003Cbr\u003E42 - Transf. saldo entre empresas",
          "format": "int32"
        },
        "ReceivableChargeType": {
          "enum": [
            "NotCharged",
            "Simple",
            "Discounted",
            "Guaranteed",
            "Linked",
            "WithoutRegistration",
            "Vendor",
            "Protested",
            "Custody",
            "WithdrawnForRenegotiation",
            "OutOfTrade",
            "Endorsed",
            "CreditOperator",
            "InNotaryOffice",
            "InStoreCompanyCharge",
            "AwaitingReceipt",
            "DirectToBoleto",
            "TotalSupply",
            "CustodyDeclinedCheck",
            "CheckWithdrawalDeposit",
            "CustodyReturnCheck",
            "CheckDeclinedDiscount",
            "LowCheckWithdrawalDiscount",
            "CheckReturnDiscount",
            "OutsourcedBilling",
            "SCPC",
            "Export",
            "DirectAssignmentCredit",
            "ThirdPartyPurchase",
            "Agreement",
            "JudicialCollection",
            "Negative",
            "SupportedByNotaryPublic",
            "ProtestCanceled",
            "AvailableForNotaryPublic",
            "DigitalWallet",
            "Bolepix",
            "BookingSimpleCharge",
            "ReservationChargeDiscountInvoice",
            "ReservationChargeDiscountCheck",
            "GuaranteedCollectionReserve",
            "LinkedChargeReserve",
            "VendorBillingReserve",
            "CustodyChargeReservation",
            "ReservationForEndorsement",
            "ReservationCheck",
            "ReserveCustodyDiscount",
            "ReservationDiscountCompror",
            "Losses",
            "LostFund"
          ],
          "type": "integer",
          "description": "Tipo de cobrança da parcela da fatura. Campo \"Tipo cobrança\" do frame \"Parcela\" do componente FCRFM001.    \r\n\u003Cbr\u003E0 - Não está em cobrança\u003Cbr\u003E1 - Simples\u003Cbr\u003E 2 - Descontada\u003Cbr\u003E 3 - Caucionada\u003Cbr\u003E 4 - Vinculada\u003Cbr\u003E 5 - Sem registro\u003Cbr\u003E 6 - Vendor\u003Cbr\u003E 8 - Protestado\u003Cbr\u003E 9 - Custódia\u003Cbr\u003E11 - Retirado para renegociação\u003Cbr\u003E12 - Fora de negociação\u003Cbr\u003E13 - Endossado\u003Cbr\u003E14 - Operadora de crédito\u003Cbr\u003E15 - Em cartório\u003Cbr\u003E16 - Cobrança na loja/empresa\u003Cbr\u003E17 - Aguardando recebimento\u003Cbr\u003E18 - Direto para boleto\u003Cbr\u003E19 - Abatimento total\u003Cbr\u003E20 - Custódia cheque recusado\u003Cbr\u003E21 - Custódia cheque baixa/retirada\u003Cbr\u003E22 - Custódia cheque devolução\u003Cbr\u003E23 - Desconto cheque recusado\u003Cbr\u003E24 - Desconto cheque baixa/retirada\u003Cbr\u003E25 - Desconto cheque devolução\u003Cbr\u003E26 - Cobrança terceirizada\u003Cbr\u003E27 - SCPC\u003Cbr\u003E28 - Exportação\u003Cbr\u003E29 - Cessão direito/crédito\u003Cbr\u003E30 - Compra para terceiros\u003Cbr\u003E31 - Convênio\u003Cbr\u003E32 - Cobrança Judicial\u003Cbr\u003E33 - Negativado\u003Cbr\u003E34 - Sustado em cartório\u003Cbr\u003E35 - Protesto cancelado\u003Cbr\u003E36 - Disponível para cartório\u003Cbr\u003E37 - Carteira digital\u003Cbr\u003E38 - Bolepix\u003Cbr\u003E51 - Reserva cobrança simples\u003Cbr\u003E52 - Reserva cobrança desconto faturado\u003Cbr\u003E53 - Reserva cobrança desconto cheque\u003Cbr\u003E54 - Reserva cobrança caucionada\u003Cbr\u003E56 - Reserva cobrança vinculada\u003Cbr\u003E59 - Reserva cobrança vendor\u003Cbr\u003E60 - Reserva cobrança custódia\u003Cbr\u003E70 - Reserva para endosso\u003Cbr\u003E80 - Reserva cheque\u003Cbr\u003E85 - Reserva desconto custódia\u003Cbr\u003E90 - Reserva desconto compror\u003Cbr\u003E98 - Perdas\u003Cbr\u003E99 - PDD - Fundo perdido",
          "format": "int32"
        },
        "ReceivableDischargeType": {
          "enum": [
            "TitleNotDischarged",
            "ViaReceipt",
            "DischargeForDeposit",
            "InvoiceGrouping",
            "AdvanceReturn",
            "DebitAccount",
            "Automatic",
            "ViaBank",
            "DischargeForDiscount",
            "DischargeByRenegotiation",
            "ViaBilling",
            "WarrantyReceipt",
            "DischargeByBankAccount",
            "DischargeOnRepresentativeAccount",
            "DischargeByCardRecalculation",
            "DischargeByOperationCenter",
            "Exempt",
            "DischargeByTotalReduction",
            "DischargeDiscountedTitle",
            "DischargeDebtTransfer",
            "DischargeByElectronicExtract",
            "DischargeByExtension",
            "DischargeByExport",
            "DischargeByVendor",
            "DischargeEmployeeInvoice",
            "DischargePartnerInvoice",
            "DischargeFutureAdvance",
            "DischargeCredevFuture",
            "DischargeEndorsedTitle",
            "CommissionDiscount",
            "DischargeSettleShop",
            "DischargeCardWithCredev",
            "DischargeByBreak",
            "DischargeOutsourcedBilling",
            "DischargeByWithdrawalChargeOutsourced",
            "EcommerceBillet",
            "DischargeByThirdPartyTitle",
            "AgreementClosing",
            "SettleBetweenCompanies",
            "EcommerceDeposit",
            "OnlineEcommerceTransfer",
            "AnotherDischarge"
          ],
          "type": "integer",
          "description": "tipo de faturamento das faturas. Campo \"Tipo faturamento\" do componente FCRFM001\".\r\n\u003Cbr\u003E0 - Título não baixado\u003Cbr\u003E1 - Via recebimento\u003Cbr\u003E2 - Baixa para depósito\u003Cbr\u003E3 - Agrupamento de fatura\u003Cbr\u003E4 - Devolução de adiant.\u003Cbr\u003E5 - Deb. conta (comis., folha)\u003Cbr\u003E6 - Automática (outro proc)\u003Cbr\u003E7 - Via banco\u003Cbr\u003E8 - Baixa para desconto\u003Cbr\u003E9 - Baixa por renegociação\u003Cbr\u003E10 - Via faturamento\u003Cbr\u003E11 - Recebimento de garantia\u003Cbr\u003E12 - Baixa por conta bancária\u003Cbr\u003E13 - Baixa na conta representante\u003Cbr\u003E14 - Baixa por recálculo de cartão\u003Cbr\u003E15 - Baixa por central de operação\u003Cbr\u003E16 - Isentado\u003Cbr\u003E17 - Baixa por abatimento total\u003Cbr\u003E18 - Baixa título descontado\u003Cbr\u003E19 - Baixa transferência dívida\u003Cbr\u003E20 - Baixa por extrato eletronico\u003Cbr\u003E21 - Baixa por prorrogação\u003Cbr\u003E22 - Baixa por exportação\u003Cbr\u003E23 - Baixa por vendor\u003Cbr\u003E24 - Baixa fatura de funcionário\u003Cbr\u003E25 - Baixa fatura sócio\u003Cbr\u003E26 - Baixa adiantamento futuro\u003Cbr\u003E27 - Baixa CREDEV futuro\u003Cbr\u003E28 - Baixa título endossado\u003Cbr\u003E29 - Desconto em comissão\u003Cbr\u003E30 - Baixa acerto loja\u003Cbr\u003E31 - Baixa cartão com credev\u003Cbr\u003E32 - Baixa por Quebra\u003Cbr\u003E33 - Baixa cobrança terceirizada\u003Cbr\u003E34 - Baixa por retirada de cobrança terceirizada\u003Cbr\u003E35 - Boleto e-commerce\u003Cbr\u003E36 - Baixa por título de terceiros\u003Cbr\u003E37 - Fechamento de Convênio\u003Cbr\u003E38 - Acerto entre empresas\u003Cbr\u003E40 - Depósito e-commerces\u003Cbr\u003E41 - Transferência online e-commerce\u003Cbr\u003E50 - Outra baixa",
          "format": "int32"
        },
        "ReceivableStatusType": {
          "enum": [
            "Normal",
            "Returned",
            "Canceled",
            "Broken"
          ],
          "type": "integer",
          "description": "Situação das faturas. Campo \"Situação\" do componente FCRFM001\".\r\n\u003Cbr\u003E1 - Normal\u003Cbr\u003E2 - Devolvido\u003Cbr\u003E3 - Cancelado\u003Cbr\u003E4 - Quebrada",
          "format": "int32"
        }
      },
      "securitySchemes": {
        "Bearer": {
          "type": "apiKey",
          "description": "JWT Authorization header using the Bearer scheme. Example: \"Authorization: Bearer {token}\"",
          "name": "Authorization",
          "in": "header"
        }
      }
    },
    "security": [
      {
        "Bearer": []
      }
    ]
  }
</file>

<file path="alembic.ini">
# A configuration file for Alembic.
# See: https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file

[alembic]
# path to migration scripts
script_location = alembic

# template for migration file names, e.g. "%%(year)d%%(month).2d%%(day).2d_%%(rev)s"
# file_template = %%(rev)s_%%(slug)s

# timezone for computation of timestamps within migration files
# Eg: UTC, EST5EDT
# timezone =

# sys.path path, will be prepended to sys.path if present.
# defaults to %%(here)s
# prepend_sys_path = .

# sqlalchemy.url = driver://user:pass@localhost/dbname
# O URL será carregado dinamicamente a partir da configuração da aplicação em alembic/env.py
sqlalchemy.url = postgresql+psycopg://user:password@host:port/database

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="alembic/env.py">
import os
import sys
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# --- Adicionar Raiz do Projeto ao sys.path ---
# Garante que o Alembic possa encontrar os módulos da sua aplicação
# Ajuste para adicionar o diretório PAI do diretório 'alembic', que é a raiz do projeto.
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT) # Adiciona a raiz do projeto
# --------------------------------------------

# --- Importar configurações e Base dos modelos ---
try:
    # As importações agora devem funcionar, pois 'src' está dentro de PROJECT_ROOT
    from src.config import config as app_config
    from src.database.base import Base
    # Importar todos os modelos ORM para que o Alembic os reconheça
    import src.domain # Garante que __init__.py de domain importe os modelos
except ImportError as e:
    print(f"Erro ao importar módulos da aplicação: {e}")
    print("Certifique-se de que está executando o alembic a partir do diretório raiz do projeto")
    print(f"PROJECT_ROOT: {PROJECT_ROOT}")
    print(f"sys.path: {sys.path}")
    sys.exit(1)
# ----------------------------------------------

# este é o objeto MetaData do Alembic para suporte a 'autogenerate'
# --- Definir target_metadata a partir do Base importado ---
target_metadata = Base.metadata
# -------------------------------------------------------

# outras configurações do arquivo .ini, se houver:
config = context.config

# --- Configurar a URL do banco dinamicamente ---
db_url = app_config.SQLALCHEMY_DATABASE_URI
if not db_url:
    print("Erro: SQLALCHEMY_DATABASE_URI não está configurado na aplicação.")
    sys.exit(1)
config.set_main_option('sqlalchemy.url', db_url)
# ---------------------------------------------

# Interpreta o arquivo de configuração para logging do Python.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Demais configurações e funções run_migrations_offline/online permanecem iguais...

def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        compare_type=True,
        # Usar a convenção de nomenclatura definida em Base
        naming_convention=target_metadata.naming_convention,
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            compare_type=True,
            # Usar a convenção de nomenclatura definida em Base
            naming_convention=target_metadata.naming_convention,
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
</file>

<file path="alembic/README">
Generic single-database configuration.
</file>

<file path="alembic/script.py.mako">
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
</file>

<file path="alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py">
# alembic/versions/29ece17d793b_increase_size_of_freight_type_columns_.py
"""Increase size of freight_type columns in nota_fiscal

Revision ID: 29ece17d793b
Revises: 75de064288e5 # ID da migração anterior que criou as tabelas fiscais
Create Date: 2025-04-03 13:34:08.282181 # Data de criação original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# sqlalchemy.dialects não é estritamente necessário para VARCHAR, mas não prejudica
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '29ece17d793b'
down_revision: Union[str, None] = '75de064288e5' # Aponta para a migração anterior
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comandos CORRIGIDOS para ALTERAR as colunas ###
    # Alterar apenas o tipo/tamanho das colunas necessárias na tabela nota_fiscal
    op.alter_column('nota_fiscal', 'freight_type',
           existing_type=sa.VARCHAR(length=10), # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=50),      # Define o novo tipo/tamanho
           existing_nullable=True)           # Mantém a nulidade existente

    op.alter_column('nota_fiscal', 'freight_type_redispatch',
           existing_type=sa.VARCHAR(length=20), # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=50),      # Define o novo tipo/tamanho
           existing_nullable=True)           # Mantém a nulidade existente
    # ### Fim dos Comandos CORRIGIDOS ###


def downgrade() -> None:
    # ### Comandos CORRIGIDOS para REVERTER a alteração ###
    # Reverter para os tipos/tamanhos originais
    op.alter_column('nota_fiscal', 'freight_type_redispatch',
           existing_type=sa.VARCHAR(length=50), # Informa o tipo atual (VARCHAR 50)
           type_=sa.VARCHAR(length=20),      # Define o tipo antigo (VARCHAR 20)
           existing_nullable=True)

    op.alter_column('nota_fiscal', 'freight_type',
           existing_type=sa.VARCHAR(length=50), # Informa o tipo atual (VARCHAR 50)
           type_=sa.VARCHAR(length=10),      # Define o tipo antigo (VARCHAR 10)
           existing_nullable=True)
    # ### Fim dos Comandos CORRIGIDOS ###
</file>

<file path="alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py">
# alembic/versions/72333f760af5_increase_size_of_ncm_column_in_nota_.py
"""Increase size of ncm column in nota_fiscal_item

Revision ID: 72333f760af5
Revises: 29ece17d793b # ID da migração anterior (a que alterou freight_type)
Create Date: 2025-04-03 13:47:41.300907 # Data de criação original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# Removido import não utilizado de postgresql, mas pode manter se preferir
# from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '72333f760af5'
down_revision: Union[str, None] = '29ece17d793b' # Aponta para a migração que alterou freight_type
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comandos CORRIGIDOS para ALTERAR a coluna ncm ###
    op.alter_column('nota_fiscal_item', 'ncm',
           existing_type=sa.VARCHAR(length=8),  # Informa o tipo existente no DB
           type_=sa.VARCHAR(length=12),     # Define o novo tipo/tamanho
           existing_nullable=True)          # Mantém a nulidade existente
    # ### Fim dos Comandos CORRIGIDOS ###


def downgrade() -> None:
    # ### Comandos CORRIGIDOS para REVERTER a alteração ###
    op.alter_column('nota_fiscal_item', 'ncm',
           existing_type=sa.VARCHAR(length=12), # Informa o tipo atual (VARCHAR 12)
           type_=sa.VARCHAR(length=8),       # Define o tipo antigo (VARCHAR 8)
           existing_nullable=True)
    # ### Fim dos Comandos CORRIGIDOS ###
</file>

<file path="alembic/versions/75de064288e5_adiciona_tabelas_iniciais.py">
"""Adiciona tabelas iniciais

Revision ID: 75de064288e5
Revises: 
Create Date: 2025-04-03 11:25:43.778254

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '75de064288e5'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('product_observations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('reference_code', sa.Text(), nullable=False),
    sa.Column('observation', sa.Text(), nullable=False),
    sa.Column('user', sa.Text(), nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('resolved', sa.Boolean(), nullable=False),
    sa.Column('resolved_user', sa.Text(), nullable=True),
    sa.Column('resolved_timestamp', postgresql.TIMESTAMP(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_product_observations'))
    )
    op.create_index(op.f('ix_product_observations_reference_code'), 'product_observations', ['reference_code'], unique=False)
    op.create_index(op.f('ix_product_observations_resolved'), 'product_observations', ['resolved'], unique=False)
    op.create_table('users',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('username', sa.Text(), nullable=False),
    sa.Column('password_hash', sa.Text(), nullable=False),
    sa.Column('name', sa.Text(), nullable=False),
    sa.Column('email', sa.Text(), nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('last_login', postgresql.TIMESTAMP(timezone=True), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_users'))
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_index(op.f('ix_users_username'), 'users', ['username'], unique=True)
    op.create_table('user_permissions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('is_admin', sa.Boolean(), nullable=False),
    sa.Column('can_access_products', sa.Boolean(), nullable=False),
    sa.Column('can_access_fabrics', sa.Boolean(), nullable=False),
    sa.Column('can_access_customer_panel', sa.Boolean(), nullable=False),
    sa.Column('can_access_fiscal', sa.Boolean(), nullable=False),
    sa.Column('can_access_accounts_receivable', sa.Boolean(), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_user_permissions_user_id_users'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_user_permissions'))
    )
    op.create_index(op.f('ix_user_permissions_user_id'), 'user_permissions', ['user_id'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_user_permissions_user_id'), table_name='user_permissions')
    op.drop_table('user_permissions')
    op.drop_index(op.f('ix_users_username'), table_name='users')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    op.drop_index(op.f('ix_product_observations_resolved'), table_name='product_observations')
    op.drop_index(op.f('ix_product_observations_reference_code'), table_name='product_observations')
    op.drop_table('product_observations')
    # ### end Alembic commands ###
</file>

<file path="alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py">
# alembic/versions/863da6d8e21b_add_unique_constraint_on_branch_.py
"""Add unique constraint on branch, sequence, date for nota_fiscal

Revision ID: 863da6d8e21b
Revises: 72333f760af5 # ID da migração anterior (a que alterou ncm)
Create Date: 2025-04-03 14:36:59.832089 # Data de criação original

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# Removido import não utilizado
# from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '863da6d8e21b'
down_revision: Union[str, None] = '72333f760af5' # Aponta para a migração que alterou ncm
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### Comando CORRIGIDO para ADICIONAR a constraint UNIQUE ###
    # Adicionar a constraint unique composta na tabela nota_fiscal
    op.create_unique_constraint(
        'uq_nota_fiscal_branch_sequence_date', # Nome sugerido para a constraint
        'nota_fiscal',                         # Nome da tabela
        ['branch_code', 'invoice_sequence', 'invoice_date'] # Colunas na constraint
    )
    # ### Fim do Comando CORRIGIDO ###


def downgrade() -> None:
    # ### Comando CORRIGIDO para REMOVER a constraint UNIQUE ###
    # Remover a constraint unique ao reverter
    op.drop_constraint(
        'uq_nota_fiscal_branch_sequence_date', # Nome da constraint a ser removida
        'nota_fiscal',                         # Nome da tabela
        type_='unique'                         # Tipo da constraint
    )
    # ### Fim do Comando CORRIGIDO ###
</file>

<file path="backend_structure.md">
saldo-api/
├── .env                 # Environment variables (SECRET_KEY, API creds, DB connection, etc.) # MODIFIED
├── .gitignore
├── requirements.txt     # MODIFIED (Added SQLAlchemy, psycopg)
├── run.py               # Simple script to run the Flask app
├── README.md            # Project overview, setup, structure # MODIFIED
│
└── src/
    ├── __init__.py
    ├── app.py               # Flask app factory (create_app) # MODIFIED (SQLAlchemy init)
    ├── config/
    │   ├── __init__.py
    │   ├── settings.py      # Load env vars, define Config object, build DB URI # MODIFIED
    │   └── README.md        # Explanation of config files # MODIFIED
    │
    ├── domain/              # Data models (DTOs for ERP and Local DB)
    │   ├── __init__.py
    │   ├── accounts_receivable.py
    │   ├── balance.py
    │   ├── cost.py
    │   ├── fabric_details.py
    │   ├── fiscal.py
    │   ├── observation.py
    │   ├── person.py
    │   ├── user.py
    │   └── README.md        # Explanation of domain models
    │
    ├── database/            # Database interaction layer (PostgreSQL with SQLAlchemy Core)
    │   ├── __init__.py      # Initialize SQLAlchemy engine, repositories, schema
    │   ├── base_repository.py # Uses SQLAlchemy Engine and text()
    │   ├── observation_repository.py # Adapted for SQLAlchemy
    │   ├── product_repository.py # Adapted for SQLAlchemy (Placeholder)
    │   ├── schema_manager.py # Handles table creation/migration (PostgreSQL syntax)
    │   ├── user_repository.py # Adapted for SQLAlchemy
    │   └── README.md        # Explanation of database layer
    │
    ├── services/            # Business logic layer
    │   ├── __init__.py
    │   ├── accounts_receivable_service.py
    │   ├── auth_service.py
    │   ├── customer_service.py
    │   ├── fabric_service.py
    │   ├── fiscal_service.py
    │   ├── observation_service.py
    │   ├── product_service.py
    │   └── README.md        # Explanation of business services
    │
    ├── erp_integration/     # Layer for interacting with the TOTVS ERP API
    │   ├── __init__.py
    │   ├── accounts_receivable_service.py
    │   ├── erp_auth_service.py
    │   ├── erp_balance_service.py
    │   ├── erp_cost_service.py
    │   ├── erp_fiscal_service.py
    │   ├── erp_person_service.py
    │   ├── erp_product_service.py
    │   └── README.md        # Explanation of ERP integration layer
    │
    ├── api/                 # Flask Blueprints and route definitions
    │   ├── __init__.py
    │   ├── routes/
    │   │   ├── __init__.py
    │   │   ├── accounts_receivable.py
    │   │   ├── auth.py
    │   │   ├── customer_panel.py
    │   │   ├── fabrics.py
    │   │   ├── fiscal.py
    │   │   ├── observations.py
    │   │   ├── products.py
    │   │   └── users.py
    │   ├── decorators.py
    │   ├── errors.py
    │   └── README.md        # Explanation of the API layer
    │
    └── utils/
        ├── __init__.py
        ├── fabric_list_builder.py
        ├── logger.py
        ├── matrix_builder.py
        ├── pdf_utils.py
        ├── system_monitor.py
        └── README.md        # Explanation of utility functions
</file>

<file path="README.md">
# Saldo API

API Flask para consulta de saldos de produtos e tecidos, custos, dados de clientes e contas a receber, integrando-se a um ERP TOTVS e utilizando PostgreSQL como banco de dados com SQLAlchemy ORM e Alembic para migrações.

## Funcionalidades Principais

*   **Consulta de Saldo de Produtos:** Retorna o saldo de produtos acabados em formato de matriz (cor x tamanho), com diferentes modos de cálculo (base, vendas, produção).
*   **Consulta de Saldo de Tecidos:** Retorna uma lista de tecidos (matérias-primas) com saldo, custo e detalhes (largura, gramatura, encolhimento).
*   **Gerenciamento de Observações:** Permite adicionar, visualizar e resolver observações associadas a produtos (armazenadas no PostgreSQL).
*   **Painel do Cliente:** Busca dados cadastrais (PF/PJ) e estatísticas financeiras de clientes diretamente do ERP.
*   **Contas a Receber:** Permite buscar documentos de contas a receber com filtros avançados e gerar boletos em PDF via ERP.
*   **Módulo Fiscal:** Permite buscar notas fiscais (NF-e) com filtros e gerar DANFE em PDF via ERP.
*   **Gerenciamento de Usuários:** CRUD de usuários e suas permissões (armazenadas no PostgreSQL, acesso restrito a administradores).
*   **Autenticação e Autorização:** Sistema de login baseado em token JWT com controle de acesso por permissões.
*   **Migrações de Banco de Dados:** Gerenciamento do schema do banco de dados PostgreSQL usando Alembic.

## Estrutura do Projeto

O projeto segue uma arquitetura em camadas para melhor organização e manutenibilidade:

```
saldo-api/
├── .env # Variáveis de ambiente (Credenciais DB, API, Chaves)
├── requirements.txt # Dependências Python
├── run.py # Ponto de entrada para execução
├── alembic.ini # Configuração do Alembic
├── alembic/ # Diretório de migrações do Alembic
│ ├── env.py # Script de ambiente do Alembic
│ ├── script.py.mako # Template de migração
│ └── versions/ # Arquivos de scripts de migração
├── README.md # Este arquivo
│
└── src/
├── app.py # Fábrica da aplicação Flask (create_app)
├── config/ # Configurações (lê .env, define objeto Config)
├── domain/ # Modelos de dados (ORM para DB local, Dataclasses para ERP/DTOs)
├── database/ # Camada de acesso ao banco de dados (PostgreSQL com SQLAlchemy ORM)
├── services/ # Camada de lógica de negócio
├── erp_integration/ # Camada de integração com a API ERP TOTVS
├── api/ # Camada da API REST (Blueprints, rotas, decorators, errors)
└── utils/ # Utilitários (logger, builders, etc.)
```



Consulte os `README.md` dentro de cada diretório (`src/config`, `src/database`, etc.) para mais detalhes sobre sua responsabilidade.

## Setup e Instalação

1.  **Clone o Repositório:**
    ```bash
    git clone <url-do-repositorio>
    cd saldo-api
    ```

2.  **Pré-requisitos:**
    *   **Python:** 3.10 ou superior.
    *   **PostgreSQL:** Um servidor PostgreSQL instalado e acessível.
    *   **Cliente PostgreSQL (libpq):** Bibliotecas cliente do PostgreSQL instaladas e acessíveis.
    *   **Git:** Sistema de controle de versão.

3.  **Crie e Ative um Ambiente Virtual:**
    ```bash
    python -m venv venv
    # Linux/macOS:
    source venv/bin/activate
    # Windows:
    .\venv\Scripts\activate
    ```

4.  **Instale as Dependências:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configure o Banco de Dados PostgreSQL:** (Instruções permanecem as mesmas)
    *   Crie um banco de dados (ex: `connector_db`).
    *   Crie um usuário (ex: `saldo_api_user`) com senha segura.
    *   Conceda privilégios ao usuário no banco.
    *   Configure o `pg_hba.conf` para permitir conexões.

6.  **Configure as Variáveis de Ambiente (`.env`):** (Instruções permanecem as mesmas)
    *   Copie `.env.example` para `.env` (se existir) ou crie um novo.
    *   Preencha `SECRET_KEY`, `DB_TYPE=POSTGRES`, `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`, credenciais da API TOTVS, e configurações da app Flask.

7.  **Aplique as Migrações do Banco de Dados:**
    *   Com as variáveis de ambiente configuradas e o banco acessível, aplique as migrações do Alembic para criar/atualizar o schema:
    ```bash
    alembic upgrade head
    ```
    *   Na primeira execução, isso criará todas as tabelas (`users`, `user_permissions`, `product_observations`, `alembic_version`). A função `initialize_schema` em `src/app.py` também garantirá a criação do usuário `admin` padrão se ele não existir.

8.  **Execute a Aplicação:**
    ```bash
    python run.py
    ```
    A API Flask iniciará e estará disponível em `http://<APP_HOST>:<APP_PORT>`.

## Fluxo de Trabalho de Migração (Alembic)

Sempre que você modificar os modelos ORM em `src/domain/` (adicionar/remover/alterar tabelas ou colunas):

1.  **Gere uma Nova Migração Automática:**
    ```bash
    alembic revision --autogenerate -m "Descreva a mudança aqui"
    ```

2.  **Revise o Script Gerado:** Verifique o arquivo Python criado em `alembic/versions/`. Ajuste se necessário (o autogenerate pode precisar de retoques em casos complexos).

3.  **Aplique a Migração ao Banco:**
    ```bash
    alembic upgrade head
    ```

4.  **Commite** o novo script de migração junto com as alterações nos modelos.

Para reverter a última migração (use com cuidado):
```bash
alembic downgrade -1
```
Para ver o histórico de migrações e o estado atual:
```bash
alembic history
alembic current
```

## Padrões de Desenvolvimento

*   **Nomenclatura:** `snake_case` para variáveis/funções, `PascalCase` para classes, `UPPER_SNAKE_CASE` para constantes.
*   **Estrutura:** Arquitetura em camadas (API, Services, ERP Integration, Database, Domain).
*   **Banco de Dados:** PostgreSQL.
*   **ORM/DB Layer:** **SQLAlchemy ORM** para interação com o banco de dados local.
*   **Migrações:** Alembic para gerenciamento do schema do banco de dados.
*   **Tipagem:** Uso extensivo de type hints.
*   **Modelos:** Uso de **classes ORM (herdando de `Base`)** para representar tabelas do banco local e **`dataclasses`** para representar estruturas de dados do ERP ou DTOs específicos.
*   **Logs:** Logs detalhados usando o módulo `logging` e `ConcurrentRotatingFileHandler`.
*   **Error Handling:** Exceções customizadas e tratamento robusto de erros.
*   **Documentação:** Docstrings, READMEs nos diretórios chave.
*   **Variáveis de Ambiente:** Configurações gerenciadas via `.env`.

## Desenvolvimento Futuro

*   Implementar caching para respostas da API ERP.
*   Adicionar testes unitários e de integração.
*   Melhorar a configuração de CORS para produção.
*   Expandir funcionalidades (Detalhes NF, Link PIX, etc.).
*   Armazenar dados do ERP no PostgreSQL para relatórios/análises futuras.
</file>

<file path="requirements.txt">
Flask>=2.0.0
Flask-Cors>=3.0.0
python-dotenv>=0.19.0
requests>=2.25.0
psutil>=5.8.0
PyJWT>=2.0.0
bcrypt>=3.2.0
cachetools>=5.0.0
SQLAlchemy>=2.0
psycopg>=3.0
alembic>=1.7
</file>

<file path="run.py">
# run.py
# Entry point for running the Flask application.
import os
import sys
import traceback
from src.app import create_app
from src.utils.logger import logger
from src.config.settings import load_config

# Load configuration early
config = load_config()

if __name__ == '__main__':
    app = create_app(config)
    logger.info(f"Starting server on {config.APP_HOST}:{config.APP_PORT}")

    try:
        # Use waitress or gunicorn for production instead of app.run
        app.run(host=config.APP_HOST, port=config.APP_PORT, debug=config.APP_DEBUG)
    except Exception as e:
        logger.critical(f"Fatal error starting server: {e}", exc_info=True)
        logger.critical(f"Traceback: {traceback.format_exc()}")
        sys.exit(1)
</file>

<file path="src/__init__.py">
# src/__init__.py
# This file marks the 'src' directory as a Python package.
</file>

<file path="src/api/__init__.py">
# src/api/__init__.py
# Initializes the API layer and registers blueprints.

from flask import Flask
from .routes.auth import auth_bp
from .routes.users import users_bp
from .routes.products import products_bp
from .routes.fabrics import fabrics_bp
from .routes.observations import observations_bp
from .routes.customer_panel import customer_panel_bp
from .routes.fiscal import fiscal_bp
from .routes.accounts_receivable import accounts_receivable_bp # <<<--- ADDED
from src.utils.logger import logger

# List of blueprints to register
# Add new blueprints here as they are created
BLUEPRINTS = [
    (auth_bp, '/api/auth'),
    (users_bp, '/api/users'),
    (products_bp, '/api/products'),
    (fabrics_bp, '/api/fabrics'),
    (observations_bp, '/api/observations'),
    (customer_panel_bp, '/api/customer_panel'),
    (fiscal_bp, '/api/fiscal'),
    (accounts_receivable_bp, '/api/accounts-receivable'), # <<<--- ADDED
]

def register_blueprints(app: Flask):
    """
    Registers all defined blueprints with the Flask application.

    Args:
        app: The Flask application instance.
    """
    logger.info("Registering API blueprints...")
    for bp, prefix in BLUEPRINTS:
        app.register_blueprint(bp, url_prefix=prefix)
        logger.debug(f"Blueprint '{bp.name}' registered with prefix '{prefix}'.")
    logger.info("All API blueprints registered.")

__all__ = ["register_blueprints"]
</file>

<file path="src/api/decorators.py">
# src/api/decorators.py
# Defines custom decorators for API endpoints, primarily for authentication and authorization.

from functools import wraps
from flask import request, current_app, jsonify
from src.services.auth_service import AuthService
from src.api.errors import AuthenticationError, ForbiddenError, ApiError, ConfigurationError # Added Config Error
from src.utils.logger import logger

# Helper to get auth_service instance from app context
def _get_auth_service() -> AuthService:
        service = current_app.config.get('auth_service')
        if not service:
            logger.critical("AuthService not found in application config!")
            # Raising allows Flask's error handlers to catch it
            raise ApiError("Authentication service is unavailable.", 503)
        return service

def login_required(f):
    """
    Decorator to ensure the user is logged in (valid token).
    Attaches the user object to request.current_user.
    """
    @wraps(f)
    def decorated_function(*args, **kwargs):
        try:
            auth_service = _get_auth_service()
            user = auth_service.get_current_user_from_request()
            if not user:
                    logger.debug("Access denied: No valid token/user found.")
                    # Raise specific error type for handler
                    raise AuthenticationError("Authentication required. Please log in.")

            # Attach user to the request context for use in the endpoint
            request.current_user = user
            logger.debug(f"Access granted for user: {user.username} (ID: {user.id})")
            return f(*args, **kwargs)
        except AuthenticationError as e:
                # Handle auth errors specifically (e.g., token expired, invalid)
                return jsonify({"error": str(e)}), 401
        except ConfigurationError as e: # Handle missing secret key during verification
                logger.critical(f"Auth configuration error during login_required: {e}")
                return jsonify({"error": "Internal server configuration error."}), 500
        except ApiError as e:
                # Handle service unavailable error
                return jsonify({"error": e.message}), e.status_code
        except Exception as e:
                # Catch unexpected errors during user retrieval
                logger.error(f"Error during login_required check: {e}", exc_info=True)
                return jsonify({"error": "Internal server error during authentication check."}), 500
    return decorated_function

def admin_required(f):
    """
    Decorator to ensure the user is logged in AND is an administrator.
    Must be used *after* @login_required.
    """
    @wraps(f)
    @login_required # Ensures login_required runs first and sets request.current_user
    def decorated_function(*args, **kwargs):
        # request.current_user is guaranteed to exist here if @login_required passed
        user = request.current_user
        # Check permissions object exists before accessing attributes
        if not user.permissions or not user.permissions.is_admin:
            logger.warning(f"Access denied: User '{user.username}' (ID: {user.id}) is not an admin.")
            # Raise specific error type for handler
            raise ForbiddenError("Admin privileges required.")

        logger.debug(f"Admin access granted for user: {user.username}")
        return f(*args, **kwargs)
    return decorated_function

# --- Permission-specific decorators ---

def _permission_required(permission_attr: str, error_message: str):
    """Generic factory for permission decorators."""
    def decorator(f):
        @wraps(f)
        @login_required # Always require login first
        def decorated_function(*args, **kwargs):
            user = request.current_user
            # Check if user has permissions object and the specific permission OR is admin
            has_perm = (user.permissions and getattr(user.permissions, permission_attr, False))
            is_admin = (user.permissions and user.permissions.is_admin)

            if not (has_perm or is_admin):
                logger.warning(f"Access denied for user '{user.username}': Lacks permission '{permission_attr}'.")
                raise ForbiddenError(error_message)

            logger.debug(f"Permission '{permission_attr}' granted for user: {user.username} (Admin={is_admin})")
            return f(*args, **kwargs)
        return decorated_function
    return decorator

# Define specific permission decorators using the factory
products_access_required = _permission_required(
    'can_access_products',
    'Access to product information required.'
)

fabrics_access_required = _permission_required(
    'can_access_fabrics',
    'Access to fabric information required.'
)

customer_panel_access_required = _permission_required(
    'can_access_customer_panel',
    'Access to customer panel required.'
)

fiscal_access_required = _permission_required(
    'can_access_fiscal',
    'Access to fiscal module required.'
)

accounts_receivable_access_required = _permission_required( # <<<--- ADDED
    'can_access_accounts_receivable',
    'Access to accounts receivable module required.'
)
</file>

<file path="src/api/errors.py">
# src/api/errors.py
# Defines custom application exceptions and Flask error handlers.

from flask import jsonify, request
from werkzeug.exceptions import HTTPException
from src.utils.logger import logger

# --- Custom Application Exceptions ---

class ApiError(Exception):
    """Base class for custom API errors."""
    status_code = 500
    message = "An internal server error occurred."

    def __init__(self, message=None, status_code=None, payload=None):
        super().__init__()
        if message is not None:
            self.message = message
        if status_code is not None:
            self.status_code = status_code
        self.payload = payload # Optional additional data

    def to_dict(self):
        rv = dict(self.payload or ())
        rv['error'] = self.message
        return rv

class ValidationError(ApiError):
    """Indicates invalid data provided by the client."""
    status_code = 400
    message = "Validation failed."

class AuthenticationError(ApiError):
    """Indicates failure to authenticate."""
    status_code = 401
    message = "Authentication failed."

class InvalidTokenError(AuthenticationError):
    """Indicates the provided token is invalid."""
    message = "Invalid authentication token provided."

class ExpiredTokenError(AuthenticationError):
    """Indicates the provided token has expired."""
    message = "Authentication token has expired."

class ForbiddenError(ApiError):
    """Indicates the user does not have permission for the action."""
    status_code = 403
    message = "You do not have permission to perform this action."

class NotFoundError(ApiError):
    """Indicates a requested resource was not found."""
    status_code = 404
    message = "The requested resource was not found."

class ServiceError(ApiError):
     """Indicates a general error within a service layer operation."""
     status_code = 500
     message = "A service error occurred."

class DatabaseError(ApiError):
    """Indicates an error during a database operation."""
    status_code = 500
    message = "A database error occurred."

class ErpIntegrationError(ApiError):
    """Indicates an error during communication with the external ERP."""
    status_code = 502 # Bad Gateway might be appropriate
    message = "Error communicating with the ERP system."

class ErpNotFoundError(NotFoundError):
     """Indicates a resource was specifically not found in the ERP."""
     message = "Resource not found in the ERP system."

class ConfigurationError(ApiError):
     """Indicates a problem with the application's configuration."""
     status_code = 500
     message = "Application configuration error."


# --- Flask Error Handlers ---

def register_error_handlers(app):
    """Registers custom error handlers with the Flask app."""

    @app.errorhandler(ApiError)
    def handle_api_error(error):
        """Handler for custom ApiError exceptions."""
        logger.warning(f"API Error Handled: {type(error).__name__} - Status: {error.status_code} - Msg: {error.message}")
        response = jsonify(error.to_dict())
        response.status_code = error.status_code
        return response

    @app.errorhandler(HTTPException)
    def handle_http_exception(error):
        """Handler for standard werkzeug HTTPExceptions (like 404, 405)."""
        # Log werkzeug's default exceptions
        # Now 'request' is available
        logger.warning(f"HTTP Exception Handled: {error.code} {error.name} - Path: {request.path} - Msg: {error.description}")
        response = jsonify({"error": f"{error.name}: {error.description}"})
        response.status_code = error.code
        # CORS headers should be handled by Flask-CORS middleware even for errors
        return response

    @app.errorhandler(Exception)
    def handle_generic_exception(error):
        """Handler for any other unhandled exceptions."""
        # Log the full traceback for unexpected errors
        logger.error(f"Unhandled Exception: {error}", exc_info=True)
        # Return a generic 500 error to the client
        response = jsonify({"error": "An unexpected internal server error occurred."})
        response.status_code = 500
        return response

    logger.info("Custom error handlers registered.")
</file>

<file path="src/api/README.md">
# src/api

Este diretório contém a camada da API da aplicação, responsável por expor os endpoints HTTP e lidar com as requisições e respostas, utilizando Flask.

## Arquivos e Subdiretórios

*   **`__init__.py`**: Inicializa o pacote `api` e contém a função `register_blueprints` para registrar todos os blueprints da API na aplicação Flask principal.
*   **`decorators.py`**: Define decoradores customizados (`@login_required`, `@admin_required`, etc.) para controle de acesso (autenticação e autorização). O `@login_required` agora utiliza o `AuthService` (com sua própria sessão de banco de dados) para validar o token e carregar o usuário (`request.current_user`).
*   **`errors.py`**: Define exceções customizadas (`ApiError`, `ValidationError`, etc.) e registra os manipuladores de erro (`@app.errorhandler`) no Flask para respostas JSON padronizadas.
*   **`routes/`**: Subdiretório contendo os blueprints Flask:
    *   `accounts_receivable.py`: Endpoints de Contas a Receber.
    *   `auth.py`: Endpoints de autenticação (`/login`, `/logout`, `/verify`). O endpoint de login chama o `AuthService`.
    *   `customer_panel.py`: Endpoints do painel do cliente.
    *   `fabrics.py`: Endpoint para consulta de tecidos.
    *   `fiscal.py`: Endpoints para o módulo Fiscal.
    *   `observations.py`: Endpoints para gerenciamento de observações. Chamam o `ObservationService` e convertem os objetos ORM `Observation` retornados em JSON usando `.to_dict()`.
    *   `products.py`: Endpoints para produtos acabados.
    *   `users.py`: Endpoints para gerenciamento de usuários (CRUD). Chamam diretamente os métodos do `UserRepository` (obtendo a sessão via `get_db_session` dentro da rota) ou o `AuthService`. Convertem os objetos ORM `User` em JSON usando `.to_dict()`.
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Definir os endpoints da API usando Flask Blueprints.
*   Receber requisições HTTP, validar e extrair dados.
*   Utilizar os decoradores de `decorators.py` para autenticação/autorização.
*   Chamar os métodos apropriados na camada de serviço (`src/services`). **A camada da API não gerencia mais diretamente as sessões de banco de dados; isso é feito pelos serviços que precisam delas.**
*   Receber os resultados (dados brutos, objetos ORM, Dataclasses) ou exceções da camada de serviço.
*   Formatar os resultados em respostas JSON. Para objetos ORM, utiliza o método `.to_dict()` do objeto antes de serializar.
*   Utilizar os manipuladores de erro de `errors.py` para respostas de erro consistentes.
*   Interagir com o contexto da aplicação Flask (`current_app`, `request`, `session`).

## Fluxo de Requisição Típico (com ORM)

1.  Requisição HTTP chega ao Flask.
2.  Flask roteia para o endpoint correspondente.
3.  Decoradores (`@login_required`, etc.) são executados. `@login_required` chama `AuthService.get_current_user_from_request()`, que usa `get_db_session()` para buscar o usuário no banco via `UserRepository`. Se ok, `request.current_user` é populado com o objeto `User` ORM. Se falhar, erro 401/403 é retornado.
4.  A função do endpoint é executada.
5.  A função extrai dados da `request`.
6.  A função chama o método do serviço apropriado (ex: `ObservationService.add_observation`).
7.  O serviço executa a lógica:
    *   Se precisar do banco, ele usa `with get_db_session() as db:`.
    *   Obtém o repositório necessário (ex: `self.observation_repository`).
    *   Chama o método do repositório, **passando a sessão `db`**.
    *   O repositório interage com o banco usando a sessão ORM.
    *   Se precisar do ERP, chama o serviço de integração ERP correspondente.
8.  O serviço retorna dados (podem ser objetos ORM, Dataclasses, dicts) ou lança uma exceção. A sessão do banco é commitada/revertida/fechada pelo `get_db_session()`.
9.  Se o serviço retornar dados:
    *   Se forem objetos ORM, a função do endpoint chama `.to_dict()` neles.
    *   Os dados (agora dicionários/listas) são formatados em JSON e retornados com status 2xx.
10. Se o serviço lançar uma exceção, o manipulador de erro correspondente em `errors.py` captura e retorna a resposta JSON apropriada (4xx ou 5xx).
11. Se ocorrer uma exceção inesperada, o manipulador genérico em `errors.py` captura, loga e retorna 500.
</file>

<file path="src/api/routes/__init__.py">
# src/api/routes/__init__.py
# Makes 'routes' a sub-package of 'api'.
</file>

<file path="src/api/routes/accounts_receivable.py">
# src/api/routes/accounts_receivable.py
# Defines API endpoints for the Accounts Receivable module.

from flask import Blueprint, request, jsonify, current_app, Response
from src.services.accounts_receivable_service import AccountsReceivableService
from src.api.decorators import login_required, accounts_receivable_access_required # Use new decorator
from src.api.errors import ApiError, ErpIntegrationError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger
from src.config import config

accounts_receivable_bp = Blueprint('accounts_receivable', __name__)

# Helper to get Service instance
def _get_ar_service() -> AccountsReceivableService:
    service = current_app.config.get('accounts_receivable_service')
    if not service:
        logger.critical("AccountsReceivableService not found in application config!")
        raise ServiceError("Accounts Receivable service is unavailable.", 503)
    return service

@accounts_receivable_bp.route('/search', methods=['POST'])
@login_required
@accounts_receivable_access_required # Apply permission check
def search_receivables():
    """
    Searches for accounts receivable documents based on provided filters.
    Handles pagination and customer name enrichment.
    ---
    tags: [Accounts Receivable]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      description: JSON payload containing filters, pagination, order, and expand options.
      content:
        application/json:
          schema:
            # Ideally reference the DocumentRequestModel schema defined elsewhere
            # For now, define structure inline or reference external file if using swagger gen
            type: object
            properties:
              filter:
                type: object
                description: "Object containing various filter fields (see DocumentFilterModel)."
                # Add example filter properties here if needed
                example: {"customerCpfCnpjList": ["11122233300"], "startExpiredDate": "2023-01-01"}
              expand:
                type: string
                description: "Comma-separated list of fields to expand (e.g., 'check,invoice,commissioneds,calculateValue'). 'calculateValue' and 'invoice' are implicitly added if needed."
                example: "check,commissions"
              order:
                type: string
                description: "Comma-separated list for ordering (e.g., '-expiredDate,receivableCode')."
                example: "-expiredDate"
              page:
                type: integer
                description: "Page number (default: 1)"
                default: 1
              pageSize:
                type: integer
                description: "Items per page (default/max: 100)"
                default: 100
    responses:
      200:
        description: List of receivable documents found with pagination info.
        content:
          application/json:
            schema:
              type: object
              properties:
                items:
                  type: array
                  items:
                    # Define schema for FormattedReceivableListItem
                    type: object
                    properties:
                      customer_code: { type: integer, nullable: true }
                      customer_cpf_cnpj: { type: string, nullable: true }
                      customer_name: { type: string, nullable: true }
                      invoice_number: { type: integer, nullable: true }
                      document_number: { type: integer, nullable: true } # receivableCode
                      installment_number: { type: integer, nullable: true }
                      bearer_name: { type: string, nullable: true }
                      issue_date: { type: string, format: "date-time", nullable: true }
                      expired_date: { type: string, format: "date-time", nullable: true }
                      days_late: { type: integer, nullable: true }
                      payment_date: { type: string, format: "date-time", nullable: true }
                      value_original: { type: number, format: "float", nullable: true }
                      value_increase: { type: number, format: "float", nullable: true }
                      value_rebate: { type: number, format: "float", nullable: true }
                      value_paid: { type: number, format: "float", nullable: true }
                      value_corrected: { type: number, format: "float", nullable: true }
                      status: { type: integer, nullable: true, description: "1=Normal, 2=Devolvido, 3=Cancelado, 4=Quebrada" }
                      document_type: { type: integer, nullable: true, description: "e.g., 1=Fatura, 2=Cheque..." }
                      billing_type: { type: integer, nullable: true, description: "e.g., 1=Venda Vista, 2=Venda Prazo..." }
                      discharge_type: { type: integer, nullable: true, description: "e.g., 0=Não Baixado, 1=Via Recebimento..." }
                      charge_type: { type: integer, nullable: true, description: "e.g., 0=Não Cobrança, 1=Simples..." }
                page: { type: integer }
                pageSize: { type: integer }
                totalItems: { type: integer }
                totalPages: { type: integer }
                hasNext: { type: boolean }
      400:
        description: Bad request (Invalid JSON, invalid filters or parameters).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      500:
        description: Internal server error or ERP integration error.
      503:
        description: Service unavailable.
    """
    logger.info("Search accounts receivable request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
        return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Extract filters and pagination
    raw_filters = data.get('filter')
    expand = data.get('expand')
    order = data.get('order')
    try:
        page = int(data.get('page', 1))
        page_size = int(data.get('pageSize', 100)) # Use AR page size limit
    except (ValueError, TypeError):
         return jsonify({"error": "Invalid page or pageSize parameters. Must be integers."}), 400

    try:
        service = _get_ar_service()
        result = service.search_receivables(raw_filters, page, page_size, expand, order)
        return jsonify(result), 200

    except ValidationError as e:
        logger.warning(f"Validation error searching receivables: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Not found error searching receivables: {e}")
        # Return 200 with empty list for search not found? Or 404?
        # Let's follow existing pattern and maybe return 200 OK with empty data for search misses
        return jsonify({ "items": [], "page": page, "pageSize": page_size, "totalItems": 0, "totalPages": 0, "hasNext": False }), 200
        # return jsonify({"error": str(e)}), 404 # Alternative: return 404
    except ServiceError as e:
        logger.error(f"Service error searching receivables: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except ApiError as e: # Catch other specific API errors if needed
        logger.error(f"API error searching receivables: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error searching receivables: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while searching receivables."}), 500


@accounts_receivable_bp.route('/boleto', methods=['POST'])
@login_required
@accounts_receivable_access_required # Apply permission check
def generate_boleto():
    """
    Generates and returns the Bank Slip (Boleto) PDF for a specific installment.
    ---
    tags: [Accounts Receivable]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            # Reference BankSlipRequestModel schema
            type: object
            properties:
              branchCode:
                type: integer
                description: "Código da empresa (max 4)."
                example: 1
              customerCode:
                type: integer
                description: "Código do cliente (max 9)."
                example: 12345
              customerCpfCnpj:
                type: string
                description: "CPF/CNPJ do cliente (alternativa a customerCode)."
                example: "11122233300"
              receivableCode:
                type: integer
                format: int64 # As per swagger
                description: "Código da fatura (max 10)."
                example: 98765
              installmentNumber:
                type: integer
                description: "Número da parcela (max 3)."
                example: 1
            required: [branchCode, customerCode, receivableCode, installmentNumber]
    responses:
      200:
        description: Boleto PDF content.
        content:
          application/pdf:
            schema:
              type: string
              format: binary
      400:
        description: Bad request (Invalid JSON, missing required fields, validation error).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      404:
        description: Boleto could not be generated (e.g., installment not found or not eligible).
      500:
        description: Internal server error or ERP integration error.
      502:
        description: Error communicating with ERP during Boleto generation.
      503:
        description: Service unavailable.
    """
    logger.info("Generate boleto request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
        return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Basic check for required fields
    required = ['branchCode', 'customerCode', 'receivableCode', 'installmentNumber']
    if not all(field in data for field in required):
         missing = [field for field in required if field not in data]
         return jsonify({"error": f"Missing required fields: {', '.join(missing)}"}), 400

    try:
        service = _get_ar_service()
        pdf_bytes = service.generate_boleto_pdf(data)

        doc_num = data.get('receivableCode', 'unknown')
        inst_num = data.get('installmentNumber', 'unknown')
        filename = f"boleto_{doc_num}_{inst_num}.pdf"

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'inline; filename="{filename}"'
            }
        )

    except ValidationError as e:
        logger.warning(f"Validation error generating boleto: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Boleto generation failed - Not Found: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error generating boleto: {e.message}", exc_info=True if e.status_code >= 500 else False)
        status_code = e.status_code
        # Check if underlying cause was ERP specific status code
        if isinstance(e.__cause__, ErpIntegrationError) and hasattr(e.__cause__, 'status_code'):
             status_code = e.__cause__.status_code # Use original ERP status if available
        return jsonify({"error": e.message}), status_code
    except ApiError as e: # Catch other specific API errors if needed
        logger.error(f"API error generating boleto: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error generating boleto: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while generating the boleto."}), 500
</file>

<file path="src/api/routes/auth.py">
# src/api/routes/auth.py
# Defines API endpoints related to user authentication and session management.

from flask import Blueprint, request, jsonify, current_app, session
from src.services.auth_service import AuthService # Import the specific service
from src.api.decorators import login_required # Import decorators
from src.api.errors import AuthenticationError, ApiError # Import custom errors
from src.utils.logger import logger

auth_bp = Blueprint('auth', __name__)

# Helper to get auth_service instance from app context
def _get_auth_service() -> AuthService:
     service = current_app.config.get('auth_service')
     if not service:
          logger.critical("AuthService not found in application config!")
          raise ApiError("Authentication service is unavailable.", 503)
     return service

@auth_bp.route('/login', methods=['POST'])
def login():
    """
    Endpoint for user login. Expects JSON payload with 'username' and 'password'.
    Sets a token in the session and returns user info upon success.
    ---
    tags: [Authentication]
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              username:
                type: string
                example: "testuser"
              password:
                type: string
                example: "password123"
            required: [username, password]
    responses:
      200:
        description: Login successful
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Login successful"
                token:
                  type: string
                  description: JWT token (also set in session cookie)
                user:
                  type: object
                  # Define user object structure here based on User.to_dict()
                  example: {"id": 1, "username": "testuser", "name": "Test User", "email": "test@example.com", "is_active": true, "permissions": {"is_admin": false, ...}}
      400:
        description: Bad request (missing fields or invalid JSON)
      401:
        description: Authentication failed (invalid credentials or inactive user)
      500:
        description: Internal server error
    """
    logger.info("Login request received.")
    if not request.is_json:
        logger.warning("Login failed: Request is not JSON.")
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    username = data.get('username')
    password = data.get('password')

    if not username or not password:
        logger.warning("Login failed: Missing username or password.")
        return jsonify({"error": "Username and password are required"}), 400

    try:
        auth_service = _get_auth_service()
        token, user_data = auth_service.login(username, password)
        logger.info(f"User '{username}' logged in successfully.")
        # Token is set in session by the service, return it in response body too
        return jsonify({
            "message": "Login successful",
            "token": token,
            "user": user_data
        }), 200
    except AuthenticationError as e:
        logger.warning(f"Login failed for '{username}': {e}")
        return jsonify({"error": str(e)}), 401
    except ApiError as e: # Catch specific internal errors if needed
         logger.error(f"API error during login for '{username}': {e.message}", exc_info=True)
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error during login for '{username}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred during login."}), 500


@auth_bp.route('/logout', methods=['POST'])
@login_required # Ensure user is logged in to log out
def logout():
    """
    Endpoint for user logout. Clears the session token.
    ---
    tags: [Authentication]
    security:
      - bearerAuth: [] # Indicate JWT Bearer token is expected
    responses:
      200:
        description: Logout successful
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Logout successful"
      401:
        description: Unauthorized (not logged in)
      500:
        description: Internal server error
    """
    logger.info(f"Logout request received for user: {getattr(request, 'current_user', 'Unknown')}")
    try:
        auth_service = _get_auth_service()
        auth_service.logout()
        return jsonify({"message": "Logout successful"}), 200
    except Exception as e:
        logger.error(f"Error during logout: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred during logout."}), 500


@auth_bp.route('/verify', methods=['GET'])
@login_required # Uses the decorator to handle token verification
def verify_token():
    """
    Endpoint to verify the current user's token (passed via header or session).
    Returns current user information if the token is valid.
    Implicitly tested by the @login_required decorator.
    ---
    tags: [Authentication]
    security:
      - bearerAuth: []
    responses:
      200:
        description: Token is valid
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                  example: "Token is valid"
                user:
                  type: object
                  # Define user object structure here
                  example: {"id": 1, "username": "testuser", ...}
      401:
        description: Unauthorized (invalid or expired token)
      500:
        description: Internal server error
    """
    # If @login_required passes, the token is valid and request.current_user is set.
    try:
        user = request.current_user # Access user set by decorator
        logger.info(f"Token verified for user: {user.username} (ID: {user.id})")
        # Return user data (ensure sensitive info like password hash is excluded)
        user_data = user.to_dict(include_hash=False)
        return jsonify({
            "message": "Token is valid",
            "user": user_data
        }), 200
    except AttributeError:
         # Should not happen if decorator works, but handle defensively
         logger.error("request.current_user not set after @login_required passed!")
         return jsonify({"error": "Internal server error during token verification."}), 500
    except Exception as e:
         logger.error(f"Unexpected error during token verification: {e}", exc_info=True)
         return jsonify({"error": "An internal server error occurred during verification."}), 500
</file>

<file path="src/api/routes/customer_panel.py">
# src/api/routes/customer_panel.py (Continued)
# Defines API endpoints for accessing customer data and statistics.

from flask import Blueprint, request, jsonify, current_app
from src.services.customer_service import CustomerService # Import the specific service
from src.erp_integration.erp_person_service import ErpPersonService # Needed to instantiate service
from src.erp_integration import erp_auth_service # Need auth for ERP service
from src.api.decorators import login_required, customer_panel_access_required # Import decorators
from src.api.errors import ApiError, NotFoundError, ValidationError # Import custom errors
from src.utils.logger import logger

customer_panel_bp = Blueprint('customer_panel', __name__)

# Helper function to instantiate or get the CustomerService
# This could be improved with a proper dependency injection framework later
def _get_customer_service() -> CustomerService:
     erp_person_svc = ErpPersonService(erp_auth_service) # Use singleton ERP auth
     # Simple instantiation:
     return CustomerService(erp_person_svc)

@customer_panel_bp.route('/data', methods=['POST'])
@login_required
@customer_panel_access_required
def get_customer_data():
    """
    Fetches customer master data (Individual or Legal Entity) based on search criteria.
    ---
    tags: [Customer Panel]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              search_term:
                type: string
                description: "Customer Code, CPF (11 digits), or CNPJ (14 digits)"
                example: "12345"
              search_type:
                type: string
                description: "'PF' or 'PJ'. Required only if search_term is a Customer Code."
                example: "PF"
            required: [search_term]
    responses:
      200:
        description: Customer data found
        content:
          application/json:
            schema:
              # Define schema based on CustomerService._format_customer_data output
              type: object
              properties:
                 customer_type: {type: string, enum: [PF, PJ]}
                 code: {type: integer}
                 name: {type: string, description: "Name (PF) or Legal Name (PJ)"}
                 # ... other common and specific fields ...
      400:
        description: Bad request (Invalid JSON, missing fields, invalid search term format)
      401:
        description: Unauthorized
      403:
        description: Forbidden (User lacks permission)
      404:
        description: Customer not found
      500:
        description: Internal server error or ERP integration error
    """
    logger.info("Customer data request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    search_term = data.get('search_term')
    search_type = data.get('search_type') # Optional

    if not search_term:
        return jsonify({"error": "Field 'search_term' is required"}), 400

    try:
        customer_service = _get_customer_service()
        customer_details = customer_service.get_customer_details(str(search_term).strip(), search_type)
        return jsonify(customer_details), 200

    except ValidationError as e:
        logger.warning(f"Validation error fetching customer data: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Customer not found for search term '{search_term}': {e}")
        return jsonify({"error": str(e)}), 404
    except ApiError as e: # Catch specific internal/ERP errors
         logger.error(f"API error fetching customer data for '{search_term}': {e.message}", exc_info=False) # Don't need full stack for known API errors
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching customer data for '{search_term}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@customer_panel_bp.route('/statistics', methods=['GET'])
@login_required
@customer_panel_access_required
def get_customer_statistics():
    """
    Fetches financial statistics for a given customer code.
    ---
    tags: [Customer Panel]
    security:
      - bearerAuth: []
    parameters:
      - in: query
        name: customer_code
        schema:
          type: integer
        required: true
        description: The code of the customer.
    responses:
      200:
        description: Customer statistics found
        content:
          application/json:
            schema:
              # Define schema based on CustomerService._format_statistics output
              type: object
              properties:
                 average_delay_days: {type: integer, nullable: true}
                 # ... other statistics fields ...
      400:
        description: Bad request (Missing or invalid customer_code)
      401:
        description: Unauthorized
      403:
        description: Forbidden (User lacks permission)
      404:
        description: Statistics not found for the customer
      500:
        description: Internal server error or ERP integration error
    """
    logger.info("Customer statistics request received.")
    customer_code_str = request.args.get('customer_code')

    if not customer_code_str:
        return jsonify({"error": "Query parameter 'customer_code' is required"}), 400

    try:
        customer_code = int(customer_code_str)
    except (ValueError, TypeError):
        return jsonify({"error": "Query parameter 'customer_code' must be an integer"}), 400

    try:
        # Get current user details for permission checks/logic if needed
        current_user = request.current_user # Set by @login_required
        is_admin = current_user.permissions.is_admin if current_user and current_user.permissions else False

        customer_service = _get_customer_service()
        statistics = customer_service.get_customer_statistics(customer_code, is_admin)
        return jsonify(statistics), 200

    except NotFoundError as e:
        logger.warning(f"Statistics not found for customer code {customer_code}: {e}")
        return jsonify({"error": str(e)}), 404
    except ApiError as e: # Catch specific internal/ERP errors
         logger.error(f"API error fetching statistics for customer {customer_code}: {e.message}", exc_info=False)
         return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching statistics for customer {customer_code}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500
</file>

<file path="src/api/routes/fabrics.py">
# src/api/routes/fabrics.py
# Routes related to fabric information.

from flask import Blueprint, request, jsonify, current_app
from src.services.fabric_service import FabricService
from src.services.auth_service import AuthService
from src.api.decorators import login_required, fabrics_access_required
from src.api.errors import ApiError, NotFoundError, ServiceError
from src.utils.logger import logger

# --- Get Service Instances ---
# Helper functions to get services from app context
def _get_fabric_service() -> FabricService:
    service = current_app.config.get('fabric_service')
    if not service:
        logger.critical("FabricService not found in application config!")
        raise ServiceError("Fabric service is unavailable.", 503)
    return service

# --- Blueprint Definition ---
fabrics_bp = Blueprint('fabrics', __name__)

# --- Routes ---

@fabrics_bp.route('/balances', methods=['POST'])
@login_required
@fabrics_access_required
def get_fabric_balances():
    """
    Endpoint to get fabric balances, costs, and details.
    Accepts optional 'filter' and 'force_refresh' in JSON body.
    ---
    tags:
      - Fabrics
    security:
      - bearerAuth: []
    parameters:
      - in: body
        name: body
        schema:
          type: object
          properties:
            filter:
              type: string
              description: Optional text to filter fabrics by description/code (client-side).
              example: "JEANS"
            force_refresh:
              type: boolean
              description: If true, bypasses the cache and fetches fresh data.
              example: false
    responses:
      200:
        description: List of fabrics with balance, cost, and details.
        schema:
          type: object
          properties:
            fabrics:
              type: array
              items:
                type: object
                properties:
                  code:
                    type: integer
                  description:
                    type: string
                  balance:
                    type: integer
                  cost:
                    type: number
                    format: float
                    nullable: true
                  width:
                    type: number
                    format: float
                    nullable: true
                  grammage:
                    type: number
                    format: float
                    nullable: true
                  shrinkage:
                    type: number
                    format: float
                    nullable: true
            total_items:
               type: integer
      400:
        description: Invalid input.
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      404:
        description: No fabrics found.
      500:
        description: Internal server error or error fetching data from ERP.
      503:
        description: Service unavailable.
    """
    logger.info("Fabric balances request received.")
    data = request.get_json() or {}
    search_filter = data.get('filter')
    force_refresh = data.get('force_refresh', False)

    try:
        fabric_service = _get_fabric_service()
        fabric_list = fabric_service.get_fabrics(
            search_filter=search_filter,
            force_refresh=force_refresh
        )

        logger.info(f"Returning {len(fabric_list)} fabrics.")
        # Structure the response as expected by the frontend service
        return jsonify({
            "fabrics": fabric_list,
            "total_items": len(fabric_list) # Total items *after* filtering
        }), 200

    except NotFoundError as e:
        logger.warning(f"Fabric fetch failed: {e}")
        return jsonify({"error": str(e)}), 404
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error fetching fabrics: {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching fabrics: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred."}), 500


@fabrics_bp.route('/cache/clear', methods=['POST'])
@login_required
@fabrics_access_required # Or maybe admin_required? Check requirements.
def clear_fabric_cache():
    """
    Endpoint to manually clear the fabric data cache.
    ---
    tags:
      - Fabrics
    security:
      - bearerAuth: []
    responses:
      200:
        description: Cache cleared successfully.
        schema:
          type: object
          properties:
            message:
              type: string
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      500:
        description: Internal server error.
      503:
        description: Service unavailable.
    """
    logger.info(f"Request received to clear fabric cache by user '{request.current_user.username}'.")
    try:
        fabric_service = _get_fabric_service()
        fabric_service.clear_fabric_cache()
        return jsonify({"message": "Cache de tecidos limpo com sucesso."}), 200
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error clearing fabric cache: {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error clearing fabric cache: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while clearing the cache."}), 500

# --- Service Instantiation (Done in app factory) ---
# You need to ensure FabricService is instantiated and added to app.config['fabric_service']
# in src/app.py, similar to how auth_service is done.
</file>

<file path="src/api/routes/fiscal.py">
# src/api/routes/fiscal.py
# Defines API endpoints for the Fiscal module.

from typing import Any, Dict
from flask import Blueprint, request, jsonify, current_app, Response
import base64
from src.services.fiscal_service import FiscalService
from src.api.decorators import login_required, fiscal_access_required
from src.api.errors import ApiError, ErpIntegrationError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger
from src.config import config # For default fiscal page size

fiscal_bp = Blueprint('fiscal', __name__)

# Helper to get FiscalService instance
def _get_fiscal_service() -> FiscalService:
    service = current_app.config.get('fiscal_service')
    if not service:
        logger.critical("FiscalService not found in application config!")
        raise ServiceError("Fiscal service is unavailable.", 503)
    return service

@fiscal_bp.route('/invoices/search', methods=['POST'])
@login_required
@fiscal_access_required
def search_fiscal_invoices():
    """
    Searches for fiscal invoices based on provided filters.
    Handles pagination.
    ---
    tags: [Fiscal]
    security:
      - bearerAuth: []
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              page:
                type: integer
                description: "Page number (default: 1)"
                default: 1
              pageSize:
                type: integer
                description: f"Items per page (default: {config.FISCAL_PAGE_SIZE}, max: 100)"
                default: config.FISCAL_PAGE_SIZE
              # <<<--- MODIFIED: Use a single field for customer input --- >>>
              customer_code_cpf_cnpj:
                type: string
                description: "Customer Code, CPF (11 digits), or CNPJ (14 digits). Can be comma-separated for multiple values (only for codes or only for CPF/CNPJ, not mixed)."
                example: "389" # or "11122233344,55566677788899"
              # ----------------------------------------------------------
              invoice_number:
                type: string
                description: "Single number, comma-separated list, or range (e.g., 100-150)."
                example: "1001,1005"
              start_date:
                type: string
                format: date-time
                description: "Start issue date (ISO 8601 format, e.g., YYYY-MM-DD or YYYY-MM-DDTHH:mm:ss)."
                example: "2023-10-01"
              end_date:
                type: string
                format: date-time
                description: "End issue date (ISO 8601 format)."
                example: "2023-10-31T23:59:59"
              status:
                type: string
                description: "Comma-separated list of statuses (e.g., Authorized, Canceled)."
                example: "Authorized"
    responses:
      200:
        description: List of invoices found with pagination info.
        content:
          application/json:
            schema:
              type: object
              properties:
                items:
                  type: array
                  items:
                     $ref: '#/components/schemas/FormattedInvoiceListItem'
                page: { type: integer }
                pageSize: { type: integer }
                totalItems: { type: integer }
                totalPages: { type: integer }
      400:
        description: Bad request (Invalid filters or parameters).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      500:
        description: Internal server error or ERP integration error.
      503:
        description: Service unavailable.
    """
    logger.info("Search fiscal invoices request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not isinstance(data, dict):
         return jsonify({"error": "Invalid JSON payload type. Expected an object."}), 400

    # Extract filters from request data
    filters = {}
    customer_input = data.get("customer_code_cpf_cnpj")
    invoice_number_input = data.get("invoice_number")
    start_date_input = data.get("start_date")
    end_date_input = data.get("end_date")
    status_input = data.get("status")

    # --- START: Intelligent Customer Filter Mapping ---
    if customer_input:
        customer_input_str = str(customer_input).strip()
        # Basic check: if it contains only digits and maybe commas
        is_potentially_numeric = all(c.isdigit() or c == ',' for c in customer_input_str.replace(" ", ""))

        if is_potentially_numeric:
             # Check length characteristics to distinguish code/list-of-codes from CPF/CNPJ
             codes = [c.strip() for c in customer_input_str.split(',') if c.strip()]
             # Heuristic: Assume codes are shorter than 11 digits, CPF/CNPJ are 11 or 14
             if all(len(code) < 11 for code in codes):
                 logger.debug(f"Treating customer input '{customer_input_str}' as customer_code")
                 filters["customer_code"] = customer_input_str # Pass comma-separated string to service
             elif all(len(code) == 11 or len(code) == 14 for code in codes):
                 logger.debug(f"Treating customer input '{customer_input_str}' as customer_cpf_cnpj")
                 filters["customer_cpf_cnpj"] = customer_input_str # Pass comma-separated string to service
             else:
                 # Ambiguous or mixed format
                 logger.warning(f"Ambiguous customer input format: '{customer_input_str}'. Could not determine if code(s) or CPF/CNPJ(s).")
                 # Return error or try one? Let's return an error for clarity.
                 return jsonify({"error": "Invalid format for 'customer_code_cpf_cnpj'. Provide only code(s) or only CPF/CNPJ(s), not mixed or invalid lengths."}), 400
        else:
             # Contains non-digits (excluding comma/space), definitely not code/CPF/CNPJ
             return jsonify({"error": "Invalid characters found in 'customer_code_cpf_cnpj'."}), 400
    # --- END: Intelligent Customer Filter Mapping ---


    # Add other filters if they exist
    if invoice_number_input:
        filters["invoice_number"] = invoice_number_input
    if start_date_input:
        filters["start_date"] = start_date_input
    if end_date_input:
        filters["end_date"] = end_date_input
    if status_input:
        filters["status"] = status_input

    # Extract pagination parameters with validation
    try:
        page = int(data.get('page', 1))
        page_size = int(data.get('pageSize', config.FISCAL_PAGE_SIZE))

        if page < 1:
            page = 1
        if page_size < 1:
            page_size = config.FISCAL_PAGE_SIZE # Fallback to default
        # Service layer will clamp page_size if > 100

    except (ValueError, TypeError):
         logger.warning(f"Invalid pagination parameters received: page={data.get('page')}, pageSize={data.get('pageSize')}")
         return jsonify({"error": "Invalid page or pageSize parameters. Must be integers."}), 400

    try:
        fiscal_service = _get_fiscal_service()
        # Pass the filters dict (now containing the *correct* key based on input)
        result: Dict[str, Any] = fiscal_service.search_invoices(filters, page, page_size)
        return jsonify(result), 200

    except ValidationError as e:
        logger.warning(f"Validation error searching invoices: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"Unexpected NotFoundError during invoice search: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error searching invoices: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except ApiError as e:
        logger.error(f"API error searching invoices: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error searching invoices: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while searching invoices."}), 500


@fiscal_bp.route('/danfe/<string:access_key>', methods=['GET'])
@login_required
@fiscal_access_required
def generate_danfe(access_key: str):
    """
    Generates and returns the DANFE PDF for a given invoice access key.
    ---
    tags: [Fiscal]
    security:
      - bearerAuth: []
    parameters:
      - in: path
        name: access_key
        schema:
          type: string
          pattern: '^\d{44}$' # Regex for 44 digits
        required: true
        description: The 44-digit access key of the NF-e.
    responses:
      200:
        description: DANFE PDF content.
        content:
          application/pdf:
            schema:
              type: string
              format: binary
      400:
        description: Bad request (Invalid access key format).
      401:
        description: Unauthorized.
      403:
        description: Forbidden (User lacks permission).
      404:
        description: Invoice or DANFE not found for the given access key.
      500:
        description: Internal server error or ERP integration error.
      502:
        description: Error communicating with ERP during DANFE generation.
      503:
        description: Service unavailable.
    """
    logger.info(f"Generate DANFE request received for access key: ...{access_key[-6:]}")

    try:
        fiscal_service = _get_fiscal_service()
        pdf_bytes = fiscal_service.generate_danfe_pdf(access_key)

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'inline; filename="danfe_{access_key}.pdf"'
            }
        )

    except ValidationError as e:
        logger.warning(f"Validation error generating DANFE for key ...{access_key[-6:]}: {e}")
        return jsonify({"error": str(e)}), 400
    except NotFoundError as e:
        logger.warning(f"DANFE/XML not found for key ...{access_key[-6:]}: {e}")
        return jsonify({"error": str(e)}), 404
    except ServiceError as e:
        logger.error(f"Service error generating DANFE for key ...{access_key[-6:]}: {e.message}", exc_info=True if e.status_code >= 500 else False)
        status_code = e.status_code if hasattr(e, 'status_code') and e.status_code else 500
        if isinstance(e.__cause__, ErpIntegrationError) and hasattr(e.__cause__, 'status_code'):
             status_code = e.__cause__.status_code
        return jsonify({"error": e.message}), status_code
    except ApiError as e:
        logger.error(f"API error generating DANFE: {e.message}", exc_info=True if e.status_code >= 500 else False)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error generating DANFE for key ...{access_key[-6:]}: {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred while generating the DANFE."}), 500


# Define Schema for OpenAPI (ensure it matches FormattedInvoiceListItem)
components = {
    "schemas": {
        "FormattedInvoiceListItem": {
            "type": "object",
            "properties": {
                "status": {"type": "string", "nullable": True},
                "recipient_name": {"type": "string", "nullable": True},
                "sales_order_code": {"type": "integer", "nullable": True},
                "invoice_number": {"type": "integer", "nullable": True},
                "invoice_series": {"type": "string", "nullable": True},
                "issue_date": {"type": "string", "format": "date-time", "nullable": True},
                "total_value": {"type": "number", "format": "float", "nullable": True},
                "total_quantity": {"type": "number", "format": "float", "nullable": True},
                "operation_name": {"type": "string", "nullable": True},
                "shipping_company_name": {"type": "string", "nullable": True},
                "access_key": {"type": "string", "nullable": True, "maxLength": 44, "minLength": 44}
            }
        }
    }
}
</file>

<file path="src/api/routes/observations.py">
# src/api/routes/observations.py
# Defines API endpoints for managing product observations using ORM.

from flask import Blueprint, request, jsonify, current_app

# Import Service
from src.services.observation_service import ObservationService

# Import ORM Model (apenas para type hints se necessário, serviço retorna ORM)
# from src.domain.observation import Observation

from src.api.decorators import login_required, products_access_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ForbiddenError, ServiceError, DatabaseError
from src.utils.logger import logger

observations_bp = Blueprint('observations', __name__)

# Helper para obter ObservationService
def _get_observation_service() -> ObservationService:
     service = current_app.config.get('observation_service')
     if not service:
          # Idealmente, a injeção deve ser garantida no create_app
          logger.critical("ObservationService not found in application config!")
          raise ServiceError("Observation service is unavailable.", 503) # Usar ServiceError
     return service

@observations_bp.route('/product/<string:reference_code>', methods=['POST'])
@login_required
@products_access_required
def add_product_observation(reference_code: str):
    """Adds a new observation for a specific product reference code."""
    logger.info(f"Add observation request for reference: {reference_code}")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    observation_text = data.get('observation_text')

    if not observation_text:
        return jsonify({"error": "Field 'observation_text' is required"}), 400

    try:
        current_user = request.current_user
        observation_service = _get_observation_service()
        # Serviço agora gerencia a sessão internamente
        new_observation = observation_service.add_observation(reference_code, observation_text, current_user)
        # Converter objeto ORM para dict
        return jsonify(new_observation.to_dict()), 201

    except ValidationError as e:
        logger.warning(f"Validation error adding observation for '{reference_code}': {e}")
        return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e: # Capturar erros do serviço/DB
         logger.error(f"Service/DB error adding observation for '{reference_code}': {e}", exc_info=True)
         # Retornar 500 ou status específico do ServiceError
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to add observation: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error adding observation for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/product/<string:reference_code>', methods=['GET'])
@login_required
@products_access_required
def get_product_observations(reference_code: str):
    """Retrieves observations for a specific product reference code."""
    logger.info(f"Get observations request for reference: {reference_code}")
    include_resolved_str = request.args.get('include_resolved', 'true').lower()
    include_resolved = include_resolved_str == 'true'

    try:
        observation_service = _get_observation_service()
        # Serviço retorna lista de objetos ORM
        observations = observation_service.get_observations_for_product(reference_code, include_resolved)
        # Converter lista de objetos ORM para lista de dicts
        observations_data = [obs.to_dict() for obs in observations]
        return jsonify(observations_data), 200

    except ValidationError as e:
         logger.warning(f"Validation error getting observations for '{reference_code}': {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting observations for '{reference_code}': {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get observations: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting observations for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/product/<string:reference_code>/unresolved_count', methods=['GET'])
@login_required
@products_access_required
def get_product_unresolved_observations_count(reference_code: str):
    """Retrieves the count of unresolved observations for a specific product reference code."""
    logger.info(f"Get unresolved count request for reference: {reference_code}")
    try:
        observation_service = _get_observation_service()
        count = observation_service.get_unresolved_count(reference_code)
        return jsonify({"reference_code": reference_code, "unresolved_count": count}), 200

    except ValidationError as e:
         logger.warning(f"Validation error getting unresolved count for '{reference_code}': {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting unresolved count for '{reference_code}': {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get unresolved count: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting unresolved count for '{reference_code}': {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/<int:observation_id>/resolve', methods=['PUT'])
@login_required
@products_access_required
def resolve_product_observation(observation_id: int):
    """Marks a specific observation as resolved."""
    logger.info(f"Resolve observation request for ID: {observation_id}")
    try:
        current_user = request.current_user
        observation_service = _get_observation_service()
        success = observation_service.resolve_observation(observation_id, current_user)

        if success:
            return jsonify({"message": f"Observation {observation_id} marked as resolved."}), 200
        else:
             # Serviço pode retornar False se já estava resolvido ou não encontrado
             # O serviço agora levanta NotFoundError, então este 'else' pode indicar 'já resolvido'.
             logger.warning(f"Failed to mark observation {observation_id} as resolved (possibly already resolved).")
             # Manter 400 ou talvez um 200 com mensagem diferente? 400 indica que o estado não mudou como pedido.
             return jsonify({"error": f"Observation {observation_id} could not be resolved (it might already be resolved)."}), 400

    except NotFoundError as e:
        logger.warning(f"Cannot resolve observation ID {observation_id}: Not found.")
        return jsonify({"error": str(e)}), 404
    except ValidationError as e:
         logger.warning(f"Validation error resolving observation {observation_id}: {e}")
         return jsonify({"error": str(e)}), 400
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error resolving observation {observation_id}: {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to resolve observation: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error resolving observation {observation_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@observations_bp.route('/pending_references', methods=['GET'])
@login_required
@products_access_required
def get_pending_references():
    """Retrieves references with pending observations."""
    logger.info("Get pending references request received.")
    try:
        observation_service = _get_observation_service()
        # Serviço retorna lista de dicts já formatados pelo repositório
        references = observation_service.get_references_with_pending_observations()
        return jsonify(references), 200
    except (ServiceError, DatabaseError) as e:
         logger.error(f"Service/DB error getting pending references: {e}", exc_info=True)
         status_code = e.status_code if hasattr(e, 'status_code') else 500
         msg = e.message if hasattr(e, 'message') else str(e)
         return jsonify({"error": f"Failed to get pending references: {msg}"}), status_code
    except Exception as e:
        logger.error(f"Unexpected error getting pending references: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500
</file>

<file path="src/api/routes/products.py">
# src/api/routes/products.py
# Routes related to finished product information.

from flask import Blueprint, request, jsonify, current_app
from src.services.product_service import ProductService
from src.api.decorators import login_required, products_access_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ServiceError
from src.utils.logger import logger

# --- Get Service Instances ---
def _get_product_service() -> ProductService:
    service = current_app.config.get('product_service')
    if not service:
        logger.critical("ProductService not found in application config!")
        raise ServiceError("Product service is unavailable.", 503)
    return service

# --- Blueprint Definition ---
products_bp = Blueprint('products', __name__)

# --- Routes ---

@products_bp.route('/balance_matrix', methods=['POST'])
@login_required
@products_access_required
def get_product_balance_matrix():
    """
    Gets the product balance matrix for a given reference code and calculation mode.
    Also returns the raw product items used to build the matrix.
    ---
    tags:
      - Products
    security:
      - bearerAuth: []
    parameters:
      - in: body
        name: body
        required: true
        schema:
          type: object
          required:
            - reference_code
          properties:
            reference_code:
              type: string
              description: The product reference code.
              example: "1010"
            calculation_mode:
              type: string
              description: Balance calculation mode ('base', 'sales', 'production'). Defaults to 'base'.
              example: "sales"
              enum: ["base", "sales", "production"]
    responses:
      200:
        description: Product balance matrix and raw items.
        schema:
          # Define the expected response structure here (matching ProductService return)
          type: object
          properties:
             reference_code:
               type: string
             calculation_mode:
               type: string
             matrix:
               # Define matrix structure (simplified example)
               type: object
             product_items:
               # Define product items structure (simplified example)
               type: array
               items:
                 type: object
      400:
        description: Invalid input (e.g., missing reference code, invalid mode).
      401:
        description: Authentication required.
      403:
        description: Permission denied.
      404:
        description: Product reference not found.
      500:
        description: Internal server error or error fetching data from ERP.
      503:
        description: Service unavailable.
    """
    data = request.get_json()
    if not data or not data.get('reference_code'):
        return jsonify({"error": "Campo 'reference_code' é obrigatório."}), 400

    reference_code = str(data.get('reference_code')).strip().upper()
    calculation_mode = str(data.get('calculation_mode', 'base')).lower()

    logger.info(f"Balance matrix request: Ref={reference_code}, Mode={calculation_mode}")

    try:
        product_service = _get_product_service()
        # Call the updated service method
        result = product_service.get_product_balance_matrix_with_items(reference_code, calculation_mode)
        return jsonify(result), 200

    except (ValidationError, NotFoundError) as e:
        logger.warning(f"Product matrix request failed (Ref: {reference_code}): {e}")
        status = 400 if isinstance(e, ValidationError) else 404
        return jsonify({"error": str(e)}), status
    except (ServiceError, ApiError) as e:
        logger.error(f"Service error fetching product matrix (Ref: {reference_code}): {e}", exc_info=True)
        return jsonify({"error": e.message}), e.status_code
    except Exception as e:
        logger.error(f"Unexpected error fetching product matrix (Ref: {reference_code}): {e}", exc_info=True)
        return jsonify({"error": "An unexpected error occurred."}), 500
</file>

<file path="src/api/routes/users.py">
# src/api/routes/users.py
# Defines API endpoints for managing users (CRUD). Requires admin privileges.

from flask import Blueprint, request, jsonify, current_app
from src.domain.user import User, UserPermissions
from src.database.user_repository import UserRepository
from sqlalchemy.orm import Session
from src.database import get_db_session

from src.api.decorators import admin_required
from src.api.errors import ApiError, NotFoundError, ValidationError, ForbiddenError, DatabaseError
from src.utils.logger import logger

from sqlalchemy.exc import SQLAlchemyError

users_bp = Blueprint('users', __name__)

# Helper para obter UserRepository (pode ser movido para um local central se repetido)
def _get_user_repository() -> UserRepository:
      # Tentar obter do contexto da app se injetado (boa prática)
      repo = current_app.config.get('user_repository')
      if repo:
           return repo
      else:
           # Fallback: criar instância (menos ideal para testes, mas funciona)
           from src.database import get_user_repository as get_repo_func
           logger.warning("UserRepository accessed via factory function in users route.")
           return get_repo_func()

@users_bp.route('', methods=['GET'])
@admin_required
def get_all_users():
    """Retrieves a list of all users. (Admin only)"""
    logger.info("Get all users request received.")
    try:
        # Obter sessão e chamar repositório
        with get_db_session() as db:
            user_repo = _get_user_repository()
            users = user_repo.get_all(db) # Passar a sessão 'db'
        # Converter objetos ORM para dicts
        users_data = [user.to_dict(include_hash=False) for user in users]
        return jsonify({"users": users_data}), 200
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error retrieving all users: {e}", exc_info=True)
          # Usar ApiError ou erro específico
          return jsonify({"error": "Failed to retrieve users due to database error."}), 500
    except Exception as e:
        logger.error(f"Error retrieving all users: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while retrieving users."}), 500


@users_bp.route('/<int:user_id>', methods=['GET'])
@admin_required
def get_user_by_id(user_id: int):
    """Retrieves a specific user by their ID. (Admin only)"""
    logger.info(f"Get user by ID request received for ID: {user_id}")
    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            user = user_repo.find_by_id(db, user_id) # Passar a sessão
        if not user:
            logger.warning(f"User with ID {user_id} not found.")
            raise NotFoundError(f"User with ID {user_id} not found.")

        # Converter objeto ORM para dict
        return jsonify(user.to_dict(include_hash=False)), 200
    except NotFoundError as e:
        return jsonify({"error": str(e)}), 404
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error retrieving user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error retrieving user."}), 500
    except Exception as e:
        logger.error(f"Error retrieving user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred."}), 500


@users_bp.route('', methods=['POST'])
@admin_required
def create_user():
    """Creates a new user with specified permissions. (Admin only)"""
    logger.info("Create user request received.")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()

    required = ['username', 'password', 'name']
    missing = [field for field in required if field not in data or not data[field]]
    if missing:
        logger.warning(f"Create user failed: Missing required fields: {missing}")
        return jsonify({"error": f"Missing required fields: {', '.join(missing)}"}), 400

    try:
        # Criar instância de UserPermissions a partir dos dados da API
        permissions = UserPermissions(
            is_admin=data.get('is_admin', False),
            can_access_products=data.get('can_access_products', False),
            can_access_fabrics=data.get('can_access_fabrics', False),
            can_access_customer_panel=data.get('can_access_customer_panel', False),
            can_access_fiscal=data.get('can_access_fiscal', False),
            can_access_accounts_receivable=data.get('can_access_accounts_receivable', False)
        )

        # Criar instância de User e associar permissões
        user = User(
            username=data['username'],
            name=data['name'],
            email=data.get('email'),
            is_active=data.get('is_active', True),
            permissions=permissions # Associar o objeto de permissões
        )
        # Definir a senha (o método set_password está no modelo User)
        user.set_password(data['password'])
        if not user.password_hash: # Verificar se o hash foi gerado
              raise ValidationError("Failed to process password.")

        # Usar sessão para adicionar ao banco
        with get_db_session() as db:
            user_repo = _get_user_repository()
            created_user = user_repo.add(db, user) # Passar sessão e objeto User

        logger.info(f"User '{created_user.username}' (ID: {created_user.id}) created successfully.")
        # Converter objeto ORM para dict
        return jsonify(created_user.to_dict(include_hash=False)), 201

    except (ValidationError, ValueError) as e: # Captura erros de validação ou duplicidade
        logger.warning(f"Validation error creating user: {e}")
        return jsonify({"error": str(e)}), 400
    except (DatabaseError, SQLAlchemyError) as e:
         logger.error(f"Database error creating user: {e}", exc_info=True)
         return jsonify({"error": "Database error creating user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error creating user: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while creating user."}), 500


@users_bp.route('/<int:user_id>', methods=['PUT'])
@admin_required
def update_user(user_id: int):
    """Updates an existing user's details and/or permissions. (Admin only)"""
    logger.info(f"Update user request received for ID: {user_id}")
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.get_json()
    if not data:
          return jsonify({"error": "Request body cannot be empty for update."}), 400

    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            # Buscar o usuário existente na sessão atual
            user = user_repo.find_by_id(db, user_id)
            if not user:
                raise NotFoundError(f"User with ID {user_id} not found.")

            # Atualizar campos do objeto User (a sessão rastreia as mudanças)
            if 'name' in data: user.name = data['name']
            if 'email' in data: user.email = data['email']
            if 'is_active' in data: user.is_active = data['is_active']

            new_password = data.get('password')
            if new_password:
                logger.debug(f"Updating password for user ID: {user_id}")
                user.set_password(new_password)
                if not user.password_hash:
                     raise ValidationError("Failed to process new password.")

            # Atualizar permissões (garantir que o objeto permissions existe)
            if not user.permissions:
                 logger.warning(f"User ID {user_id} found but missing permissions object during update. Creating default.")
                 user.permissions = UserPermissions() # Cria default associado

            # Atualizar campos do objeto UserPermissions
            user.permissions.is_admin = data.get('is_admin', user.permissions.is_admin)
            user.permissions.can_access_products = data.get('can_access_products', user.permissions.can_access_products)
            user.permissions.can_access_fabrics = data.get('can_access_fabrics', user.permissions.can_access_fabrics)
            user.permissions.can_access_customer_panel = data.get('can_access_customer_panel', user.permissions.can_access_customer_panel)
            user.permissions.can_access_fiscal = data.get('can_access_fiscal', user.permissions.can_access_fiscal)
            user.permissions.can_access_accounts_receivable = data.get('can_access_accounts_receivable', user.permissions.can_access_accounts_receivable)

            # Chamar o update do repositório (que apenas faz flush opcionalmente)
            # O commit será feito pelo get_db_session
            updated_user = user_repo.update(db, user) # Passa sessão e objeto modificado

        logger.info(f"User ID {user_id} update process completed.")
        # Retornar o usuário atualizado convertido para dict
        return jsonify(updated_user.to_dict(include_hash=False)), 200

    except NotFoundError as e:
          return jsonify({"error": str(e)}), 404
    except (ValidationError, ValueError) as e: # Captura validação ou email duplicado
        logger.warning(f"Validation error updating user ID {user_id}: {e}")
        return jsonify({"error": str(e)}), 400
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error updating user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error updating user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error updating user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while updating user."}), 500


@users_bp.route('/<int:user_id>', methods=['DELETE'])
@admin_required
def delete_user(user_id: int):
    """Deletes a user by their ID. (Admin only)"""
    logger.info(f"Delete user request received for ID: {user_id}")
    current_user = request.current_user # Set by @admin_required -> @login_required

    if current_user.id == user_id:
        raise ForbiddenError("Cannot delete your own user account.")

    try:
        with get_db_session() as db:
            user_repo = _get_user_repository()
            success = user_repo.delete(db, user_id) # Passar sessão

        if success:
            logger.info(f"User ID {user_id} deleted successfully.")
            return jsonify({"message": f"User ID {user_id} deleted successfully."}), 200
        else:
            # Se delete retornou False, significa que usuário não foi encontrado
            raise NotFoundError(f"User with ID {user_id} not found for deletion.")

    except ForbiddenError as e:
          return jsonify({"error": str(e)}), 403
    except NotFoundError as e:
        return jsonify({"error": str(e)}), 404
    except (DatabaseError, SQLAlchemyError) as e:
          logger.error(f"Database error deleting user ID {user_id}: {e}", exc_info=True)
          return jsonify({"error": "Database error deleting user."}), 500
    except Exception as e:
        logger.error(f"Unexpected error deleting user ID {user_id}: {e}", exc_info=True)
        return jsonify({"error": "An internal server error occurred while deleting user."}), 500
</file>

<file path="src/app.py">
# src/app.py
from flask import Flask, jsonify
from flask_cors import CORS
import atexit
import os
from sqlalchemy.exc import SQLAlchemyError

from src.config import Config
from src.api import register_blueprints
from src.api.errors import register_error_handlers, ConfigurationError, DatabaseError
from src.database import (
    get_db_session,
    init_sqlalchemy,
    dispose_sqlalchemy_engine,
)
from src.utils.logger import logger, configure_logger
from src.utils.system_monitor import start_resource_monitor, stop_resource_monitor

from src.database.user_repository import UserRepository
from src.database.observation_repository import ObservationRepository
from src.database.fiscal_repository import FiscalRepository

from src.services import (
    AuthService,
    CustomerService,
    FabricService,
    ObservationService,
    ProductService,
    FiscalService,
    AccountsReceivableService,
    FiscalSyncService
)
from src.services.fiscal_sync_service import (
    start_fiscal_sync_scheduler,
    stop_fiscal_sync_scheduler
)

from src.erp_integration import (
    erp_auth_service,
    ErpBalanceService,
    ErpCostService,
    ErpPersonService,
    ErpProductService,
    ErpFiscalService,
    ErpAccountsReceivableService
)

def create_app(config_object: Config) -> Flask:
    """
    Factory function to create and configure the Flask application with SQLAlchemy.

    Args:
        config_object: The configuration object for the application.

    Returns:
        The configured Flask application instance.
    """
    app = Flask("Connector-Backend")
    app.config.from_object(config_object)

    # --- Logging ---
    configure_logger(config_object.LOG_LEVEL)
    logger.info("Iniciando a aplicação Flask para o Connector-Backend.")
    logger.info(f"Nome da aplicação: {app.name}")
    logger.info(f"Modo de depuração: {app.config.get('APP_DEBUG')}")

    # --- Secret Key Check ---
    if not app.config.get('SECRET_KEY') or app.config.get('SECRET_KEY') == 'default_secret_key_change_me_in_env':
            logger.critical("ALERTA CRÍTICO DE SEGURANÇA: SECRET_KEY não está definida ou está usando o valor padrão!")
            if not app.config.get('APP_DEBUG', False):
                raise ConfigurationError("SECRET_KEY deve ser configurada com um valor seguro e único em produção.")
            else:
                logger.warning("Usando SECRET_KEY padrão/insegura no modo de depuração.")

    # --- CORS Configuration ---
    CORS(app, supports_credentials=True, resources={r"/api/*": {"origins": "*"}})
    logger.info("CORS configurado para permitir todas as origens (Atualizar para produção).")

    # --- Database Initialization (SQLAlchemy) ---
    db_engine = None
    try:
        db_uri = app.config.get('SQLALCHEMY_DATABASE_URI')
        if not db_uri:
             raise ConfigurationError("SQLALCHEMY_DATABASE_URI não está configurado.")

        db_engine = init_sqlalchemy(db_uri)
        logger.info("Motor SQLAlchemy e fábrica de sessões inicializados com sucesso.")

        atexit.register(dispose_sqlalchemy_engine)
        logger.debug("Registrado descarte do motor SQLAlchemy para saída da aplicação.")

    except (DatabaseError, ConfigurationError, SQLAlchemyError) as db_init_err:
        logger.critical(f"Falha ao inicializar o banco de dados: {db_init_err}", exc_info=True)
        import sys
        sys.exit(1)
    except Exception as generic_db_err:
         logger.critical(f"Erro inesperado durante a inicialização do banco de dados: {generic_db_err}", exc_info=True)
         import sys
         sys.exit(1)

    # --- Dependency Injection (Service Instantiation) ---
    logger.info("Instanciando serviços...")
    if not db_engine:
         logger.critical("Motor de banco de dados não disponível para instanciação de serviços.")
         import sys
         sys.exit(1)

    try:
        # --- Instanciar Repositórios Diretamente ---
        user_repo = UserRepository(db_engine)
        observation_repo = ObservationRepository(db_engine)
        fiscal_repo = FiscalRepository(db_engine)

        # Adicionar repositórios ao config da app
        app.config['user_repository'] = user_repo
        app.config['observation_repository'] = observation_repo
        app.config['fiscal_repository'] = fiscal_repo

        # ERP Integration Services
        erp_balance_svc = ErpBalanceService(erp_auth_service)
        erp_cost_svc = ErpCostService(erp_auth_service)
        erp_person_svc = ErpPersonService(erp_auth_service)
        erp_product_svc = ErpProductService(erp_auth_service)
        erp_fiscal_svc = ErpFiscalService(erp_auth_service)
        erp_ar_svc = ErpAccountsReceivableService(erp_auth_service)

        # Application Services
        auth_svc = AuthService(user_repo)
        customer_svc = CustomerService(erp_person_svc)
        fabric_svc = FabricService(erp_balance_svc, erp_cost_svc, erp_product_svc)
        observation_svc = ObservationService(observation_repo)
        product_svc = ProductService(erp_balance_svc)
        fiscal_svc = FiscalService(fiscal_repo, erp_fiscal_svc)
        ar_svc = AccountsReceivableService(erp_ar_svc, erp_person_svc)
        fiscal_sync_svc = FiscalSyncService(erp_fiscal_svc, fiscal_repo)

        # Store service instances in app config
        app.config['auth_service'] = auth_svc
        app.config['customer_service'] = customer_svc
        app.config['fabric_service'] = fabric_svc
        app.config['observation_service'] = observation_svc
        app.config['product_service'] = product_svc
        app.config['fiscal_service'] = fiscal_svc
        app.config['accounts_receivable_service'] = ar_svc
        app.config['fiscal_sync_service'] = fiscal_sync_svc

        logger.info("Serviços instanciados e adicionados à configuração do aplicativo.")

    except Exception as service_init_err:
        logger.critical(f"Falha ao instanciar serviços: {service_init_err}", exc_info=True)
        import sys
        sys.exit(1)

    # --- Register Blueprints (API Routes) ---
    register_blueprints(app)

    # --- Register Error Handlers ---
    register_error_handlers(app)

    # --- Resource Monitoring ---
    if not app.debug or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        start_resource_monitor(interval_seconds=300)
        atexit.register(stop_resource_monitor)

    # --- Start Background Schedulers ---
    if not app.debug or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        logger.info("Iniciando agendadores de tarefas em segundo plano...")
        start_fiscal_sync_scheduler(fiscal_sync_svc)
        atexit.register(stop_fiscal_sync_scheduler)
        logger.info("Agendador de sincronização fiscal iniciado.")

    # --- Simple Health Check Endpoint ---
    @app.route('/health', methods=['GET'])
    def health_check():
        db_status = "ok"
        db_error = None
        try:
             with get_db_session() as db:
                 pass
        except Exception as e:
             logger.error(f"Verificação de saúde da sessão do banco de dados falhou: {e}")
             db_status = "error"
             db_error = str(e)

        sync_running = FiscalSyncService._is_running

        return jsonify({
            "status": "ok",
            "database": db_status,
            "database_error": db_error if db_error else None,
            "sync_service_running": sync_running
        }), 200 if db_status == "ok" else 503

    logger.info("Aplicação Connector-Backend configurada com sucesso.")
    return app
</file>

<file path="src/config/__init__.py">
# src/config/__init__.py
# Makes 'config' a package. Exports relevant items.

from .settings import config, Config, load_config

__all__ = ["config", "Config", "load_config"]
</file>

<file path="src/config/README.md">
# src/config

Este diretório contém a configuração da aplicação.

## Arquivos

*   **`settings.py`**:
    *   Carrega variáveis de ambiente do arquivo `.env` na raiz do projeto usando `python-dotenv`.
    *   Define a classe `Config` (um `dataclass`) que agrupa todas as configurações da aplicação (Flask, API ERP, Banco de Dados).
    *   Lê as variáveis de conexão do PostgreSQL (`POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`).
    *   Constrói a `SQLALCHEMY_DATABASE_URI` usada pelo SQLAlchemy para conectar ao banco.
    *   Fornece valores padrão para configurações caso não sejam definidas no ambiente.
    *   Exporta uma instância singleton `config` da classe `Config`, que pode ser importada em outros módulos.
    *   Realiza validações básicas (ex: nível de log).
*   **`README.md`**: Este arquivo.

## Uso

Importe a instância `config` de `src.config` para acessar as configurações em qualquer lugar da aplicação:

```python
from src.config import config

api_url = config.API_BASE_URL
debug_mode = config.APP_DEBUG
db_uri = config.SQLALCHEMY_DATABASE_URI # URI para SQLAlchemy
</file>

<file path="src/config/settings.py">
# src/config/settings.py
# Loads environment variables and defines the application configuration.

from dataclasses import dataclass, field
from typing import Optional
from dotenv import load_dotenv
import os
import logging
import sys
from urllib.parse import quote_plus # Para senhas na URL

# Determine the project root directory dynamically
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
dotenv_path = os.path.join(PROJECT_ROOT, '.env')
load_dotenv(dotenv_path=dotenv_path)
print(f"Loading .env file from: {dotenv_path}") # Debug print

@dataclass
class Config:
    """
    Application configuration loaded from environment variables.
    Provides type hints and default values.
    """
    # Flask Settings
    SECRET_KEY: str = field(default_factory=lambda: os.environ.get('SECRET_KEY', 'default_secret_key_change_me_in_env'))
    APP_HOST: str = field(default_factory=lambda: os.environ.get('APP_HOST', '0.0.0.0'))
    APP_PORT: int = field(default_factory=lambda: int(os.environ.get('APP_PORT', 5004)))
    APP_DEBUG: bool = field(default_factory=lambda: os.environ.get('APP_DEBUG', 'True').lower() == 'true')
    TOKEN_EXPIRATION_HOURS: int = field(default_factory=lambda: int(os.environ.get('TOKEN_EXPIRATION_HOURS', 24)))
    LOG_LEVEL: str = field(default_factory=lambda: os.environ.get('LOG_LEVEL', 'DEBUG').upper())

    # --- Database Settings ---
    DB_TYPE: str = field(default_factory=lambda: os.environ.get('DB_TYPE', 'POSTGRES').upper()) # Default to POSTGRES

    # PostgreSQL Specific Settings (read from .env)
    POSTGRES_HOST: str = field(default_factory=lambda: os.environ.get('POSTGRES_HOST', 'localhost'))
    POSTGRES_PORT: int = field(default_factory=lambda: int(os.environ.get('POSTGRES_PORT', 5432)))
    POSTGRES_USER: str = field(default_factory=lambda: os.environ.get('POSTGRES_USER', ''))
    POSTGRES_PASSWORD: str = field(default_factory=lambda: os.environ.get('POSTGRES_PASSWORD', ''))
    POSTGRES_DB: str = field(default_factory=lambda: os.environ.get('POSTGRES_DB', ''))

    # --- SQLAlchemy Database URL ---
    # Constructed based on the DB_TYPE and specific settings
    SQLALCHEMY_DATABASE_URI: Optional[str] = None

    # TOTVS ERP Company Code
    COMPANY_CODE: int = field(default_factory=lambda: int(os.environ.get('COMPANY_CODE', 1)))

    # TOTVS ERP API Integration Settings
    API_BASE_URL: str = field(default_factory=lambda: os.environ.get('API_BASE_URL', 'http://10.1.1.221:11980/api/totvsmoda'))
    PAGE_SIZE: int = field(default_factory=lambda: int(os.environ.get('PAGE_SIZE', 1000)))
    FISCAL_PAGE_SIZE: int = field(default_factory=lambda: min(int(os.environ.get('FISCAL_PAGE_SIZE', 50)), 100))
    MAX_RETRIES: int = field(default_factory=lambda: int(os.environ.get('MAX_RETRIES', 3)))

    # TOTVS ERP API Endpoints (relative to API_BASE_URL)
    BALANCES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('BALANCES_ENDPOINT', '/product/v2/balances/search'))
    COSTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('COSTS_ENDPOINT', '/product/v2/costs/search'))
    PRODUCTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('PRODUCTS_ENDPOINT', '/product/v2/products/search'))
    INDIVIDUALS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('INDIVIDUALS_ENDPOINT', '/person/v2/individuals/search'))
    LEGAL_ENTITIES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('LEGAL_ENTITIES_ENDPOINT', '/person/v2/legal-entities/search'))
    PERSON_STATS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('PERSON_STATS_ENDPOINT', '/person/v2/person-statistics'))
    TOKEN_ENDPOINT: str = field(default_factory=lambda: os.environ.get('TOKEN_ENDPOINT', '/authorization/v2/token'))
    ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT', '/accounts-receivable/v2/documents/search'))
    ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT', '/accounts-receivable/v2/bank-slip'))
    ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT: str = field(default_factory=lambda: os.environ.get('ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT', '/accounts-receivable/v2/payment-link'))
    FISCAL_INVOICES_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_INVOICES_ENDPOINT', '/fiscal/v2/invoices/search'))
    FISCAL_XML_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_XML_ENDPOINT', '/fiscal/v2/xml-contents'))
    FISCAL_DANFE_ENDPOINT: str = field(default_factory=lambda: os.environ.get('FISCAL_DANFE_ENDPOINT', '/fiscal/v2/danfe-search'))

    # TOTVS ERP API Credentials
    API_USERNAME: str = field(default_factory=lambda: os.environ.get('API_USERNAME', ''))
    API_PASSWORD: str = field(default_factory=lambda: os.environ.get('API_PASSWORD', ''))
    CLIENT_ID: str = field(default_factory=lambda: os.environ.get('CLIENT_ID', 'kduapiv2'))
    CLIENT_SECRET: str = field(default_factory=lambda: os.environ.get('CLIENT_SECRET', ''))
    GRANT_TYPE: str = field(default_factory=lambda: os.environ.get('GRANT_TYPE', 'password'))

    def __post_init__(self):
        # Validate log level
        valid_levels = list(logging._nameToLevel.keys())
        if self.LOG_LEVEL not in valid_levels:
             print(f"Warning: Invalid LOG_LEVEL '{self.LOG_LEVEL}'. Valid levels: {valid_levels}. Defaulting to DEBUG.", file=sys.stderr)
             self.LOG_LEVEL = 'DEBUG'

        # --- Build SQLAlchemy Database URI ---
        if self.DB_TYPE == 'POSTGRES':
            if not all([self.POSTGRES_HOST, self.POSTGRES_USER, self.POSTGRES_PASSWORD, self.POSTGRES_DB]):
                print("Warning: Missing PostgreSQL connection details in environment variables. Database connection will likely fail.", file=sys.stderr)
                self.SQLALCHEMY_DATABASE_URI = None
            else:
                 # Use quote_plus for password in case it has special characters
                 encoded_password = quote_plus(self.POSTGRES_PASSWORD)
                 # Specify the driver (+psycopg)
                 self.SQLALCHEMY_DATABASE_URI = f"postgresql+psycopg://{self.POSTGRES_USER}:{encoded_password}@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"
        elif self.DB_TYPE == 'SQLITE':
             # Keep SQLite support if needed temporarily (requires DATABASE_PATH in .env)
             db_path = os.environ.get('DATABASE_PATH')
             if db_path:
                  abs_path = os.path.join(PROJECT_ROOT, db_path) if not os.path.isabs(db_path) else db_path
                  os.makedirs(os.path.dirname(abs_path), exist_ok=True)
                  self.SQLALCHEMY_DATABASE_URI = f"sqlite:///{abs_path}"
             else:
                  print("Warning: DB_TYPE is SQLITE but DATABASE_PATH is not set.", file=sys.stderr)
                  self.SQLALCHEMY_DATABASE_URI = None
        else:
             print(f"Warning: Unsupported DB_TYPE '{self.DB_TYPE}'. No database URI configured.", file=sys.stderr)
             self.SQLALCHEMY_DATABASE_URI = None

        # Validate Fiscal Page Size
        if self.FISCAL_PAGE_SIZE > 100:
            print(f"Warning: FISCAL_PAGE_SIZE ({self.FISCAL_PAGE_SIZE}) exceeds ERP limit of 100. Clamping to 100.", file=sys.stderr)
            self.FISCAL_PAGE_SIZE = 100
        elif self.FISCAL_PAGE_SIZE < 1:
            print(f"Warning: FISCAL_PAGE_SIZE ({self.FISCAL_PAGE_SIZE}) is invalid. Setting to default 50.", file=sys.stderr)
            self.FISCAL_PAGE_SIZE = 50

# Singleton instance, created by load_config
_config_instance: Optional[Config] = None

def load_config() -> Config:
    """Loads or returns the singleton Config instance."""
    global _config_instance
    if _config_instance is None:
        _config_instance = Config()
        # Log loaded config values (mask sensitive ones)
        print("--- Configuration Loaded ---")
        print(f"  APP_HOST: {_config_instance.APP_HOST}")
        print(f"  APP_PORT: {_config_instance.APP_PORT}")
        print(f"  APP_DEBUG: {_config_instance.APP_DEBUG}")
        print(f"  LOG_LEVEL: {_config_instance.LOG_LEVEL}")
        print(f"  DB_TYPE: {_config_instance.DB_TYPE}")
        # Mask password in logged URI
        db_uri_log = str(_config_instance.SQLALCHEMY_DATABASE_URI)
        if _config_instance.POSTGRES_PASSWORD:
             db_uri_log = db_uri_log.replace(quote_plus(_config_instance.POSTGRES_PASSWORD), '********')
        print(f"  SQLALCHEMY_DATABASE_URI: {db_uri_log}")
        print(f"  API_BASE_URL: {_config_instance.API_BASE_URL}")
        print(f"  API_USERNAME: {'*' * len(_config_instance.API_USERNAME) if _config_instance.API_USERNAME else 'Not Set'}")
        print(f"  COMPANY_CODE: {_config_instance.COMPANY_CODE}")
        print(f"  PAGE_SIZE (General): {_config_instance.PAGE_SIZE}")
        print(f"  FISCAL_PAGE_SIZE: {_config_instance.FISCAL_PAGE_SIZE}")
        print("--------------------------")
    return _config_instance

# Expose the singleton instance directly
config = load_config()

# Helper to get PROJECT_ROOT if needed elsewhere
def get_project_root() -> str:
    return PROJECT_ROOT
</file>

<file path="src/database/__init__.py">
# src/database/__init__.py
# Initializes SQLAlchemy components: Engine, SessionLocal, Base metadata.
# Uses local imports for logger/errors to prevent circular dependencies during Alembic runs.

import threading
from typing import Optional, Generator
from contextlib import contextmanager
from sqlalchemy import create_engine
from sqlalchemy.engine import Engine
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.exc import SQLAlchemyError

# Importar Base diretamente - ESSENCIAL para Alembic
from .base import Base
# NÃO importar logger, errors, ConfigurationError, SchemaManager aqui no topo

# --- SQLAlchemy Engine and Session Factory Globals ---
_sqla_engine: Optional[Engine] = None
_SessionLocalFactory: Optional[sessionmaker[Session]] = None
_engine_lock = threading.Lock()

# --- Função de Inicialização do Engine e Session Factory ---
def init_sqlalchemy(database_uri: str, pool_size: int = 10, max_overflow: int = 20) -> Engine:
    """
    Initializes the SQLAlchemy engine, session factory, and database schema.
    Should be called once during application startup.
    Uses local imports for logger/errors.
    """
    # --- Importações locais ---
    from src.utils.logger import logger # Importa logger aqui
    from src.api.errors import DatabaseError, ConfigurationError # Importa errors aqui
    # -------------------------

    global _sqla_engine, _SessionLocalFactory
    with _engine_lock:
        if _sqla_engine and _SessionLocalFactory:
            logger.warning("SQLAlchemy engine and session factory already initialized.")
            return _sqla_engine

        if not database_uri:
            # Logger pode não estar disponível ainda se a config falhar aqui,
            # mas ConfigurationError será levantado.
            # logger.critical("Database URI is not configured. Cannot initialize SQLAlchemy.")
            raise ConfigurationError("Database URI is missing in configuration.")

        logger.info(f"Initializing SQLAlchemy engine and session factory...")
        try:
            # 1. Create the Engine
            engine = create_engine(
                database_uri,
                pool_size=pool_size,
                max_overflow=max_overflow,
                pool_recycle=3600,
                echo=False
            )

            # 2. Test Connection
            try:
                with engine.connect() as connection:
                    logger.info("Database connection successful.")
            except SQLAlchemyError as conn_err:
                logger.critical(f"Database connection failed: {conn_err}", exc_info=True)
                raise DatabaseError(f"Failed to connect to the database: {conn_err}") from conn_err

            # 3. Create Session Factory (SessionLocal)
            _SessionLocalFactory = sessionmaker(
                autocommit=False, autoflush=False, bind=engine, expire_on_commit=False
            )
            logger.info("SQLAlchemy session factory (SessionLocal) created.")

            # 4. Initialize Schema (uses the engine)
            # --- Importar SchemaManager localmente ---
            from .schema_manager import SchemaManager
            # ---------------------------------------
            try:
                logger.info("Initializing database schema...")
                schema_manager = SchemaManager(engine)
                schema_manager.initialize_schema()
                logger.info("Database schema initialization complete.")
            except Exception as schema_err:
                logger.critical(f"Database schema initialization failed: {schema_err}", exc_info=True)
                engine.dispose()
                raise DatabaseError(f"Schema initialization failed: {schema_err}") from schema_err

            # Store the initialized engine
            _sqla_engine = engine
            logger.info("SQLAlchemy initialization complete.")
            return _sqla_engine

        except (DatabaseError, ConfigurationError) as e: # Capturar config error tb
             # Logger pode não estar disponível se falhar cedo
             print(f"ERROR: Database/Configuration error during SQLAlchemy initialization: {e}")
             raise
        except SQLAlchemyError as e:
             # Logger pode não estar disponível
             print(f"ERROR: SQLAlchemy error during initialization: {e}")
             logger.critical(f"SQLAlchemy engine/session factory initialization failed: {e}", exc_info=True)
             raise DatabaseError(f"SQLAlchemy initialization failed: {e}") from e
        except Exception as e:
             # Logger pode não estar disponível
             print(f"ERROR: Unexpected error during SQLAlchemy initialization: {e}")
             logger.critical(f"Unexpected error during SQLAlchemy initialization: {e}", exc_info=True)
             if 'engine' in locals() and engine: engine.dispose()
             raise DatabaseError(f"Unexpected error during database initialization: {e}") from e

# --- Função para Obter uma Sessão (Gerenciador de Contexto) ---
@contextmanager
def get_db_session() -> Generator[Session, None, None]:
    """
    Dependency function/context manager to get a database session.
    Manages session lifecycle (commit, rollback, close).
    Uses local imports for logger/errors.
    """
    # --- Importações locais ---
    from src.utils.logger import logger # Importa logger aqui
    from src.api.errors import DatabaseError # Importa errors aqui
    # -------------------------

    if not _SessionLocalFactory:
        # Logger pode não estar disponível aqui se a inicialização falhou muito cedo
        # logger.critical("SessionLocal factory not initialized. Call init_sqlalchemy() first.")
        print("CRITICAL ERROR: Database session factory has not been initialized.")
        raise RuntimeError("Database session factory has not been initialized.")

    db: Optional[Session] = None
    try:
        db = _SessionLocalFactory()
        yield db
        db.commit()
        logger.debug("Database session committed successfully.")
    except SQLAlchemyError as sql_ex:
        logger.error(f"Database error occurred in session: {sql_ex}", exc_info=True)
        if db:
            db.rollback()
            logger.warning("Database session rolled back due to SQLAlchemyError.")
        raise DatabaseError(f"Database operation failed: {sql_ex}") from sql_ex
    except Exception as e:
        logger.error(f"Error occurred in database session: {e}", exc_info=True)
        if db:
            db.rollback()
            logger.warning("Database session rolled back due to exception.")
        raise
    finally:
        if db:
            db.close()
            logger.debug("Database session closed.")

# --- Função de Desligamento do Engine ---
def dispose_sqlalchemy_engine():
    """Closes all connections in the engine's pool. Call during application shutdown."""
    # --- Importações locais ---
    from src.utils.logger import logger # Importa logger aqui
    # -------------------------

    global _sqla_engine, _SessionLocalFactory
    with _engine_lock:
        if _sqla_engine:
            logger.info("Disposing SQLAlchemy engine connection pool...")
            try:
                _sqla_engine.dispose()
                _sqla_engine = None
                _SessionLocalFactory = None
                logger.info("SQLAlchemy engine connection pool disposed.")
            except Exception as e:
                logger.error(f"Error disposing SQLAlchemy engine pool: {e}", exc_info=True)
        else:
            logger.debug("SQLAlchemy engine shutdown called, but engine already disposed or not initialized.")

# --- Itens Exportados Atualizados ---
# Somente funções e Base são exportados
__all__ = [
    "init_sqlalchemy",
    "get_db_session",
    "dispose_sqlalchemy_engine",
    "Base", # Essencial
]
</file>

<file path="src/database/base_repository.py">
# src/database/base_repository.py
# Provides a simplified base class for ORM repositories.

from sqlalchemy.engine import Engine
from sqlalchemy.orm import sessionmaker, Session # Import Session stuff
from typing import Optional, Callable # Import Callable for SessionLocal type hint

from src.utils.logger import logger
from src.api.errors import DatabaseError

class BaseRepository:
    """
    Base class for data repositories using SQLAlchemy ORM Sessions.
    Stores the engine to potentially create sessions if needed,
    but individual methods should ideally receive a session.
    """

    def __init__(self, engine: Engine):
        """
        Initializes the BaseRepository.

        Args:
            engine: The SQLAlchemy Engine instance.
        """
        if not isinstance(engine, Engine):
             raise TypeError("engine must be an instance of sqlalchemy.engine.Engine")
        self.engine = engine
        # Criar a fábrica de sessões localmente se não for injetada globalmente?
        # Por simplicidade, vamos assumir que os repositórios filhos obterão
        # a sessão via get_db_session() ou injeção.
        logger.debug(f"{self.__class__.__name__} initialized with SQLAlchemy engine: {engine.url.database}")

    # Métodos _execute e _execute_transaction foram removidos.
    # Os repositórios filhos usarão a API da Sessão SQLAlchemy diretamente.
    # Ex: session.query(...), session.add(...), session.execute(select(...))

    # Poderíamos adicionar um helper para obter sessão aqui, mas é melhor
    # gerenciar a sessão externamente (ex: com get_db_session).
    # def _get_session(self) -> Session:
    #     if not self._session_factory: # Precisaria da fábrica aqui
    #         raise RuntimeError("Session factory not available in repository.")
    #     return self._session_factory()
</file>

<file path="src/database/base.py">
# src/database/base.py
# Define a base declarativa para os modelos SQLAlchemy ORM.

from sqlalchemy.orm import declarative_base
from sqlalchemy import MetaData

# Convenção de nomenclatura para constraints (opcional, mas recomendado)
# Garante nomes consistentes para chaves primárias, estrangeiras, índices, etc.
# Evita problemas com nomes muito longos ou colisões em alguns SGBDs.
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s"
}

# Cria uma instância de MetaData com a convenção de nomenclatura
# O schema pode ser definido aqui se você usar schemas no PostgreSQL (ex: metadata=MetaData(schema="meu_schema"))
metadata = MetaData(naming_convention=convention)

# Cria a Base declarativa usando a metadata configurada
Base = declarative_base(metadata=metadata)

# Você pode adicionar aqui classes base customizadas com colunas comuns (id, created_at, etc.)
# se desejar, mas por enquanto manteremos simples.
# Exemplo:
# class BaseTimestampedModel(Base):
#     __abstract__ = True # Não cria tabela para esta classe
#     created_at: Mapped[datetime] = mapped_column(default=func.now())
#     updated_at: Mapped[datetime] = mapped_column(default=func.now(), onupdate=func.now())
</file>

<file path="src/database/fiscal_repository.py">
# src/database/fiscal_repository.py
# Handles database operations for Fiscal data using SQLAlchemy ORM.

import re # Importar regex para o range
from datetime import datetime, timezone, date, time # Adicionado timezone, date, time
from typing import List, Optional, Dict, Any, Tuple
from sqlalchemy import select, func, delete, update, and_, or_ # Importar and_, or_
from sqlalchemy.orm import Session, joinedload, selectinload, make_transient
from sqlalchemy.orm.exc import NoResultFound
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.fiscal_orm import (
    NotaFiscalOrm, NotaFiscalItemOrm, NotaFiscalItemProdutoOrm,
    NotaFiscalPagamentoOrm, NotaFiscalPedidoVendaOrm, NotaFiscalObservacaoOrm
)
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError
from src.utils.data_conversion import safe_float, safe_int, parse_optional_date, parse_optional_datetime, parse_optional_time

class FiscalRepository(BaseRepository):
    """
    Repository for managing Fiscal data (NotaFiscal and related entities) using ORM Sessions.
    Methods expect a Session object to be passed in.
    """

    # --- Upsert Logic ---
    def upsert_invoice(self, db: Session, invoice_data: Dict[str, Any]) -> Optional[NotaFiscalOrm]:
        """
        Creates or updates a Nota Fiscal and its related entities based on ERP data.
        Prioritizes lookup by (branch_code, invoice_sequence, invoice_date). Handles potential
        duplicates from ERP pagination by checking access_key if primary lookup fails.
        More robust handling of potential duplicates within the same session flush.

        Args:
            db: The SQLAlchemy Session.
            invoice_data: A dictionary representing a single invoice item from the ERP API response.

        Returns:
            The created or updated NotaFiscalOrm object, or None if essential data is missing or skipped.
        """
        if not isinstance(invoice_data, dict):
            logger.warning(f"Pulando upsert da nota fiscal: dados recebidos não são um dicionário: {invoice_data}")
            return None

        branch_code = safe_int(invoice_data.get('branchCode'))
        invoice_sequence = safe_int(invoice_data.get('invoiceSequence'))
        invoice_code = safe_int(invoice_data.get('invoiceCode')) # Usado para logs e busca secundária
        access_key = (invoice_data.get('eletronic') or {}).get('accessKey')
        invoice_date = parse_optional_date(invoice_data.get('invoiceDate')) # Adicionado invoice_date à chave natural

        # Validação da chave natural primária
        if branch_code is None or invoice_sequence is None or invoice_date is None:
            logger.warning(f"Pulando upsert da nota fiscal: Faltando branchCode ({branch_code}), invoiceSequence ({invoice_sequence}) ou invoiceDate ({invoice_date}).")
            return None

        # --- Chave Natural Primária ---
        natural_key_filter = (
            NotaFiscalOrm.branch_code == branch_code,
            NotaFiscalOrm.invoice_sequence == invoice_sequence,
            NotaFiscalOrm.invoice_date == invoice_date
        )
        existing_invoice: Optional[NotaFiscalOrm] = None
        created_new = False

        try:
            # --- Busca Robusta ---
            # 1. Tentar buscar na sessão atual primeiro (caso já processado no batch)
            for obj in db.new: # Objetos a serem inseridos
                if (isinstance(obj, NotaFiscalOrm) and
                        obj.branch_code == branch_code and
                        obj.invoice_sequence == invoice_sequence and
                        obj.invoice_date == invoice_date):
                    existing_invoice = obj
                    logger.debug(f"Nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} já pendente para inserção na sessão.")
                    break
            if not existing_invoice:
                 for obj in db.dirty: # Objetos a serem atualizados
                     if (isinstance(obj, NotaFiscalOrm) and
                            obj.branch_code == branch_code and
                            obj.invoice_sequence == invoice_sequence and
                            obj.invoice_date == invoice_date):
                          existing_invoice = obj
                          logger.debug(f"Nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} já pendente para atualização na sessão.")
                          break

            # 2. Se não estiver na sessão, buscar no banco pela chave natural
            if not existing_invoice:
                stmt_natural = select(NotaFiscalOrm).where(and_(*natural_key_filter))
                existing_invoice = db.scalars(stmt_natural).one_or_none()

            # 3. Se ainda não encontrado E houver access_key, tentar por access_key no banco
            #    (Cobre casos de inconsistência na chave natural vs access_key ou erros anteriores)
            if not existing_invoice and access_key:
                stmt_access_key = select(NotaFiscalOrm).where(NotaFiscalOrm.access_key == access_key)
                invoice_by_key = db.scalars(stmt_access_key).one_or_none()
                if invoice_by_key:
                    logger.warning(f"Nota fiscal encontrada pela access_key '{access_key}' mas não pela chave natural ({branch_code}/{invoice_sequence}/{invoice_date}). Usando registro existente encontrado pela chave.")
                    existing_invoice = invoice_by_key

            # --- Helper Function to Map Data ---
            def map_data_to_invoice(target: NotaFiscalOrm, data: Dict[str, Any]):
                eletronic_data = data.get('eletronic') or {}
                shipping_data = data.get('shippingCompany') or {}

                target.branch_cnpj = data.get('branchCnpj')
                target.person_code = safe_int(data.get('personCode'))
                target.person_name = data.get('personName')
                target.invoice_code = safe_int(data.get('invoiceCode'))
                target.serial_code = data.get('serialCode')
                target.invoice_status = data.get('invoiceStatus')
                target.access_key = eletronic_data.get('accessKey')
                target.electronic_invoice_status = eletronic_data.get('electronicInvoiceStatus')
                target.receipt = str(eletronic_data.get('receipt')) if eletronic_data.get('receipt') is not None else None
                target.receivement_date = parse_optional_datetime(eletronic_data.get('receivementDate'))
                target.disable_protocol = eletronic_data.get('disableProtocol')
                target.disable_date = parse_optional_datetime(eletronic_data.get('disableDate'))
                target.transaction_branch_code = safe_int(data.get('transactionBranchCode'))
                target.transaction_date = parse_optional_date(data.get('transactionDate'))
                target.transaction_code = safe_int(data.get('transactionCode'))
                target.inclusion_component_code = data.get('inclusionComponentCode')
                target.user_code = safe_int(data.get('userCode'))
                target.origin = data.get('origin')
                target.document_type = safe_int(data.get('documentType'))
                target.operation_type = data.get('operationType')
                target.operation_code = safe_int(data.get('operationCode'))
                target.operation_name = data.get('operatioName') # Potential typo in source data 'operatioName'?
                target.invoice_date = parse_optional_date(data.get('invoiceDate')) # Já validado
                target.issue_date = parse_optional_date(data.get('issueDate'))
                target.release_date = parse_optional_date(data.get('releaseDate'))
                target.exit_time = parse_optional_time(data.get('exitTime'))
                target.lastchange_date = parse_optional_datetime(data.get('lastchangeDate'))
                target.payment_condition_code = safe_int(data.get('paymentConditionCode'))
                target.payment_condition_name = data.get('paymentConditionName')
                target.discount_percentage = safe_float(data.get('discountPercentage'))
                target.quantity = safe_float(data.get('quantity'))
                target.product_value = safe_float(data.get('productValue'))
                target.additional_value = safe_float(data.get('additionalValue'))
                target.shipping_value = safe_float(data.get('shippingValue'))
                target.insurance_value = safe_float(data.get('insuranceValue'))
                target.ipi_value = safe_float(data.get('ipiValue'))
                target.base_icms_value = safe_float(data.get('baseIcmsValue'))
                target.icms_value = safe_float(data.get('icmsValue'))
                target.icms_subst_value = safe_float(data.get('icmsSubStValue')) # Typo? 'icmsSubstValue'?
                target.total_value = safe_float(data.get('totalValue'))
                target.shipping_company_code = safe_int(shipping_data.get('shippingCompanyCode'))
                target.shipping_company_name = shipping_data.get('shippingCompanyName')
                target.freight_type = shipping_data.get('freightType') # Source had 'freitghtType'?
                target.freight_type_redispatch = shipping_data.get('freightTypeRedispatch') # Source had 'freitghtTypeRedispatch'?
                target.freight_value = safe_float(shipping_data.get('freightValue'))
                target.package_number = safe_int(shipping_data.get('packageNumber'))
                target.gross_weight = safe_float(shipping_data.get('grossWeight'))
                target.net_weight = safe_float(shipping_data.get('netWeight'))
                target.species = shipping_data.get('species')
                target.terminal_code = safe_int(data.get('terminalCode'))
                target.observation_nfe = data.get('observationNFE') # Campo de observação único

            # --- Atualizar ou Criar ---
            if existing_invoice:
                # --- ATUALIZAÇÃO ---
                new_last_change = parse_optional_datetime(invoice_data.get('lastchangeDate'))
                should_update = True
                if existing_invoice.lastchange_date and new_last_change:
                    # Normalizar para UTC ou comparar como naive (se ambos forem naive)
                    existing_ts = existing_invoice.lastchange_date
                    new_ts = new_last_change
                    if existing_ts.tzinfo and new_ts.tzinfo:
                         if new_ts.astimezone(timezone.utc) <= existing_ts.astimezone(timezone.utc):
                              should_update = False
                    elif not existing_ts.tzinfo and not new_ts.tzinfo:
                         if new_ts <= existing_ts:
                              should_update = False
                    else: # Mistura de naive e aware, assume que deve atualizar
                         logger.warning(f"Comparando timestamp naive e aware para NF {branch_code}/{invoice_sequence}/{invoice_date}. Atualizando por segurança.")

                if not should_update:
                     logger.debug(f"Pulando atualização da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}, timestamp não alterado ou mais antigo ({new_last_change}).")
                     return existing_invoice

                logger.debug(f"Atualizando nota fiscal existente ID {existing_invoice.id} ({branch_code}/{invoice_sequence}/{invoice_date})")
                invoice = existing_invoice
                map_data_to_invoice(invoice, invoice_data)
                # Limpar filhos ANTES de adicionar novos para evitar duplicatas
                invoice.items.clear()
                invoice.payments.clear()
                invoice.sales_orders.clear()
                invoice.observations.clear()
                # Flush pode ajudar a garantir que deletes ocorram antes de inserts se houver constraints
                # db.flush() # Descomente se necessário, mas pode impactar performance
            else:
                 # --- CRIAÇÃO ---
                 logger.debug(f"Criando nova nota fiscal ({branch_code}/{invoice_sequence}/{invoice_date}, Chave: ...{access_key[-6:] if access_key else 'N/A'})")
                 # Checagem prévia por access_key (melhoria contra race condition/duplicidade)
                 if access_key:
                      stmt_check_key = select(NotaFiscalOrm.id).where(NotaFiscalOrm.access_key == access_key).limit(1)
                      key_already_exists = db.execute(stmt_check_key).scalar_one_or_none()
                      if key_already_exists:
                           logger.warning(f"Access_key duplicada '{access_key}' encontrada antes do INSERT para {branch_code}/{invoice_sequence}/{invoice_date}. Pulando este registro.")
                           return None # Pula esta nota

                 invoice = NotaFiscalOrm(branch_code=branch_code, invoice_sequence=invoice_sequence, invoice_date=invoice_date)
                 map_data_to_invoice(invoice, invoice_data)
                 db.add(invoice)
                 created_new = True # Marca que foi criado

            # --- Handle Children (Processar e associar ao 'invoice' correto) ---

            # Items and their Products
            items_list = invoice_data.get('items')
            if isinstance(items_list, list):
                for item_data in items_list:
                    if not isinstance(item_data, dict): continue
                    item_orm = NotaFiscalItemOrm(
                        nota_fiscal=invoice, # Associação feita aqui
                         sequence=safe_int(item_data.get('sequence')),
                         code=item_data.get('code'), name=item_data.get('name'),
                         ncm=item_data.get('ncm'), cfop=safe_int(item_data.get('cfop')),
                         measure_unit=item_data.get('measureUnit'), quantity=safe_float(item_data.get('quantity')),
                         gross_value=safe_float(item_data.get('grossValue')), discount_value=safe_float(item_data.get('discountValue')),
                         net_value=safe_float(item_data.get('netValue')), unit_gross_value=safe_float(item_data.get('unitGrossValue')),
                         unit_discount_value=safe_float(item_data.get('unitDiscountValue')), unit_net_value=safe_float(item_data.get('unitNetValue')),
                         additional_value=safe_float(item_data.get('additionalValue')), freight_value=safe_float(item_data.get('freightValue')),
                         insurance_value=safe_float(item_data.get('insuranceValue')), additional_item_information=item_data.get('additionalItemInformation')
                    )
                    # Não precisa de db.add(item_orm) por causa do cascade
                    products_list = item_data.get('products')
                    if isinstance(products_list, list):
                         for prod_data in products_list:
                              if not isinstance(prod_data, dict): continue
                              prod_orm = NotaFiscalItemProdutoOrm(
                                  item=item_orm, # Associação feita aqui
                                  product_code=safe_int(prod_data.get('productCode')), product_name=prod_data.get('productName'),
                                  dealer_code=safe_int(prod_data.get('dealerCode')), quantity=safe_float(prod_data.get('quantity')),
                                  unit_gross_value=safe_float(prod_data.get('unitGrossValue')), unit_discount_value=safe_float(prod_data.get('unitDiscountValue')),
                                  unit_net_value=safe_float(prod_data.get('unitNetValue')), gross_value=safe_float(prod_data.get('grossValue')),
                                  discount_value=safe_float(prod_data.get('discountValue')), net_value=safe_float(prod_data.get('netValue'))
                              )
                              # Associação via backref/relationship, não precisa add
                              item_orm.item_products.append(prod_orm)
                    # Associação via backref/relationship
                    invoice.items.append(item_orm)

            # Payments
            payments_list = invoice_data.get('payments')
            if isinstance(payments_list, list):
                for payment_data in payments_list:
                    if not isinstance(payment_data, dict): continue
                    payment_orm = NotaFiscalPagamentoOrm(
                        nota_fiscal=invoice, # Associação
                        document_number=safe_int(payment_data.get('documentNumber')), expiration_date=parse_optional_datetime(payment_data.get('expirationDate')),
                        payment_value=safe_float(payment_data.get('paymentValue')), document_type_code=safe_int(payment_data.get('documentTypeCode')),
                        document_type=payment_data.get('documentType'), installment=safe_int(payment_data.get('installment')),
                        bearer_code=safe_int(payment_data.get('bearerCode')), bearer_name=payment_data.get('bearerName')
                    )
                    invoice.payments.append(payment_orm) # Associação

            # Sales Orders
            sales_order_list = invoice_data.get('salesOrder')
            if isinstance(sales_order_list, list):
                for order_data in sales_order_list:
                    if not isinstance(order_data, dict): continue
                    order_orm = NotaFiscalPedidoVendaOrm(
                        nota_fiscal=invoice, # Associação
                        branch_code=safe_int(order_data.get('branchCode')), order_code=safe_int(order_data.get('orderCode')),
                        customer_order_code=order_data.get('customerOrderCode')
                    )
                    invoice.sales_orders.append(order_orm) # Associação

            # Observations (observationNF list)
            observations_list = invoice_data.get('observationNF')
            if isinstance(observations_list, list):
                 for obs_data in observations_list:
                      if not isinstance(obs_data, dict): continue
                      obs_orm = NotaFiscalObservacaoOrm(
                          nota_fiscal=invoice, # Associação
                          observation=obs_data.get('observation'),
                          sequence=safe_int(obs_data.get('sequence'))
                      )
                      invoice.observations.append(obs_orm) # Associação


            # --- Flush Final ---
            # O flush aqui pode detectar UniqueViolations ANTES do commit do batch
            # db.flush() # Descomente se encontrar problemas de integridade complexos
            log_operation = "Criada" if created_new else "Atualizada"
            logger.debug(f"{log_operation} nota fiscal {branch_code}/{invoice_sequence}/{invoice_date} na sessão. Commit pendente.")
            return invoice

        except IntegrityError as e:
            db.rollback() # Rollback da sessão atual para não afetar o resto do batch
            logger.error(f"Erro de integridade do banco de dados durante upsert para nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            # Checar constraints específicas se necessário
            # if "uq_nota_fiscal_branch_sequence_date" in str(e.orig) or "ix_nota_fiscal_access_key" in str(e.orig):
            #      logger.warning(f"IntegrityError (chave duplicada?) para nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}. Pulando este registro.")
            #      return None # Pular este item
            # else:
                 # Outro erro de integridade, pode ser melhor propagar
            raise DatabaseError(f"Erro de integridade processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e
        except SQLAlchemyError as e:
            db.rollback() # Rollback da sessão atual
            logger.error(f"Erro de banco de dados durante upsert da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e
        except Exception as e:
            db.rollback() # Rollback da sessão atual
            logger.error(f"Erro inesperado durante upsert da nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado processando nota fiscal {branch_code}/{invoice_sequence}/{invoice_date}: {e}") from e


    # --- Get Latest Sync Timestamp ---
    def get_latest_sync_timestamp(self, db: Session) -> Optional[datetime]:
        """
        Finds the maximum 'lastchange_date' from the nota_fiscal table.
        """
        logger.debug("Consultando timestamp mais recente de sincronização (max lastchange_date) na tabela nota_fiscal.")
        try:
            stmt = select(func.max(NotaFiscalOrm.lastchange_date))
            latest_timestamp = db.scalar(stmt)
            if latest_timestamp:
                 # Certificar que o timestamp retornado é timezone-aware (UTC)
                 if latest_timestamp.tzinfo is None:
                      logger.warning(f"Timestamp {latest_timestamp} do DB é naive, assumindo UTC.")
                      latest_timestamp = latest_timestamp.replace(tzinfo=timezone.utc)
                 else:
                      latest_timestamp = latest_timestamp.astimezone(timezone.utc)
                 logger.info(f"Timestamp mais recente de sincronização encontrado: {latest_timestamp.isoformat()}")
            else:
                 logger.info("Nenhum timestamp anterior de sincronização encontrado no banco de dados.")
            return latest_timestamp
        except SQLAlchemyError as e:
             logger.error(f"Erro de banco de dados ao obter timestamp mais recente de sincronização: {e}", exc_info=True)
             return None # Retorna None para indicar falha ou ausência
        except Exception as e:
            logger.error(f"Erro inesperado ao obter timestamp mais recente de sincronização: {e}", exc_info=True)
            return None # Retorna None


    # --- Find Invoices Local ---
    def find_invoices_local(self, db: Session, filters: Dict[str, Any], page: int, page_size: int) -> Tuple[List[NotaFiscalOrm], int]:
        """
        Searches for invoices in the LOCAL database based on provided filters.
        Args:
            db: The SQLAlchemy Session.
            filters: Dictionary of filter criteria mapped from API request.
            page: Page number (starting from 1).
            page_size: Number of items per page.
        Returns:
            A tuple containing: (list of NotaFiscalOrm objects, total_count).
        """
        logger.debug(f"Buscando notas fiscais locais com filtros: {filters}, Página: {page}, TamanhoPágina: {page_size}")
        try:
            query = select(NotaFiscalOrm)
            applied_filters = [] # Para logar os filtros aplicados

            # --- Apply Filters ---

            # Filtro por Status (Chave API: 'status', Campo ORM: electronic_invoice_status)
            if 'status' in filters:
                status_input = filters['status']
                if status_input and isinstance(status_input, str):
                    # Divide por vírgula, remove espaços e converte para minúsculo
                    status_list_lower = [s.strip().lower() for s in status_input.split(',') if s.strip()]
                    if status_list_lower:
                        query = query.where(func.lower(NotaFiscalOrm.electronic_invoice_status).in_(status_list_lower))
                        applied_filters.append(f"status IN {status_list_lower}")

            # Filtro por Nome do Destinatário (Chave API: 'recipient_name' - Manter se útil)
            if 'recipient_name' in filters:
                name_filter = filters['recipient_name']
                if name_filter and isinstance(name_filter, str):
                    query = query.where(NotaFiscalOrm.person_name.ilike(f"%{name_filter}%"))
                    applied_filters.append(f"recipient_name LIKE '%{name_filter}%'")

            # Filtro por Número da Nota Fiscal (Chave API: 'invoice_number', Campo ORM: invoice_code)
            if 'invoice_number' in filters:
                num_input = filters['invoice_number']
                if num_input and isinstance(num_input, str):
                    num_input = num_input.strip()
                    # 1. Checar por Range (ex: "100-150")
                    range_match = re.match(r'^(\d+)\s*-\s*(\d+)$', num_input)
                    if range_match:
                        start_num = safe_int(range_match.group(1))
                        end_num = safe_int(range_match.group(2))
                        if start_num is not None and end_num is not None and start_num <= end_num:
                            query = query.where(NotaFiscalOrm.invoice_code.between(start_num, end_num))
                            applied_filters.append(f"invoice_number BETWEEN {start_num} AND {end_num}")
                        else:
                            logger.warning(f"Range de número de nota inválido: '{num_input}'. Ignorando filtro.")
                    # 2. Checar por Lista (ex: "101, 105, 200")
                    elif ',' in num_input:
                        int_num_list = [safe_int(n.strip()) for n in num_input.split(',') if safe_int(n.strip()) is not None]
                        if int_num_list:
                            query = query.where(NotaFiscalOrm.invoice_code.in_(int_num_list))
                            applied_filters.append(f"invoice_number IN {int_num_list}")
                        else:
                             logger.warning(f"Lista de números de nota inválida ou vazia: '{num_input}'. Ignorando filtro.")
                    # 3. Assumir Número Único
                    else:
                        single_num = safe_int(num_input)
                        if single_num is not None:
                            query = query.where(NotaFiscalOrm.invoice_code == single_num)
                            applied_filters.append(f"invoice_number == {single_num}")
                        else:
                             logger.warning(f"Número de nota inválido: '{num_input}'. Ignorando filtro.")


            # Filtro por Chave de Acesso (Chave API: 'access_key')
            if 'access_key' in filters:
                 key = filters['access_key']
                 if key and isinstance(key, str) and len(key) == 44 and key.isdigit():
                      query = query.where(NotaFiscalOrm.access_key == key)
                      applied_filters.append(f"access_key == ...{key[-6:]}")
                 elif key:
                      logger.warning(f"Formato de chave de acesso inválido no filtro: '{key}'. Ignorando.")


            # Filtro por Código do Cliente (Chave API interna: 'customer_code', Campo ORM: person_code)
            if 'customer_code' in filters:
                code_input = filters['customer_code']
                if code_input and isinstance(code_input, str):
                    # Tratar lista separada por vírgula
                    code_list = [safe_int(c.strip()) for c in code_input.split(',') if safe_int(c.strip()) is not None]
                    if len(code_list) == 1:
                         query = query.where(NotaFiscalOrm.person_code == code_list[0])
                         applied_filters.append(f"person_code == {code_list[0]}")
                    elif len(code_list) > 1:
                         query = query.where(NotaFiscalOrm.person_code.in_(code_list))
                         applied_filters.append(f"person_code IN {code_list}")
                    else:
                        logger.warning(f"Lista de códigos de cliente inválida ou vazia: '{code_input}'. Ignorando filtro.")


            # Filtro por CPF/CNPJ do Cliente (Chave API interna: 'customer_cpf_cnpj')
            # !!! AJUSTE NECESSÁRIO QUANDO O JOIN COM A TABELA DE PESSOAS/CLIENTES FOR IMPLEMENTADO !!!
            if 'customer_cpf_cnpj' in filters:
                 cpf_cnpj_input = filters['customer_cpf_cnpj']
                 if cpf_cnpj_input and isinstance(cpf_cnpj_input, str):
                     cpf_cnpj_list = [doc.strip() for doc in cpf_cnpj_input.split(',') if doc.strip() and doc.isdigit() and (len(doc) == 11 or len(doc) == 14)]
                     if cpf_cnpj_list:
                          # --- Placeholder ---
                          # Substitua 'NotaFiscalOrm.branch_cnpj' pelo campo correto após o JOIN com a tabela de Pessoas/Clientes
                          # Exemplo: Se houver um relacionamento 'person' em NotaFiscalOrm:
                          # from src.domain.person_orm import PersonOrm # Importar
                          # query = query.join(PersonOrm, NotaFiscalOrm.person_code == PersonOrm.code) # Exemplo de JOIN
                          # query = query.where(PersonOrm.cpf_cnpj.in_(cpf_cnpj_list)) # Exemplo de filtro no campo correto
                          logger.warning("Filtro por CPF/CNPJ ainda não implementado com JOIN. Usando placeholder NotaFiscalOrm.branch_cnpj.")
                          query = query.where(NotaFiscalOrm.branch_cnpj.in_(cpf_cnpj_list)) # <<< AJUSTE ESTA LINHA FUTURAMENTE
                          applied_filters.append(f"branch_cnpj IN {cpf_cnpj_list} (Placeholder!)") # Ajuste o nome do campo no log também
                          # --- Fim Placeholder ---
                     else:
                          logger.warning(f"Lista de CPF/CNPJ inválida ou vazia: '{cpf_cnpj_input}'. Ignorando filtro.")


            # Filtro por Data de Emissão (Chaves API: 'start_date', 'end_date', Campo ORM: issue_date)
            start_issue_date = parse_optional_date(filters.get('start_date')) # Simplificado, API só usa 'start_date' agora
            end_issue_date = parse_optional_date(filters.get('end_date'))     # Simplificado, API só usa 'end_date' agora
            if start_issue_date:
                 query = query.where(NotaFiscalOrm.issue_date >= start_issue_date)
                 applied_filters.append(f"issue_date >= {start_issue_date.isoformat()}")
            if end_issue_date:
                 # Para garantir que a data final seja inclusiva
                 query = query.where(NotaFiscalOrm.issue_date <= end_issue_date)
                 applied_filters.append(f"issue_date <= {end_issue_date.isoformat()}")


            # Log dos filtros efetivamente aplicados
            if applied_filters:
                logger.info(f"Filtros aplicados na consulta: {'; '.join(applied_filters)}")
            else:
                logger.info("Nenhum filtro específico aplicado na consulta.")


            # --- Count Total Matching Items ---
            # Contar *depois* de aplicar todos os filtros WHERE
            count_query = select(func.count()).select_from(query.subquery())
            total_count = db.scalar(count_query) or 0
            logger.debug(f"Contagem total ANTES da paginação (com filtros): {total_count}")

            # --- Apply Ordering ---
            # Ordenar antes da paginação
            query = query.order_by(NotaFiscalOrm.issue_date.desc(), NotaFiscalOrm.invoice_code.desc())

            # --- Apply Pagination ---
            offset = (page - 1) * page_size
            query = query.limit(page_size).offset(offset)

            # --- Eager Loading ---
            # Carregar relacionamentos necessários para a formatação no FiscalService
            query = query.options(
                selectinload(NotaFiscalOrm.sales_orders) # Usado em _format_invoice_list_item
                # Adicione outros relacionamentos se forem usados na formatação
            )

            # --- Execute Query ---
            results = db.scalars(query).all()

            logger.info(f"Busca local concluída. {len(results)} itens retornados para página {page}. Total de itens correspondentes: {total_count}.")
            return list(results), total_count

        except SQLAlchemyError as e:
            logger.error(f"Erro de banco de dados na busca de notas fiscais locais: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados durante busca de notas fiscais locais: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado na busca de notas fiscais locais: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado durante busca de notas fiscais locais: {e}") from e
</file>

<file path="src/database/observation_repository.py">
# src/database/observation_repository.py
# Handles database operations for Product Observations using SQLAlchemy ORM.

from datetime import datetime, timezone
from typing import List, Optional, Dict, Any
from sqlalchemy import select, func, delete, update # Import select, func, delete, update
from sqlalchemy.orm import Session # Import Session
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.observation import Observation # Import ORM model
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError

class ObservationRepository(BaseRepository):
    """
    Repository for managing Product Observations using SQLAlchemy ORM Sessions.
    Methods now expect a Session object to be passed in.
    """

    # O construtor ainda recebe Engine, mas não o usaremos diretamente nos métodos ORM.
    # def __init__(self, engine: Engine):
    #     super().__init__(engine)
    #     logger.info("ObservationRepository initialized with SQLAlchemy engine (ready for ORM sessions).")


    def add(self, db: Session, observation: Observation) -> Observation:
        """Adds a new observation to the database using ORM Session."""
        if not observation.reference_code or not observation.observation_text or not observation.user:
             raise ValueError("Missing required fields (reference_code, observation_text, user).")

        logger.debug(f"ORM: Adding observation for ref '{observation.reference_code}' to session")
        try:
            # Define timestamp se não estiver definido
            if observation.timestamp is None:
                 observation.timestamp = datetime.now(timezone.utc)

            db.add(observation)
            db.flush() # Para obter o ID gerado
            logger.info(f"ORM: Observation added to session (ID: {observation.id}) for ref: {observation.reference_code}. Commit pending.")
            # Commit é tratado externamente
            return observation
        except IntegrityError as e: # Capturar erros de constraint se houver (improvável aqui)
            db.rollback()
            logger.error(f"ORM: Database integrity error adding observation: {e}", exc_info=True)
            raise DatabaseError(f"Failed to add observation due to integrity constraint: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error adding observation: {e}", exc_info=True)
            raise DatabaseError(f"Failed to add observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error adding observation for ref '{observation.reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while adding observation: {e}") from e

    def find_by_id(self, db: Session, observation_id: int) -> Optional[Observation]:
        """Finds an observation by its ID using ORM Session."""
        logger.debug(f"ORM: Finding observation by ID {observation_id}")
        try:
            observation = db.get(Observation, observation_id)
            if observation:
                 logger.debug(f"ORM: Observation found by ID {observation_id}.")
            else:
                 logger.debug(f"ORM: Observation not found by ID {observation_id}.")
            return observation
        except SQLAlchemyError as e:
             logger.error(f"ORM: Database error finding observation by ID {observation_id}: {e}", exc_info=True)
             raise DatabaseError(f"Database error finding observation by ID: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Unexpected error finding observation by ID {observation_id}: {e}", exc_info=True)
             raise DatabaseError(f"Unexpected error finding observation by ID: {e}") from e


    def find_by_reference_code(self, db: Session, reference_code: str, include_resolved: bool = True) -> List[Observation]:
        """Finds observations for a reference code using ORM Session."""
        logger.debug(f"ORM: Finding obs for ref '{reference_code}' (resolved={include_resolved})")
        try:
            stmt = select(Observation).where(Observation.reference_code == reference_code)
            if not include_resolved:
                stmt = stmt.where(Observation.resolved == False)
            stmt = stmt.order_by(Observation.timestamp.desc())

            observations = db.scalars(stmt).all()
            logger.debug(f"ORM: Found {len(observations)} obs for ref '{reference_code}'.")
            return list(observations)
        except SQLAlchemyError as e:
             logger.error(f"ORM: Database error finding obs by ref '{reference_code}': {e}", exc_info=True)
             raise DatabaseError(f"Database error finding obs by ref: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Unexpected error finding obs by ref {reference_code}: {e}", exc_info=True)
             raise DatabaseError(f"Unexpected error finding obs by ref: {e}") from e

    def update(self, db: Session, observation_to_update: Observation) -> Observation:
        """Updates an existing observation using ORM Session."""
        if observation_to_update.id is None:
            raise ValueError("Cannot update observation without an ID.")

        logger.debug(f"ORM: Updating observation ID {observation_to_update.id} in session")
        try:
            # Se o objeto veio de fora da sessão, buscar primeiro ou usar merge.
            # Assumindo que o objeto já está na sessão ou será gerenciado pelo chamador.
            db.flush() # Envia as alterações pendentes (se houver) sem commitar
            logger.info(f"ORM: Observation ID {observation_to_update.id} marked for update. Commit pending.")
            # Commit é externo
            return observation_to_update
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error updating observation ID {observation_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Failed to update observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error updating observation ID {observation_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while updating observation: {e}") from e


    def mark_as_resolved(self, db: Session, observation_id: int, resolved_by_user: str) -> bool:
        """Marks a specific observation as resolved using ORM Session."""
        logger.debug(f"ORM: Marking observation ID {observation_id} as resolved by '{resolved_by_user}'")
        try:
            observation = db.get(Observation, observation_id)
            if not observation:
                 logger.warning(f"ORM: Attempted to resolve non-existent observation ID {observation_id}.")
                 raise NotFoundError(f"Observation with ID {observation_id} not found.")

            if observation.resolved:
                 logger.warning(f"ORM: Observation ID {observation_id} was already resolved.")
                 return False # Indicar que nenhuma alteração foi feita

            observation.resolved = True
            observation.resolved_user = resolved_by_user
            observation.resolved_timestamp = datetime.now(timezone.utc)
            db.flush() # Envia a alteração
            logger.info(f"ORM: Observation ID {observation_id} marked as resolved in session. Commit pending.")
            # Commit é externo
            return True
        except NotFoundError:
             raise # Re-raise not found error
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error marking obs ID {observation_id} as resolved: {e}", exc_info=True)
            raise DatabaseError(f"Failed to resolve observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error marking obs ID {observation_id} as resolved: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while resolving observation: {e}") from e

    def get_unresolved_count(self, db: Session, reference_code: str) -> int:
        """Gets the count of unresolved observations using ORM Session."""
        logger.debug(f"ORM: Getting unresolved count for ref '{reference_code}'")
        try:
            stmt = (
                select(func.count(Observation.id))
                .where(Observation.reference_code == reference_code)
                .where(Observation.resolved == False)
            )
            count = db.scalar(stmt)
            count = count if count is not None else 0
            logger.debug(f"ORM: Unresolved count for ref '{reference_code}': {count}")
            return count
        except SQLAlchemyError as e:
            logger.error(f"ORM: Failed get unresolved count for ref '{reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"Database error getting unresolved count: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Unexpected error getting unresolved count for ref '{reference_code}': {e}", exc_info=True)
            raise DatabaseError(f"Unexpected error getting unresolved count: {e}") from e

    def get_references_with_pending(self, db: Session) -> List[Dict[str, Any]]:
        """Gets distinct references with the latest pending observation using ORM."""
        # Esta query é um pouco mais complexa com ORM puro sem window functions diretas
        # Vamos manter a lógica de subquery similar à SQL original
        logger.debug("ORM: Getting references with pending observations")
        try:
            # Subquery para encontrar o timestamp mais recente não resolvido por referência
            subq = (
                select(
                    Observation.reference_code,
                    func.max(Observation.timestamp).label("max_timestamp")
                )
                .where(Observation.resolved == False)
                .group_by(Observation.reference_code)
                .subquery('latest_pending')
            )

            # Query principal para pegar os detalhes da observação mais recente
            stmt = (
                select(
                    Observation.reference_code,
                    Observation.user,
                    Observation.timestamp
                )
                .join(subq, (Observation.reference_code == subq.c.reference_code) & (Observation.timestamp == subq.c.max_timestamp))
                .where(Observation.resolved == False) # Garantir que ainda não foi resolvido (caso haja duplicatas de timestamp)
                .order_by(Observation.timestamp.desc())
            )

            results = db.execute(stmt).mappings().all() # Executa e pega como dicionários

            # Formata o resultado (converte datetime para isoformat)
            formatted_results = [
                 {
                      "reference_code": row["reference_code"],
                      "user": row["user"],
                      "timestamp": row["timestamp"].isoformat() if isinstance(row["timestamp"], datetime) else None
                 } for row in results
            ]

            logger.debug(f"ORM: Found {len(formatted_results)} references with pending observations.")
            return formatted_results
        except SQLAlchemyError as e:
            logger.error(f"ORM: Failed to get references with pending observations: {e}", exc_info=True)
            raise DatabaseError(f"Database error getting pending references: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Unexpected error getting pending references: {e}", exc_info=True)
            raise DatabaseError(f"Unexpected error getting pending references: {e}") from e

    def delete_by_id(self, db: Session, observation_id: int) -> bool:
        """Deletes an observation by its ID using ORM Session."""
        logger.debug(f"ORM: Deleting observation ID {observation_id}")
        try:
            observation = db.get(Observation, observation_id)
            if observation:
                db.delete(observation)
                db.flush()
                logger.info(f"ORM: Observation ID {observation_id} marked for deletion. Commit pending.")
                return True
            else:
                logger.warning(f"ORM: Attempted to delete observation ID {observation_id}, but it was not found.")
                return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Database error deleting obs ID {observation_id}: {e}", exc_info=True)
            raise DatabaseError(f"Failed to delete observation: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Unexpected error deleting obs ID {observation_id}: {e}", exc_info=True)
            raise DatabaseError(f"An unexpected error occurred while deleting observation: {e}") from e
</file>

<file path="src/database/product_repository.py">
# src/database/product_repository.py
# Handles database operations related to products (if any beyond observations).

"""
NOTA: Atualmente, todas as operações de BD relacionadas ao produto parecem estar focadas em
'product_observations'. Elas são manipuladas por `ObservationRepository`.

Se houvesse outras tabelas ou dados específicos do produto para gerenciar localmente
(por exemplo, detalhes do produto em cache, metadados do produto local), este repositório
lidaria com essas operações.

Este arquivo é mantido como um espaço reservado demonstrando a estrutura e a integração do SQLAlchemy.
"""

from sqlalchemy.engine import Engine
from .base_repository import BaseRepository
from src.utils.logger import logger
from typing import Optional

class ProductRepository(BaseRepository):
    """
    Repositório para gerenciar dados de produtos no banco de dados local usando SQLAlchemy.
    Atualmente, a lógica de observação está no ObservationRepository.
    """

    def __init__(self, engine: Engine):
        super().__init__(engine)
        logger.info("ProductRepository inicializado (Placeholder) com o engine do SQLAlchemy.")
    
    # Adicione métodos aqui conforme necessário para operações específicas de produtos no banco de dados
    # Exemplo:
    # def cache_product_details(self, product_data: dict):
    #     # Lógica para inserir/atualizar dados no cache usando self._execute
    #     pass
    #
    # def get_cached_product_details(self, product_code: int) -> Optional[dict]:
    #     # Lógica para buscar dados do cache usando self._execute
    #     pass
</file>

<file path="src/database/README.md">
# src/database

Este diretório contém toda a lógica relacionada à interação com o banco de dados **PostgreSQL**, utilizando **SQLAlchemy ORM** e **Alembic** para gerenciamento de schema.

## Arquivos

*   **`__init__.py`**: Inicializa os componentes do SQLAlchemy (`Engine`, `sessionmaker` para criar `SessionLocal`) quando a aplicação inicia, usando a URI do banco definida na configuração. Fornece a função `get_db_session` (um gerenciador de contexto) para obter e gerenciar sessões de banco de dados. **Não contém mais as funções de fábrica de repositórios nem a inicialização do SchemaManager aqui.**
*   **`base.py`**: Define a base declarativa (`Base`) do SQLAlchemy da qual todos os modelos ORM herdam. Também configura metadados e convenções de nomenclatura, que são usados pelo Alembic.
*   **`base_repository.py`**: Define a classe `BaseRepository` simplificada, que serve como ponto de inicialização comum para repositórios, armazenando a `Engine`.
*   **`observation_repository.py`**: Define `ObservationRepository`, responsável pelas operações CRUD relacionadas às observações de produto (`product_observations`) usando a API de Sessão do ORM.
*   **`product_repository.py`**: Placeholder para operações relacionadas a dados de *produtos* armazenados localmente.
*   **`schema_manager.py`**: Define `SchemaManager`, **agora com responsabilidade reduzida**. Sua função principal é garantir que as tabelas existam na **primeira inicialização** (usando `Base.metadata.create_all`) antes que o Alembic seja aplicado, e garantir dados iniciais essenciais (usuário administrador). **NÃO é mais responsável por criar índices, constraints ou aplicar alterações de schema (ALTER TABLE) - isso é feito pelo Alembic.**
*   **`user_repository.py`**: Define `UserRepository`, responsável pelas operações CRUD para as tabelas `users` e `user_permissions` usando a API de Sessão do ORM.
*   **`README.md`**: Este arquivo.

## Funcionamento com Alembic

1.  **Inicialização da App (`src/app.py`):**
    *   A função `init_sqlalchemy()` deste pacote é chamada. Ela cria a `Engine` global do SQLAlchemy e configura a fábrica de sessões `SessionLocal`.
    *   O `SchemaManager` é instanciado e `initialize_schema()` é chamado. Ele executa `Base.metadata.create_all(engine)` (que cria tabelas que *não* existem) e garante o usuário admin.
2.  **Gerenciamento de Schema (Alembic):**
    *   **Fora da execução normal da aplicação**, o desenvolvedor usa os comandos `alembic` para gerenciar o schema.
    *   `alembic revision --autogenerate`: Compara os modelos ORM (`Base.metadata`) com o banco de dados e gera um script de migração em `alembic/versions/`.
    *   `alembic upgrade head`: Aplica os scripts de migração pendentes ao banco de dados, efetivamente criando/alterando tabelas, colunas, índices, etc.
    *   Isso garante que as alterações no schema sejam versionadas e aplicadas de forma consistente em diferentes ambientes (desenvolvimento, teste, produção).
3.  **Repositórios e Operações:** (Funcionamento permanece o mesmo)
    *   Os serviços obtêm instâncias dos repositórios.
    *   Para operações no banco, os serviços usam `get_db_session()` para obter uma `Session`.
    *   A `Session` é passada para os métodos do repositório.
    *   Os repositórios usam a `Session` e a API ORM para interagir com o banco.
    *   O contexto `get_db_session()` gerencia commit/rollback/close.
4.  **Desligamento:** Na finalização da aplicação, `dispose_sqlalchemy_engine()` fecha o pool de conexões.

## Modelos de Dados

Os repositórios trabalham com os modelos ORM definidos em `src/domain` (ex: `User`, `Observation`), que herdam de `src/database/base.py::Base`. O Alembic usa esses mesmos modelos (`Base.metadata`) como a "verdade" sobre como o schema do banco de dados deve ser.
</file>

<file path="src/database/schema_manager.py">
# src/database/schema_manager.py
# Gerencia a criação inicial das tabelas do banco de dados e dados essenciais.

import bcrypt
import os
from datetime import datetime, timezone
from sqlalchemy.engine import Engine, Connection
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from sqlalchemy import text

from .base import Base
from src.utils.logger import logger
from src.api.errors import DatabaseError, ConfigurationError

DEFAULT_ADMIN_PASSWORD = 'admin'
try:
    from src.config import config
    DEFAULT_ADMIN_PASSWORD = os.environ.get('DEFAULT_ADMIN_PASSWORD', config.SECRET_KEY[:8] if config.SECRET_KEY else 'admin')
    if len(DEFAULT_ADMIN_PASSWORD) < 6:
        logger.warning("Senha padrão do admin é muito curta, usando 'admin123' como alternativa.")
        DEFAULT_ADMIN_PASSWORD = 'admin123'
except (ImportError, ConfigurationError) as e:
    print(f"Aviso: Não foi possível carregar a configuração para senha do admin, usando '{DEFAULT_ADMIN_PASSWORD}'. Erro: {e}")

class SchemaManager:
    def __init__(self, engine: Engine):
        self.engine = engine
        logger.debug("SchemaManager inicializado com o engine do SQLAlchemy.")

    def initialize_schema(self):
        try:
            logger.info("Iniciando a criação do esquema do banco de dados...")
            Base.metadata.create_all(bind=self.engine)
            logger.info("Tabelas criadas/verificadas com sucesso.")

            with self.engine.connect() as connection:
                with connection.begin():
                    logger.debug("Verificando existência do usuário admin...")
                    self._ensure_admin_user_exists(connection)
                    logger.debug("Verificação do usuário admin concluída.")

            logger.info("Esquema do banco de dados inicializado com sucesso.")

        except SQLAlchemyError as e:
            logger.critical(f"Falha na inicialização do esquema do banco de dados: {e}", exc_info=True)
            raise DatabaseError(f"Falha na inicialização do esquema: {e}") from e
        except Exception as e:
            logger.critical(f"Erro inesperado na inicialização do esquema: {e}", exc_info=True)
            raise DatabaseError(f"Falha na inicialização do esquema: {e}") from e

    def _ensure_admin_user_exists(self, connection: Connection):
        logger.debug("Verificando existência do usuário admin...")
        try:
            check_query = text("SELECT id FROM users WHERE LOWER(username) = LOWER(:username)")
            result = connection.execute(check_query, {'username': 'admin'})
            admin_user_row = result.fetchone()

            if not admin_user_row:
                logger.info("Usuário admin não encontrado. Criando...")
                password = DEFAULT_ADMIN_PASSWORD
                hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
                now_utc = datetime.now(timezone.utc)

                user_insert_query = text("""
                    INSERT INTO users (username, password_hash, name, email, created_at, is_active)
                    VALUES (:username, :password_hash, :name, :email, :created_at, :is_active)
                    RETURNING id
                """)
                user_result = connection.execute(user_insert_query, {
                    'username': 'admin', 'password_hash': hashed_password, 'name': 'Administrator',
                    'email': 'admin@example.com', 'created_at': now_utc, 'is_active': True
                })
                admin_id = user_result.scalar_one()
                logger.debug(f"Usuário admin criado com ID: {admin_id}")

                perm_insert_query = text("""
                    INSERT INTO user_permissions
                    (user_id, is_admin, can_access_products, can_access_fabrics, can_access_customer_panel, can_access_fiscal, can_access_accounts_receivable)
                    VALUES (:user_id, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)
                """)
                connection.execute(perm_insert_query, {'user_id': admin_id})
                logger.info("Usuário admin criado com permissões totais.")
            else:
                admin_id = admin_user_row[0]
                logger.debug(f"Usuário admin já existe (ID: {admin_id}). Verificando permissões...")
                perm_upsert_query = text("""
                    INSERT INTO user_permissions (user_id, is_admin, can_access_products, can_access_fabrics, can_access_customer_panel, can_access_fiscal, can_access_accounts_receivable)
                    VALUES (:user_id, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)
                    ON CONFLICT (user_id) DO UPDATE SET
                        is_admin = EXCLUDED.is_admin,
                        can_access_products = EXCLUDED.can_access_products,
                        can_access_fabrics = EXCLUDED.can_access_fabrics,
                        can_access_customer_panel = EXCLUDED.can_access_customer_panel,
                        can_access_fiscal = EXCLUDED.can_access_fiscal,
                        can_access_accounts_receivable = EXCLUDED.can_access_accounts_receivable;
                """)
                connection.execute(perm_upsert_query, {'user_id': admin_id})
                logger.debug(f"Permissões garantidas para o usuário admin (ID: {admin_id}).")

        except IntegrityError as e:
            logger.warning(f"Falha ao criar/atualizar usuário admin devido a restrição de integridade: {e}")
        except SQLAlchemyError as e:
            logger.error(f"Erro SQLAlchemy ao garantir usuário admin: {e}", exc_info=True)
            raise
        except Exception as e:
            logger.error(f"Erro inesperado ao garantir usuário admin: {e}", exc_info=True)
            raise
</file>

<file path="src/database/user_repository.py">
# src/database/user_repository.py
# Gerencia operações de banco de dados relacionadas a Usuários e Permissões usando SQLAlchemy ORM.

from datetime import datetime, timezone
from typing import List, Optional, Dict, Any
from sqlalchemy import select, func, delete, update
from sqlalchemy.orm import Session, joinedload, selectinload
from sqlalchemy.exc import IntegrityError, SQLAlchemyError

from .base_repository import BaseRepository
from src.domain.user import User, UserPermissions
from src.utils.logger import logger
from src.api.errors import DatabaseError, NotFoundError, ValidationError

class UserRepository(BaseRepository):
    """
    Repositório para gerenciar dados de Usuário e Permissões usando Sessões SQLAlchemy ORM.
    Os métodos agora esperam que um objeto Session seja passado.
    """

    def find_by_username(self, db: Session, username: str) -> Optional[User]:
        """
        Busca um usuário ativo pelo nome de usuário (case-insensitive) usando Sessão ORM.
        """
        logger.debug(f"ORM: Buscando usuário ativo pelo username '{username}'")
        try:
            stmt = (
                select(User)
                .options(joinedload(User.permissions))
                .where(func.lower(User.username) == func.lower(username))
                .where(User.is_active == True)
            )
            user = db.scalars(stmt).first()

            if user:
                logger.debug(f"ORM: Usuário encontrado pelo username '{username}': ID {user.id}")
            else:
                logger.debug(f"ORM: Usuário ativo não encontrado pelo username '{username}'.")
            return user
        except SQLAlchemyError as e:
            logger.error(f"ORM: Erro de banco de dados ao buscar usuário pelo username '{username}': {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados ao buscar usuário pelo username: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Erro inesperado ao buscar usuário pelo username '{username}': {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado ao buscar usuário pelo username: {e}") from e

    def find_by_id(self, db: Session, user_id: int) -> Optional[User]:
        """Busca um usuário pelo ID usando Sessão ORM (independente do status ativo)."""
        logger.debug(f"ORM: Buscando usuário pelo ID {user_id}")
        try:
            user = db.get(User, user_id, options=[joinedload(User.permissions)])
            if user:
                 logger.debug(f"ORM: Usuário encontrado pelo ID {user_id}.")
                 if user.permissions is None:
                      logger.warning(f"ORM: Usuário ID {user_id} encontrado, mas relacionamento permissions é None. Inconsistência de dados?")
            else:
                 logger.debug(f"ORM: Usuário não encontrado pelo ID {user_id}.")
            return user
        except SQLAlchemyError as e:
            logger.error(f"ORM: Erro de banco de dados ao buscar usuário pelo ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Erro de banco de dados ao buscar usuário pelo ID: {e}") from e
        except Exception as e:
            logger.error(f"ORM: Erro inesperado ao buscar usuário pelo ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Erro inesperado ao buscar usuário pelo ID: {e}") from e

    def get_all(self, db: Session) -> List[User]:
        """Recupera todos os usuários do banco de dados usando Sessão ORM."""
        logger.debug("ORM: Recuperando todos os usuários")
        try:
            stmt = select(User).options(joinedload(User.permissions)).order_by(User.username)
            users = db.scalars(stmt).all()
            logger.debug(f"ORM: Recuperados {len(users)} usuários do banco de dados.")
            return list(users)
        except SQLAlchemyError as e:
             logger.error(f"ORM: Erro de banco de dados ao recuperar todos os usuários: {e}", exc_info=True)
             raise DatabaseError(f"Erro de banco de dados ao recuperar todos os usuários: {e}") from e
        except Exception as e:
             logger.error(f"ORM: Erro inesperado ao recuperar todos os usuários: {e}", exc_info=True)
             raise DatabaseError(f"Erro inesperado ao recuperar todos os usuários: {e}") from e

    def add(self, db: Session, user: User) -> User:
        """Adiciona um novo usuário e suas permissões usando Sessão ORM."""
        if not user.username or not user.password_hash or not user.name:
             raise ValueError("Campos obrigatórios faltando (username, password_hash, name) para Usuário.")
        if user.permissions is None:
             logger.warning(f"Objeto User para '{user.username}' está sem objeto UserPermissions associado. Criando padrão.")
             user.permissions = UserPermissions()

        logger.debug(f"ORM: Adicionando usuário '{user.username}' à sessão")
        try:
            if user.created_at is None:
                user.created_at = datetime.now(timezone.utc)

            db.add(user)
            db.flush()
            logger.info(f"ORM: Usuário '{user.username}' adicionado à sessão (ID: {user.id}, Perm ID: {getattr(user.permissions, 'id', None)}). Commit pendente.")
            return user
        except IntegrityError as e:
            db.rollback()
            logger.warning(f"ORM: Erro de integridade do banco de dados ao adicionar usuário '{user.username}': {e}")
            error_info = str(e.orig).lower() if e.orig else str(e).lower()
            if "users_username_key" in error_info or "unique constraint" in error_info and "username" in error_info:
                 raise ValueError(f"Username '{user.username}' já existe.")
            if "users_email_key" in error_info or "unique constraint" in error_info and "email" in error_info and user.email:
                 raise ValueError(f"Email '{user.email}' já existe.")
            raise DatabaseError(f"Falha ao adicionar usuário devido a restrição de integridade: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao adicionar usuário '{user.username}': {e}", exc_info=True)
            raise DatabaseError(f"Falha ao adicionar usuário: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao adicionar usuário '{user.username}': {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao adicionar usuário: {e}") from e


    def update(self, db: Session, user_to_update: User) -> User:
        """Atualiza um usuário existente e suas permissões usando Sessão ORM."""
        if user_to_update.id is None:
            raise ValueError("Não é possível atualizar usuário sem um ID.")
        if not user_to_update.password_hash:
             raise ValueError("Hash de senha não pode estar vazio para atualização.")

        logger.debug(f"ORM: Atualizando usuário ID {user_to_update.id} na sessão")
        try:
            db.flush()
            logger.info(f"ORM: Usuário ID {user_to_update.id} marcado para atualização na sessão. Commit pendente.")
            return user_to_update
        except IntegrityError as e:
            db.rollback()
            logger.warning(f"ORM: Erro de integridade do banco de dados ao atualizar usuário ID {user_to_update.id}: {e}")
            error_info = str(e.orig).lower() if e.orig else str(e).lower()
            if "users_email_key" in error_info or "unique constraint" in error_info and "email" in error_info:
                 raise ValueError(f"Email '{user_to_update.email}' já está em uso por outro usuário.")
            raise DatabaseError(f"Falha ao atualizar usuário devido a restrição de integridade: {e}") from e
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao atualizar usuário ID {user_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Falha ao atualizar usuário: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao atualizar usuário ID {user_to_update.id}: {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao atualizar usuário: {e}") from e

    def delete(self, db: Session, user_id: int) -> bool:
        """Exclui um usuário pelo ID usando Sessão ORM."""
        logger.debug(f"ORM: Excluindo usuário ID {user_id}")
        try:
            user = db.get(User, user_id)
            if user:
                db.delete(user)
                db.flush()
                logger.info(f"ORM: Usuário ID {user_id} marcado para exclusão na sessão. Commit pendente.")
                return True
            else:
                logger.warning(f"ORM: Tentativa de excluir usuário ID {user_id}, mas usuário não foi encontrado.")
                return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Erro de banco de dados ao excluir usuário ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Falha ao excluir usuário: {e}") from e
        except Exception as e:
            db.rollback()
            logger.error(f"ORM: Erro inesperado ao excluir usuário ID {user_id}: {e}", exc_info=True)
            raise DatabaseError(f"Ocorreu um erro inesperado ao excluir usuário: {e}") from e

    def update_last_login(self, db: Session, user_id: int) -> bool:
        """Atualiza o timestamp de último login para um usuário usando Sessão ORM."""
        logger.debug(f"ORM: Atualizando último login para usuário ID {user_id}")
        try:
            user = db.get(User, user_id)
            if user:
                user.last_login = datetime.now(timezone.utc)
                db.flush()
                logger.debug(f"ORM: Último login do Usuário ID {user_id} marcado para atualização. Commit pendente.")
                return True
            else:
                 logger.warning(f"ORM: Falha ao atualizar último login para usuário ID {user_id} (usuário não encontrado).")
                 return False
        except SQLAlchemyError as e:
            db.rollback()
            logger.error(f"ORM: Falha ao atualizar último login para usuário ID {user_id}: {e}", exc_info=True)
            return False
        except Exception as e:
             db.rollback()
             logger.error(f"ORM: Erro inesperado ao atualizar último login para usuário ID {user_id}: {e}", exc_info=True)
             return False
</file>

<file path="src/domain/__init__.py">
# src/domain/__init__.py
# Makes 'domain' a package. Exports domain models.

# ORM Models (já convertidos ou serão nos próximos passos)
from .user import User, UserPermissions
from .observation import Observation

# Dataclasses (ainda não convertidos para ORM, se aplicável)
# Se converter todos para ORM, remova os imports específicos de dataclasses
# que foram substituídos.
from .balance import Balance, ProductItem, ProductResponse
from .cost import Cost, ProductCost, CostResponse
from .fabric_details import FabricDetailsItem, FabricDetailValue
from .person import Address, Phone, Email, IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from .fiscal import FormattedInvoiceListItem, InvoiceXmlOutDto, DanfeRequestModel, DanfeResponseModel
from .accounts_receivable import (
    DocumentChangeModel, DocumentFilterModel, DocumentRequestModel, DocumentModel,
    DocumentResponseModel, BankSlipRequestModel, AccountsReceivableTomasResponseModel,
    FormattedReceivableListItem, CalculatedValuesModel, InvoiceDataModel
)


# Mantemos todos os exports por enquanto. Se um modelo for *completamente*
# substituído e não for mais usado como Dataclass em nenhum lugar,
# pode ser removido daqui. No entanto, é seguro manter todos.
__all__ = [
    # ORM Models
    "User", "UserPermissions",
    "Observation",

    # Dataclasses (Potencialmente a serem convertidos ou usados como DTOs)
    "Balance", "ProductItem", "ProductResponse",
    "Cost", "ProductCost", "CostResponse",
    "FabricDetailsItem", "FabricDetailValue",
    "Address", "Phone", "Email", "IndividualDataModel", "LegalEntityDataModel", "PersonStatisticsResponseModel",
    "FormattedInvoiceListItem", "InvoiceXmlOutDto", "DanfeRequestModel", "DanfeResponseModel",
    "DocumentChangeModel", "DocumentFilterModel", "DocumentRequestModel", "DocumentModel",
    "DocumentResponseModel", "BankSlipRequestModel", "AccountsReceivableTomasResponseModel",
    "FormattedReceivableListItem", "CalculatedValuesModel", "InvoiceDataModel"
]
</file>

<file path="src/domain/accounts_receivable.py">
# src/domain/accounts_receivable.py
# Defines data models related to Accounts Receivable operations based on ERP API.

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from src.utils.logger import logger

# --- Models based on AccountsReceivable.json components/schemas ---

@dataclass(frozen=True)
class DocumentChangeModel:
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    in_check: Optional[bool] = None # API says boolean, not nullable? Check usage. Defaulting to None safety.

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentChangeModel']:
        if not data: return None
        return cls(
            start_date=data.get('startDate'),
            end_date=data.get('endDate'),
            in_check=data.get('inCheck')
        )

    def to_dict(self) -> Dict[str, Any]:
        d = {}
        if self.start_date is not None: d['startDate'] = self.start_date
        if self.end_date is not None: d['endDate'] = self.end_date
        if self.in_check is not None: d['inCheck'] = self.in_check
        return d

@dataclass(frozen=True)
class DocumentFilterModel:
    change: Optional[DocumentChangeModel] = None
    branch_code_list: Optional[List[int]] = field(default_factory=list)
    customer_code_list: Optional[List[int]] = field(default_factory=list)
    customer_cpf_cnpj_list: Optional[List[str]] = field(default_factory=list)
    start_expired_date: Optional[str] = None
    end_expired_date: Optional[str] = None
    start_payment_date: Optional[str] = None
    end_payment_date: Optional[str] = None
    start_issue_date: Optional[str] = None
    end_issue_date: Optional[str] = None
    start_credit_date: Optional[str] = None
    end_credit_date: Optional[str] = None
    status_list: Optional[List[int]] = field(default_factory=list)
    document_type_list: Optional[List[int]] = field(default_factory=list)
    billing_type_list: Optional[List[int]] = field(default_factory=list)
    discharge_type_list: Optional[List[int]] = field(default_factory=list)
    charge_type_list: Optional[List[int]] = field(default_factory=list)
    has_open_invoices: Optional[bool] = None
    receivable_code_list: Optional[List[float]] = field(default_factory=list) # API uses number/double
    our_number_list: Optional[List[float]] = field(default_factory=list) # API uses number/double
    commissioned_code: Optional[int] = None
    commissioned_cpf_cnpj: Optional[str] = None
    closing_code_commission: Optional[int] = None
    closing_company_commission: Optional[int] = None
    closing_date_commission: Optional[str] = None
    closing_commissioned_code: Optional[int] = None
    closing_commissioned_cpf_cnpj: Optional[str] = None

    # No from_dict needed, service layer builds this for the request
    def to_dict(self) -> Dict[str, Any]:
        d = {}
        if self.change: d['change'] = self.change.to_dict()
        if self.branch_code_list: d['branchCodeList'] = self.branch_code_list
        if self.customer_code_list: d['customerCodeList'] = self.customer_code_list
        if self.customer_cpf_cnpj_list: d['customerCpfCnpjList'] = self.customer_cpf_cnpj_list
        if self.start_expired_date: d['startExpiredDate'] = self.start_expired_date
        if self.end_expired_date: d['endExpiredDate'] = self.end_expired_date
        if self.start_payment_date: d['startPaymentDate'] = self.start_payment_date
        if self.end_payment_date: d['endPaymentDate'] = self.end_payment_date
        if self.start_issue_date: d['startIssueDate'] = self.start_issue_date
        if self.end_issue_date: d['endIssueDate'] = self.end_issue_date
        if self.start_credit_date: d['startCreditDate'] = self.start_credit_date
        if self.end_credit_date: d['endCreditDate'] = self.end_credit_date
        if self.status_list: d['statusList'] = self.status_list
        if self.document_type_list: d['documentTypeList'] = self.document_type_list
        if self.billing_type_list: d['billingTypeList'] = self.billing_type_list
        if self.discharge_type_list: d['dischargeTypeList'] = self.discharge_type_list
        if self.charge_type_list: d['chargeTypeList'] = self.charge_type_list
        if self.has_open_invoices is not None: d['hasOpenInvoices'] = self.has_open_invoices
        if self.receivable_code_list: d['receivableCodeList'] = self.receivable_code_list
        if self.our_number_list: d['ourNumberList'] = self.our_number_list
        if self.commissioned_code: d['commissionedCode'] = self.commissioned_code
        if self.commissioned_cpf_cnpj: d['commissionedCpfCnpj'] = self.commissioned_cpf_cnpj
        if self.closing_code_commission: d['closingCodeCommission'] = self.closing_code_commission
        if self.closing_company_commission: d['closingCompanyCommission'] = self.closing_company_commission
        if self.closing_date_commission: d['closingDateCommission'] = self.closing_date_commission
        if self.closing_commissioned_code: d['closingCommissionedCode'] = self.closing_commissioned_code
        if self.closing_commissioned_cpf_cnpj: d['closingCommissionedCpfCnpj'] = self.closing_commissioned_cpf_cnpj
        return d


@dataclass(frozen=True)
class DocumentRequestModel:
    filter: Optional[DocumentFilterModel] = None
    expand: Optional[str] = None
    order: Optional[str] = None
    page: int = 1
    page_size: int = 100

    # No from_dict needed, service layer builds this
    def to_dict(self) -> Dict[str, Any]:
        d = {
            "page": self.page,
            "pageSize": self.page_size,
        }
        if self.filter: d['filter'] = self.filter.to_dict()
        if self.expand: d['expand'] = self.expand
        if self.order: d['order'] = self.order
        return d

@dataclass(frozen=True)
class CalculatedValuesModel:
    days_late: Optional[int] = None
    increase_value: Optional[float] = None
    interest_value: Optional[float] = None
    fine_value: Optional[float] = None
    discount_value: Optional[float] = None
    corrected_value: Optional[float] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['CalculatedValuesModel']:
        if not data: return None
        return cls(
            days_late=data.get('daysLate'),
            increase_value=data.get('increaseValue'),
            interest_value=data.get('interestValue'),
            fine_value=data.get('fineValue'),
            discount_value=data.get('discountValue'),
            corrected_value=data.get('correctedValue')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__ # Simple mapping

# Define CheckInstallmentModel, InvoiceDataModel, CommissionDataModel similarly if needed
# For brevity, we'll focus on the main DocumentModel and the formatted output
@dataclass(frozen=True)
class InvoiceDataModel: # Placeholder - add fields as needed
    invoice_code: Optional[int] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['InvoiceDataModel']:
        if not data: return None
        return cls(invoice_code=data.get('invoiceCode'))

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__

@dataclass(frozen=True)
class DocumentModel:
    # Core Fields
    branch_code: Optional[int] = None
    customer_code: Optional[int] = None
    customer_cpf_cnpj: Optional[str] = None
    receivable_code: Optional[int] = None # API uses int64
    installment_code: Optional[int] = None
    max_change_filter_date: Optional[str] = None
    expired_date: Optional[str] = None
    payment_date: Optional[str] = None
    issue_date: Optional[str] = None
    settlement_branch_code: Optional[int] = None
    settlement_date: Optional[str] = None
    settlement_sequence: Optional[int] = None
    status: Optional[int] = None
    document_type: Optional[int] = None
    billing_type: Optional[int] = None
    discharge_type: Optional[int] = None
    charge_type: Optional[int] = None
    origin_installment: Optional[int] = None
    bearer_code: Optional[int] = None
    bearer_name: Optional[str] = None
    installment_value: Optional[float] = None
    paid_value: Optional[float] = None
    net_value: Optional[float] = None
    discount_value: Optional[float] = None
    rebate_value: Optional[float] = None
    interest_value: Optional[float] = None # Distinct from calculated_values.interest_value
    assessment_value: Optional[float] = None # Distinct from calculated_values.fine_value
    bar_code: Optional[str] = None
    digitable_line: Optional[str] = None
    our_number: Optional[int] = None # API uses int64
    dac_our_number: Optional[str] = None
    qr_code_pix: Optional[str] = None
    discharge_user: Optional[int] = None
    registration_user: Optional[int] = None
    # Expanded Fields (optional based on 'expand' parameter)
    calculated_values: Optional[CalculatedValuesModel] = None
    check: Optional[Dict[str, Any]] = None # Simplified for now
    invoice: Optional[List[InvoiceDataModel]] = field(default_factory=list)
    commissions: Optional[List[Dict[str, Any]]] = field(default_factory=list) # Simplified

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentModel']:
        if not data: return None

        calculated_values = CalculatedValuesModel.from_dict(data.get('calculatedValues'))
        invoices_raw = data.get('invoice', [])
        invoices = [InvoiceDataModel.from_dict(inv) for inv in invoices_raw if inv] if isinstance(invoices_raw, list) else []
        invoices = [inv for inv in invoices if inv is not None] # Filter out Nones


        return cls(
            branch_code=data.get('branchCode'),
            customer_code=data.get('customerCode'),
            customer_cpf_cnpj=data.get('customerCpfCnpj'),
            receivable_code=data.get('receivableCode'),
            installment_code=data.get('installmentCode'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            expired_date=data.get('expiredDate'),
            payment_date=data.get('paymentDate'),
            issue_date=data.get('issueDate'),
            settlement_branch_code=data.get('settlementBranchCode'),
            settlement_date=data.get('settlementDate'),
            settlement_sequence=data.get('settlementSequence'),
            status=data.get('status'),
            document_type=data.get('documentType'),
            billing_type=data.get('billingType'),
            discharge_type=data.get('dischargeType'),
            charge_type=data.get('chargeType'),
            origin_installment=data.get('originInstallment'),
            bearer_code=data.get('bearerCode'),
            bearer_name=data.get('bearerName'),
            installment_value=data.get('installmentValue'),
            paid_value=data.get('paidValue'),
            net_value=data.get('netValue'),
            discount_value=data.get('discountValue'),
            rebate_value=data.get('rebateValue'),
            interest_value=data.get('interestValue'),
            assessment_value=data.get('assessmentValue'),
            bar_code=data.get('barCode'),
            digitable_line=data.get('digitableLine'),
            our_number=data.get('ourNumber'),
            dac_our_number=data.get('dacOurNumber'),
            qr_code_pix=data.get('qrCodePix'),
            discharge_user=data.get('dischargeUser'),
            registration_user=data.get('registrationUser'),
            calculated_values=calculated_values,
            check=data.get('check'), # Keep as dict for now
            invoice=invoices,
            commissions=data.get('commissions') # Keep as list of dicts
        )

    def to_dict(self) -> Dict[str, Any]:
        d = self.__dict__.copy()
        if self.calculated_values: d['calculated_values'] = self.calculated_values.to_dict()
        if self.invoice: d['invoice'] = [inv.to_dict() for inv in self.invoice]
        # check and commissions kept as dicts/list of dicts
        return d


@dataclass(frozen=True)
class DocumentResponseModel:
    count: int = 0
    total_pages: int = 0
    has_next: bool = False
    total_items: int = 0
    items: List[DocumentModel] = field(default_factory=list)

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['DocumentResponseModel']:
        if not data: return None
        items_raw = data.get('items', [])
        items = [DocumentModel.from_dict(item) for item in items_raw if item] if isinstance(items_raw, list) else []
        items = [item for item in items if item is not None]

        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "count": self.count,
            "totalPages": self.total_pages,
            "hasNext": self.has_next,
            "totalItems": self.total_items,
            "items": [item.to_dict() for item in self.items]
        }

@dataclass(frozen=True)
class BankSlipRequestModel:
    branch_code: int
    customer_code: int
    receivable_code: int # API int64
    installment_number: int
    customer_cpf_cnpj: Optional[str] = None # Keep this field in the model

    def to_dict(self) -> Dict[str, Any]:
        d = {
            "branchCode": self.branch_code,
            "customerCode": self.customer_code, # Always include customerCode
            "receivableCode": self.receivable_code,
            "installmentNumber": self.installment_number,
        }
        # Only add customerCpfCnpj if customerCode is somehow missing (shouldn't happen with current validation)
        # OR if the API strictly requires *only one*, then we never add CpfCnpj here.
        # Let's enforce sending only customerCode as requested.
        # if not self.customer_code and self.customer_cpf_cnpj:
        #     d['customerCpfCnpj'] = self.customer_cpf_cnpj
        # Since customerCode is required, we simply don't add customerCpfCnpj to the dict being sent to ERP.
        return d

@dataclass(frozen=True)
class AccountsReceivableTomasResponseModel:
    content: Optional[str] = None
    uniface_response_status: Optional[str] = None
    uniface_message: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Optional[Dict[str, Any]]) -> Optional['AccountsReceivableTomasResponseModel']:
        if not data: return None
        return cls(
            content=data.get('content'),
            uniface_response_status=data.get('unifaceResponseStatus'),
            uniface_message=data.get('unifaceMessage')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__


# --- Formatted output model for the /search endpoint ---
@dataclass(frozen=True)
class FormattedReceivableListItem:
    customer_code: Optional[int] = None
    customer_cpf_cnpj: Optional[str] = None
    customer_name: Optional[str] = None # Enriched field
    invoice_number: Optional[int] = None # From nested invoice -> invoiceCode
    document_number: Optional[int] = None # receivableCode
    installment_number: Optional[int] = None # installmentCode
    bearer_name: Optional[str] = None
    issue_date: Optional[str] = None
    expired_date: Optional[str] = None
    days_late: Optional[int] = None # From calculated_values
    payment_date: Optional[str] = None
    value_original: Optional[float] = None # installmentValue
    value_increase: Optional[float] = None # Combined calculated values
    value_rebate: Optional[float] = None # Combined rebate/discount values
    value_paid: Optional[float] = None # paidValue
    value_corrected: Optional[float] = None # From calculated_values
    status: Optional[int] = None
    document_type: Optional[int] = None
    billing_type: Optional[int] = None
    discharge_type: Optional[int] = None
    charge_type: Optional[int] = None

    # No from_dict needed, built in service layer
    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__
</file>

<file path="src/domain/balance.py">
# src/domain/balance.py
# Defines data models related to product balances from the ERP.

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from src.utils.logger import logger # Use the application's configured logger

@dataclass(frozen=True)
class Balance:
    """
    Represents a single balance entry for a product variant. Immutable.

    Corresponds to an item within the 'balances' list in the ERP API response.
    """
    branch_code: int
    stock_code: int
    stock_description: str
    stock: int = 0
    sales_order: int = 0
    input_transaction: int = 0
    output_transaction: int = 0
    production_order_progress: int = 0
    production_order_wait_lib: int = 0
    stock_temp: Optional[int] = None
    production_planning: Optional[int] = None
    purchase_order: Optional[int] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Balance object to a dictionary."""
        return self.__dict__ # Dataclasses provide __dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Balance':
        """Creates a Balance object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for Balance.from_dict: {type(data)}")
            raise ValueError("Invalid data format for Balance")
        return cls(
            branch_code=data.get('branchCode', 0),
            stock_code=data.get('stockCode', 0),
            stock_description=data.get('stockDescription', ''),
            stock=data.get('stock', 0),
            sales_order=data.get('salesOrder', 0),
            input_transaction=data.get('inputTransaction', 0),
            output_transaction=data.get('outputTransaction', 0),
            production_order_progress=data.get('productionOrderProgress', 0),
            production_order_wait_lib=data.get('productionOrderWaitLib', 0),
            stock_temp=data.get('stockTemp'),
            production_planning=data.get('productionPlanning'),
            purchase_order=data.get('purchaseOrder')
        )

@dataclass(frozen=True)
class ProductItem:
    """
    Represents a product variant (SKU) with its details and balances. Immutable.

    Corresponds to an item within the 'items' list in the ERP API balance response.
    """
    product_code: int
    product_name: str
    product_sku: str
    reference_code: str
    color_code: str
    color_name: str
    size_name: str
    balances: List[Balance] = field(default_factory=list)
    locations: Optional[List[Any]] = None # Type hint could be more specific if structure is known
    max_change_filter_date: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductItem object to a dictionary."""
        return {
            **self.__dict__, # Get base attributes
            'balances': [b.to_dict() for b in self.balances] # Convert nested balances
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductItem':
        """Creates a ProductItem object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductItem.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductItem")

        balances_data = data.get('balances', [])
        if not isinstance(balances_data, list):
             logger.warning(f"Invalid 'balances' format in ProductItem data for product {data.get('productCode')}. Expected list, got {type(balances_data)}.")
             balances = []
        else:
             balances = [Balance.from_dict(b_data) for b_data in balances_data if isinstance(b_data, dict)]

        return cls(
            product_code=data.get('productCode', 0),
            product_name=data.get('productName', ''),
            product_sku=data.get('productSku', ''),
            reference_code=data.get('referenceCode', ''),
            color_code=data.get('colorCode', ''),
            color_name=data.get('colorName', ''),
            size_name=data.get('sizeName', ''),
            balances=balances,
            locations=data.get('locations'),
            max_change_filter_date=data.get('maxChangeFilterDate')
        )

    # --- Balance Calculation Methods ---
    # These methods assume the relevant balance data is in the *first* Balance object
    # in the balances list, which seems to be the pattern in the original code.
    # Consider adding checks or making this assumption explicit.

    def _get_primary_balance(self) -> Optional[Balance]:
        """Helper to get the primary balance object (first in the list)."""
        if self.balances:
            return self.balances[0]
        logger.warning(f"ProductItem {self.product_code} has no balance data.")
        return None

    def calculate_base_balance(self) -> int:
        """Calculates base balance: stock + input - output."""
        balance = self._get_primary_balance()
        if balance:
            return balance.stock + balance.input_transaction - balance.output_transaction
        return 0

    def calculate_sales_balance(self) -> int:
        """Calculates balance considering sales orders: base_balance - sales_order."""
        balance = self._get_primary_balance()
        if balance:
            return self.calculate_base_balance() - balance.sales_order
        return 0

    def calculate_production_balance(self) -> int:
        """Calculates balance considering sales and production: base_balance - sales + production."""
        balance = self._get_primary_balance()
        if balance:
            return (self.calculate_base_balance() - balance.sales_order +
                    balance.production_order_progress + balance.production_order_wait_lib)
        return 0

    def get_balance_for_mode(self, mode: str) -> int:
        """
        Returns the calculated balance based on the specified mode.

        Args:
            mode: Calculation mode ('base', 'sales', 'production').

        Returns:
            The calculated balance value.

        Raises:
            ValueError: If the mode is unrecognized.
        """
        if mode == 'base':
            return self.calculate_base_balance()
        elif mode == 'sales':
            return self.calculate_sales_balance()
        elif mode == 'production':
            return self.calculate_production_balance()
        else:
            logger.error(f"Unrecognized balance calculation mode: {mode}")
            raise ValueError(f"Unrecognized balance calculation mode: {mode}")


@dataclass(frozen=True)
class ProductResponse:
    """
    Represents the overall structure of the balance API response. Immutable.
    """
    count: int
    total_pages: int
    has_next: bool
    total_items: int
    items: List[ProductItem] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductResponse object to a dictionary."""
        return {
             **self.__dict__,
            'items': [item.to_dict() for item in self.items]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductResponse':
        """
        Creates a ProductResponse object from the raw API response dictionary.

        Args:
            data: The dictionary parsed from the API JSON response.

        Returns:
            A ProductResponse object.

        Raises:
            ValueError: If the input data is not a dictionary or has invalid format.
        """
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductResponse.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductResponse")

        items_data = data.get('items', [])
        if not isinstance(items_data, list):
            logger.warning(f"Invalid 'items' format in ProductResponse data. Expected list, got {type(items_data)}.")
            items = []
        else:
            items = []
            for item_data in items_data:
                 if isinstance(item_data, dict):
                     try:
                         items.append(ProductItem.from_dict(item_data))
                     except ValueError as e:
                          logger.error(f"Skipping invalid item in ProductResponse: {e} - Data: {item_data}")
                 else:
                     logger.warning(f"Skipping non-dict item in ProductResponse items list: {item_data}")


        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )
</file>

<file path="src/domain/cost.py">
# src/domain/cost.py
# Defines data models related to product costs from the ERP.

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from src.utils.logger import logger # Use the application's configured logger

@dataclass(frozen=True)
class Cost:
    """
    Represents a single cost entry for a product variant. Immutable.

    Corresponds to an item within the 'costs' list in the ERP API response.
    """
    branch_code: int
    cost_code: int
    cost_name: str
    cost: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Cost object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Cost':
        """Creates a Cost object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for Cost.from_dict: {type(data)}")
            raise ValueError("Invalid data format for Cost")
        return cls(
            branch_code=data.get('branchCode', 0),
            cost_code=data.get('costCode', 0),
            cost_name=data.get('costName', ''),
            cost=data.get('cost', 0.0) # Ensure float conversion if necessary
        )

@dataclass(frozen=True)
class ProductCost:
    """
    Represents a product variant (SKU) with its details and costs. Immutable.

    Corresponds to an item within the 'items' list in the ERP API cost response.
    """
    product_code: int
    product_name: str
    product_sku: str
    reference_code: str
    color_code: str
    color_name: str
    size_name: str
    costs: List[Cost] = field(default_factory=list)
    max_change_filter_date: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the ProductCost object to a dictionary."""
        return {
            **self.__dict__,
            'costs': [c.to_dict() for c in self.costs]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProductCost':
        """Creates a ProductCost object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for ProductCost.from_dict: {type(data)}")
            raise ValueError("Invalid data format for ProductCost")

        costs_data = data.get('costs', [])
        if not isinstance(costs_data, list):
            logger.warning(f"Invalid 'costs' format in ProductCost data for product {data.get('productCode')}. Expected list, got {type(costs_data)}.")
            costs = []
        else:
            costs = [Cost.from_dict(c_data) for c_data in costs_data if isinstance(c_data, dict)]

        return cls(
            product_code=data.get('productCode', 0),
            product_name=data.get('productName', ''),
            product_sku=data.get('productSku', ''),
            reference_code=data.get('referenceCode', ''),
            color_code=data.get('colorCode', ''),
            color_name=data.get('colorName', ''),
            size_name=data.get('sizeName', ''),
            costs=costs,
            max_change_filter_date=data.get('maxChangeFilterDate')
        )

    def get_primary_cost_value(self) -> float:
        """
        Returns the value of the primary cost (first in the list).

        Returns:
            Cost value (float) or 0.0 if no costs are available.
        """
        if self.costs:
            return self.costs[0].cost
        logger.warning(f"ProductCost {self.product_code} has no cost data.")
        return 0.0

@dataclass(frozen=True)
class CostResponse:
    """
    Represents the overall structure of the cost API response. Immutable.
    """
    count: int
    total_pages: int
    has_next: bool
    total_items: int
    items: List[ProductCost] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the CostResponse object to a dictionary."""
        return {
             **self.__dict__,
            'items': [item.to_dict() for item in self.items]
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CostResponse':
        """
        Creates a CostResponse object from the raw API response dictionary.

        Args:
            data: The dictionary parsed from the API JSON response.

        Returns:
            A CostResponse object.

        Raises:
            ValueError: If the input data is not a dictionary or has invalid format.
        """
        if not isinstance(data, dict):
            logger.error(f"Invalid data type for CostResponse.from_dict: {type(data)}")
            raise ValueError("Invalid data format for CostResponse")

        items_data = data.get('items', [])
        if not isinstance(items_data, list):
             logger.warning(f"Invalid 'items' format in CostResponse data. Expected list, got {type(items_data)}.")
             items = []
        else:
            items = []
            for item_data in items_data:
                 if isinstance(item_data, dict):
                      try:
                          items.append(ProductCost.from_dict(item_data))
                      except ValueError as e:
                           logger.error(f"Skipping invalid item in CostResponse: {e} - Data: {item_data}")
                 else:
                      logger.warning(f"Skipping non-dict item in CostResponse items list: {item_data}")

        return cls(
            count=data.get('count', 0),
            total_pages=data.get('totalPages', 0),
            has_next=data.get('hasNext', False),
            total_items=data.get('totalItems', 0),
            items=items
        )
</file>

<file path="src/domain/fabric_details.py">
# src/domain/fabric_details.py
# Defines data models related to fabric-specific details (width, grammage, etc.) from the ERP.
# Renamed from original product_model.py for clarity.

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from src.utils.logger import logger

@dataclass(frozen=True)
class FabricDetailValue:
    """
    Represents a single additional field value for a fabric. Immutable.

    Corresponds to an item in the 'additionalFields' list in the ERP Product API response.
    """
    code: int # Field code (e.g., 1=Width, 2=Grammage, 3=Shrinkage)
    name: str # Field name (provided by ERP)
    value: Any # Field value (can be string, number, etc.)

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FabricDetailValue object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['FabricDetailValue']:
        """Creates a FabricDetailValue from a dictionary, returns None if invalid."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for FabricDetailValue.from_dict: {type(data)}")
            return None
        try:
            # Basic validation
            code = int(data.get('code'))
            name = str(data.get('name', ''))
            value = data.get('value') # Keep original type for flexibility
            return cls(code=code, name=name, value=value)
        except (TypeError, ValueError, KeyError) as e:
            logger.error(f"Error creating FabricDetailValue from dict: {e}. Data: {data}")
            return None


@dataclass(frozen=True)
class FabricDetailsItem:
    """
    Represents a fabric product with its specific details (width, grammage, shrinkage). Immutable.

    Derived from the ERP Product API response, focusing on relevant additional fields.
    """
    product_code: int
    width: Optional[float] = None      # Largura (Code 1)
    grammage: Optional[float] = None   # Gramatura (Code 2)
    shrinkage: Optional[float] = None  # Encolhimento (Code 3)
    # Add other relevant fields if needed from the base product data
    # product_name: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FabricDetailsItem object to a dictionary."""
        return self.__dict__

    @classmethod
    def from_product_api_item(cls, item_data: Dict[str, Any]) -> Optional['FabricDetailsItem']:
        """
        Creates a FabricDetailsItem from a single item dictionary from the ERP Product API response.

        Args:
            item_data: Dictionary representing one product item from the ERP API.

        Returns:
            A FabricDetailsItem object or None if essential data is missing or invalid.
        """
        if not isinstance(item_data, dict):
            logger.warning(f"Invalid item_data type for FabricDetailsItem: {type(item_data)}")
            return None

        product_code = item_data.get('productCode')
        if not product_code:
            logger.warning("Skipping item in FabricDetailsItem creation: missing productCode.")
            return None

        additional_fields_data = item_data.get('additionalFields', [])
        if not isinstance(additional_fields_data, list):
            logger.warning(f"Invalid 'additionalFields' format for product {product_code}. Expected list.")
            additional_fields_data = []

        width = None
        grammage = None
        shrinkage = None

        for field_data in additional_fields_data:
            field_obj = FabricDetailValue.from_dict(field_data)
            if field_obj and field_obj.value is not None: # Check if value exists
                try:
                    if field_obj.code == 1:  # Largura
                        width = float(field_obj.value)
                    elif field_obj.code == 2:  # Gramatura
                        grammage = float(field_obj.value)
                    elif field_obj.code == 3:  # Encolhimento
                        shrinkage = float(field_obj.value)
                except (ValueError, TypeError) as e:
                    logger.warning(f"Could not convert fabric detail value for product {product_code}, field code {field_obj.code}. Value: '{field_obj.value}', Error: {e}")

        return cls(
            product_code=product_code,
            width=width,
            grammage=grammage,
            shrinkage=shrinkage
            # product_name=item_data.get('productName') # Optionally include name
        )

# Note: The overall Product Response structure for the /products/search endpoint
# is similar to Balance/Cost responses, but might have slightly different fields.
# If needed, a dedicated FabricDetailsResponse dataclass could be created,
# similar to ProductResponse or CostResponse. For now, the erp_product_service
# might just return a list of FabricDetailsItem.
</file>

<file path="src/domain/fiscal_orm.py">
# src/domain/fiscal_orm.py
# Define os modelos ORM para as tabelas Fiscais usando SQLAlchemy.

from datetime import datetime, date, time # Importar tipos necessários
from typing import Optional, List, Dict, Any # Importar tipos necessários
from sqlalchemy import (
    Integer, String, Text, Boolean, DateTime, Date, Time, Numeric, ForeignKey, func
)
from sqlalchemy.orm import relationship, Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP, VARCHAR, NUMERIC # Tipos específicos PG

# Importar Base
from src.database.base import Base
from src.utils.logger import logger

# --- Tabela Principal: Nota Fiscal ---
class NotaFiscalOrm(Base):
    __tablename__ = 'nota_fiscal'

    # Chave Primária Composta (ou usar um ID único se preferir?)
    # Usar sequence parece mais robusto como PK se branchCode puder repetir.
    # Vamos usar um ID autoincremento por simplicidade e indexar a chave natural.
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    branch_code: Mapped[int] = mapped_column(Integer, nullable=False, index=True) # FK para 'empresas' (futuro)
    invoice_sequence: Mapped[int] = mapped_column(Integer, nullable=False, index=True)

    # --- Chave Natural (para busca/unicidade) ---
    # unique constraint para (branch_code, invoice_sequence) pode ser adicionado via Alembic
    # __table_args__ = (UniqueConstraint('branch_code', 'invoice_sequence', name='uq_nota_fiscal_branch_sequence'),)

    # --- Dados da Empresa/Pessoa ---
    branch_cnpj: Mapped[Optional[str]] = mapped_column(VARCHAR(14))
    person_code: Mapped[Optional[int]] = mapped_column(Integer, index=True) # FK para 'pessoas' (futuro)
    person_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Identificação da Nota ---
    invoice_code: Mapped[Optional[int]] = mapped_column(Integer, index=True) # Número da NF-e
    serial_code: Mapped[Optional[str]] = mapped_column(VARCHAR(5)) # Série
    invoice_status: Mapped[Optional[str]] = mapped_column(VARCHAR(20)) # Issued, Canceled, etc.
    access_key: Mapped[Optional[str]] = mapped_column(VARCHAR(44), unique=True, index=True) # Chave de Acesso (pode ser PK?)
    electronic_invoice_status: Mapped[Optional[str]] = mapped_column(VARCHAR(30)) # Authorized, Canceled, Denied
    receipt: Mapped[Optional[str]] = mapped_column(Text) # Protocolo/Recibo (pode ser longo?)
    receivement_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True)) # Data autorização
    disable_protocol: Mapped[Optional[str]] = mapped_column(Text)
    disable_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))

    # --- Dados da Transação/Operação ---
    transaction_branch_code: Mapped[Optional[int]] = mapped_column(Integer)
    transaction_date: Mapped[Optional[date]] = mapped_column(Date)
    transaction_code: Mapped[Optional[int]] = mapped_column(Integer)
    inclusion_component_code: Mapped[Optional[str]] = mapped_column(VARCHAR(30))
    user_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'usuarios' (futuro)
    origin: Mapped[Optional[str]] = mapped_column(VARCHAR(20)) # Own, ThirdParty
    document_type: Mapped[Optional[int]] = mapped_column(Integer) # 55, 65
    operation_type: Mapped[Optional[str]] = mapped_column(VARCHAR(10)) # Input, Output
    operation_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'operacoes' (futuro)
    operation_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Datas e Horas ---
    invoice_date: Mapped[Optional[date]] = mapped_column(Date) # Data de movimento
    issue_date: Mapped[Optional[date]] = mapped_column(Date, index=True) # Data de emissão
    release_date: Mapped[Optional[date]] = mapped_column(Date) # Data de lançamento
    exit_time: Mapped[Optional[time]] = mapped_column(Time) # Hora de saída
    lastchange_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True), index=True) # Ultima alteração ERP

    # --- Valores Totais ---
    # Usar NUMERIC para valores monetários
    payment_condition_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'cond_pagamento' (futuro)
    payment_condition_name: Mapped[Optional[str]] = mapped_column(Text)
    discount_percentage: Mapped[Optional[float]] = mapped_column(NUMERIC(10, 4)) # Ajustar precisão/escala
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4)) # Ajustar precisão/escala
    product_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2)) # Ajustar precisão/escala
    additional_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    shipping_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    insurance_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    ipi_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    base_icms_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    icms_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    icms_subst_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    total_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))

    # --- Dados de Frete ---
    shipping_company_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'pessoas' (futuro)
    shipping_company_name: Mapped[Optional[str]] = mapped_column(Text)
    freight_type: Mapped[Optional[str]] = mapped_column(VARCHAR(50)) # CIF, FOB, etc.
    freight_type_redispatch: Mapped[Optional[str]] = mapped_column(VARCHAR(50))
    freight_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    package_number: Mapped[Optional[int]] = mapped_column(Integer)
    gross_weight: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 3)) # Ajustar precisão/escala
    net_weight: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 3))
    species: Mapped[Optional[str]] = mapped_column(VARCHAR(50))

    # --- Outros ---
    terminal_code: Mapped[Optional[int]] = mapped_column(Integer)
    observation_nfe: Mapped[Optional[str]] = mapped_column(Text) # Campo único de obs NFE

    # Timestamps locais
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=func.now(), nullable=False)
    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=func.now(), onupdate=func.now(), nullable=False)

    # --- Relacionamentos (um-para-muitos) ---
    items: Mapped[List["NotaFiscalItemOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    payments: Mapped[List["NotaFiscalPagamentoOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    sales_orders: Mapped[List["NotaFiscalPedidoVendaOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")
    observations: Mapped[List["NotaFiscalObservacaoOrm"]] = relationship(back_populates="nota_fiscal", cascade="all, delete-orphan", lazy="select")

    def __repr__(self):
        return f"<NotaFiscalOrm(id={self.id}, branch={self.branch_code}, seq={self.invoice_sequence}, num={self.invoice_code}, key=...{str(self.access_key)[-6:] if self.access_key else 'N/A'})>"


# --- Tabela de Itens da Nota Fiscal ---
class NotaFiscalItemOrm(Base):
    __tablename__ = 'nota_fiscal_item'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    sequence: Mapped[int] = mapped_column(Integer, nullable=False)
    code: Mapped[Optional[str]] = mapped_column(Text) # Código fiscal do produto
    name: Mapped[Optional[str]] = mapped_column(Text)
    ncm: Mapped[Optional[str]] = mapped_column(VARCHAR(12))
    cfop: Mapped[Optional[int]] = mapped_column(Integer)
    measure_unit: Mapped[Optional[str]] = mapped_column(VARCHAR(6))
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4))
    gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    unit_gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6)) # Mais casas decimais para unitário
    unit_discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    additional_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    freight_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    insurance_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    additional_item_information: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="items")

    # --- Relacionamento (um-para-muitos para produtos do item) ---
    item_products: Mapped[List["NotaFiscalItemProdutoOrm"]] = relationship(back_populates="item", cascade="all, delete-orphan", lazy="select")

    def __repr__(self):
        return f"<NotaFiscalItemOrm(id={self.id}, nf_id={self.nota_fiscal_id}, seq={self.sequence})>"


# --- Tabela de Produtos do Item da Nota Fiscal ---
class NotaFiscalItemProdutoOrm(Base):
    __tablename__ = 'nota_fiscal_item_produto'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    item_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal_item.id', ondelete='CASCADE'), index=True)

    product_code: Mapped[Optional[int]] = mapped_column(Integer) # FK para 'produtos' (futuro)
    product_name: Mapped[Optional[str]] = mapped_column(Text)
    dealer_code: Mapped[Optional[int]] = mapped_column(Integer)
    quantity: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 4))
    unit_gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    unit_net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 6))
    gross_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    discount_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    net_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))

    # --- Relacionamento (muitos-para-um) ---
    item: Mapped["NotaFiscalItemOrm"] = relationship(back_populates="item_products")

    def __repr__(self):
        return f"<NotaFiscalItemProdutoOrm(id={self.id}, item_id={self.item_id}, product_code={self.product_code})>"


# --- Tabela de Pagamentos da Nota Fiscal ---
class NotaFiscalPagamentoOrm(Base):
    __tablename__ = 'nota_fiscal_pagamento'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    document_number: Mapped[Optional[int]] = mapped_column(Integer)
    expiration_date: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))
    payment_value: Mapped[Optional[float]] = mapped_column(NUMERIC(15, 2))
    document_type_code: Mapped[Optional[int]] = mapped_column(Integer)
    document_type: Mapped[Optional[str]] = mapped_column(VARCHAR(50))
    installment: Mapped[Optional[int]] = mapped_column(Integer)
    bearer_code: Mapped[Optional[int]] = mapped_column(Integer)
    bearer_name: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="payments")

    def __repr__(self):
        return f"<NotaFiscalPagamentoOrm(id={self.id}, nf_id={self.nota_fiscal_id}, installment={self.installment})>"


# --- Tabela de Pedidos de Venda da Nota Fiscal ---
class NotaFiscalPedidoVendaOrm(Base):
    __tablename__ = 'nota_fiscal_pedido_venda'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    branch_code: Mapped[Optional[int]] = mapped_column(Integer)
    order_code: Mapped[Optional[int]] = mapped_column(Integer, index=True)
    customer_order_code: Mapped[Optional[str]] = mapped_column(Text)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="sales_orders")

    def __repr__(self):
        return f"<NotaFiscalPedidoVendaOrm(id={self.id}, nf_id={self.nota_fiscal_id}, order_code={self.order_code})>"


# --- Tabela de Observações da Nota Fiscal ---
class NotaFiscalObservacaoOrm(Base):
    __tablename__ = 'nota_fiscal_observacao'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nota_fiscal_id: Mapped[int] = mapped_column(ForeignKey('nota_fiscal.id', ondelete='CASCADE'), index=True)

    observation: Mapped[Optional[str]] = mapped_column(Text)
    sequence: Mapped[Optional[int]] = mapped_column(Integer)

    # --- Relacionamento (muitos-para-um) ---
    nota_fiscal: Mapped["NotaFiscalOrm"] = relationship(back_populates="observations")

    def __repr__(self):
        return f"<NotaFiscalObservacaoOrm(id={self.id}, nf_id={self.nota_fiscal_id}, seq={self.sequence})>"
</file>

<file path="src/domain/fiscal.py">
# src/domain/fiscal.py
# Defines data models related to Fiscal module operations (DANFE, XML, Invoice List).

from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
from src.utils.logger import logger

@dataclass(frozen=True)
class FormattedInvoiceListItem:
    """Represents essential data for an invoice in a list view, formatted for API response."""
    status: Optional[str] = None        # Mapped from electronicInvoiceStatus
    recipient_name: Optional[str] = None # Mapped from personName
    sales_order_code: Optional[int] = None     # Mapped from salesOrder -> orderCode
    invoice_number: Optional[int] = None   # Mapped from invoiceCode
    invoice_series: Optional[str] = None    # Mapped from serialCode
    issue_date: Optional[str] = None     # Mapped from eletronic -> receivementDate or issueDate
    total_value: Optional[float] = None  # Mapped from totalValue
    total_quantity: Optional[float] = None     # Mapped from quantity
    operation_name: Optional[str] = None # Mapped from operatioName
    shipping_company_name: Optional[str] = None # Mapped from shippingCompany -> shippingCompanyName
    access_key: Optional[str] = None     # Mapped from eletronic -> accessKey

    def to_dict(self) -> Dict[str, Any]:
        """Converts the FormattedInvoiceListItem object to a dictionary."""
        return self.__dict__


@dataclass(frozen=True)
class InvoiceXmlOutDto:
    """
    Represents the response from the GET /xml-contents/{accessKey} endpoint. Immutable.
    Corresponds to the InvoiceXmlOutDto schema.
    """
    processing_type: Optional[str] = None # Maps to ElectronicInvoiceStatusType enum
    main_invoice_xml: Optional[str] = None # Base64 encoded XML
    cancel_invoice_xml: Optional[str] = None # Base64 encoded XML

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['InvoiceXmlOutDto']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for InvoiceXmlOutDto.from_dict: {type(data)}")
            return None
        return cls(
            processing_type=data.get('processingType'),
            main_invoice_xml=data.get('mainInvoiceXml'),
            cancel_invoice_xml=data.get('cancelInvoiceXml')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__

@dataclass(frozen=True)
class DanfeRequestModel:
    """
    Represents the request body for the POST /danfe-search endpoint. Immutable.
    Corresponds to the DanfeRequestModel schema.
    """
    main_invoice_xml: str # Base64 encoded XML - marked as required in swagger
    nfe_document_type: Optional[int] = None # Maps to NfeDocumentType enum (1=Normal, 2=Simplified)

    def to_dict(self) -> Dict[str, Any]:
        # Return only non-None fields to match typical API expectations
        d = {"mainInvoiceXml": self.main_invoice_xml}
        if self.nfe_document_type is not None:
            d["nfeDocumentType"] = self.nfe_document_type
        return d

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['DanfeRequestModel']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for DanfeRequestModel.from_dict: {type(data)}")
            return None
        main_xml = data.get('mainInvoiceXml')
        if not main_xml:
            logger.warning("Missing required 'mainInvoiceXml' for DanfeRequestModel.")
            return None
        return cls(
            main_invoice_xml=main_xml,
            nfe_document_type=data.get('nfeDocumentType')
        )

@dataclass(frozen=True)
class DanfeResponseModel:
    """
    Represents the response from the POST /danfe-search endpoint. Immutable.
    Corresponds to the DanfeResponseModel schema.
    """
    danfe_pdf_base64: Optional[str] = None # Base64 encoded PDF

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['DanfeResponseModel']:
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for DanfeResponseModel.from_dict: {type(data)}")
            return None
        # Adjust key based on testing if needed (e.g., if API returns 'pdfBase64')
        return cls(
            danfe_pdf_base64=data.get('danfePdfBase64')
        )

    def to_dict(self) -> Dict[str, Any]:
        return self.__dict__
</file>

<file path="src/domain/observation.py">
# src/domain/observation.py
# Define o modelo ORM para Product Observations usando SQLAlchemy.

from datetime import datetime, timezone
from typing import Optional, Dict, Any
from sqlalchemy import (
    Column, Integer, String, Boolean, DateTime, Text, func # Import func if using database default timestamps
)
from sqlalchemy.orm import Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP # Importar tipo específico do PG

# Importar Base
from src.database.base import Base
from src.utils.logger import logger

class Observation(Base):
    """
    Representa uma observação de produto como modelo ORM.
    """
    __tablename__ = 'product_observations'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    # Usar Text para códigos/textos potencialmente longos
    reference_code: Mapped[str] = mapped_column(Text, nullable=False, index=True)
    observation_text: Mapped[str] = mapped_column("observation", Text, nullable=False) # Mapeia para coluna 'observation' existente
    # Coluna "user" precisa de aspas se for palavra reservada, mas SQLAlchemy pode lidar com isso.
    # Se o nome do atributo no Python for diferente, use mapped_column("user", ...)
    user: Mapped[str] = mapped_column(Text, nullable=False)
    # Usar TIMESTAMP(timezone=True) para PostgreSQL, com default via Python/SQLAlchemy
    timestamp: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=lambda: datetime.now(timezone.utc), nullable=False)
    resolved: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False, index=True)
    resolved_user: Mapped[Optional[str]] = mapped_column(Text)
    resolved_timestamp: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))

    def to_dict(self) -> Dict[str, Any]:
        """Converte o objeto Observation para um dicionário."""
        return {
            'id': self.id,
            'reference_code': self.reference_code,
            # Retorna o nome do atributo python 'observation_text'
            'observation_text': self.observation_text,
            'user': self.user,
            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
            'resolved': self.resolved,
            'resolved_user': self.resolved_user,
            'resolved_timestamp': self.resolved_timestamp.isoformat() if self.resolved_timestamp else None,
        }

    # @classmethod from_dict não é necessário para ORM, o SQLAlchemy cuida disso.

    def __repr__(self):
        return f"<Observation(id={self.id}, ref='{self.reference_code}', resolved={self.resolved})>"
</file>

<file path="src/domain/person.py">
# src/domain/person.py
# Defines data models related to Person data (Individuals, Legal Entities) from the ERP.

from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from src.utils.logger import logger

@dataclass(frozen=True)
class Address:
    """Represents a person's address details. Immutable."""
    sequence_code: Optional[int] = None
    address_type_code: Optional[int] = None
    address_type: Optional[str] = None
    public_place: Optional[str] = None
    address: Optional[str] = None
    address_number: Optional[str] = None # API might return string
    complement: Optional[str] = None
    neighborhood: Optional[str] = None
    ibge_city_code: Optional[int] = None
    city_name: Optional[str] = None
    state_abbreviation: Optional[str] = None
    cep: Optional[str] = None
    bcb_country_code: Optional[int] = None
    country_name: Optional[str] = None
    post_office_box: Optional[str] = None # API might return string
    reference: Optional[str] = None
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Address']:
        """Creates an Address object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for Address.from_dict: {type(data)}")
            return None
        # Use .get with default None for Optional fields
        return cls(
            sequence_code=data.get('sequenceCode'),
            address_type_code=data.get('addressTypeCode'),
            address_type=data.get('addressType'),
            public_place=data.get('publicPlace'),
            address=data.get('address'),
            address_number=str(data['addressNumber']) if data.get('addressNumber') is not None else None,
            complement=data.get('complement'),
            neighborhood=data.get('neighborhood'),
            ibge_city_code=data.get('ibgeCityCode'),
            city_name=data.get('cityName'),
            state_abbreviation=data.get('stateAbbreviation'),
            cep=data.get('cep'),
            bcb_country_code=data.get('bcbCountryCode'),
            country_name=data.get('countryName'),
            post_office_box=str(data['postOfficeBox']) if data.get('postOfficeBox') is not None else None,
            reference=data.get('reference'),
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Address object to a dictionary."""
        return self.__dict__

@dataclass(frozen=True)
class Phone:
    """Represents a person's phone number details. Immutable."""
    sequence: Optional[int] = None
    type_code: Optional[int] = None
    type_name: Optional[str] = None
    number: Optional[str] = None
    branch_line: Optional[str] = None # API might return string
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Phone']:
        """Creates a Phone object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for Phone.from_dict: {type(data)}")
             return None
        # Note the inconsistent capitalization in the original 'Sequence'
        return cls(
            sequence=data.get('Sequence') or data.get('sequence'), # Handle both cases
            type_code=data.get('typeCode'),
            type_name=data.get('typeName'),
            number=data.get('number'),
            branch_line=str(data['branchLine']) if data.get('branchLine') is not None else None,
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Phone object to a dictionary."""
        return self.__dict__

@dataclass(frozen=True)
class Email:
    """Represents a person's email address details. Immutable."""
    sequence: Optional[int] = None
    type_code: Optional[int] = None
    type_name: Optional[str] = None
    email: Optional[str] = None
    is_default: bool = False

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['Email']:
        """Creates an Email object from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for Email.from_dict: {type(data)}")
            return None
        return cls(
            sequence=data.get('sequence'),
            type_code=data.get('typeCode'),
            type_name=data.get('typeName'),
            email=data.get('email'),
            is_default=data.get('isDefault', False)
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the Email object to a dictionary."""
        return self.__dict__


@dataclass(frozen=True)
class IndividualDataModel:
    """Represents data for an individual (Pessoa Física). Immutable."""
    code: int
    cpf: str
    is_inactive: bool
    name: str
    rg: Optional[str] = None
    rg_federal_agency: Optional[str] = None
    birth_date: Optional[str] = None # Keep as string from API? Or parse to date? Keep str for now.
    branch_insert_code: Optional[int] = None
    addresses: List[Address] = field(default_factory=list)
    phones: List[Phone] = field(default_factory=list)
    emails: List[Email] = field(default_factory=list)
    is_customer: Optional[bool] = None
    is_supplier: Optional[bool] = None
    is_employee: Optional[bool] = None
    employee_status: Optional[str] = None
    customer_status: Optional[str] = None
    insert_date: Optional[str] = None # Keep as string
    # --- Other fields from original model (add as needed) ---
    marital_status: Optional[str] = None
    gender: Optional[str] = None
    # ctps: Optional[int] = None # Example of omitted fields, add back if needed
    # ... many other fields ...
    max_change_filter_date: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['IndividualDataModel']:
        """Creates an IndividualDataModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for IndividualDataModel.from_dict: {type(data)}")
             return None

        code = data.get('code')
        cpf = data.get('cpf')
        name = data.get('name')

        if not code or not cpf or not name:
             logger.warning(f"Missing essential data (code, cpf, name) for IndividualDataModel: {data.get('code')}")
             return None

        # Process nested lists safely
        addresses_data = data.get('addresses', [])
        phones_data = data.get('phones', [])
        emails_data = data.get('emails', [])

        addresses = [Address.from_dict(addr) for addr in addresses_data if isinstance(addr, dict)]
        addresses = [addr for addr in addresses if addr is not None] # Filter out None results
        phones = [Phone.from_dict(phone) for phone in phones_data if isinstance(phone, dict)]
        phones = [phone for phone in phones if phone is not None]
        emails = [Email.from_dict(email) for email in emails_data if isinstance(email, dict)]
        emails = [email for email in emails if email is not None]

        return cls(
            code=code,
            cpf=cpf,
            is_inactive=data.get('isInactive', False),
            name=name,
            rg=data.get('rg'),
            rg_federal_agency=data.get('rgFederalAgency'),
            birth_date=data.get('birthDate'),
            branch_insert_code=data.get('branchInsertCode'),
            addresses=addresses,
            phones=phones,
            emails=emails,
            is_customer=data.get('isCustomer'),
            is_supplier=data.get('isSupplier'),
            is_employee=data.get('isEmployee'),
            employee_status=data.get('employeeStatus'),
            customer_status=data.get('customerStatus'),
            insert_date=data.get('insertDate'),
            marital_status=data.get('maritalStatus'),
            gender=data.get('gender'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            # Add other fields here if needed
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the IndividualDataModel object to a dictionary."""
        return {
             **self.__dict__,
            'addresses': [a.to_dict() for a in self.addresses],
            'phones': [p.to_dict() for p in self.phones],
            'emails': [e.to_dict() for e in self.emails],
        }

@dataclass(frozen=True)
class LegalEntityDataModel:
    """Represents data for a legal entity (Pessoa Jurídica). Immutable."""
    # --- Fields WITHOUT defaults first ---
    code: int
    cnpj: str
    is_inactive: bool
    name: str # Razão Social

    # --- Fields WITH defaults ---
    branch_insert_code: Optional[int] = None # API schema says required, but play safe
    fantasy_name: Optional[str] = None
    uf: Optional[str] = None
    number_state_registration: Optional[str] = None
    date_foundation: Optional[str] = None # Keep as string
    share_capital: Optional[float] = None
    addresses: List[Address] = field(default_factory=list)
    phones: List[Phone] = field(default_factory=list)
    emails: List[Email] = field(default_factory=list)
    insert_date: Optional[str] = None # Keep as string
    max_change_filter_date: Optional[str] = None
    is_customer: Optional[bool] = None
    is_supplier: Optional[bool] = None
    is_representative: Optional[bool] = None
    customer_status: Optional[str] = None
    # ... add other fields with defaults here ...


    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['LegalEntityDataModel']:
        """Creates a LegalEntityDataModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
             logger.warning(f"Invalid data type for LegalEntityDataModel.from_dict: {type(data)}")
             return None

        # Essential fields
        code = data.get('code')
        cnpj = data.get('cnpj')
        name = data.get('name') # Razão Social
        is_inactive=data.get('isInactive', False) # Default to False if missing

        if code is None or cnpj is None or name is None:
             logger.warning(f"Missing essential data (code, cnpj, name) for LegalEntityDataModel: {data.get('code')}")
             return None

        # Process nested lists safely
        addresses_data = data.get('addresses', [])
        phones_data = data.get('phones', [])
        emails_data = data.get('emails', [])

        addresses = [Address.from_dict(addr) for addr in addresses_data if isinstance(addr, dict)]
        addresses = [addr for addr in addresses if addr is not None]
        phones = [Phone.from_dict(phone) for phone in phones_data if isinstance(phone, dict)]
        phones = [phone for phone in phones if phone is not None]
        emails = [Email.from_dict(email) for email in emails_data if isinstance(email, dict)]
        emails = [email for email in emails if email is not None]

        return cls(
            # Non-default args first
            code=code,
            cnpj=cnpj,
            is_inactive=is_inactive,
            name=name,
            # Default args next
            branch_insert_code=data.get('branchInsertCode'),
            fantasy_name=data.get('fantasyName'),
            uf=data.get('uf'),
            number_state_registration=data.get('numberStateRegistration'),
            date_foundation=data.get('dateFoundation'),
            share_capital=data.get('shareCapital'),
            addresses=addresses,
            phones=phones,
            emails=emails,
            insert_date=data.get('insertDate'),
            max_change_filter_date=data.get('maxChangeFilterDate'),
            is_customer=data.get('isCustomer'),
            is_supplier=data.get('isSupplier'),
            is_representative=data.get('isRepresentative'),
            customer_status=data.get('customerStatus'),
            # Add other fields here if needed
        )

    def to_dict(self) -> Dict[str, Any]:
        """Converts the LegalEntityDataModel object to a dictionary."""
        return {
             **self.__dict__,
            'addresses': [a.to_dict() for a in self.addresses],
            'phones': [p.to_dict() for p in self.phones],
            'emails': [e.to_dict() for e in self.emails],
        }


@dataclass(frozen=True)
class PersonStatisticsResponseModel:
    """Represents customer statistics data from the ERP API. Immutable."""
    average_delay: Optional[int] = None
    maximum_delay: Optional[int] = None
    purchase_quantity: Optional[int] = None
    total_purchase_value: Optional[float] = None
    average_purchase_value: Optional[float] = None
    biggest_purchase_date: Optional[str] = None # Keep as string
    biggest_purchase_value: Optional[float] = None
    first_purchase_date: Optional[str] = None # Keep as string
    first_purchase_value: Optional[float] = None
    last_purchase_value: Optional[float] = None
    last_purchase_date: Optional[str] = None # Keep as string
    total_installments_paid: Optional[float] = None
    quantity_installments_paid: Optional[int] = None
    average_value_installments_paid: Optional[float] = None
    total_installments_delayed: Optional[float] = None
    quantity_installments_delayed: Optional[int] = None
    average_installment_delay: Optional[float] = None
    total_installments_open: Optional[float] = None
    quantity_installments_open: Optional[int] = None
    average_installments_open: Optional[float] = None
    last_invoice_paid_value: Optional[float] = None
    last_invoice_paid_date: Optional[str] = None # Keep as string

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> Optional['PersonStatisticsResponseModel']:
        """Creates a PersonStatisticsResponseModel from a dictionary (e.g., from API)."""
        if not isinstance(data, dict):
            logger.warning(f"Invalid data type for PersonStatisticsResponseModel.from_dict: {type(data)}")
            return None
        # Directly map fields, relying on dataclass defaults for missing keys
        # Add type checks/conversions if API types are unreliable
        try:
            return cls(
                average_delay=data.get('averageDelay'),
                maximum_delay=data.get('maximumDelay'),
                purchase_quantity=data.get('purchaseQuantity'),
                total_purchase_value=data.get('totalPurchaseValue'),
                average_purchase_value=data.get('averagePurchaseValue'),
                biggest_purchase_date=data.get('biggestPurchaseDate'),
                biggest_purchase_value=data.get('biggestPurchaseValue'),
                first_purchase_date=data.get('firstPurchaseDate'),
                first_purchase_value=data.get('firstPurchaseValue'),
                last_purchase_value=data.get('lastPurchaseValue'),
                last_purchase_date=data.get('lastPurchaseDate'),
                total_installments_paid=data.get('totalInstallmentsPaid'),
                quantity_installments_paid=data.get('quantityInstallmentsPaid'),
                average_value_installments_paid=data.get('averageValueInstallmentsPaid'),
                total_installments_delayed=data.get('totalInstallmentsDelayed'),
                quantity_installments_delayed=data.get('quantityInstallmentsDelayed'),
                average_installment_delay=data.get('averageInstallmentDelay'),
                total_installments_open=data.get('totalInstallmentsOpen'),
                quantity_installments_open=data.get('quantityInstallmentsOpen'),
                average_installments_open=data.get('averageInstallmentsOpen'),
                last_invoice_paid_value=data.get('lastInvoicePaidValue'),
                last_invoice_paid_date=data.get('lastInvoicePaidDate')
            )
        except (TypeError, ValueError) as e:
            logger.error(f"Error creating PersonStatisticsResponseModel from dict: {e}. Data: {data}", exc_info=True)
            return None # Return None if data types are wrong

    def to_dict(self) -> Dict[str, Any]:
        """Converts the PersonStatisticsResponseModel object to a dictionary."""
        return self.__dict__
</file>

<file path="src/domain/README.md">
# src/domain

Este diretório contém os modelos de dados da aplicação. Eles representam as estruturas de dados manipuladas pela aplicação, incluindo tanto os modelos ORM para o banco de dados local quanto Dataclasses para representar dados vindos do ERP ou usados como DTOs (Data Transfer Objects).

## Arquivos

*   **Modelos ORM (SQLAlchemy):**
    *   `user.py`: Define os modelos ORM `User` e `UserPermissions` mapeados para as tabelas do banco de dados local. Herdam de `src.database.base.Base`.
    *   `observation.py`: Define o modelo ORM `Observation` mapeado para a tabela `product_observations`. Herda de `src.database.base.Base`.
*   **Dataclasses (DTOs / Modelos ERP):**
    *   `accounts_receivable.py`: Define modelos Dataclass para dados de Contas a Receber do ERP (ex: `DocumentModel`, `BankSlipRequestModel`, `FormattedReceivableListItem`).
    *   `balance.py`: Define `Balance`, `ProductItem`, `ProductResponse` (Dataclasses) para dados de saldo do ERP.
    *   `cost.py`: Define `Cost`, `ProductCost`, `CostResponse` (Dataclasses) para dados de custo do ERP.
    *   `fabric_details.py`: Define `FabricDetailValue`, `FabricDetailsItem` (Dataclasses) para detalhes específicos de tecidos (largura, gramatura, etc.) do ERP.
    *   `fiscal.py`: Define modelos Dataclass para operações do módulo Fiscal (ex: `FormattedInvoiceListItem`, `InvoiceXmlOutDto`, `DanfeResponseModel`).
    *   `person.py`: Define `Address`, `Phone`, `Email`, `IndividualDataModel`, `LegalEntityDataModel`, `PersonStatisticsResponseModel` (Dataclasses) para dados de pessoa (PF/PJ) do ERP.
*   **Outros:**
    *   `__init__.py`: Exporta todos os modelos (ORM e Dataclasses) para fácil importação.
    *   `README.md`: Este arquivo.

## Padrões

*   **Modelos ORM:**
    *   Implementados como classes Python que herdam de `src.database.base.Base`.
    *   Usam `Mapped` e `mapped_column` do SQLAlchemy 2.0 para definir atributos e mapeamento de colunas.
    *   Definem relacionamentos usando `relationship`.
    *   Podem conter métodos de lógica de negócio relacionados ao próprio modelo (ex: `User.verify_password`).
    *   Incluem um método `to_dict()` para facilitar a serialização para JSON na camada da API.
*   **Dataclasses:**
    *   Usados para representar estruturas de dados que *não* são mapeadas diretamente para tabelas do banco local (principalmente dados do ERP ou DTOs específicos da API).
    *   Geralmente `frozen=True` (imutáveis) para dados vindos de fontes externas.
    *   Incluem métodos `from_dict` (ou similar) para criar instâncias a partir de respostas de API e `to_dict` para serialização.
*   **Type Hinting:** Tipos são definidos para todos os atributos.
*   **Validação:** A validação nos métodos `from_dict` de Dataclasses é básica. Validações mais complexas podem residir nos serviços. Modelos ORM dependem das constraints do banco e validações na camada de serviço antes da persistência.
</file>

<file path="src/domain/user.py">
# src/domain/user.py
from datetime import datetime, timezone
import bcrypt
from typing import Optional, Dict, Any, TYPE_CHECKING
from sqlalchemy import (
    Column, Integer, String, Boolean, DateTime, ForeignKey, func, Text
)
from sqlalchemy.orm import relationship, Mapped, mapped_column
from sqlalchemy.dialects.postgresql import TIMESTAMP

from src.database.base import Base
from src.utils.logger import logger

if TYPE_CHECKING:
    pass

class UserPermissions(Base):
    """
    Representa as permissões ORM associadas a um usuário.
    """
    __tablename__ = 'user_permissions'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    user_id: Mapped[int] = mapped_column(ForeignKey('users.id', ondelete='CASCADE'), unique=True, nullable=False, index=True)

    is_admin: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_products: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_fabrics: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_customer_panel: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_fiscal: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    can_access_accounts_receivable: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)

    user: Mapped["User"] = relationship(back_populates="permissions")

    def to_dict(self) -> Dict[str, Any]:
        """Converte o objeto UserPermissions para um dicionário."""
        return {
            'id': self.id,
            'user_id': self.user_id,
            'is_admin': self.is_admin,
            'can_access_products': self.can_access_products,
            'can_access_fabrics': self.can_access_fabrics,
            'can_access_customer_panel': self.can_access_customer_panel,
            'can_access_fiscal': self.can_access_fiscal,
            'can_access_accounts_receivable': self.can_access_accounts_receivable,
        }

    def __repr__(self):
        return f"<UserPermissions(id={self.id}, user_id={self.user_id}, is_admin={self.is_admin})>"

class User(Base):
    """
    Representa um usuário da aplicação como modelo ORM.
    """
    __tablename__ = 'users'

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    username: Mapped[str] = mapped_column(Text, unique=True, nullable=False, index=True)
    password_hash: Mapped[str] = mapped_column(Text, nullable=False)
    name: Mapped[str] = mapped_column(Text, nullable=False)
    email: Mapped[Optional[str]] = mapped_column(Text, unique=True, index=True)
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=lambda: datetime.now(timezone.utc), nullable=False)
    last_login: Mapped[Optional[datetime]] = mapped_column(TIMESTAMP(timezone=True))
    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)

    permissions: Mapped["UserPermissions"] = relationship(
        "UserPermissions",
        back_populates="user",
        cascade="all, delete-orphan",
        uselist=False,
        lazy="joined"
    )

    def set_password(self, password: str):
        """Hashes the given password and sets the password_hash."""
        if not password:
            self.password_hash = ""
            logger.warning(f"Tentativa de definir senha vazia para usuário {self.username}")
            return
        try:
            salt = bcrypt.gensalt()
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            self.password_hash = hashed.decode('utf-8')
        except Exception as e:
            logger.error(f"Erro ao fazer hash da senha para usuário {self.username}: {e}")
            self.password_hash = ""

    def verify_password(self, password: str) -> bool:
        """Verifies the given password against the stored hash."""
        if not self.password_hash or not password:
            logger.debug(f"Verificação de senha falhou para usuário {self.username}: Hash ou senha fornecida ausente.")
            return False
        try:
            hash_bytes = self.password_hash.encode('utf-8')
            result = bcrypt.checkpw(password.encode('utf-8'), hash_bytes)
            logger.debug(f"Resultado da verificação de senha para usuário {self.username}: {result}")
            return result
        except ValueError as e:
             logger.error(f"Erro ao verificar senha para usuário {self.username}: {e}. Possível valor de hash corrompido: '{self.password_hash[:10]}...'")
             return False
        except Exception as e:
            logger.error(f"Erro inesperado ao verificar senha para usuário {self.username}: {e}")
            return False

    def update_last_login(self):
        """Sets the last_login timestamp to the current time UTC."""
        self.last_login = datetime.now(timezone.utc)

    def to_dict(self, include_hash: bool = False) -> Dict[str, Any]:
        """
        Converts the User object to a dictionary.
        Args:
            include_hash: Whether to include the password_hash in the output. Defaults to False.
        Returns:
            Dictionary representation of the user.
        """
        data = {
            'id': self.id,
            'username': self.username,
            'name': self.name,
            'email': self.email,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'last_login': self.last_login.isoformat() if self.last_login else None,
            'is_active': self.is_active,
            'permissions': self.permissions.to_dict() if self.permissions else None
        }
        if include_hash:
            data['password_hash'] = self.password_hash
        return data

    def __repr__(self):
        perm_id = getattr(self.permissions, 'id', None)
        return f"<User(id={self.id}, username='{self.username}', perm_id={perm_id})>"
</file>

<file path="src/erp_integration/__init__.py">
# src/erp_integration/__init__.py
# Makes 'erp_integration' a package. Exports ERP service classes.

from .erp_auth_service import ErpAuthService
from .erp_balance_service import ErpBalanceService
from .erp_cost_service import ErpCostService
from .erp_person_service import ErpPersonService
from .erp_product_service import ErpProductService
from .erp_fiscal_service import ErpFiscalService
from .erp_accounts_receivable_service import ErpAccountsReceivableService # Added Accounts Receivable service

# Instantiate singleton for ERP Auth if desired, as it's likely stateless
# and used by other ERP services.
erp_auth_service = ErpAuthService()

# Other services might be instantiated here or passed the auth service instance
# when they are created (dependency injection).

__all__ = [
    "ErpAuthService",
    "erp_auth_service", # Export instance too
    "ErpBalanceService",
    "ErpCostService",
    "ErpPersonService",
    "ErpProductService",
    "ErpFiscalService",
    "ErpAccountsReceivableService", # Added to exports
]
</file>

<file path="src/erp_integration/erp_accounts_receivable_service.py">
# src/erp_integration/erp_accounts_receivable_service.py
# Fetches Accounts Receivable data from the TOTVS ERP API.

import requests
from typing import Optional, Dict, Any
from src.config import config
# Import domain models if needed for type hints, but methods return raw dicts
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError

class ErpAccountsReceivableService:
    """
    Service to interact with the ERP's Accounts Receivable endpoints.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpAccountsReceivableService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        self.documents_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_DOCUMENTS_ENDPOINT}"
        self.bank_slip_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_BANKSLIP_ENDPOINT}"
        # self.payment_link_url = f"{self.base_url}{config.ACCOUNTS_RECEIVABLE_PAYMENTLINK_ENDPOINT}" # If needed later
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE
        logger.info("ErpAccountsReceivableService initialized.")

    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None) -> Dict[str, Any]:
        """Internal helper to make requests, handling auth and retries."""
        # This can be copied/adapted from ErpPersonService or ErpFiscalService
        # Ensure it handles POST correctly and specific error cases for this API
        attempt = 0
        last_exception: Optional[Exception] = None

        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP AR API: {method} {url}")
            response = None
            status_code = None
            response_text_snippet = "N/A"

            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                }

                timeout = 45 # Slightly longer timeout might be needed

                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=timeout)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=timeout)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                status_code = response.status_code
                try:
                    response_text_snippet = response.text[:1000] if response.text else "(Empty Body)"
                except Exception as read_err:
                    response_text_snippet = f"(Error reading response body: {read_err})"

                logger.debug(f"ERP AR Response Status: {status_code}, Body Snippet: {response_text_snippet}")

                # Check specific AR error patterns if necessary (e.g., 400 with DomainNotificationMessage)
                # The Swagger shows 400 for Bad Request, 200 for Success. No explicit 404 mentioned for search/boleto.
                # If a 400 contains useful info in DomainNotificationMessage, parse it?
                if status_code == 400:
                    error_detail = response_text_snippet # Default error detail
                    try:
                        error_json = response.json()
                        if isinstance(error_json, dict):
                           msg = error_json.get('message') or error_json.get('Message') # Check common keys
                           det_msg = error_json.get('detailedMessage') or error_json.get('DetailedMessage')
                           error_detail = f"{msg or 'Bad Request'} ({det_msg or response_text_snippet})"
                    except requests.exceptions.JSONDecodeError:
                        pass # Stick with the text snippet
                    logger.warning(f"ERP AR API returned 400 Bad Request for {method} {url}. Detail: {error_detail}")
                    # Map 400 to ErpIntegrationError for now, service layer might interpret further
                    raise ErpIntegrationError(f"ERP AR API returned Bad Request (400): {error_detail}")


                if status_code == 401 and attempt <= self.max_retries:
                     logger.warning(f"ERP AR API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                     self.erp_auth_service.invalidate_token()
                     last_exception = requests.exceptions.HTTPError(f"401 Client Error: Unauthorized for url: {url}", response=response)
                     continue # Retry

                # Raise other HTTP errors (>= 400, excluding 400/401 handled above)
                response.raise_for_status()

                # Handle cases where API returns 200 but empty body or non-JSON
                try:
                     resp_json = response.json()
                     if not resp_json and method.upper() != "GET": # Allow empty response for GET maybe, but not POST results
                          logger.warning(f"Received empty successful response (2xx) from ERP AR API: {method} {url}")
                          # Treat as error for POST requests expecting data
                          raise ErpIntegrationError(f"Received empty successful response from ERP AR API: {method} {url}")
                     return resp_json
                except requests.exceptions.JSONDecodeError as json_err:
                     logger.error(f"Failed to decode JSON response from {method} {url}. Status: {status_code}, Error: {json_err}. Response: {response_text_snippet}")
                     raise ErpIntegrationError(f"Received non-JSON response from ERP AR API: {json_err}") from json_err

            except requests.exceptions.HTTPError as e:
                 # Catches errors raised by raise_for_status (excluding 400/401 retry)
                 logger.error(f"HTTP error {status_code} from ERP AR API ({method} {url}): {e}. Response: {response_text_snippet}", exc_info=False)
                 last_exception = ErpIntegrationError(f"ERP AR API request failed with status {status_code}: {response_text_snippet}")
                 break # Break loop for non-retryable HTTP errors

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP AR API ({method} {url}): {e}", exc_info=True)
                 last_exception = ErpIntegrationError(f"Network error connecting to ERP AR API: {e}")
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying AR API call after network error (Attempt {attempt}).")
                      continue # Retry on network errors
                 else:
                      break # Exhausted retries

            except ErpIntegrationError as e: # Catch 400 errors raised above
                 last_exception = e
                 raise e # Re-raise immediately

            except Exception as e:
                 logger.error(f"Unexpected error during ERP AR API request ({method} {url}): {e}", exc_info=True)
                 error_msg = f"Unexpected error during ERP AR API request: {e}"
                 if response:
                      error_msg += f" | Response Status: {status_code}, Response Snippet: {response_text_snippet}"
                 last_exception = ErpIntegrationError(error_msg)
                 break

        # If loop finishes due to exhausted retries or non-retryable error
        log_message = f"Failed ERP AR API request after {attempt} attempts: {method} {url}. LastError: {last_exception}"
        logger.error(log_message)
        if isinstance(last_exception, ErpIntegrationError):
            raise last_exception
        elif isinstance(last_exception, Exception):
            raise ErpIntegrationError(log_message) from last_exception
        else:
             raise ErpIntegrationError(f"Exhausted retries or failed for ERP AR API request: {method} {url}")


    def search_documents(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Calls the ERP endpoint to search for accounts receivable documents."""
        logger.debug(f"Calling ERP AR documents search with payload: {payload}")
        # Note: _make_request returns the parsed dictionary directly
        return self._make_request(self.documents_url, method="POST", json_payload=payload)

    def get_bank_slip(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Calls the ERP endpoint to generate a bank slip (boleto)."""
        logger.debug(f"Calling ERP AR bank slip generation with payload: {payload}")
        # Note: _make_request returns the parsed dictionary directly
        return self._make_request(self.bank_slip_url, method="POST", json_payload=payload)
</file>

<file path="src/erp_integration/erp_auth_service.py">
# src/erp_integration/erp_auth_service.py
# Handles authentication with the TOTVS ERP API to obtain Bearer tokens.

import time
import requests
from typing import Optional, Dict, Any
from threading import Lock
from src.config import config # Import app configuration
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Use custom error

class ErpAuthService:
    """
    Manages authentication with the ERP API (TOTVS) using OAuth Password Grant.
    Handles token acquisition, caching, expiration, and renewal.
    Designed as a thread-safe singleton.
    """
    _instance = None
    _lock = Lock()
    _token_lock = Lock() # Separate lock specifically for token refresh logic

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(ErpAuthService, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        """Initializes the ErpAuthService (called only once due to Singleton)."""
        if self._initialized:
            return
        with self._lock:
            if self._initialized:
                 return

            self._access_token: Optional[str] = None
            self._expires_at: float = 0 # Store expiration time as timestamp
            # Construct full URLs from config
            self.auth_url = f"{config.API_BASE_URL.rstrip('/')}{config.TOKEN_ENDPOINT}"
            self.client_id = config.CLIENT_ID
            self.client_secret = config.CLIENT_SECRET
            self.username = config.API_USERNAME
            self.password = config.API_PASSWORD
            self.grant_type = config.GRANT_TYPE

            if not self.username or not self.password:
                 logger.warning("ERP API username or password not configured. Authentication will likely fail.")
            if not self.client_id: # Client secret might be optional depending on grant type
                 logger.warning("ERP API client_id not configured.")

            self._initialized = True
            logger.info(f"ErpAuthService initialized for URL: {self.auth_url}")

    def get_token(self) -> str:
        """
        Returns a valid Bearer token for accessing the ERP API.
        Handles token expiration and renewal automatically. Thread-safe.

        Returns:
            A valid access token string.

        Raises:
            ErpIntegrationError: If unable to obtain or refresh the token.
        """
        with self._token_lock: # Ensure only one thread refreshes the token at a time
            # Check expiry with a safety margin (e.g., 60 seconds)
            # time.time() is generally preferred over time.monotonic() for expiration checks
            # as it relates to wall-clock time, which 'exp' usually represents.
            safety_margin = 60
            if not self._access_token or time.time() >= (self._expires_at - safety_margin):
                logger.info("ERP token missing or expired/near expiry. Refreshing...")
                try:
                    self._refresh_token()
                except Exception as e:
                    # Log the error from _refresh_token and re-raise specific type
                    logger.critical(f"Failed to refresh ERP token: {e}", exc_info=True)
                    raise ErpIntegrationError("Failed to obtain/refresh ERP API token.") from e

            if not self._access_token:
                 # This should not happen if _refresh_token succeeds, but handle defensively
                 logger.error("Access token is still None after refresh attempt.")
                 raise ErpIntegrationError("Failed to obtain ERP API token after refresh.")

            return self._access_token

    def invalidate_token(self):
        """Forces the token to be refreshed on the next call to get_token()."""
        with self._token_lock:
            logger.info("Invalidating stored ERP token.")
            self._access_token = None
            self._expires_at = 0

    def _refresh_token(self):
        """
        Internal method to request a new token from the ERP's authorization endpoint.
        This method is called internally by get_token() when needed.
        Assumes _token_lock is held by the caller.
        """
        auth_data = {
            'username': self.username,
            'password': self.password,
            'client_id': self.client_id,
            'grant_type': self.grant_type
        }
        # Add client_secret only if it's provided (some grant types might not require it)
        if self.client_secret:
            auth_data['client_secret'] = self.client_secret

        logger.debug(f"Requesting new ERP token from {self.auth_url}")
        try:
            response = requests.post(
                self.auth_url,
                data=auth_data, # Use data for application/x-www-form-urlencoded
                timeout=15 # Increased timeout for auth requests
            )
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

            token_data = response.json()

            if 'access_token' not in token_data:
                 logger.error(f"ERP Auth response missing 'access_token'. Response: {token_data}")
                 raise ErpIntegrationError("Received invalid token response from ERP.")

            self._access_token = token_data['access_token']
            expires_in = token_data.get('expires_in', 3600) # Default to 1 hour if missing
            try:
                 # Calculate expiration time based on 'expires_in'
                 self._expires_at = time.time() + int(expires_in)
            except (ValueError, TypeError):
                 logger.warning(f"Invalid 'expires_in' value received: {expires_in}. Defaulting to 1 hour.")
                 self._expires_at = time.time() + 3600

            logger.info(f"Successfully refreshed ERP token. Expires in approx {expires_in} seconds.")
            # Log partial token for debugging if needed, but be careful
            # logger.debug(f"New token: {self._access_token[:10]}...{self._access_token[-10:]}")

        except requests.exceptions.RequestException as e:
            logger.error(f"Network error during ERP token refresh request to {self.auth_url}: {e}", exc_info=True)
            # Invalidate potentially stale token on network error
            self._access_token = None
            self._expires_at = 0
            raise ErpIntegrationError(f"Network error contacting ERP auth server: {e}") from e
        except Exception as e:
             logger.error(f"Unexpected error during ERP token refresh: {e}", exc_info=True)
             # Invalidate potentially stale token on any error
             self._access_token = None
             self._expires_at = 0
             # Include response text in error if available
             err_msg = f"Unexpected error refreshing ERP token: {e}"
             if 'response' in locals() and hasattr(response, 'text'):
                  err_msg += f" | Response: {response.text[:500]}" # Limit response length
             raise ErpIntegrationError(err_msg) from e
</file>

<file path="src/erp_integration/erp_balance_service.py">
# src/erp_integration/erp_balance_service.py
# Fetches product balance data from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.balance import ProductResponse, ProductItem # Domain models
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpBalanceService:
    """
    Service to interact with the ERP's product balance endpoint.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpBalanceService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.BALANCES_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpBalanceService initialized for URL: {self.api_url}")

    def get_balances(self,
                     reference_code_list: Optional[List[str]] = None,
                     is_fabric: bool = False) -> List[ProductItem]:
        """
        Retrieves product balances from the ERP, handling pagination.

        Args:
            reference_code_list: Optional list of reference codes to filter by (only for finished products).
            is_fabric: If True, applies filters for raw materials (fabrics).
                       If False, applies filters for finished products.

        Returns:
            A list of ProductItem objects containing balance data.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_items: List[ProductItem] = []
        current_page = 1
        has_next = True

        log_prefix = "fabrics" if is_fabric else f"products (Refs: {reference_code_list or 'All'})"
        logger.info(f"Starting ERP balance fetch for {log_prefix}.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for {log_prefix} balances...")
            try:
                payload = self._build_request_payload(current_page, reference_code_list, is_fabric)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid response data for page {current_page}. Aborting fetch.")
                    # Should this be an error? Depends on API contract. Assume empty list is valid.
                    break # Stop pagination if response is weird

                # Parse response using domain model
                product_response = ProductResponse.from_dict(response_data)
                page_items = product_response.items
                all_items.extend(page_items)

                has_next = product_response.has_next
                total_pages = product_response.total_pages
                logger.debug(f"Fetched page {current_page}/{total_pages or '?'}. Items: {len(page_items)}. HasNext: {has_next}")

                current_page += 1

                # Safety break: Avoid infinite loops if hasNext is always true
                if current_page > (total_pages + 5) and total_pages > 0: # Allow a few extra pages just in case
                     logger.warning(f"Potential infinite loop detected in balance pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500: # Absolute safety limit
                     logger.warning(f"Reached absolute page limit (500) for balance fetch. Stopping.")
                     break


            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for {log_prefix} balances: {e}", exc_info=True)
                 # Re-raise the specific error
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for {log_prefix} balances: {e}", exc_info=True)
                 # Wrap in generic ERP error
                 raise ErpIntegrationError(f"Unexpected error during balance fetch: {e}") from e

        logger.info(f"Finished ERP balance fetch for {log_prefix}. Total items retrieved: {len(all_items)}")
        return all_items

    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Makes the actual HTTP request to the ERP API, handling retries and auth.

        Args:
            payload: The request body (dictionary).

        Returns:
            The JSON response dictionary from the API.

        Raises:
            ErpIntegrationError: If the request fails after retries.
        """
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP balance API.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    # Add other headers if required by ERP
                }

                response = requests.post(
                    self.api_url,
                    json=payload,
                    headers=headers,
                    timeout=30 # Adjust timeout as needed
                )
                response.raise_for_status() # Raise HTTPError for 4xx/5xx
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 # Check for 401 Unauthorized specifically for token refresh
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP API returned 401 Unauthorized (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      # Optional: Add a small delay before retrying?
                      # time.sleep(0.5)
                      continue # Go to next attempt loop
                 else:
                      # For other HTTP errors or if retries exhausted
                      response_text = e.response.text[:500] # Limit response text length
                      logger.error(f"HTTP error {status_code} from ERP balance API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 # Includes connection errors, timeouts, etc.
                 logger.error(f"Network error connecting to ERP balance API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying after network error (Attempt {attempt}).")
                      # Optional: Add delay before retry
                      # time.sleep(1)
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP API after {attempt} attempts: {e}") from e
            # except Exception as e: # Catch other potential errors like JSONDecodeError
            #      logger.error(f"Unexpected error during ERP API request: {e}", exc_info=True)
            #      # Should we retry on unexpected errors? Maybe not.
            #      raise ErpIntegrationError(f"Unexpected error during ERP API request: {e}") from e

        # Should not be reached if loop logic is correct, but as fallback:
        logger.error("Exhausted retries for ERP balance API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP balance API.")


    def _build_request_payload(self, page: int, reference_code_list: Optional[List[str]], is_fabric: bool) -> Dict[str, Any]:
        """Constructs the JSON payload for the balance API request."""

        # Common parts
        base_payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "colorCode,productSize", # Consistent ordering
             "filter": {
                 "branchInfo": {
                     "branchCode": self.company_code,
                     "isActive": True,
                     # Specific flags based on product type
                 }
             },
             "option": {
                 "balances": [
                     {
                         "branchCode": self.company_code,
                         "stockCodeList": [1], # Always use stock code 1 (FISICO)? Verify requirement.
                         # Specific flags based on product type
                     }
                 ]
             }
        }

        # Type-specific adjustments
        if is_fabric:
             # Filters for Raw Materials / Tecidos
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": False,
                 "isRawMaterial": True,
                 "isBulkMaterial": False, # Assuming fabrics aren't bulk
                 "isOwnProduction": False,
             })
             # Fabric-specific classifications (Example based on original code)
             base_payload["filter"]["classifications"] = [
                 {"type": 4000, "codeList": ["001"]}, # Example: Tipo = Matéria Prima
                 {"type": 4001, "codeList": ["001", "002", "003"]} # Example: Subtipo = Tecido Plano, Malha, etc.
             ]
             # Balance options for fabrics (don't need sales/production orders?)
             base_payload["option"]["balances"][0].update({
                 "isSalesOrder": False, # Typically no sales orders for raw materials?
                 "isTransaction": True, # Inputs/Outputs
                 "isProductionOrder": False, # Typically no production orders *for* raw materials?
             })
        else:
             # Filters for Finished Products
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": True,
                 "isRawMaterial": False,
                 "isBulkMaterial": False,
                 "isOwnProduction": True, # Assuming finished goods are own production
             })
             # Add reference code filter if provided
             if reference_code_list:
                  base_payload["filter"]["referenceCodeList"] = reference_code_list
             # Balance options for finished products
             base_payload["option"]["balances"][0].update({
                 "isSalesOrder": True, # Include sales orders
                 "isTransaction": True, # Inputs/Outputs
                 "isProductionOrder": True, # Include production orders
             })

        logger.debug(f"Generated ERP balance payload: {base_payload}")
        return base_payload
</file>

<file path="src/erp_integration/erp_cost_service.py">
# src/erp_integration/erp_cost_service.py
# Fetches product cost data from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.cost import CostResponse, ProductCost # Domain models
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpCostService:
    """
    Service to interact with the ERP's product cost endpoint.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpCostService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.COSTS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpCostService initialized for URL: {self.api_url}")

    def get_costs(self,
                  reference_code_list: Optional[List[str]] = None,
                  is_fabric: bool = False) -> List[ProductCost]:
        """
        Retrieves product costs from the ERP, handling pagination.

        Args:
            reference_code_list: Optional list of reference codes to filter by.
            is_fabric: If True, applies filters for raw materials (fabrics).
                       If False, applies filters for finished products.

        Returns:
            A list of ProductCost objects containing cost data.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_items: List[ProductCost] = []
        current_page = 1
        has_next = True

        log_prefix = "fabrics" if is_fabric else f"products (Refs: {reference_code_list or 'All'})"
        logger.info(f"Starting ERP cost fetch for {log_prefix}.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for {log_prefix} costs...")
            try:
                payload = self._build_request_payload(current_page, reference_code_list, is_fabric)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid cost response data for page {current_page}. Aborting fetch.")
                    break

                cost_response = CostResponse.from_dict(response_data)
                page_items = cost_response.items
                all_items.extend(page_items)

                has_next = cost_response.has_next
                total_pages = cost_response.total_pages
                logger.debug(f"Fetched cost page {current_page}/{total_pages or '?'}. Items: {len(page_items)}. HasNext: {has_next}")

                current_page += 1

                # Safety break
                if current_page > (total_pages + 5) and total_pages > 0:
                     logger.warning(f"Potential infinite loop detected in cost pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500:
                     logger.warning(f"Reached absolute page limit (500) for cost fetch. Stopping.")
                     break


            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for {log_prefix} costs: {e}", exc_info=True)
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for {log_prefix} costs: {e}", exc_info=True)
                 raise ErpIntegrationError(f"Unexpected error during cost fetch: {e}") from e

        logger.info(f"Finished ERP cost fetch for {log_prefix}. Total items retrieved: {len(all_items)}")
        return all_items


    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Makes the HTTP request to the ERP API, handling retries and auth."""
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP cost API.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                }
                response = requests.post(self.api_url, json=payload, headers=headers, timeout=30)
                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Cost API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP cost API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP cost API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP cost API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying cost API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP cost API after {attempt} attempts: {e}") from e

        logger.error("Exhausted retries for ERP cost API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP cost API.")


    def _build_request_payload(self, page: int, reference_code_list: Optional[List[str]], is_fabric: bool) -> Dict[str, Any]:
        """Constructs the JSON payload for the cost API request."""

        base_payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "colorCode,productSize", # Or relevant order for costs
             "filter": {
                 "branchInfo": {
                     "branchCode": self.company_code,
                     "isActive": True,
                 }
             },
             "option": {
                 # Specify which cost codes are needed
                 "costs": [{"branchCode": self.company_code, "costCodeList": [2]}] # Example: Cost Code 2 = Custo Reposição? Verify.
             }
        }

        if is_fabric:
             # Filters for Raw Materials / Tecidos
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": False,
                 "isRawMaterial": True,
                 "isBulkMaterial": False,
                 "isOwnProduction": False,
             })
             base_payload["filter"]["classifications"] = [
                 {"type": 4000, "codeList": ["001"]},
                 {"type": 4001, "codeList": ["001", "002", "003"]}
             ]
        else:
             # Filters for Finished Products
             base_payload["filter"]["branchInfo"].update({
                 "isFinishedProduct": True,
                 "isRawMaterial": False,
                 "isBulkMaterial": False,
                 "isOwnProduction": True,
             })
             if reference_code_list:
                  base_payload["filter"]["referenceCodeList"] = reference_code_list

        logger.debug(f"Generated ERP cost payload: {base_payload}")
        return base_payload
</file>

<file path="src/erp_integration/erp_fiscal_service.py">
# src/erp_integration/erp_fiscal_service.py
# Fetches Fiscal data (Invoices) raw data from the TOTVS ERP API, focusing on sync needs.

import requests
from typing import Optional, List, Dict, Any
from src.config import config
# Não precisa mais de modelos de domínio aqui, retorna dicionário bruto
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError # Custom errors

# Define the specific page size limit for this endpoint
ERP_FISCAL_PAGE_SIZE = 100 # ERP Limit

class ErpFiscalService:
    """
    Service to interact with the ERP's Fiscal endpoints, primarily focused on
    fetching raw invoice data for synchronization purposes.
    Handles direct communication, authentication, and basic error handling.
    Pagination logic is handled by the caller (e.g., FiscalSyncService).
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpFiscalService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        # Somente a URL de busca é necessária aqui para sync
        self.invoices_search_url = f"{self.base_url}{config.FISCAL_INVOICES_ENDPOINT}"
        self.xml_content_url_template = f"{self.base_url}{config.FISCAL_XML_ENDPOINT}/{{accessKey}}"
        self.danfe_search_url = f"{self.base_url}{config.FISCAL_DANFE_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE # Pode ser necessário para headers/filtros default
        logger.info("ErpFiscalService initialized (Refactored for Raw Data Fetch).")


    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None, stream: bool = False) -> requests.Response:
        """
        Internal helper to make requests to the Fiscal API, handling auth and retries.
        Returns the raw Response object.
        (This method remains largely the same as before, focusing on robust request execution)
        """
        attempt = 0
        last_exception: Optional[Exception] = None
        response: Optional[requests.Response] = None

        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP Fiscal API: {method} {url}")
            response = None
            status_code = None
            response_text_snippet = "N/A"

            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    "Accept": "application/json" if not stream else "*/*"
                    # Adicionar headers de empresa se a API TOTVS exigir
                    # "CompanyCode": str(self.company_code),
                    #"BranchCode": str(self.company_code),
                }

                timeout = 60 if stream else 45 # Increased timeout slightly

                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=timeout, stream=stream)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=timeout, stream=stream)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                status_code = response.status_code
                try:
                    response_text_snippet = response.text[:1000] if response.text else "(Empty Body)"
                except Exception as read_err:
                    response_text_snippet = f"(Error reading response body: {read_err})"

                logger.debug(f"ERP Response Status: {status_code}, Body Snippet: {response_text_snippet}")

                if status_code == 404:
                     logger.warning(f"ERP Fiscal API returned 404 Not Found for {method} {url}. Params/Payload: {params or json_payload}")
                     raise ErpNotFoundError(f"Resource not found in ERP for request {method} {url}.")

                if status_code == 401 and attempt <= self.max_retries:
                     logger.warning(f"ERP Fiscal API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                     self.erp_auth_service.invalidate_token()
                     last_exception = requests.exceptions.HTTPError(f"401 Client Error: Unauthorized for url: {url}", response=response)
                     continue # Retry

                # Check specific error patterns if needed (e.g., 400 with specific messages)
                if status_code == 400:
                    error_detail = response_text_snippet # Default
                    try:
                        error_json = response.json()
                        if isinstance(error_json, dict):
                           msg = error_json.get('message') or error_json.get('Message')
                           det_msg = error_json.get('detailedMessage') or error_json.get('DetailedMessage')
                           error_detail = f"{msg or 'Bad Request'} ({det_msg or response_text_snippet})"
                    except requests.exceptions.JSONDecodeError:
                        pass # Stick with the text snippet
                    logger.warning(f"ERP Fiscal API returned 400 Bad Request for {method} {url}. Detail: {error_detail}")
                    # Raise specific error that sync service might handle differently
                    raise ErpIntegrationError(f"ERP API returned Bad Request (400): {error_detail}", status_code=400)


                response.raise_for_status() # Raise other HTTP errors

                # Success
                return response

            except requests.exceptions.HTTPError as e:
                 logger.error(f"HTTP error {status_code} from ERP Fiscal API ({method} {url}): {e}. Response: {response_text_snippet}", exc_info=False)
                 last_exception = ErpIntegrationError(f"ERP Fiscal API request failed with status {status_code}: {response_text_snippet}", status_code=status_code)
                 break

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP Fiscal API ({method} {url}): {e}", exc_info=True)
                 last_exception = ErpIntegrationError(f"Network error connecting to ERP Fiscal API: {e}")
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying Fiscal API call after network error (Attempt {attempt}).")
                      continue # Retry
                 else:
                      break # Exhausted retries

            except ErpNotFoundError as e:
                 last_exception = e
                 raise e # Re-raise specific 404

            except ErpIntegrationError as e: # Catch 400 error raised above
                 last_exception = e
                 raise e # Re-raise

            except Exception as e:
                 logger.error(f"Unexpected error during ERP Fiscal API request ({method} {url}): {e}", exc_info=True)
                 error_msg = f"Unexpected error during ERP Fiscal API request: {e}"
                 if response:
                      error_msg += f" | Response Status: {status_code}, Response Snippet: {response_text_snippet}"
                 last_exception = ErpIntegrationError(error_msg)
                 break # Don't retry unexpected errors

        # If loop finishes
        log_message = f"Failed ERP Fiscal API request after {attempt} attempts: {method} {url}. LastError: {last_exception}"
        logger.error(log_message)
        if isinstance(last_exception, (ErpIntegrationError, ErpNotFoundError)):
            raise last_exception
        elif isinstance(last_exception, Exception):
            raise ErpIntegrationError(log_message) from last_exception
        else:
             raise ErpIntegrationError(f"Exhausted retries or failed for ERP Fiscal API request: {method} {url}")


    # --- Fetch Raw Data for a SINGLE Page ---
    def fetch_invoices_page(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Fetches a single page of raw invoice data from the ERP based on the payload.
        Handles JSON decoding and basic response validation.

        Args:
            payload: The full request payload for the ERP's /invoices/search endpoint,
                     including filter, expand, order, page, and pageSize.

        Returns:
            The raw JSON response dictionary from the ERP for the requested page.

        Raises:
            ErpIntegrationError: If the API call fails, returns non-JSON, or invalid structure.
            ErpNotFoundError: If the API returns 404 (though less likely for search).
        """
        logger.debug(f"Fetching raw ERP invoices page {payload.get('page')} with payload.")
        # Payload details are not logged here for brevity, but could be if needed
        # logger.debug(f"Payload: {payload}")

        try:
            response = self._make_request(self.invoices_search_url, method="POST", json_payload=payload)

            # Decode JSON response
            try:
                response_data = response.json()
            except requests.exceptions.JSONDecodeError as json_err:
                logger.error(f"Failed to decode JSON response for invoice fetch page {payload.get('page')}. Status: {response.status_code}, Error: {json_err}. Response Text: {response.text[:500]}")
                raise ErpIntegrationError(f"Received non-JSON response from ERP invoice search: {json_err}") from json_err

            # Basic validation of the expected structure
            if not isinstance(response_data, dict) or 'items' not in response_data or 'hasNext' not in response_data:
                logger.error(f"Invalid response structure received from ERP invoice search: {response_data}")
                raise ErpIntegrationError("Invalid response structure received from ERP invoice search.")

            logger.debug(f"Successfully fetched raw data for page {payload.get('page')}. Items: {len(response_data.get('items', []))}, HasNext: {response_data.get('hasNext')}")
            return response_data # Return the full raw dictionary

        except (ErpNotFoundError, ErpIntegrationError) as e:
             # Logged in _make_request, just re-raise
             raise e
        except Exception as e:
             logger.error(f"Unexpected error in fetch_invoices_page ERP call: {e}", exc_info=True)
             raise ErpIntegrationError(f"Unexpected error during ERP raw invoice fetch: {e}") from e

    # --- Methods for DANFE/XML (remain mostly the same as they fetch specific items) ---
    def get_xml_content_raw(self, access_key: str) -> Dict[str, Any]:
        """Gets the raw XML content response for a given access key."""
        logger.debug(f"Fetching raw ERP XML content for access key: ...{access_key[-6:]}")
        url = self.xml_content_url_template.format(accessKey=access_key)
        try:
            response = self._make_request(url, method="GET")
            try:
                 return response.json() # Return raw dict
            except requests.exceptions.JSONDecodeError as json_err:
                 logger.error(f"Failed to decode JSON for XML key ...{access_key[-6:]}. Status: {response.status_code}, Text: {response.text[:500]}")
                 raise ErpIntegrationError(f"Received non-JSON from ERP XML content: {json_err}") from json_err
        except (ErpNotFoundError, ErpIntegrationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Unexpected error fetching raw XML for key ...{access_key[-6:]}: {e}", exc_info=True)
            raise ErpIntegrationError(f"Unexpected error getting raw XML content: {e}") from e

    def get_danfe_from_xml_raw(self, xml_base64: str) -> Dict[str, Any]:
        """Requests the DANFE PDF raw response using the invoice XML."""
        logger.debug(f"Requesting raw DANFE response from ERP using provided XML...")
        # Create payload directly here or use a simple dict
        payload = {"mainInvoiceXml": xml_base64} # Add nfeDocumentType if needed
        try:
            response = self._make_request(self.danfe_search_url, method="POST", json_payload=payload)
            try:
                 return response.json() # Return raw dict
            except requests.exceptions.JSONDecodeError as json_err:
                 logger.error(f"Failed to decode JSON response for DANFE generation. Status: {response.status_code}, Text: {response.text[:500]}")
                 raise ErpIntegrationError(f"Received non-JSON response from ERP DANFE generation: {json_err}") from json_err
        except (ErpNotFoundError, ErpIntegrationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Unexpected error generating raw DANFE response: {e}", exc_info=True)
            raise ErpIntegrationError(f"Unexpected error generating raw DANFE response: {e}") from e
</file>

<file path="src/erp_integration/erp_person_service.py">
# src/erp_integration/erp_person_service.py
# Fetches Person (Individual, Legal Entity, Statistics) data from the TOTVS ERP API.

import requests
from typing import Optional, List, Dict, Any, Union
from src.config import config
from src.domain.person import IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from .erp_auth_service import ErpAuthService
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError, ErpNotFoundError # Custom errors

class ErpPersonService:
    """
    Service to interact with the ERP's Person related endpoints.
    Handles fetching individuals, legal entities, and statistics.
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpPersonService.

        Args:
            erp_auth_service: Instance of ErpAuthService for authentication.
        """
        self.erp_auth_service = erp_auth_service
        self.base_url = config.API_BASE_URL.rstrip('/')
        # Construct full URLs for endpoints
        self.individuals_url = f"{self.base_url}{config.INDIVIDUALS_ENDPOINT}"
        self.legal_entities_url = f"{self.base_url}{config.LEGAL_ENTITIES_ENDPOINT}"
        self.stats_url = f"{self.base_url}{config.PERSON_STATS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.company_code = config.COMPANY_CODE
        logger.info("ErpPersonService initialized.")

    def _make_request(self, url: str, method: str = "POST", params: Optional[Dict] = None, json_payload: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Internal helper to make requests to the Person API, handling auth and retries.

        Args:
            url: The full URL for the API endpoint.
            method: HTTP method ("GET" or "POST").
            params: Dictionary of query parameters for GET requests.
            json_payload: Dictionary payload for POST requests.

        Returns:
            The JSON response dictionary.

        Raises:
            ErpIntegrationError: If the request fails after retries.
            ErpNotFoundError: If the API returns a 404 status.
        """
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP Person API: {method} {url}")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                    # Add company code header if required by API - Check TOTVS docs
                    # "CompanyCode": str(self.company_code),
                    # "BranchCode": str(self.company_code), # Might be needed
                }

                response: requests.Response
                if method.upper() == "POST":
                    response = requests.post(url, json=json_payload, headers=headers, timeout=20)
                elif method.upper() == "GET":
                    response = requests.get(url, params=params, headers=headers, timeout=20)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")

                # Check for 404 specifically before raise_for_status
                if response.status_code == 404:
                     logger.warning(f"ERP Person API returned 404 Not Found for {method} {url}. Params/Payload: {params or json_payload}")
                     # Map 404 to a specific custom exception
                     raise ErpNotFoundError("Resource not found in ERP.")

                response.raise_for_status() # Raise HTTPError for other 4xx/5xx
                # Handle cases where API returns 200 but empty body or non-JSON
                try:
                     return response.json()
                except requests.exceptions.JSONDecodeError:
                     logger.error(f"Failed to decode JSON response from {method} {url}. Status: {response.status_code}, Response: {response.text[:200]}")
                     raise ErpIntegrationError("Received non-JSON response from ERP Person API.")


            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Person API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      # ErpNotFoundError is handled above
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP Person API ({method} {url}): {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP Person API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP Person API ({method} {url}): {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying Person API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP Person API after {attempt} attempts: {e}") from e

        logger.error(f"Exhausted retries for ERP Person API request: {method} {url}")
        raise ErpIntegrationError(f"Exhausted retries trying to reach ERP Person API: {method} {url}")

    def _search_person(self, url: str, filter_payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Helper to perform a search and return the first item found, or None."""
        payload = {
            "filter": filter_payload,
            "expand": "phones,addresses,emails", # Request nested details
            "page": 1,
            "pageSize": 1 # Only need the first match
        }
        try:
            response_data = self._make_request(url, method="POST", json_payload=payload)
            items = response_data.get('items', [])
            if items and isinstance(items, list):
                logger.debug(f"Found person item in ERP search at {url} with filter {filter_payload}.")
                return items[0] # Return the first item dictionary
            else:
                 logger.debug(f"No items found in ERP search at {url} with filter {filter_payload}.")
                 return None
        except ErpNotFoundError:
             logger.debug(f"ERP search returned 404 (Not Found) for filter {filter_payload} at {url}.")
             return None # Treat ERP 404 as None found
        # Let other ErpIntegrationErrors propagate up


    # --- Public Methods ---

    def get_individual_by_code(self, code: int) -> Optional[IndividualDataModel]:
        """Fetches an individual from ERP by their code."""
        logger.debug(f"Searching ERP for individual by code: {code}")
        item_dict = self._search_person(self.individuals_url, {"personCodeList": [code]})
        if item_dict:
             return IndividualDataModel.from_dict(item_dict)
        return None

    def get_legal_entity_by_code(self, code: int) -> Optional[LegalEntityDataModel]:
        """Fetches a legal entity from ERP by their code."""
        logger.debug(f"Searching ERP for legal entity by code: {code}")
        item_dict = self._search_person(self.legal_entities_url, {"personCodeList": [code]})
        if item_dict:
             return LegalEntityDataModel.from_dict(item_dict)
        return None

    def get_individual_by_cpf(self, cpf: str) -> Optional[IndividualDataModel]:
        """Fetches an individual from ERP by their CPF."""
        logger.debug(f"Searching ERP for individual by CPF: {cpf[-4:]}") # Log last 4 digits
        item_dict = self._search_person(self.individuals_url, {"cpfList": [cpf]})
        if item_dict:
             return IndividualDataModel.from_dict(item_dict)
        return None

    def get_legal_entity_by_cnpj(self, cnpj: str) -> Optional[LegalEntityDataModel]:
        """Fetches a legal entity from ERP by their CNPJ."""
        logger.debug(f"Searching ERP for legal entity by CNPJ: {cnpj[-4:]}") # Log last 4 digits
        item_dict = self._search_person(self.legal_entities_url, {"cnpjList": [cnpj]})
        if item_dict:
             return LegalEntityDataModel.from_dict(item_dict)
        return None

    def get_customer_statistics(self, customer_code: int, is_admin: bool) -> Optional[PersonStatisticsResponseModel]:
        """Fetches customer statistics from the ERP."""
        # Determine BranchCode based on admin status (as per original logic)
        # TODO: Clarify requirement - should non-admins see stats only for their branch?
        branch_code = 1 if is_admin else self.company_code # Assuming 1 is a default/global branch for admin
        logger.debug(f"Fetching ERP statistics for customer code: {customer_code}, Branch: {branch_code}")

        params = {
            "CustomerCode": customer_code,
            "BranchCode": branch_code
        }
        try:
            response_data = self._make_request(self.stats_url, method="GET", params=params)
            if response_data: # Ensure response is not empty
                return PersonStatisticsResponseModel.from_dict(response_data)
            else:
                 logger.warning(f"Received empty response for statistics for customer {customer_code}.")
                 return None # Or raise ErpNotFoundError? Treat empty as not found for now.
        except ErpNotFoundError:
             logger.warning(f"ERP statistics not found (404) for customer code: {customer_code}")
             return None # Map ERP 404 to None result
</file>

<file path="src/erp_integration/erp_product_service.py">
# src/erp_integration/erp_product_service.py
# Fetches generic product data (like fabric details) from the TOTVS ERP API.

from typing import List, Optional, Dict, Any
import requests
from src.config import config
from src.domain.fabric_details import FabricDetailsItem # Domain model for results
from .erp_auth_service import ErpAuthService # ERP Auth service
from src.utils.logger import logger
from src.api.errors import ErpIntegrationError # Custom error

class ErpProductService:
    """
    Service to interact with the ERP's generic product endpoint,
    used here specifically to fetch fabric details (width, grammage, etc.).
    """

    def __init__(self, erp_auth_service: ErpAuthService):
        """
        Initializes the ErpProductService.

        Args:
            erp_auth_service: Instance of ErpAuthService to get auth tokens.
        """
        self.erp_auth_service = erp_auth_service
        self.api_url = f"{config.API_BASE_URL.rstrip('/')}{config.PRODUCTS_ENDPOINT}"
        self.max_retries = config.MAX_RETRIES
        self.page_size = config.PAGE_SIZE
        self.company_code = config.COMPANY_CODE
        logger.info(f"ErpProductService initialized for URL: {self.api_url}")

    def get_fabric_details(self) -> Dict[int, FabricDetailsItem]:
        """
        Retrieves product details relevant to fabrics (width, grammage, shrinkage)
        from the ERP, handling pagination.

        Returns:
            A dictionary mapping product_code (int) to FabricDetailsItem objects.

        Raises:
            ErpIntegrationError: If communication with the ERP fails or the response is invalid.
        """
        all_details: Dict[int, FabricDetailsItem] = {}
        current_page = 1
        has_next = True

        logger.info("Starting ERP fabric details fetch.")

        while has_next:
            logger.debug(f"Fetching page {current_page} for fabric details...")
            try:
                payload = self._build_request_payload(current_page)
                response_data = self._make_api_request(payload)

                if not response_data or not isinstance(response_data, dict):
                    logger.warning(f"Received invalid product details response data for page {current_page}. Aborting fetch.")
                    break

                items_data = response_data.get('items', [])
                if not isinstance(items_data, list):
                     logger.warning(f"Invalid 'items' format in product details response page {current_page}. Expected list.")
                     items_data = []

                processed_count = 0
                for item_dict in items_data:
                     if isinstance(item_dict, dict):
                          details_item = FabricDetailsItem.from_product_api_item(item_dict)
                          if details_item:
                               all_details[details_item.product_code] = details_item
                               processed_count += 1
                     else:
                          logger.warning(f"Skipping non-dict item in product details response: {item_dict}")


                has_next = response_data.get('hasNext', False)
                total_pages = response_data.get('totalPages', 0)
                logger.debug(f"Fetched product details page {current_page}/{total_pages or '?'}. Processed Items: {processed_count}. HasNext: {has_next}")

                current_page += 1

                # Safety break
                if current_page > (total_pages + 5) and total_pages > 0:
                     logger.warning(f"Potential infinite loop detected in product details pagination. Stopping at page {current_page-1}.")
                     break
                if current_page > 500:
                     logger.warning(f"Reached absolute page limit (500) for product details fetch. Stopping.")
                     break

            except ErpIntegrationError as e:
                 logger.error(f"Failed to fetch page {current_page} for fabric details: {e}", exc_info=True)
                 raise e
            except Exception as e:
                 logger.error(f"Unexpected error fetching page {current_page} for fabric details: {e}", exc_info=True)
                 raise ErpIntegrationError(f"Unexpected error during fabric details fetch: {e}") from e

        logger.info(f"Finished ERP fabric details fetch. Total items retrieved: {len(all_details)}")
        return all_details

    def _make_api_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Makes the HTTP request to the ERP API, handling retries and auth."""
        attempt = 0
        while attempt <= self.max_retries:
            attempt += 1
            logger.debug(f"Attempt {attempt}/{self.max_retries + 1} to call ERP product API for details.")
            try:
                token = self.erp_auth_service.get_token()
                headers = {
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json",
                }
                response = requests.post(self.api_url, json=payload, headers=headers, timeout=30)
                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                 status_code = e.response.status_code
                 if status_code == 401 and attempt <= self.max_retries:
                      logger.warning(f"ERP Product API returned 401 (Attempt {attempt}). Invalidating token and retrying.")
                      self.erp_auth_service.invalidate_token()
                      continue
                 else:
                      response_text = e.response.text[:500]
                      logger.error(f"HTTP error {status_code} from ERP product API: {e}. Response: {response_text}", exc_info=True)
                      raise ErpIntegrationError(f"ERP product API request failed with status {status_code}: {response_text}") from e

            except requests.exceptions.RequestException as e:
                 logger.error(f"Network error connecting to ERP product API: {e}", exc_info=True)
                 if attempt <= self.max_retries:
                      logger.warning(f"Retrying product API call after network error (Attempt {attempt}).")
                      continue
                 else:
                      raise ErpIntegrationError(f"Network error connecting to ERP product API after {attempt} attempts: {e}") from e

        logger.error("Exhausted retries for ERP product API request.")
        raise ErpIntegrationError("Exhausted retries trying to reach ERP product API.")


    def _build_request_payload(self, page: int) -> Dict[str, Any]:
        """Constructs the JSON payload for the product details API request (fabric specific)."""

        # Payload specifically to get fabric details (width, grammage, shrinkage)
        payload = {
            "page": page,
            "pageSize": self.page_size,
            "order": "productCode", # Order by product code
            "expand": "additionalFields", # Crucial: Expand to get the details
            "filter": {
                "branchInfo": {
                    "branchCode": self.company_code,
                    "isActive": True,
                    # Filters specific to fabrics (raw materials)
                    "isFinishedProduct": False,
                    "isRawMaterial": True,
                    "isBulkMaterial": False,
                    "isOwnProduction": False,
                },
                # Fabric-specific classifications (same as in balance/cost)
                "classifications": [
                    {"type": 4000, "codeList": ["001"]},
                    {"type": 4001, "codeList": ["001", "002", "003"]}
                ]
            },
            "option": {
                # Specify which additional fields are needed by code
                "additionalFields": [
                    {"codeList": [1, 2, 3]}  # 1=Width, 2=Grammage, 3=Shrinkage
                ],
                 # Optionally include branch info code if needed, but might not be necessary if filtering by it
                 "branchInfoCode": self.company_code,
            }
        }

        logger.debug(f"Generated ERP product details payload: {payload}")
        return payload
</file>

<file path="src/erp_integration/README.md">
# src/erp_integration

Este diretório contém a camada responsável por toda a comunicação com a API externa do ERP TOTVS. O objetivo é isolar a complexidade da integração com o ERP do resto da aplicação.

## Arquivos

*   **`erp_accounts_receivable_service.py`**: Responsável por buscar dados de documentos de contas a receber e solicitar geração de boletos via API do ERP.
*   **`erp_auth_service.py`**: Gerencia a autenticação com a API do ERP, obtendo e renovando os tokens de acesso (Bearer tokens) necessários para as demais chamadas. Implementado como um Singleton thread-safe.
*   **`erp_balance_service.py`**: Responsável por buscar dados de saldo de produtos (acabados ou matérias-primas) do endpoint `/product/v2/balances/search` do ERP.
*   **`erp_cost_service.py`**: Responsável por buscar dados de custo de produtos do endpoint `/product/v2/costs/search` do ERP.
*   **`erp_person_service.py`**: Responsável por buscar dados de pessoas (PF/PJ) e estatísticas dos endpoints `/person/v2/*` do ERP.
*   **`erp_product_service.py`**: Responsável por buscar dados genéricos de produtos do endpoint `/product/v2/products/search` do ERP, usado especificamente aqui para obter detalhes adicionais de tecidos (largura, gramatura, etc.).
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Encapsular os detalhes da comunicação com a API do ERP (URLs, payloads, headers).
*   Utilizar o `ErpAuthService` para obter tokens de autenticação válidos.
*   Realizar chamadas HTTP (GET/POST) para os endpoints específicos do ERP.
*   Implementar lógica de retentativas (`MAX_RETRIES`) em caso de falhas de rede ou erros específicos (como 401 para token expirado).
*   Tratar erros de comunicação com o ERP e lançar exceções específicas (`ErpIntegrationError`, `ErpNotFoundError`) para a camada de serviço (`src/services`).
*   Mapear as respostas JSON do ERP para os modelos de domínio definidos em `src/domain` (ex: `ProductItem`, `CostResponse`, `IndividualDataModel`, `DocumentResponseModel`).
*   Gerenciar a paginação das APIs do ERP, buscando todas as páginas necessárias para retornar um conjunto completo de dados quando aplicável.

## Interações

*   **Camada de Serviço (`src/services`)**: Os serviços de negócio utilizam os serviços desta camada para obter dados do ERP.
*   **Configuração (`src/config`)**: Utiliza as configurações definidas em `settings.py` (URLs, credenciais, códigos, etc.).
*   **Domínio (`src/domain`)**: Recebe dados brutos do ERP e os transforma nos objetos de domínio definidos.
*   **API Errors (`src/api/errors`)**: Lança exceções customizadas definidas neste pacote em caso de erros específicos do ERP.
*   **Utils (`src/utils`)**: Utiliza o `logger` para registrar informações e erros.
</file>

<file path="src/services/__init__.py">
# src/services/__init__.py
# Makes 'services' a package. Exports service classes.

from .auth_service import AuthService
from .customer_service import CustomerService
from .fabric_service import FabricService
from .observation_service import ObservationService
from .product_service import ProductService
from .fiscal_service import FiscalService
from .accounts_receivable_service import AccountsReceivableService
from .fiscal_sync_service import FiscalSyncService # <<<--- ADDED

# Optionally initialize instances here if they are stateless singletons
# and don't require request context or specific configurations per request.
# However, it's often better to instantiate them in the app factory or inject them.

# Example (if needed, but prefer instantiation in app factory):
# auth_service_instance = AuthService(...)
# observation_service_instance = ObservationService(...)

__all__ = [
    "AuthService",
    "CustomerService",
    "FabricService",
    "ObservationService",
    "ProductService",
    "FiscalService",
    "AccountsReceivableService",
    "FiscalSyncService", # <<<--- ADDED
]
</file>

<file path="src/services/accounts_receivable_service.py">
# src/services/accounts_receivable_service.py
# Contém a lógica de negócios para o módulo de Contas a Receber.

import base64
from datetime import datetime, date
from typing import Dict, Any, List, Optional, Tuple, Set, Union
from src.erp_integration.erp_accounts_receivable_service import ErpAccountsReceivableService
from src.erp_integration.erp_person_service import ErpPersonService
from src.domain.accounts_receivable import (
    DocumentChangeModel, DocumentRequestModel, DocumentFilterModel, DocumentModel, DocumentResponseModel,
    BankSlipRequestModel, AccountsReceivableTomasResponseModel, FormattedReceivableListItem,
    CalculatedValuesModel, InvoiceDataModel
)
from src.domain.person import IndividualDataModel, LegalEntityDataModel
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError, ValidationError, ErpIntegrationError
from src.config import config
from src.utils.pdf_utils import decode_base64_to_bytes

class AccountsReceivableService:
    """
    Camada de serviço para lidar com operações de Contas a Receber.
    """
    def __init__(self,
                 erp_ar_service: ErpAccountsReceivableService,
                 erp_person_service: ErpPersonService):
        self.erp_ar_service = erp_ar_service
        self.erp_person_service = erp_person_service
        logger.info("AccountsReceivableService inicializado.")

    def _parse_and_validate_filters(self, raw_filters: Optional[Dict[str, Any]]) -> Optional[DocumentFilterModel]:
        """Analisa o dicionário de filtros brutos no DocumentFilterModel, realizando validação."""
        if not raw_filters or not isinstance(raw_filters, dict):
            return None

        filter_args: Dict[str, Any] = {}

        try:
            list_int_keys = {
                'branchCodeList': 'branch_code_list', 'customerCodeList': 'customer_code_list',
                'statusList': 'status_list', 'documentTypeList': 'document_type_list',
                'billingTypeList': 'billing_type_list', 'dischargeTypeList': 'discharge_type_list',
                'chargeTypeList': 'charge_type_list'
            }
            for raw_key, model_key in list_int_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, int) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de inteiros.")
                    if value:
                        filter_args[model_key] = value

            list_str_keys = {'customerCpfCnpjList': 'customer_cpf_cnpj_list'}
            for raw_key, model_key in list_str_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, str) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de strings.")
                    if value:
                        filter_args[model_key] = value

            list_float_keys = {'receivableCodeList': 'receivable_code_list', 'ourNumberList': 'our_number_list'}
            for raw_key, model_key in list_float_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, list) or not all(isinstance(x, (int, float)) for x in value):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser uma lista de números.")
                    if value:
                        filter_args[model_key] = [float(x) for x in value]

            date_keys = {
                'startExpiredDate': 'start_expired_date', 'endExpiredDate': 'end_expired_date',
                'startPaymentDate': 'start_payment_date', 'endPaymentDate': 'end_payment_date',
                'startIssueDate': 'start_issue_date', 'endIssueDate': 'end_issue_date',
                'startCreditDate': 'start_credit_date', 'endCreditDate': 'end_credit_date',
                'closingDateCommission': 'closing_date_commission'
            }
            for raw_key, model_key in date_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    try:
                        datetime.fromisoformat(str(value).replace('Z', '+00:00'))
                        filter_args[model_key] = str(value)
                    except (ValueError, TypeError):
                         raise ValidationError(f"Formato de data inválido para o filtro '{raw_key}': {value}. Use ISO 8601.")

            bool_keys = {'hasOpenInvoices': 'has_open_invoices'}
            for raw_key, model_key in bool_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, bool):
                        raise ValidationError(f"Filtro '{raw_key}' deve ser um booleano (true/false).")
                    filter_args[model_key] = value

            simple_int_keys = {
                'commissionedCode': 'commissioned_code', 'closingCodeCommission': 'closing_code_commission',
                'closingCompanyCommission': 'closing_company_commission', 'closingCommissionedCode': 'closing_commissioned_code'
            }
            for raw_key, model_key in simple_int_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, int): raise ValidationError(f"Filtro '{raw_key}' deve ser um inteiro.")
                    filter_args[model_key] = value

            simple_str_keys = {
                'commissionedCpfCnpj': 'commissioned_cpf_cnpj', 'closingCommissionedCpfCnpj': 'closing_commissioned_cpf_cnpj'
            }
            for raw_key, model_key in simple_str_keys.items():
                value = raw_filters.get(raw_key)
                if value is not None:
                    if not isinstance(value, str): raise ValidationError(f"Filtro '{raw_key}' deve ser uma string.")
                    filter_args[model_key] = value

            change_data = raw_filters.get('change')
            if change_data is not None:
                if not isinstance(change_data, dict):
                    raise ValidationError("Filtro 'change' deve ser um objeto.")
                change_model = DocumentChangeModel.from_dict(change_data)
                if change_model:
                    filter_args['change'] = change_model #

            # --- Instanciar o dataclass congelado UMA VEZ com todos os args ---
            if not filter_args:
                return None

            parsed = DocumentFilterModel(**filter_args)
            logger.debug(f"Filtros analisados: {parsed.to_dict()}")
            return parsed

        except ValidationError:
            raise
        except Exception as e:
            logger.error(f"Erro ao analisar filtros: {e}", exc_info=True)
            raise ValidationError(f"Formato de filtro inválido: {e}")


    def _fetch_customer_names(self, documents: List[DocumentModel]) -> Dict[int, str]:
        """Busca nomes para clientes únicos presentes na lista de documentos."""
        customer_ids: Set[int] = set()
        for doc in documents:
            if doc.customer_code:
                customer_ids.add(doc.customer_code)

        if not customer_ids:
            return {}

        logger.debug(f"Buscando nomes para {len(customer_ids)} códigos de cliente únicos.")
        names_map: Dict[int, str] = {}
        # Otimização Potencial: Requisição em lote para a API de Pessoas, se suportado.
        # Por enquanto, busca um por um. Considere adicionar cache aqui (nível de requisição ou mais longo).
        for code in customer_ids:
            name = "Nome Não Encontrado"
            try:
                person: Optional[Union[LegalEntityDataModel, IndividualDataModel]] = \
                    self.erp_person_service.get_legal_entity_by_code(code)
                if person:
                    name = person.name # Razao Social
                else:
                    person = self.erp_person_service.get_individual_by_code(code)
                    if person:
                        name = person.name

                names_map[code] = name

            except ErpIntegrationError as e:
                 logger.warning(f"Falha ao buscar nome para o código de cliente {code}: {e.message}")
            except Exception as e:
                 logger.error(f"Erro inesperado ao buscar nome para o código de cliente {code}: {e}", exc_info=True)

        logger.debug(f"Nomes buscados para {len(names_map)} clientes.")
        return names_map

    def _format_receivable_list_item(self, doc: DocumentModel, customer_names: Dict[int, str]) -> FormattedReceivableListItem:
        """Formata um único DocumentModel, aplicando lógica condicional para valores calculados."""

        # Obter número da nota fiscal
        invoice_number = None
        if doc.invoice and doc.invoice[0]:
             invoice_number = doc.invoice[0].invoice_code

        # Obter nome do cliente
        cust_name = customer_names.get(doc.customer_code, "Nome Indisponível") if doc.customer_code else "Cliente Inválido"

        # --- Determinar Status do Título ---
        is_paid = doc.discharge_type != 0 or doc.payment_date is not None
        is_overdue = False
        current_date = date.today() # Usa date para comparação com expired_date

        if doc.expired_date and not is_paid:
            try:
                # Extrai apenas a parte da data para comparação
                expired_dt = datetime.fromisoformat(doc.expired_date.split('T')[0]).date()
                is_overdue = expired_dt < current_date
            except (ValueError, TypeError):
                logger.warning(f"Não foi possível analisar expired_date: {doc.expired_date} para o doc {doc.receivable_code}/{doc.installment_code}")

        # --- Inicializar valores formatados ---
        days_late = None
        value_corrected = None
        increase = 0.0
        rebate = 0.0
        calc_vals: Optional[CalculatedValuesModel] = doc.calculated_values # Mantém referência

        # --- Aplicar Lógica Condicional baseada no Status ---
        # Usar valores calculados (calculateValue) se o título estiver aberto E vencido
        use_calculated_for_current = is_overdue and calc_vals is not None

        if use_calculated_for_current:
            # *** Usa calculateValue para títulos Abertos e Vencidos ***
            logger.debug(f"Doc {doc.receivable_code}/{doc.installment_code}: Usando calculateValue (Atualmente Vencido)")
            days_late = calc_vals.days_late
            value_corrected = calc_vals.corrected_value
            # Combina acréscimo/juros/multa de calculateValue
            increase = (calc_vals.increase_value or 0.0) + \
                       (calc_vals.interest_value or 0.0) + \
                       (calc_vals.fine_value or 0.0)
            # Usa desconto do contexto de calculateValue
            rebate = (calc_vals.discount_value or 0.0)

        else:
            # *** Usa campos diretos para títulos Pagos ou Ainda Não Vencidos ***
            logger.debug(f"Doc {doc.receivable_code}/{doc.installment_code}: Usando campos diretos (Pago ou Não Vencido)")
            # days_late e value_corrected permanecem None
            # Usa juros/acréscimos históricos registrados no próprio documento
            increase = (doc.interest_value or 0.0) + (doc.assessment_value or 0.0)
            # Usa abatimento/desconto históricos registrados no próprio documento
            rebate = (doc.rebate_value or 0.0) + (doc.discount_value or 0.0)

        # --- Formatar acréscimo/abatimento final (mostrar nulo se zero) ---
        value_increase = increase if increase > 0 else None
        value_rebate = rebate if rebate > 0 else None


        # --- Instanciar FormattedReceivableListItem ---
        return FormattedReceivableListItem(
            customer_code=doc.customer_code,
            customer_cpf_cnpj=doc.customer_cpf_cnpj,
            customer_name=cust_name,
            invoice_number=invoice_number,
            document_number=doc.receivable_code,
            installment_number=doc.installment_code,
            bearer_name=doc.bearer_name,
            issue_date=doc.issue_date,
            expired_date=doc.expired_date,
            payment_date=doc.payment_date,
            value_original=doc.installment_value,
            value_paid=doc.paid_value,
            # --- Usar valores calculados condicionalmente ---
            days_late=days_late,
            value_increase=value_increase,
            value_rebate=value_rebate,
            value_corrected=value_corrected,
            # --- Mapear outros campos ---
            status=doc.status,
            document_type=doc.document_type,
            billing_type=doc.billing_type,
            discharge_type=doc.discharge_type,
            charge_type=doc.charge_type
        )

    def search_receivables(self, raw_filters: Optional[Dict[str, Any]], page: int, page_size: int, expand: Optional[str], order: Optional[str]) -> Dict[str, Any]:
        """
        Busca por documentos de contas a receber, aplica filtro de filial padrão,
        enriquece com nomes de clientes e formata os resultados.
        """
        logger.info(f"Buscando contas a receber. Página: {page}, Tamanho: {page_size}, Filtros: {raw_filters is not None}, Expandir: {expand}, Ordem: {order}")

        if page < 1: page = 1
        if page_size < 1 or page_size > 100:
             logger.warning(f"Ajustando tamanho da página de {page_size} para 100 (limite da API).")
             page_size = 100

        # Sempre expandir calculateValue e invoice para os campos necessários
        expand_list = set(item.strip() for item in expand.split(',') if item.strip()) if expand else set()
        expand_list.add("calculateValue")
        expand_list.add("invoice")
        final_expand_str = ",".join(sorted(list(expand_list)))

        try:
            # 1. Analisar e Validar Filtros do Usuário
            parsed_user_filters = self._parse_and_validate_filters(raw_filters)

            # 2. *** Garantir que o Filtro de Código da Filial Esteja Presente ***
            filter_for_request: DocumentFilterModel
            default_branch = [config.COMPANY_CODE] # Usa código da empresa da config

            if parsed_user_filters is None:
                # Nenhum filtro fornecido pelo usuário, cria filtro apenas com filial padrão
                logger.debug("Nenhum filtro de usuário fornecido. Aplicando filtro de filial padrão.")
                filter_for_request = DocumentFilterModel(branch_code_list=default_branch)
            elif not parsed_user_filters.branch_code_list:
                # Usuário forneceu filtros, mas não branchCodeList. Adiciona filial padrão.
                logger.debug("Filtros de usuário fornecidos sem branchCodeList. Adicionando filtro de filial padrão.")
                # Como DocumentFilterModel é congelado, cria um novo mesclando
                # Importante: to_dict() retorna chaves em camelCase (formato API), mas precisamos de snake_case para o modelo
                filter_dict = parsed_user_filters.to_dict()

                # Convertendo de volta para snake_case para o DocumentFilterModel
                filter_args = {}
                # Mapeamentos de camelCase para snake_case (necessário para reconstruir o modelo)
                all_keys_map = {
                     'branchCodeList': 'branch_code_list', 'customerCodeList': 'customer_code_list',
                     'statusList': 'status_list', 'documentTypeList': 'document_type_list',
                     'billingTypeList': 'billing_type_list', 'dischargeTypeList': 'discharge_type_list',
                     'chargeTypeList': 'charge_type_list',
                     'customerCpfCnpjList': 'customer_cpf_cnpj_list',
                     'receivableCodeList': 'receivable_code_list', 'ourNumberList': 'our_number_list',
                     'startExpiredDate': 'start_expired_date', 'endExpiredDate': 'end_expired_date',
                     'startPaymentDate': 'start_payment_date', 'endPaymentDate': 'end_payment_date',
                     'startIssueDate': 'start_issue_date', 'endIssueDate': 'end_issue_date',
                     'startCreditDate': 'start_credit_date', 'endCreditDate': 'end_credit_date',
                     'closingDateCommission': 'closing_date_commission',
                     'hasOpenInvoices': 'has_open_invoices',
                     'commissionedCode': 'commissioned_code', 'closingCodeCommission': 'closing_code_commission',
                     'closingCompanyCommission': 'closing_company_commission', 'closingCommissionedCode': 'closing_commissioned_code',
                     'commissionedCpfCnpj': 'commissioned_cpf_cnpj', 'closingCommissionedCpfCnpj': 'closing_commissioned_cpf_cnpj'
                 }

                for camel_key, snake_key in all_keys_map.items():
                    if camel_key in filter_dict:
                        filter_args[snake_key] = filter_dict[camel_key]

                # Tratar a chave 'change' separadamente, pois é um objeto
                if 'change' in filter_dict and filter_dict['change']:
                    filter_args['change'] = DocumentChangeModel.from_dict(filter_dict['change'])
                filter_args['branch_code_list'] = default_branch
                filter_for_request = DocumentFilterModel(**filter_args)
            else:
                logger.debug("Usuário forneceu branchCodeList nos filtros.")
                filter_for_request = parsed_user_filters

            # 3. Preparar Payload da Requisição ERP usando o filtro garantido
            request_payload = DocumentRequestModel(
                filter=filter_for_request,
                expand=final_expand_str,
                order=order,
                page=page,
                page_size=page_size
            )

            # 4. Chamar Serviço ERP
            erp_response_dict = self.erp_ar_service.search_documents(request_payload.to_dict())

            # 5. Analisar Resposta ERP
            erp_response = DocumentResponseModel.from_dict(erp_response_dict)
            if not erp_response:
                raise ServiceError("Falha ao analisar a resposta do ERP para a busca de contas a receber.")

            # 6. Buscar Nomes dos Clientes
            customer_names = self._fetch_customer_names(erp_response.items)

            # 7. Formatar Resultados
            formatted_items = [self._format_receivable_list_item(doc, customer_names) for doc in erp_response.items]

            # 8. Construir Resposta Final da API
            result = {
                "items": [item.to_dict() for item in formatted_items],
                "page": page,
                "pageSize": page_size,
                "totalItems": erp_response.total_items,
                "totalPages": erp_response.total_pages,
                "hasNext": erp_response.has_next
            }
            logger.info(f"Buscou e formatou com sucesso {len(formatted_items)} contas a receber para a página {page}. Total: {erp_response.total_items}")
            return result

        except (ValidationError, NotFoundError) as e:
            logger.warning(f"Busca de contas a receber falhou: {e}")
            raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integração com o ERP durante a busca de contas a receber: {e}", exc_info=False)
             raise ServiceError(f"Falha ao comunicar com o ERP para a busca de contas a receber: {e.message}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar contas a receber: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao buscar contas a receber: {e}") from e

    def generate_boleto_pdf(self, request_data: Dict[str, Any]) -> bytes:
        """
        Gera o PDF do Boleto Bancário para uma parcela específica de contas a receber.
        """
        logger.info(f"Requisição para gerar PDF do boleto recebida: {request_data}")

        required = ['branchCode', 'customerCode', 'receivableCode', 'installmentNumber']
        missing = [field for field in required if field not in request_data]
        if missing:
            raise ValidationError(f"Campos obrigatórios ausentes para geração do boleto: {', '.join(missing)}")

        try:
            boleto_request = BankSlipRequestModel(
                branch_code=int(request_data['branchCode']),
                customer_code=int(request_data['customerCode']),
                receivable_code=int(request_data['receivableCode']),
                installment_number=int(request_data['installmentNumber']),
                customer_cpf_cnpj=request_data.get('customerCpfCnpj')
            )
        except (ValueError, TypeError) as e:
            raise ValidationError(f"Tipo de dado inválido nos parâmetros da requisição do boleto: {e}")


        try:
            # 1. Chamar Serviço ERP
            erp_response_dict = self.erp_ar_service.get_bank_slip(boleto_request.to_dict())

            # 2. Analisar Resposta ERP
            tomas_response = AccountsReceivableTomasResponseModel.from_dict(erp_response_dict)
            if not tomas_response:
                 raise ServiceError("Falha ao analisar a resposta do ERP para a geração do boleto.")

            status_lower = tomas_response.uniface_response_status.lower() if tomas_response.uniface_response_status else ""
            if tomas_response.uniface_response_status and status_lower not in ('ok', 'success'):
                 err_msg = tomas_response.uniface_message or "Erro desconhecido do Uniface"
                 logger.error(f"Geração do boleto falhou no Uniface. Status: {tomas_response.uniface_response_status}, Mensagem: {err_msg}")
                 raise ServiceError(f"Geração do boleto falhou no ERP ({tomas_response.uniface_response_status}): {err_msg}")

            # 3. Extrair Conteúdo Base64
            pdf_base64 = tomas_response.content
            if not pdf_base64:
                logger.error("Resposta do ERP para geração do boleto está sem o 'content' (PDF Base64). Status foi: %s", tomas_response.uniface_response_status)
                raise NotFoundError("O PDF do boleto não pôde ser gerado pelo ERP (conteúdo ausente).")

            # 4. Decodificar Base64 para Bytes
            pdf_bytes = decode_base64_to_bytes(pdf_base64)
            logger.info("PDF do Boleto gerado e decodificado com sucesso.")
            return pdf_bytes

        except (ValidationError, NotFoundError) as e:
            logger.warning(f"Geração do boleto falhou: {e}")
            raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integração com o ERP durante a geração do boleto: {e}", exc_info=False)
             raise ServiceError(f"Falha na comunicação com o ERP durante a geração do boleto: {e.message}") from e
        except ServiceError as e:
             raise e
        except Exception as e:
            logger.error(f"Erro inesperado ao gerar PDF do boleto: {e}", exc_info=True)
            if isinstance(e, ServiceError):
                raise
            else:
                raise ServiceError(f"Ocorreu um erro inesperado ao gerar o boleto: {e}") from e
</file>

<file path="src/services/auth_service.py">
# src/services/auth_service.py
# Handles user authentication, token generation/verification, and current user retrieval.

import jwt
from datetime import datetime, timedelta, timezone
from flask import current_app, request, session
from typing import Tuple, Optional, Dict, Any

from src.domain.user import User
from src.database.user_repository import UserRepository
from src.database import get_db_session

from src.utils.logger import logger
from src.api.errors import AuthenticationError, InvalidTokenError, ExpiredTokenError, DatabaseError, ConfigurationError

class AuthService:
    """
    Service layer for user authentication and authorization token management using ORM.
    """

    def __init__(self, user_repository: UserRepository):
        """
        Initializes the AuthService.

        Args:
            user_repository: Instance of UserRepository.
        """
        self.user_repository = user_repository
        logger.info("AuthService initialized (ORM).")

    def login(self, username: str, password: str) -> Tuple[str, Dict[str, Any]]:
        """
        Authenticates a user, updates last login, and generates a JWT token.
        Uses a database session.

        Args:
            username: The user's username.
            password: The user's password.

        Returns:
            A tuple containing: (jwt_token, user_data_dict).

        Raises:
            AuthenticationError: If login fails due to invalid credentials or inactive user.
            DatabaseError: If a database issue occurs during user lookup or update.
        """
        logger.debug(f"Tentando login para usuário: {username}")

        try:
            with get_db_session() as db:
                user = self.user_repository.find_by_username(db, username)

                if not user:
                    logger.warning(f"Login falhou: Usuário '{username}' não encontrado ou inativo.")
                    raise AuthenticationError("Invalid username or password.")

                if not user.is_active:
                    logger.warning(f"Login falhou: Usuário '{username}' está inativo.")
                    raise AuthenticationError("User account is inactive.")

                if not user.verify_password(password):
                    logger.warning(f"Login falhou: Senha incorreta para usuário '{username}'.")
                    raise AuthenticationError("Invalid username or password.")

                self.user_repository.update_last_login(db, user.id)

                logger.info(f"Login bem-sucedido para usuário '{username}' (ID: {user.id}). Gerando token.")
                token = self._generate_token(user)

                user_data = user.to_dict(include_hash=False)

                session['token'] = token

                return token, user_data

        except (AuthenticationError, DatabaseError):
            raise
        except Exception as e:
            logger.error(f"Erro durante processamento pós-login para usuário '{username}': {e}", exc_info=True)
            raise AuthenticationError("Login process failed after authentication.") from e


    def _generate_token(self, user: User) -> str:
        """Generates a JWT token for the given user."""
        if not user or user.id is None:
            logger.error(f"Não é possível gerar token: Objeto de usuário inválido fornecido. Usuário: {user}")
            raise ValueError("Valid user object with ID required to generate token.")

        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
             logger.critical("Chave Secreta JWT não está configurada!")
             raise ConfigurationError("JWT Secret Key is missing.")

        expiration_hours = current_app.config.get('TOKEN_EXPIRATION_HOURS', 24)
        expiration_time = datetime.now(timezone.utc) + timedelta(hours=expiration_hours)

        perms_payload = {}
        if user.permissions:
             perms_payload = {
                  'adm': user.permissions.is_admin,
                  'prod': user.permissions.can_access_products,
                  'fab': user.permissions.can_access_fabrics,
                  'cust': user.permissions.can_access_customer_panel,
                  'fisc': user.permissions.can_access_fiscal,
                  'ar': user.permissions.can_access_accounts_receivable,
             }

        payload = {
            'user_id': user.id,
            'username': user.username,
            'perms': perms_payload,
            'exp': expiration_time,
            'iat': datetime.now(timezone.utc)
        }
        logger.debug(f"Gerando token JWT para usuário {user.id} com payload: {payload}")
        try:
            token = jwt.encode(payload, secret_key, algorithm='HS256')
            return token
        except Exception as e:
            logger.error(f"Falha ao codificar token JWT: {e}", exc_info=True)
            raise RuntimeError("Failed to generate authentication token.") from e

    def verify_token(self, token: str) -> Dict[str, Any]:
        """
        Verifies a JWT token and returns its payload.
        """
        secret_key = current_app.config.get('SECRET_KEY')
        if not secret_key:
             logger.critical("Chave Secreta JWT não está configurada!")
             raise ConfigurationError("JWT Secret Key is missing.")

        try:
            payload = jwt.decode(
                token,
                secret_key,
                algorithms=['HS256']
            )
            logger.debug(f"Token verificado com sucesso para user_id: {payload.get('user_id')}")
            return payload
        except jwt.ExpiredSignatureError:
            logger.warning(f"Verificação de token falhou: Token expirado. Token: {token[:10]}...")
            raise ExpiredTokenError("Authentication token has expired.")
        except jwt.InvalidTokenError as e:
            logger.warning(f"Verificação de token falhou: Token inválido. Erro: {e}. Token: {token[:10]}...")
            raise InvalidTokenError(f"Invalid authentication token: {e}")
        except Exception as e:
            logger.error(f"Erro inesperado durante verificação de token: {e}", exc_info=True)
            raise InvalidTokenError(f"Token verification failed due to an unexpected error: {e}")

    def get_current_user_from_request(self) -> Optional[User]:
        """
        Retrieves the currently authenticated user based on the token
        found in the request headers or session, using a database session.

        Returns:
            The User object if authenticated and active, otherwise None.
        """
        token = None
        auth_header = request.headers.get('Authorization')
        if auth_header and auth_header.startswith('Bearer '):
            token = auth_header.split(' ')[1]
        else:
            token = session.get('token')

        if not token:
            logger.debug("Nenhum token de autenticação encontrado no cabeçalho da requisição ou na sessão.")
            return None

        try:
            payload = self.verify_token(token)
            user_id = payload.get('user_id')
            if not user_id:
                 logger.warning("Payload de token inválido: 'user_id' ausente.")
                 return None

            with get_db_session() as db:
                user = self.user_repository.find_by_id(db, user_id)

                if not user:
                    logger.warning(f"Token válido, mas usuário com ID {user_id} não encontrado no banco de dados.")
                    return None
                if not user.is_active:
                    logger.warning(f"Token válido, mas usuário {user.username} (ID: {user_id}) está inativo.")
                    return None

                logger.debug(f"Usuário autenticado recuperado: {user.username} (ID: {user.id})")
                return user

        except (ExpiredTokenError, InvalidTokenError) as e:
            logger.debug(f"Verificação de token falhou ao obter usuário atual: {e}")
            if 'token' in session: session.pop('token')
            return None
        except DatabaseError as e:
            logger.error(f"Erro de banco de dados ao recuperar usuário atual (ID: {user_id}): {e}", exc_info=True)
            return None
        except Exception as e:
             logger.error(f"Erro inesperado ao recuperar usuário atual: {e}", exc_info=True)
             return None

    def logout(self):
         """Logs out the current user by clearing the session token."""
         if 'token' in session:
              session.pop('token')
              logger.info("Usuário deslogado, token de sessão removido.")
              return True
         logger.debug("Logout chamado mas nenhum token de sessão encontrado.")
         return False
</file>

<file path="src/services/customer_service.py">
from typing import Optional, Dict, Any, Union, List
from src.domain.person import IndividualDataModel, LegalEntityDataModel, PersonStatisticsResponseModel
from src.erp_integration.erp_person_service import ErpPersonService
from src.utils.logger import logger
from src.api.errors import NotFoundError, ServiceError, ValidationError

class CustomerService:
    def __init__(self, erp_person_service: ErpPersonService):
        self.erp_person_service = erp_person_service
        logger.info("CustomerService inicializado.")

    def get_customer_details(self, search_term: str, search_type: Optional[str] = None) -> Dict[str, Any]:
        logger.debug(f"Buscando detalhes do cliente para: '{search_term}', tipo: {search_type}")
        search_term = str(search_term).strip()
        customer_data: Optional[Union[IndividualDataModel, LegalEntityDataModel]] = None
        customer_type: str = ""

        try:
            if search_term.isdigit() and len(search_term) <= 9:
                if not search_type or search_type.upper() not in ("PF", "PJ"):
                    raise ValidationError("O campo 'search_type' ('PF' ou 'PJ') é obrigatório ao buscar por código.")
                customer_type = search_type.upper()
                customer_code = int(search_term)
                if customer_type == "PF":
                    customer_data = self.erp_person_service.get_individual_by_code(customer_code)
                else:
                    customer_data = self.erp_person_service.get_legal_entity_by_code(customer_code)

            elif len(search_term) == 11 and search_term.isdigit():
                customer_type = "PF"
                customer_data = self.erp_person_service.get_individual_by_cpf(search_term)
            elif len(search_term) == 14 and search_term.isdigit():
                customer_type = "PJ"
                customer_data = self.erp_person_service.get_legal_entity_by_cnpj(search_term)
            else:
                raise ValidationError("Formato inválido para 'search_term'. Deve ser Código (com tipo 'PF'/'PJ'), CPF (11 dígitos) ou CNPJ (14 dígitos).")

            if not customer_data:
                logger.warning(f"Cliente não encontrado para: '{search_term}', tipo: {search_type}")
                raise NotFoundError("Cliente não encontrado.")

            formatted_response = self._format_customer_data(customer_data, customer_type)
            logger.info(f"Detalhes do cliente obtidos com sucesso: {customer_data.code}")
            return formatted_response

        except (NotFoundError, ValidationError) as e:
            raise e
        except Exception as e:
            logger.error(f"Erro ao buscar detalhes do cliente '{search_term}': {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar detalhes do cliente: {e}") from e

    def get_customer_statistics(self, customer_code: int, is_admin: bool) -> Dict[str, Any]:
        logger.debug(f"Buscando estatísticas para o cliente: {customer_code}")
        try:
            statistics_data = self.erp_person_service.get_customer_statistics(customer_code, is_admin)

            if not statistics_data:
                logger.warning(f"Estatísticas não encontradas para o cliente: {customer_code}")
                raise NotFoundError(f"Estatísticas não encontradas para o cliente {customer_code}.")

            formatted_statistics = self._format_statistics(statistics_data)
            logger.info(f"Estatísticas do cliente obtidas com sucesso: {customer_code}")
            return formatted_statistics

        except NotFoundError:
            raise
        except Exception as e:
            logger.error(f"Erro ao buscar estatísticas do cliente {customer_code}: {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar estatísticas do cliente: {e}") from e

    def _format_customer_data(self, customer: Union[IndividualDataModel, LegalEntityDataModel], customer_type: str) -> Dict[str, Any]:
        common_data = {
            "code": customer.code,
            "status": "Inativo" if customer.is_inactive else "Ativo",
            "registered_at": customer.insert_date,
            "address": self._format_address(customer.addresses),
            "phones": self._format_phones(customer.phones),
            "emails": self._format_emails(customer.emails),
            "is_customer": getattr(customer, 'is_customer', None),
            "is_supplier": getattr(customer, 'is_supplier', None),
        }

        if customer_type == "PF" and isinstance(customer, IndividualDataModel):
            return {**common_data, "customer_type": "PF", "name": customer.name, "cpf": customer.cpf, "rg": customer.rg, "rg_issuer": customer.rg_federal_agency, "birth_date": customer.birth_date, "is_employee": customer.is_employee, "registered_by_branch": customer.branch_insert_code}
        elif customer_type == "PJ" and isinstance(customer, LegalEntityDataModel):
            return {**common_data, "customer_type": "PJ", "legal_name": customer.name, "trade_name": customer.fantasy_name, "cnpj": customer.cnpj, "state_registration": customer.number_state_registration, "state_registration_uf": customer.uf, "foundation_date": customer.date_foundation, "share_capital": customer.share_capital, "is_representative": customer.is_representative}
        else:
            logger.error(f"Inconsistência entre tipo '{customer_type}' e tipo de dados '{type(customer)}'")
            raise ServiceError("Erro interno ao formatar os dados do cliente.")

    def _format_address(self, addresses: List[Any]) -> Optional[Dict[str, Any]]:
        if not addresses:
            return None
        valid_addresses = [addr for addr in addresses if addr is not None]
        if not valid_addresses:
            return None
        default_address = next((addr for addr in valid_addresses if addr.is_default), None)
        address_to_format = default_address or valid_addresses[0]
        street = f"{address_to_format.public_place or ''} {address_to_format.address or ''}".strip()
        return {"street": street or None, "number": address_to_format.address_number, "neighborhood": address_to_format.neighborhood, "city": address_to_format.city_name, "state": address_to_format.state_abbreviation, "zip_code": address_to_format.cep, "type": address_to_format.address_type, "complement": address_to_format.complement, "reference": address_to_format.reference}

    def _format_phones(self, phones: List[Any]) -> List[Dict[str, Any]]:
        return [{"number": phone.number, "type": phone.type_name, "is_default": phone.is_default} for phone in phones if phone and hasattr(phone, 'number')]

    def _format_emails(self, emails: List[Any]) -> List[Dict[str, Any]]:
        return [{"email": email.email, "type": email.type_name, "is_default": email.is_default} for email in emails if email and hasattr(email, 'email')]

    def _format_statistics(self, statistics: PersonStatisticsResponseModel) -> Dict[str, Any]:
        return {"average_delay_days": statistics.average_delay, "max_delay_days": statistics.maximum_delay, "total_overdue_value": statistics.total_installments_delayed, "overdue_installments_count": statistics.quantity_installments_delayed, "total_purchases_count": statistics.purchase_quantity, "total_purchases_value": statistics.total_purchase_value, "average_purchase_value": statistics.average_purchase_value}
</file>

<file path="src/services/fabric_service.py">
import time
from typing import List, Dict, Any, Optional
from cachetools import TTLCache, cached

from src.domain.balance import ProductItem as BalanceItem # Alias para clareza
from src.domain.cost import ProductCost
from src.domain.fabric_details import FabricDetailsItem
from src.erp_integration.erp_balance_service import ErpBalanceService
from src.erp_integration.erp_cost_service import ErpCostService
from src.erp_integration.erp_product_service import ErpProductService # Para detalhes do tecido
from src.utils.fabric_list_builder import build_fabric_list, filter_fabric_list # Importar construtores
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError

# Configuração do cache: TTL de 10 minutos, máximo de 10 entradas
# Observação: Este cache é específico para a instância. Se várias instâncias forem executadas, os caches são separados.
fabric_data_cache = TTLCache(maxsize=10, ttl=600) # 600 segundos = 10 minutos

# Função auxiliar para geração de chave de cache (lida com filtro None)
def _get_cache_key(search_filter: Optional[str]) -> str:
    return f"filter:{search_filter or '_NONE_'}"

class FabricService:
    """
    Camada de serviço para operações relacionadas a tecidos (matéria-prima).
    Busca dados no ERP, combina e fornece listas formatadas com cache.
    """
    def __init__(self,
                 erp_balance_service: ErpBalanceService,
                 erp_cost_service: ErpCostService,
                 erp_product_service: ErpProductService):
        self.erp_balance_service = erp_balance_service
        self.erp_cost_service = erp_cost_service
        self.erp_product_service = erp_product_service # Injeta serviço de produtos para detalhes
        logger.info("FabricService inicializado.")

    def clear_fabric_cache(self):
        """Limpa o cache de dados de tecidos."""
        logger.info("Limpando o cache de dados de tecidos.")
        fabric_data_cache.clear()

    def get_fabrics(self, search_filter: Optional[str] = None, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """
        Recupera uma lista de tecidos (matérias-primas) com saldo, custo e detalhes,
        usando cache e opcionalmente filtrada por um termo de pesquisa.

        Args:
            search_filter: Texto para filtrar tecidos pela descrição (case-insensitive).
                           O filtro ocorre APÓS a busca e cacheamento.
            force_refresh: Se True, ignora o cache e busca dados frescos.

        Returns:
            Uma lista de dicionários, cada um representando um tecido com seus dados.

        Raises:
            ServiceError: Se ocorrer um erro na recuperação ou processamento dos dados.
            NotFoundError: Se nenhum tecido for encontrado no ERP.
        """
        cache_key = _get_cache_key(search_filter) # Usa o filtro na chave do cache
        log_prefix = f"tecidos (Filtro: '{search_filter or 'Nenhum'}', Forçar: {force_refresh})"
        logger.info(f"Buscando {log_prefix}...")

        if not force_refresh and cache_key in fabric_data_cache:
            logger.info(f"Cache encontrado para chave '{cache_key}'. Retornando dados em cache.")
            return list(fabric_data_cache[cache_key])

        logger.info(f"Cache ausente ou force_refresh=True para chave '{cache_key}'. Buscando dados do ERP.")
        try:
            full_fabric_list_unfiltered = self._fetch_and_build_fabrics()
            unfiltered_cache_key = _get_cache_key(None)
            fabric_data_cache[unfiltered_cache_key] = full_fabric_list_unfiltered
            logger.info(f"Armazenados {len(full_fabric_list_unfiltered)} tecidos no cache com chave '{unfiltered_cache_key}'.")

            if search_filter:
                logger.debug(f"Aplicando filtro no cliente: '{search_filter}'")
                filtered_list = filter_fabric_list(full_fabric_list_unfiltered, search_filter)
                logger.info(f"Lista de tecidos filtrada de {len(full_fabric_list_unfiltered)} para {len(filtered_list)} itens.")
                return filtered_list
            else:
                return full_fabric_list_unfiltered

        except NotFoundError:
            logger.warning(f"Nenhum tecido encontrado no ERP para {log_prefix}.")
            raise
        except Exception as e:
            logger.error(f"Erro ao recuperar {log_prefix}: {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar a lista de tecidos: {e}") from e

    def _fetch_and_build_fabrics(self) -> List[Dict[str, Any]]:
        """Método interno para buscar dados do ERP e construir a lista de tecidos."""
        logger.debug("Buscando saldos de tecidos no ERP...")
        fabric_balances: List[BalanceItem] = self.erp_balance_service.get_balances(is_fabric=True)
        logger.debug(f"Obtidos {len(fabric_balances)} itens de saldo para tecidos.")

        if not fabric_balances:
            raise NotFoundError("Nenhum tecido encontrado no sistema ERP.")

        logger.debug("Buscando custos de tecidos no ERP...")
        fabric_costs: List[ProductCost] = self.erp_cost_service.get_costs(is_fabric=True)
        logger.debug(f"Obtidos {len(fabric_costs)} itens de custo para tecidos.")

        logger.debug("Buscando detalhes dos tecidos (largura, gramatura, etc.) no ERP...")
        fabric_details_map: Dict[int, FabricDetailsItem] = self.erp_product_service.get_fabric_details()
        logger.debug(f"Obtidos detalhes de {len(fabric_details_map)} tecidos.")

        logger.debug("Construindo lista de tecidos...")
        full_fabric_list = build_fabric_list(fabric_balances, fabric_costs, fabric_details_map)
        logger.debug(f"Lista de tecidos construída com {len(full_fabric_list)} itens.")

        return full_fabric_list
</file>

<file path="src/services/fiscal_service.py">
# src/services/fiscal_service.py
# Contém lógica de negócio para o módulo Fiscal, agora lendo do DB local e gerando DANFE via ERP.

import base64
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple

# --- Serviços ERP (Necessário para DANFE/XML) ---
from src.erp_integration.erp_fiscal_service import ErpFiscalService

# --- Repositório Local e Session Manager ---
from src.database import get_db_session
from src.database.fiscal_repository import FiscalRepository

# --- Modelos ORM e DTOs ---
from src.domain.fiscal_orm import NotaFiscalOrm
from src.domain.fiscal import (
    FormattedInvoiceListItem, InvoiceXmlOutDto, DanfeResponseModel
)

# --- Utilitários e Erros ---
from src.utils.logger import logger
from src.utils.pdf_utils import decode_base64_to_bytes
from src.api.errors import ErpIntegrationError, ServiceError, NotFoundError, ValidationError, DatabaseError
from src.config import config
from sqlalchemy.exc import SQLAlchemyError

# Páginação padrão para busca local
LOCAL_FISCAL_PAGE_SIZE = 50

class FiscalService:
    """
    Service layer for handling fiscal operations.
    - Searches invoices from the LOCAL database (synced from ERP).
    - Generates DANFE PDF by fetching necessary data from ERP.
    """
    def __init__(self, fiscal_repository: FiscalRepository, erp_fiscal_service: ErpFiscalService):
        """
        Initializes the FiscalService.

        Args:
            fiscal_repository: Repository for accessing local fiscal data (ORM).
            erp_fiscal_service: Service for interacting with ERP for DANFE/XML.
        """
        self.fiscal_repository = fiscal_repository
        self.erp_fiscal_service = erp_fiscal_service
        logger.info("Serviço Fiscal inicializado (usando DB local para busca).")

    # --- Search Invoices (Local Database) ---
    def search_invoices(self, filters: Dict[str, Any], page: int = 1, page_size: int = LOCAL_FISCAL_PAGE_SIZE) -> Dict[str, Any]:
        """
        Searches for invoices in the LOCAL database based on filters and formats the results.

        Args:
            filters: Dictionary of filter criteria (keys should ideally match NotaFiscalOrm attributes or be mapped).
            page: Page number (starting from 1).
            page_size: Number of items per page.

        Returns:
            A dictionary containing the paginated list of formatted invoices.

        Raises:
            ValidationError: If filter validation fails (implementation needed).
            DatabaseError: If a database error occurs.
            ServiceError: For unexpected errors.
        """
        logger.info(f"Buscando notas fiscais no banco local com filtros: {filters}, Página: {page}, Itens por página: {page_size}")

        # Clamp page size (optional, based on preference for local search)
        if page_size < 1: page_size = LOCAL_FISCAL_PAGE_SIZE

        validated_filters = filters

        try:
            with get_db_session() as db:
                # Use the local repository search method
                invoice_orms, total_count = self.fiscal_repository.find_invoices_local(
                    db, validated_filters, page, page_size
                )

            # Format the ORM results into the desired API structure
            formatted_items = [self._format_invoice_list_item(orm) for orm in invoice_orms]

            total_pages = (total_count + page_size - 1) // page_size if page_size > 0 else 0

            result = {
                "items": formatted_items,
                "page": page,
                "pageSize": page_size,
                "totalItems": total_count,
                "totalPages": total_pages
            }
            logger.info(f"Busca concluída com sucesso. Encontrados {len(formatted_items)} notas fiscais para página {page}. Total de Itens: {total_count}")
            return result

        except ValidationError as e:
             logger.warning(f"Falha na validação dos filtros durante busca de notas fiscais: {e}")
             raise e
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Erro de banco de dados durante busca de notas fiscais: {e}", exc_info=True)
            raise DatabaseError("Falha ao recuperar notas fiscais do banco de dados local.") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar ou processar notas fiscais locais: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado durante a busca de notas fiscais: {e}") from e

    def _format_invoice_list_item(self, nf_orm: NotaFiscalOrm) -> Dict[str, Any]:
        """Formats a NotaFiscalOrm object into the desired list structure."""
        if not nf_orm:
            return {}

        # Get sales order code (handle potential absence of relationship data)
        sales_order_code = None
        try:
            if nf_orm.sales_orders and nf_orm.sales_orders[0]:
                 sales_order_code = nf_orm.sales_orders[0].order_code
        except Exception as rel_err:
            logger.warning(f"Não foi possível acessar relação sales_orders para NF {nf_orm.id}: {rel_err}")

        # Use the FormattedInvoiceListItem dataclass for structure and conversion
        formatted = FormattedInvoiceListItem(
            status=nf_orm.electronic_invoice_status,
            recipient_name=nf_orm.person_name,
            sales_order_code=sales_order_code,
            invoice_number=nf_orm.invoice_code,
            invoice_series=nf_orm.serial_code,
            issue_date=nf_orm.issue_date.isoformat() if nf_orm.issue_date else (nf_orm.invoice_date.isoformat() if nf_orm.invoice_date else None),
            total_value=float(nf_orm.total_value) if nf_orm.total_value is not None else None,
            total_quantity=float(nf_orm.quantity) if nf_orm.quantity is not None else None,
            operation_name=nf_orm.operation_name,
            shipping_company_name=nf_orm.shipping_company_name,
            access_key=nf_orm.access_key
        )
        return formatted.to_dict()

    # --- DANFE Generation (Still relies on ERP) ---
    def generate_danfe_pdf(self, access_key: str) -> bytes:
        """
        Generates the DANFE PDF for a given invoice access key by fetching data from ERP.
        """
        if not access_key or len(access_key) != 44 or not access_key.isdigit():
             raise ValidationError("Formato de chave de acesso inválido. Deve conter 44 dígitos.")

        logger.info(f"Gerando DANFE via ERP para chave de acesso: ...{access_key[-6:]}")
        try:
            # 1. Get XML Content (Raw) from ERP Service
            logger.debug(f"Etapa 1: Buscando XML do ERP para chave ...{access_key[-6:]}")
            xml_raw_dict = self.erp_fiscal_service.get_xml_content_raw(access_key)

            # Parse raw dict using DTO
            xml_dto = InvoiceXmlOutDto.from_dict(xml_raw_dict)
            if not xml_dto or not xml_dto.main_invoice_xml:
                 logger.error(f"Falha ao interpretar resposta do XML ou campo mainInvoiceXml ausente. Dados brutos: {xml_raw_dict}")
                 raise ServiceError(f"Conteúdo XML inválido ou ausente recebido do ERP para chave ...{access_key[-6:]}.")
            main_xml_base64 = xml_dto.main_invoice_xml
            logger.debug(f"Etapa 1: XML principal obtido com sucesso (Tamanho Base64: {len(main_xml_base64)}).")

            # 2. Get DANFE from XML (Raw) using ERP Service
            logger.debug(f"Etapa 2: Solicitando DANFE do ERP usando XML obtido...")
            danfe_raw_dict = self.erp_fiscal_service.get_danfe_from_xml_raw(main_xml_base64)

            # Parse raw dict using DTO
            danfe_dto = DanfeResponseModel.from_dict(danfe_raw_dict)
            if not danfe_dto or not danfe_dto.danfe_pdf_base64:
                 logger.error(f"Falha ao interpretar resposta do DANFE ou campo danfePdfBase64 ausente. Dados brutos: {danfe_raw_dict}")
                 raise ServiceError("DANFE PDF inválido ou ausente recebido do ERP.")
            pdf_base64 = danfe_dto.danfe_pdf_base64
            logger.debug(f"Etapa 2: DANFE PDF recebido e interpretado com sucesso (Tamanho Base64: {len(pdf_base64)}).")

            # 3. Decode Base64 to PDF bytes
            try:
                pdf_bytes = decode_base64_to_bytes(pdf_base64)
                logger.info(f"DANFE PDF gerado e decodificado com sucesso para chave ...{access_key[-6:]}.")
                return pdf_bytes
            except (ValueError, TypeError, RuntimeError) as decode_err:
                logger.error(f"Falha ao decodificar Base64 do DANFE PDF: {decode_err}", exc_info=True)
                raise ServiceError("Falha ao decodificar o PDF DANFE gerado.")

        except (NotFoundError, ValidationError) as e:
             logger.warning(f"Geração de DANFE falhou para chave ...{access_key[-6:]}: {e}")
             raise e
        except ErpIntegrationError as e:
             logger.error(f"Erro de integração com ERP durante geração de DANFE para chave ...{access_key[-6:]}: {e}", exc_info=False)
             status_code = e.status_code if hasattr(e, 'status_code') else 502
             raise ServiceError(f"Falha na comunicação com o ERP durante geração de DANFE: {e.message}", status_code=status_code) from e
        except ServiceError as e:
             logger.error(f"Erro de serviço durante geração de DANFE para chave ...{access_key[-6:]}: {e}", exc_info=True)
             raise e
        except Exception as e:
            logger.error(f"Erro inesperado ao gerar DANFE para chave de acesso ...{access_key[-6:]}: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado durante a geração do DANFE: {e}") from e
</file>

<file path="src/services/fiscal_sync_service.py">
# src/services/fiscal_sync_service.py
# Service responsible for synchronizing fiscal invoice data from ERP to local DB.

import threading
import time
from datetime import datetime, timedelta, timezone
from typing import Optional, List, Dict, Any

from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from src.database import get_db_session
from src.database.fiscal_repository import FiscalRepository
from src.erp_integration.erp_fiscal_service import ErpFiscalService, ERP_FISCAL_PAGE_SIZE
from src.utils.logger import logger
from src.api.errors import ServiceError, DatabaseError, ErpIntegrationError
from src.config import config

# --- Constants for Sync Logic ---
INITIAL_SYNC_START_YEAR = 2010
SYNC_INTERVAL_MINUTES = 5
MAX_INVOICES_PER_TRANSACTION = 500

class FiscalSyncService:
    """
    Orchestrates the synchronization of fiscal invoices from the ERP
    to the local database. Handles initial bulk load in chunks and incremental updates.
    """
    _lock = threading.Lock()
    _is_running = False

    def __init__(self, erp_fiscal_service: ErpFiscalService, fiscal_repository: FiscalRepository):
        self.erp_fiscal_service = erp_fiscal_service
        self.fiscal_repository = fiscal_repository
        self.company_code = config.COMPANY_CODE
        logger.info("Serviço de sincronização fiscal inicializado.")

    def _get_last_sync_time(self) -> Optional[datetime]:
        """Fetches the latest 'lastchange_date' from the local database."""
        try:
            with get_db_session() as db:
                return self.fiscal_repository.get_latest_sync_timestamp(db)
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao obter timestamp da última sincronização: {e}. Usando lógica de sincronização inicial.", exc_info=True)
            return None

    def run_sync(self, full_sync: bool = False):
        """
        Executes the synchronization process. Prevents concurrent runs.
        """
        if FiscalSyncService._is_running:
             logger.warning("Sincronização fiscal já está em execução. Ignorando esta chamada.")
             return

        with FiscalSyncService._lock:
             if FiscalSyncService._is_running:
                  logger.warning("Sincronização fiscal obteve o lock mas já está em execução. Ignorando.")
                  return
             FiscalSyncService._is_running = True
             logger.info(f"[CICLO INÍCIO] Iniciando ciclo de sincronização fiscal (Sincronização Completa: {full_sync}).")

        try:
            start_time_cycle = time.monotonic()
            total_processed_cycle = 0
            perform_initial_sync_logic = False

            if full_sync:
                logger.info("Sincronização completa solicitada pelo parâmetro.")
                perform_initial_sync_logic = True
            else:
                logger.info("Verificando timestamp da última sincronização para modo incremental...")
                last_sync_time = self._get_last_sync_time()

                if last_sync_time is None:
                    logger.info("Nenhuma sincronização anterior encontrada. Realizando sincronização inicial.")
                    perform_initial_sync_logic = True
                else:
                    # --- Incremental Sync Logic ---
                    start_date_inc = last_sync_time - timedelta(minutes=10)
                    end_date_inc = datetime.now(timezone.utc)
                    logger.info(f"Executando sincronização incremental de {start_date_inc.date()} até {end_date_inc.date()}")
                    try:
                        total_processed_cycle = self._sync_time_range(start_date_inc, end_date_inc)
                        logger.info(f"Sincronização incremental concluída. Processadas: {total_processed_cycle} notas fiscais.")
                    except Exception as e:
                         logger.error(f"Falha na sincronização incremental: {e}", exc_info=True)
                         raise

            # --- Initial Sync Logic (if needed) ---
            if perform_initial_sync_logic:
                logger.info("Iniciando processo de sincronização inicial em blocos de 6 meses.")
                try:
                    total_processed_cycle = self._perform_initial_sync_in_chunks()
                    logger.info(f"Processo de sincronização inicial concluído. Total processado: {total_processed_cycle} notas fiscais")
                except Exception as e:
                    logger.error(f"Falha no processo de sincronização inicial: {e}", exc_info=True)
                    raise

            elapsed_time_cycle = time.monotonic() - start_time_cycle
            elapsed_str = self._format_time_duration(elapsed_time_cycle)
            logger.info(f"[CICLO FIM] Ciclo de sincronização fiscal concluído com sucesso em {elapsed_str}. Processadas: {total_processed_cycle} notas fiscais.")

        except Exception as cycle_error:
             elapsed_time_cycle = time.monotonic() - start_time_cycle
             elapsed_str = self._format_time_duration(elapsed_time_cycle)
             logger.error(f"[CICLO ERRO] Ciclo de sincronização fiscal falhou após {elapsed_str}: {cycle_error}", exc_info=True)
        finally:
            with FiscalSyncService._lock:
                FiscalSyncService._is_running = False

    def _format_time_duration(self, seconds: float) -> str:
        """Formata duração de tempo em formato legível."""
        if seconds < 60:
            return f"{seconds:.2f} segundos"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.2f} minutos ({seconds:.2f} segundos)"
        else:
            hours = seconds / 3600
            minutes = (seconds % 3600) / 60
            return f"{hours:.2f} horas ({minutes:.2f} minutos)"

    def _perform_initial_sync_in_chunks(self) -> int:
        """
        Performs the initial data synchronization by fetching data in 6-month chunks
        and estimates remaining time.
        """
        total_processed_initial = 0
        start_year = INITIAL_SYNC_START_YEAR
        current_time = datetime.now(timezone.utc)
        end_year = current_time.year

        # --- Cálculo da Estimativa ---
        total_chunks = (end_year - start_year + 1) * 2
        chunks_processed = 0
        start_time_initial_sync = time.monotonic()

        for year in range(start_year, end_year + 1):
            logger.info(f"--- Processando sincronização inicial para o ano {year} ---")

            for half in [1, 2]:
                if year == end_year and half == 2 and current_time.month <= 6:
                     logger.info(f"Data atual está no primeiro semestre de {year}. Pulando segundo semestre.")
                     continue

                start_chunk, end_chunk = self._get_chunk_dates(year, half)
                effective_end_chunk = min(end_chunk, current_time)

                if start_chunk >= effective_end_chunk:
                    logger.info(f"Pulando bloco S{half}-{year} pois a data de início não é anterior à data de fim.")
                    continue

                # --- Log de Início do Chunk com Estimativa ---
                chunks_processed += 1
                avg_time_per_chunk = (time.monotonic() - start_time_initial_sync) / chunks_processed if chunks_processed > 0 else 0
                remaining_chunks = total_chunks - chunks_processed
                estimated_remaining_time = avg_time_per_chunk * remaining_chunks if avg_time_per_chunk > 0 else 0
                estimated_total_time = avg_time_per_chunk * total_chunks if avg_time_per_chunk > 0 else 0

                # Formatação mais clara das estimativas
                est_rem_str = self._format_time_duration(estimated_remaining_time) if estimated_remaining_time > 0 else "Calculando..."
                est_tot_str = self._format_time_duration(estimated_total_time) if estimated_total_time > 0 else "Calculando..."

                logger.info(f"""
[ESTIMATIVA]
Sincronizando bloco S{half}-{year} ({start_chunk.date()} até {effective_end_chunk.date()})
Progresso: Bloco {chunks_processed}/{total_chunks} ({(chunks_processed/total_chunks*100):.1f}%)
Tempo restante estimado: {est_rem_str}
Tempo total estimado: {est_tot_str}
[FIM ESTIMATIVA]""")

                start_time_chunk = time.monotonic()
                try:
                    processed_in_chunk = self._sync_time_range(start_chunk, effective_end_chunk)
                    total_processed_initial += processed_in_chunk
                    elapsed_chunk = time.monotonic() - start_time_chunk
                    elapsed_str = self._format_time_duration(elapsed_chunk)
                    logger.info(f"Concluído bloco S{half}-{year} em {elapsed_str}. Processadas: {processed_in_chunk} notas fiscais")
                except Exception as e:
                    logger.error(f"Erro sincronizando bloco S{half}-{year} ({start_chunk.date()} até {effective_end_chunk.date()}): {e}. Interrompendo sincronização inicial.")
                    raise

        logger.info("Processamento de blocos da sincronização inicial concluído.")
        return total_processed_initial

    def _get_chunk_dates(self, year: int, half: int) -> tuple[datetime, datetime]:
        """Calculates start and end dates for a 6-month chunk."""
        if half == 1:
            start_date = datetime(year, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
            end_date = datetime(year, 6, 30, 23, 59, 59, 999999, tzinfo=timezone.utc)
        elif half == 2:
            start_date = datetime(year, 7, 1, 0, 0, 0, tzinfo=timezone.utc)
            end_date = datetime(year, 12, 31, 23, 59, 59, 999999, tzinfo=timezone.utc)
        else:
            raise ValueError("Semestre inválido especificado")
        return start_date, end_date


    def _sync_time_range(self, start_date: datetime, end_date: datetime) -> int:
        """
        Fetches and processes invoices within a specific time range based on 'lastchangeDate'.
        Manages ERP pagination and commits data in batches. Returns the number of processed items.
        """
        current_page = 1
        has_next = True
        processed_count_range = 0
        invoices_in_batch = 0
        db: Optional[Session] = None
        db_context = None

        try:
            while has_next:
                logger.debug(f"Buscando página {current_page} do ERP para período {start_date.date()} até {end_date.date()}...")

                filter_payload = {
                    "change": {
                        "startDate": start_date.isoformat(timespec='milliseconds'),
                        "endDate": end_date.isoformat(timespec='milliseconds')
                    },
                    "branchCodeList": [self.company_code],
                    "origin": "Own",
                    "documentTypeCodeList": [55]
                }
                erp_request_payload = {
                    "filter": filter_payload,
                    "expand": "shippingCompany, salesOrder, eletronic, items, payments, observationNF, observationNFE",
                    "order": "lastchangeDate",
                    "page": current_page,
                    "pageSize": ERP_FISCAL_PAGE_SIZE
                }

                erp_response = self.erp_fiscal_service.fetch_invoices_page(erp_request_payload)
                items = erp_response.get('items', [])
                has_next = erp_response.get('hasNext', False)
                
                if items:
                     logger.info(f"Página {current_page} do ERP: Recebidas {len(items)} notas fiscais. Próxima={has_next}")
                elif has_next:
                     logger.debug(f"Página {current_page} do ERP: Recebidas 0 notas fiscais. Próxima={has_next}")

                if not items and not has_next:
                    logger.debug(f"Não há mais notas fiscais no ERP para a página {current_page} e período.")
                    break

                if not items:
                     current_page += 1
                     continue

                # --- Process Batch ---
                if db is None:
                    db_context = get_db_session()
                    db = db_context.__enter__()

                for invoice_data in items:
                    if not isinstance(invoice_data, dict): continue
                    upserted = self.fiscal_repository.upsert_invoice(db, invoice_data)
                    if upserted:
                        processed_count_range += 1
                        invoices_in_batch += 1

                    if invoices_in_batch >= MAX_INVOICES_PER_TRANSACTION:
                        logger.info(f"Confirmando lote de {invoices_in_batch} notas fiscais (Período {start_date.date()}-{end_date.date()}, Página ~{current_page})...")
                        db.commit()
                        logger.info("Lote confirmado com sucesso.")
                        invoices_in_batch = 0

                current_page += 1

        except Exception as e:
             logger.error(f"Erro durante sincronização de período ({start_date.date()} até {end_date.date()}): {e}", exc_info=True)
             if db: db.rollback()
             raise
        finally:
            if db_context:
                try:
                    if db and invoices_in_batch > 0:
                        logger.info(f"Confirmando lote final de {invoices_in_batch} notas fiscais para período {start_date.date()}-{end_date.date()}.")
                        db.commit()
                        logger.info("Lote final confirmado.")
                    db_context.__exit__(None, None, None)
                except Exception as final_err:
                    logger.error(f"Erro durante confirmação/fechamento final para sincronização de período: {final_err}", exc_info=True)
                    try:
                         if db: db.rollback()
                         db_context.__exit__(type(final_err), final_err, final_err.__traceback__)
                    except:
                          pass

        logger.info(f"Sincronização concluída para período {start_date.isoformat()} até {end_date.isoformat()}. Processadas/Atualizadas: {processed_count_range}")
        return processed_count_range


# --- Background Task Setup ---
_sync_thread: Optional[threading.Thread] = None
_stop_sync_event = threading.Event()

def _fiscal_sync_task(sync_service: FiscalSyncService, initial_delay_sec: int, interval_min: int):
    """The actual function run by the background thread."""
    logger.info(f"Tarefa de sincronização fiscal em background iniciada. Atraso inicial: {initial_delay_sec}s, Intervalo: {interval_min}min.")
    first_run = True
    while not _stop_sync_event.is_set():
        if first_run:
            logger.info(f"Aguardando {initial_delay_sec}s antes da primeira execução de sincronização fiscal...")
            wait_time = initial_delay_sec
            first_run = False
        else:
            wait_time = interval_min * 60

        interrupted = _stop_sync_event.wait(timeout=wait_time)
        if interrupted:
             logger.info("Tarefa de sincronização fiscal interrompida pelo evento de parada durante espera.")
             break

        logger.info("Tarefa de sincronização fiscal iniciando ciclo de trabalho...")
        try:
            sync_service.run_sync(full_sync=False)
        except Exception as e:
            logger.error(f"Erro não tratado durante ciclo de sincronização fiscal agendado: {e}", exc_info=True)

        logger.info(f"Ciclo de trabalho de sincronização fiscal finalizado. Aguardando próximo gatilho ({interval_min} min)...")

    logger.info("Tarefa de sincronização fiscal em background finalizada.")

def start_fiscal_sync_scheduler(sync_service: FiscalSyncService, initial_delay_sec: int = 30, interval_min: int = SYNC_INTERVAL_MINUTES):
    global _sync_thread
    if _sync_thread is None or not _sync_thread.is_alive():
        _stop_sync_event.clear()
        _sync_thread = threading.Thread(
            target=_fiscal_sync_task,
            args=(sync_service, initial_delay_sec, interval_min),
            daemon=True
        )
        _sync_thread.start()
        logger.info("Thread do agendador de sincronização fiscal iniciada.")
    else:
        logger.warning("Thread do agendador de sincronização fiscal já está em execução.")

def stop_fiscal_sync_scheduler():
    global _sync_thread
    if _sync_thread and _sync_thread.is_alive():
        logger.info("Parando thread do agendador de sincronização fiscal...")
        _stop_sync_event.set()
        _sync_thread.join(timeout=10)
        if _sync_thread.is_alive():
            logger.warning("Thread do agendador de sincronização fiscal não parou adequadamente após 10s.")
        _sync_thread = None
    else:
        logger.info("Thread do agendador de sincronização fiscal não está em execução ou já foi parada.")
</file>

<file path="src/services/observation_service.py">
# src/services/observation_service.py
# Contains business logic related to managing product observations using ORM.

from typing import List, Dict, Any
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from src.database import get_db_session
from src.database.observation_repository import ObservationRepository
from src.domain.observation import Observation
from src.domain.user import User
from src.utils.logger import logger
from src.api.errors import NotFoundError, ServiceError, ValidationError, ForbiddenError, DatabaseError
from sqlalchemy.exc import SQLAlchemyError

class ObservationService:
    """
    Camada de serviço para gerenciamento de observações de produtos usando ORM Sessions.
    """

    def __init__(self, observation_repository: ObservationRepository):
        self.observation_repository = observation_repository
        logger.info("ObservationService inicializado (ORM).")

    def add_observation(self, reference_code: str, observation_text: str, user: User) -> Observation:
        """Adiciona uma nova observação para um código de referência de produto usando ORM."""
        if not reference_code or not observation_text:
            raise ValidationError("O código de referência e o texto da observação não podem estar vazios.")
        if not user or not user.username:
            raise ValidationError("Informações de usuário válidas são necessárias para adicionar uma observação.")

        logger.info(f"Usuário '{user.username}' adicionando observação para referência '{reference_code}'.")

        observation = Observation(
            reference_code=reference_code,
            observation_text=observation_text,
            user=user.username,
            timestamp=datetime.now(timezone.utc)
        )

        try:
            with get_db_session() as db:
                created_observation = self.observation_repository.add(db, observation)
            logger.info(f"Observação (ID: {created_observation.id}) adicionada com sucesso para referência '{reference_code}'.")
            return created_observation
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao adicionar observação para referência '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"Não foi possível adicionar a observação: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao adicionar observação: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao adicionar a observação: {e}") from e

    def get_observations_for_product(self, reference_code: str, include_resolved: bool = True) -> List[Observation]:
        """Recupera observações para um código de referência de produto específico usando ORM."""
        if not reference_code:
            raise ValidationError("O código de referência não pode estar vazio.")

        logger.debug(f"Buscando observações para referência '{reference_code}' (include_resolved={include_resolved}).")
        try:
            with get_db_session() as db:
                observations = self.observation_repository.find_by_reference_code(db, reference_code, include_resolved)
            logger.debug(f"Encontradas {len(observations)} observações para referência '{reference_code}'.")
            return observations
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao recuperar observações para referência '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"Não foi possível recuperar as observações: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao recuperar observações: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao recuperar as observações: {e}") from e

    def resolve_observation(self, observation_id: int, resolving_user: User) -> bool:
        """Marca uma observação como resolvida usando ORM."""
        if not resolving_user or not resolving_user.username:
            raise ValidationError("Informações de usuário válidas são necessárias para resolver uma observação.")

        logger.info(f"Usuário '{resolving_user.username}' tentando resolver observação ID: {observation_id}.")
        try:
            with get_db_session() as db:
                success = self.observation_repository.mark_as_resolved(db, observation_id, resolving_user.username)
            if success:
                logger.info(f"Observação ID: {observation_id} resolvida com sucesso por '{resolving_user.username}'.")
            else:
                logger.warning(f"Observação ID: {observation_id} não pôde ser marcada como resolvida.")
            return success
        except NotFoundError:
            logger.warning(f"Tentativa de resolver observação ID: {observation_id} falhou: Não encontrada.")
            raise
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao resolver observação ID {observation_id}: {e}", exc_info=True)
            raise ServiceError(f"Não foi possível resolver a observação: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao resolver observação: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao resolver a observação: {e}") from e

    def get_unresolved_count(self, reference_code: str) -> int:
        """Obtém a contagem de observações não resolvidas para um código de referência de produto usando ORM."""
        if not reference_code:
            raise ValidationError("O código de referência não pode estar vazio.")

        logger.debug(f"Obtendo contagem de observações não resolvidas para referência '{reference_code}'.")
        try:
            with get_db_session() as db:
                count = self.observation_repository.get_unresolved_count(db, reference_code)
            logger.debug(f"Contagem de não resolvidas para referência '{reference_code}': {count}.")
            return count
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao obter contagem de observações não resolvidas para referência '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"Não foi possível obter a contagem de observações não resolvidas: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao obter contagem de não resolvidas: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao obter a contagem de observações não resolvidas: {e}") from e

    def get_references_with_pending_observations(self) -> List[Dict[str, Any]]:
        """Recupera referências com observações pendentes usando ORM."""
        logger.debug("Buscando referências com observações pendentes.")
        try:
            with get_db_session() as db:
                references = self.observation_repository.get_references_with_pending(db)
            logger.debug(f"Encontradas {len(references)} referências com observações pendentes.")
            return references
        except (DatabaseError, SQLAlchemyError) as e:
            logger.error(f"Falha ao recuperar referências com observações pendentes: {e}", exc_info=True)
            raise ServiceError(f"Não foi possível recuperar as referências com observações pendentes: {e}") from e
        except Exception as e:
            logger.error(f"Erro inesperado ao buscar referências pendentes: {e}", exc_info=True)
            raise ServiceError(f"Ocorreu um erro inesperado ao buscar referências com observações pendentes: {e}") from e
</file>

<file path="src/services/product_service.py">
from typing import List, Dict, Any
from src.domain.balance import ProductItem
from src.erp_integration.erp_balance_service import ErpBalanceService
from src.utils.matrix_builder import build_product_matrix
from src.utils.logger import logger
from src.api.errors import ServiceError, NotFoundError, ValidationError

class ProductService:
    """
    Camada de serviço para operações relacionadas a produtos acabados, principalmente informações de saldo.
    """
    def __init__(self, erp_balance_service: ErpBalanceService):
        self.erp_balance_service = erp_balance_service
        logger.info("ProductService inicializado.")

    def get_product_balance_matrix_with_items(self, reference_code: str, calculation_mode: str = 'base') -> Dict[str, Any]:
        """
            Recupera dados de saldo de produto para um código de referência do ERP,
            formata-os em uma estrutura de matriz (cor x tamanho) e inclui os itens brutos.

            Argumentos:
            reference_code: O código de referência do produto a ser consultado.
            computation_mode: O modo de cálculo de saldo ('base', 'sales', 'production').

            Retorna:
            Um dicionário contendo:
            {
            "reference_code": str,
            "calculation_mode": str,
            "matrix": Dict[str, Any], # A estrutura de matriz de build_product_matrix
            "product_items": List[Dict[str, Any]] # Dados brutos de ProductItem como dicts
            }

            Gera:
            ValidationError: Se os parâmetros de entrada forem inválidos.
            NotFoundError: Se nenhum produto for encontrado para o código de referência.
            ServiceError: Se ocorrer um erro durante a comunicação do ERP ou o processamento de dados.
        """
        if not reference_code:
            raise ValidationError("O código de referência do produto não pode estar vazio.")
        if calculation_mode not in ['base', 'sales', 'production']:
            raise ValidationError(f"Modo de cálculo inválido: '{calculation_mode}'. Modos válidos: 'base', 'sales', 'production'.")

        logger.info(f"Buscando matriz de saldo e itens para referência '{reference_code}', modo '{calculation_mode}'.")

        try:
            logger.debug(f"Chamando serviço de saldo do ERP para código de referência: {reference_code}")
            product_items: List[ProductItem] = self.erp_balance_service.get_balances(
                reference_code_list=[reference_code],
                is_fabric=False
            )

            if not product_items:
                logger.warning(f"Nenhum item de produto encontrado no ERP para código de referência: {reference_code}")
                raise NotFoundError(f"Nenhum produto encontrado para o código de referência '{reference_code}'.")

            logger.debug(f"Encontrados {len(product_items)} itens de produto para referência '{reference_code}'. Construindo matriz...")
            matrix_data = build_product_matrix(product_items, calculation_mode)
            logger.info(f"Matriz de saldo construída com sucesso para referência '{reference_code}'.")

            product_items_dict = [item.to_dict() for item in product_items]

            response_data = {
                "reference_code": reference_code,
                "calculation_mode": calculation_mode,
                "matrix": matrix_data,
                "product_items": product_items_dict
            }
            return response_data

        except (NotFoundError, ValidationError) as e:
             raise e
        except Exception as e:
            logger.error(f"Erro ao obter matriz de saldo do produto para '{reference_code}': {e}", exc_info=True)
            raise ServiceError(f"Falha ao recuperar matriz de saldo do produto: {e}") from e
</file>

<file path="src/services/README.md">
# src/services

Este diretório contém a camada de lógica de negócio da aplicação. Os serviços orquestram as operações, coordenando chamadas para a camada de integração com o ERP (`src/erp_integration`) e a camada de acesso ao banco de dados (`src/database`), aplicando regras de negócio e gerenciando o ciclo de vida das sessões de banco de dados para operações que o exigem.

## Arquivos

*   **`accounts_receivable_service.py`**: Lógica para buscar, filtrar, enriquecer e formatar documentos de contas a receber, além de gerar boletos. Utiliza `ErpAccountsReceivableService` e `ErpPersonService`.
*   **`auth_service.py`**: Lógica para autenticação de usuários (login, geração/verificação de token JWT). Utiliza `UserRepository` e gerencia a sessão de banco de dados (`get_db_session`) para buscar usuários e atualizar o último login.
*   **`customer_service.py`**: Lógica para buscar e formatar dados de clientes (PF/PJ) e estatísticas. Utiliza `ErpPersonService`.
*   **`fabric_service.py`**: Lógica para obter a lista de tecidos, combinando dados de saldo, custo e detalhes. Utiliza `ErpBalanceService`, `ErpCostService`, `ErpProductService` e `utils`.
*   **`fiscal_service.py`**: Lógica para buscar notas fiscais e gerar DANFE. Utiliza `ErpFiscalService`.
*   **`observation_service.py`**: Lógica de negócio para gerenciar observações de produto (adicionar, buscar, resolver, contar). Utiliza `ObservationRepository` e gerencia a sessão de banco de dados (`get_db_session`) para todas as operações no banco.
*   **`product_service.py`**: Lógica para obter informações de produtos acabados (matriz de saldo). Utiliza `ErpBalanceService` e `utils`.
*   **`README.md`**: Este arquivo.

## Responsabilidades

*   Implementar os casos de uso da aplicação.
*   Validar dados de entrada.
*   Coordenar interações entre diferentes fontes de dados (ERP e banco de dados local).
*   Aplicar regras de negócio.
*   **Gerenciar Sessões de Banco de Dados:** Para operações que modificam ou leem dados do banco local (ex: login, gerenciamento de observações, CRUD de usuários), os serviços utilizam o gerenciador de contexto `get_db_session()` para obter uma `Session` SQLAlchemy e passá-la aos métodos do repositório correspondente. A sessão garante a atomicidade das operações (commit/rollback).
*   Formatar dados para serem retornados pela camada da API (convertendo objetos ORM em dicionários quando necessário).
*   Lançar exceções específicas (`ValidationError`, `NotFoundError`, `ServiceError`, `DatabaseError`) para serem tratadas pela camada da API.

## Interações

*   **Camada da API (`src/api`)**: Chama os métodos dos serviços.
*   **Camada de Integração ERP (`src/erp_integration`)**: Os serviços utilizam os serviços de integração para interagir com o ERP.
*   **Camada de Banco de Dados (`src/database`)**:
    *   Obtém instâncias dos repositórios (`UserRepository`, `ObservationRepository`) via funções fábrica (`get_user_repository`, etc.).
    *   Utiliza `get_db_session()` para obter e gerenciar sessões SQLAlchemy.
    *   Passa a `Session` ativa para os métodos dos repositórios que precisam interagir com o banco.
*   **Domínio (`src/domain`)**: Os serviços manipulam os objetos de domínio (modelos ORM e Dataclasses).
</file>

<file path="src/utils/__init__.py">
# src/utils/__init__.py

from .logger import logger
from .matrix_builder import build_product_matrix
from .fabric_list_builder import build_fabric_list, filter_fabric_list
from .system_monitor import log_system_resources, start_resource_monitor
from .pdf_utils import decode_base64_to_bytes

__all__ = [
    "logger",
    "build_product_matrix",
    "build_fabric_list",
    "filter_fabric_list",
    "log_system_resources",
    "start_resource_monitor",
    "decode_base64_to_bytes",
]
</file>

<file path="src/utils/data_conversion.py">
# src/utils/data_conversion.py
from datetime import datetime, date, time, timezone
from typing import Any, Optional, Union
from .logger import logger
import sys

def safe_int(value: Any) -> Optional[int]:
    """Converte um valor para inteiro de forma segura, retornando None em caso de falha."""
    if value is None:
        return None
    try:
        if isinstance(value, float) and value.is_integer():
            return int(value)
        if isinstance(value, str):
            try:
                float_val = float(value)
                if float_val.is_integer():
                    return int(float_val)
            except ValueError:
                pass 
        return int(value)
    except (ValueError, TypeError) as e:
        logger.debug(f"Não foi possível converter o valor '{value}' (tipo: {type(value)}) para inteiro: {e}")
        return None

def safe_float(value: Any) -> Optional[float]:
    """Converte um valor para float de forma segura, retornando None em caso de falha."""
    if value is None:
        return None
    try:
        return float(value)
    except (ValueError, TypeError) as e:
        logger.debug(f"Não foi possível converter o valor '{value}' (tipo: {type(value)}) para float: {e}")
        return None

def parse_optional_datetime(value: Optional[str]) -> Optional[datetime]:
    """Converte uma string ISO 8601 para um objeto datetime com fuso horário UTC, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        dt_str = value.replace('Z', '+00:00')
        formatos = [
            "%Y-%m-%dT%H:%M:%S.%f%z",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S.%f",
            "%Y-%m-%dT%H:%M:%S",
        ]
        parsed_dt = None
        for fmt in formatos:
            try:
                parsed_dt = datetime.strptime(dt_str, fmt)
                break
            except ValueError:
                continue

        if parsed_dt is None:
            parsed_dt = datetime.fromisoformat(dt_str)

        if parsed_dt.tzinfo is None:
            parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
        else:
            parsed_dt = parsed_dt.astimezone(timezone.utc)

        return parsed_dt
    except (ValueError, TypeError) as e:
        logger.warning(f"Não foi possível converter '{value}' para datetime: {e}")
        return None

def parse_optional_date(value: Optional[str]) -> Optional[date]:
    """Converte uma string (YYYY-MM-DD) para um objeto date, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        date_str = value.split('T')[0]
        return date.fromisoformat(date_str)
    except (ValueError, TypeError) as e:
        logger.warning(f"Não foi possível converter '{value}' para date: {e}")
        return None

def parse_optional_time(value: Optional[str]) -> Optional[time]:
    """Converte uma string (HH:MM:SS ou HH:MM:SS.ffffff) para um objeto time, retornando None em caso de falha."""
    if not value or not isinstance(value, str):
        return None
    try:
        time_str = value.split('T')[-1].split('+')[0].split('-')[0].split('Z')[0]
        formatos = ["%H:%M:%S.%f", "%H:%M:%S"]
        parsed_time = None
        for fmt in formatos:
            try:
                dt_obj = datetime.strptime(time_str, fmt)
                parsed_time = dt_obj.time()
                break
            except ValueError:
                continue
        if parsed_time is None:
            raise ValueError("Formato de hora não reconhecido")
        return parsed_time
    except (ValueError, TypeError, IndexError) as e:
        logger.warning(f"Não foi possível converter '{value}' para time: {e}")
        return None
</file>

<file path="src/utils/fabric_list_builder.py">
from typing import List, Dict, Any, Optional, TYPE_CHECKING
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.domain.balance import ProductItem as BalanceItem
    from src.domain.cost import ProductCost
    from src.domain.fabric_details import FabricDetailsItem

def build_fabric_list(
    balances: List['BalanceItem'],
    costs: List['ProductCost'],
    details: Dict[int, 'FabricDetailsItem']
) -> List[Dict[str, Any]]:
    """
    Constrói uma lista de tecidos combinando dados de saldo, custo e detalhes.
    """
    from src.domain.balance import ProductItem as BalanceItem
    from src.domain.cost import ProductCost
    from src.domain.fabric_details import FabricDetailsItem

    logger.debug(f"Construindo lista de tecidos com {len(balances)} itens de saldo, {len(costs)} itens de custo, {len(details)} itens de detalhes.")

    cost_map: Dict[int, ProductCost] = {cost.product_code: cost for cost in costs if isinstance(cost, ProductCost)}
    fabric_list: List[Dict[str, Any]] = []
    processed_codes = set()

    for balance_item in balances:
        if not isinstance(balance_item, BalanceItem) or balance_item.product_code in processed_codes:
            continue

        product_code = balance_item.product_code
        processed_codes.add(product_code)

        # Calcular saldo
        fabric_balance = 0
        if balance_item.balances:
            try:
                fabric_balance = balance_item.calculate_base_balance()
            except Exception as e:
                logger.error(f"Erro ao calcular saldo do tecido {product_code}: {e}")
        else:
            logger.warning(f"Tecido {product_code} não possui entradas de saldo.")

        # Obter custo
        cost_value: Optional[float] = None
        cost_item = cost_map.get(product_code)
        if cost_item:
            try:
                cost_value = cost_item.get_primary_cost_value()
            except Exception as e:
                logger.error(f"Erro ao obter custo do tecido {product_code}: {e}")
        else:
            logger.debug(f"Nenhum dado de custo encontrado para o tecido {product_code}.")

        # Obter detalhes
        details_item = details.get(product_code)
        width, grammage, shrinkage = None, None, None
        if isinstance(details_item, FabricDetailsItem):
            width = details_item.width
            grammage = details_item.grammage
            shrinkage = details_item.shrinkage
        elif details_item is not None:
            logger.warning(f"Detalhes encontrados para tecido {product_code}, mas o tipo está incorreto: {type(details_item)}")

        fabric_dict = {
            "code": product_code,
            "description": balance_item.product_name or "N/A",
            "balance": fabric_balance,
            "cost": cost_value,
            "width": width,
            "grammage": grammage,
            "shrinkage": shrinkage
        }
        fabric_list.append(fabric_dict)

    balance_codes = {b.product_code for b in balances if isinstance(b, BalanceItem)}
    cost_only_codes = set(cost_map.keys()) - balance_codes
    details_only_codes = set(details.keys()) - balance_codes

    if cost_only_codes:
        logger.warning(f"Custos encontrados para {len(cost_only_codes)} códigos de produto não presentes nos saldos: {list(cost_only_codes)[:10]}...")
    if details_only_codes:
        logger.warning(f"Detalhes encontrados para {len(details_only_codes)} códigos de produto não presentes nos saldos: {list(details_only_codes)[:10]}...")

    logger.info(f"Lista de tecidos construída com {len(fabric_list)} itens únicos.")
    return fabric_list

def filter_fabric_list(
    fabric_list: List[Dict[str, Any]],
    search_text: Optional[str]
) -> List[Dict[str, Any]]:
    """
    Filtra a lista de tecidos com base no texto de pesquisa no campo 'description'.
    """
    if not search_text:
        logger.debug("Nenhum filtro de pesquisa fornecido para a lista de tecidos.")
        return fabric_list

    search_lower = search_text.lower()
    logger.debug(f"Filtrando lista de tecidos ({len(fabric_list)} itens) com o texto: '{search_text}'")

    filtered_list = [
        item for item in fabric_list
        if isinstance(item.get("description"), str) and search_lower in item["description"].lower()
    ]

    logger.info(f"Lista de tecidos filtrada para {len(filtered_list)} itens.")
    return filtered_list
</file>

<file path="src/utils/logger.py">
import logging
import os
import sys
import traceback
from datetime import datetime
from concurrent_log_handler import ConcurrentRotatingFileHandler
from typing import Optional

# --- Configuração ---
LOG_DIRECTORY = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "logs")
LOG_FILENAME_BASE = "app.log"  # Nome base do arquivo de log
LOG_LEVEL_DEFAULT = "DEBUG"  # Nível de log padrão
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d | %(funcName)s] - %(message)s'
LOG_MAX_BYTES = 10 * 1024 * 1024  # 10 MB
LOG_BACKUP_COUNT = 10

class Logger:
    """Encapsula a configuração do logger usando ConcurrentRotatingFileHandler."""
    _instance = None
    _logger = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(Logger, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, name: str = "SaldoAPI", log_level: Optional[str] = None):
        if self._initialized:
            return

        # Determinar nível de log
        level_str = log_level
        if level_str is None:
            try:
                from src.config import config  # Importação atrasada para evitar dependências circulares
                level_str = config.LOG_LEVEL
            except ImportError:
                level_str = LOG_LEVEL_DEFAULT
        level_str = level_str.upper()

        numeric_level = getattr(logging, level_str, None)
        if not isinstance(numeric_level, int):
            print(f"Aviso: Nível de log inválido '{level_str}'. Usando DEBUG por padrão.", file=sys.stderr)
            numeric_level = logging.DEBUG
            level_str = "DEBUG"

        self._logger = logging.getLogger(name)
        self._logger.setLevel(numeric_level)

        if not self._logger.handlers:
            formatter = logging.Formatter(LOG_FORMAT)

            # Console
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(formatter)
            self._logger.addHandler(console_handler)

            # Arquivo (ConcurrentRotatingFileHandler)
            try:
                os.makedirs(LOG_DIRECTORY, exist_ok=True)
                log_file_path = os.path.join(LOG_DIRECTORY, LOG_FILENAME_BASE)

                file_handler = ConcurrentRotatingFileHandler(
                    filename=log_file_path,
                    mode='a',
                    maxBytes=LOG_MAX_BYTES,
                    backupCount=LOG_BACKUP_COUNT,
                    encoding='utf-8',
                )
                file_handler.setFormatter(formatter)
                self._logger.addHandler(file_handler)
                print(f"Log configurado (ConcurrentRotatingFileHandler). Nível: {level_str}. Arquivo: {log_file_path}")
            except Exception as e:
                print(f"Erro ao configurar log de arquivo: {e}", file=sys.stderr)

        self._initialized = True

    def get_logger(self) -> logging.Logger:
        """Retorna a instância do logger configurado."""
        if not self._logger:
            raise RuntimeError("Logger não foi inicializado.")
        return self._logger

# Instância global do logger
logger_instance = Logger()
logger = logger_instance.get_logger()

def configure_logger(level: str):
    """Reconfigura o nível global do logger."""
    global logger_instance, logger
    logger_instance = Logger(log_level=level)
    logger = logger_instance.get_logger()
</file>

<file path="src/utils/matrix_builder.py">
# src/utils/matrix_builder.py
import re
from typing import List, Dict, Any, Tuple, Set, Optional, TYPE_CHECKING
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.domain.balance import ProductItem

def build_product_matrix(products: List['ProductItem'], calculation_mode: str = 'base') -> Dict[str, Any]:
    from src.domain.balance import ProductItem

    if not products:
        logger.warning("build_product_matrix chamado com lista de produtos vazia.")
        return {"colors": [], "sizes": [], "values": {}, "totals": {"base_balance": 0, "sales_orders": 0, "in_production": 0}}

    if calculation_mode not in ['base', 'sales', 'production']:
        raise ValueError(f"Modo de cálculo inválido: {calculation_mode}")

    logger.debug(f"Construindo matriz para {len(products)} itens de produto, modo '{calculation_mode}'.")

    color_set: Set[Tuple[str, str]] = set()
    size_set: Set[str] = set()
    product_map: Dict[Tuple[str, str], ProductItem] = {}

    for p in products:
        if not p or not p.color_code or not p.size_name:
            logger.warning(f"Ignorando ProductItem inválido na construção da matriz: {p}")
            continue
        if not isinstance(p, ProductItem):
            logger.warning(f"Ignorando item com tipo inesperado {type(p)} na construção da matriz.")
            continue
        color_set.add((p.color_code, p.color_name or p.color_code))
        size_set.add(p.size_name)
        product_map[(p.color_code, p.size_name)] = p

    sorted_colors = sorted(list(color_set), key=lambda c: c[0])
    sorted_sizes = _smart_sort_sizes(list(size_set))

    matrix: Dict[str, Any] = {
        "colors": [{"code": code, "name": name} for code, name in sorted_colors],
        "sizes": sorted_sizes,
        "values": {}
    }

    for color_code, color_name in sorted_colors:
        matrix["values"][color_code] = {}
        for size_name in sorted_sizes:
            product = product_map.get((color_code, size_name))
            value = 0
            status = "critical"
            product_code_for_cell: Optional[int] = None

            if product:
                try:
                    value = product.get_balance_for_mode(calculation_mode)
                    status = _determine_status(value)
                    product_code_for_cell = product.product_code
                except ValueError as e:
                    logger.error(f"Erro ao calcular saldo para {product.product_code}: {e}")
                    status = "error"
                except Exception as e:
                    logger.error(f"Erro inesperado ao processar produto {product.product_code}: {e}", exc_info=True)
                    status = "error"
            else:
                logger.debug(f"Nenhuma variante de produto encontrada para Cor={color_code}, Tamanho={size_name}.")

            matrix["values"][color_code][size_name] = {
                "value": value,
                "status": status,
                "product_code": product_code_for_cell
            }

    matrix["totals"] = _calculate_totals(products)
    logger.debug("Construção da matriz concluída.")
    return matrix

def _calculate_totals(products: List['ProductItem']) -> Dict[str, int]:
    from src.domain.balance import ProductItem

    total_base_balance = 0
    total_sales_orders = 0
    total_in_production = 0

    for product in products:
        if not isinstance(product, ProductItem):
            logger.warning(f"Ignorando item com tipo inesperado {type(product)} no cálculo dos totais.")
            continue

        if product.balances:
            total_base_balance += product.calculate_base_balance()
            primary_balance = product._get_primary_balance()
            if primary_balance:
                total_sales_orders += primary_balance.sales_order
                total_in_production += (primary_balance.production_order_progress + primary_balance.production_order_wait_lib)
        else:
            logger.warning(f"Produto {product.product_code} incluído no cálculo dos totais, mas sem dados de saldo.")

    return {
        "base_balance": total_base_balance,
        "sales_orders": total_sales_orders,
        "in_production": total_in_production
    }

def _smart_sort_sizes(sizes: List[str]) -> List[str]:
    def sort_key(size: str) -> Tuple[int, int, str]:
        size_upper = size.upper()
        order_map = {"RN": 0, "BB": 1, "PP": 10, "P": 20, "M": 30, "G": 40, "GG": 50, "XG": 60, "EG": 70, "EGG": 80, "UN": 999, "UNICO": 999}
        if size_upper in order_map:
            return (1, order_map[size_upper], size_upper)
        if size_upper.isdigit():
            return (2, int(size_upper), size_upper)
        match_lead_num = re.match(r'(\d+)\s*(.*)', size_upper)
        if match_lead_num:
            return (3, int(match_lead_num.group(1)), size_upper)
        return (9999, 0, size_upper)

    try:
        return sorted(sizes, key=sort_key)
    except Exception as e:
        logger.error(f"Erro ao ordenar tamanhos: {e}. Usando ordenação alfanumérica padrão.", exc_info=True)
        return sorted(sizes)

def _determine_status(value: int) -> str:
    if value <= 0:
        return "critical"
    elif value < 10:
        return "low"
    else:
        return "sufficient"
</file>

<file path="src/utils/pdf_utils.py">
# src/utils/pdf_utils.py
import base64
import binascii
from .logger import logger

def decode_base64_to_bytes(base64_string: str) -> bytes:
    """
    Decodifica uma string Base64 em bytes.

    Args:
        base64_string: A string codificada em Base64.

    Returns:
        Os bytes decodificados.

    Raises:
        ValueError: Se a string de entrada estiver vazia.
        TypeError: Se a entrada não for uma string.
        binascii.Error: Se a string Base64 for inválida ou corrompida.
    """
    if not base64_string:
        raise ValueError("A string Base64 de entrada não pode ser vazia.")
    if not isinstance(base64_string, str):
        raise TypeError("A entrada deve ser uma string.")

    try:
        decoded_bytes = base64.b64decode(base64_string, validate=True)
        logger.debug(f"Base64 decodificado com sucesso (tamanho: {len(base64_string)}) para bytes (tamanho: {len(decoded_bytes)}).")
        return decoded_bytes
    except binascii.Error as e:
        logger.error(f"Falha ao decodificar a string Base64: {e}", exc_info=True)
        raise ValueError(f"String Base64 inválida fornecida: {e}") from e
    except Exception as e:
        logger.error(f"Erro inesperado durante a decodificação Base64: {e}", exc_info=True)
        raise RuntimeError("Ocorreu um erro inesperado durante a decodificação Base64.") from e
</file>

<file path="src/utils/README.md">
# src/utils

Este diretório contém módulos utilitários que fornecem funcionalidades de suporte usadas em várias partes da aplicação, mas que não se encaixam diretamente na lógica de negócio principal, acesso a dados ou integração ERP.

## Arquivos

*   **`fabric_list_builder.py`**: Contém as funções `build_fabric_list` e `filter_fabric_list`. A primeira combina dados de saldo, custo e detalhes de tecidos em uma lista formatada. A segunda filtra essa lista com base em um texto de busca.
*   **`logger.py`**: Configura o logger da aplicação (usando o módulo `logging` do Python). Define o formato, nível e handlers (console e arquivo rotativo) para os logs. Exporta a instância `logger` configurada para ser usada em toda a aplicação.
*   **`matrix_builder.py`**: Contém a função `build_product_matrix` que transforma uma lista de dados de saldo de produto (obtida do ERP) em uma estrutura de matriz (cor x tamanho) para exibição no frontend. Inclui lógica para ordenação inteligente de tamanhos e cálculo de totais.
*   **`pdf_utils.py`**: Fornece funções utilitárias para manipulação de dados PDF, como decodificar strings Base64 para bytes.
*   **`system_monitor.py`**: Fornece funções (`log_system_resources`, `start_resource_monitor`, `stop_resource_monitor`) para registrar periodicamente o uso de recursos do sistema (memória, CPU, threads) pela aplicação. Útil para monitoramento e diagnóstico de performance.
*   **`README.md`**: Este arquivo.

## Uso

Importe as funções ou a instância `logger` diretamente destes módulos onde for necessário.

```python
# Exemplo de uso do logger
from src.utils.logger import logger
logger.info("Esta é uma mensagem informativa.")
logger.error("Ocorreu um erro.", exc_info=True)

# Exemplo de uso do matrix_builder (em um serviço, por exemplo)
from src.utils.matrix_builder import build_product_matrix
from src.domain.balance import ProductItem # Assuming product_items is List[ProductItem]
matrix_data = build_product_matrix(product_items, 'sales')

# Exemplo de uso do pdf_utils (em um serviço, por exemplo)
from src.utils.pdf_utils import decode_base64_to_bytes
pdf_bytes = decode_base64_to_bytes(base64_pdf_string) # <<< ADDED

# Exemplo de uso do system_monitor (na inicialização da app, por exemplo)
from src.utils.system_monitor import start_resource_monitor
start_resource_monitor() # Inicia o monitoramento em background
</file>

<file path="src/utils/system_monitor.py">
# src/utils/system_monitor.py
import os
import psutil
import threading
import time
from typing import Optional
from .logger import logger

_monitor_thread: Optional[threading.Thread] = None
_stop_monitor = threading.Event()

def log_system_resources():
    """Registra informações sobre o uso atual de recursos do sistema (Memória, CPU, Threads, etc.)."""
    try:
        process = psutil.Process(os.getpid())

        memoria_info = process.memory_info()
        mem_mb = memoria_info.rss / (1024 * 1024)
        logger.info(f"Uso de Recursos - Memória (RSS): {mem_mb:.2f} MB")

        cpu_percent = process.cpu_percent(interval=0.1)
        logger.info(f"Uso de Recursos - CPU: {cpu_percent:.2f}%")

        threads = process.num_threads()
        logger.info(f"Uso de Recursos - Threads: {threads}")

        try:
            arquivos_abertos = len(process.open_files())
            logger.info(f"Uso de Recursos - Arquivos Abertos: {arquivos_abertos}")
        except (psutil.AccessDenied, NotImplementedError, Exception) as e:
            logger.debug(f"Não foi possível obter a contagem de arquivos abertos: {type(e).__name__}")

        try:
            conexoes = len(process.connections(kind='inet'))
            logger.info(f"Uso de Recursos - Conexões de Rede (inet): {conexoes}")
        except (psutil.AccessDenied, NotImplementedError, Exception) as e:
            logger.debug(f"Não foi possível obter a contagem de conexões de rede: {type(e).__name__}")

    except psutil.NoSuchProcess:
        logger.warning("Não foi possível obter informações do processo para monitoramento de recursos (processo finalizado?).")
    except Exception as e:
        logger.error(f"Erro ao registrar uso de recursos do sistema: {e}", exc_info=True)

def _monitor_task(interval_seconds: int = 300):
    """Tarefa em segundo plano que registra recursos periodicamente."""
    logger.info(f"Iniciando monitoramento periódico de recursos (Intervalo: {interval_seconds}s)")
    while not _stop_monitor.is_set():
        log_system_resources()
        _stop_monitor.wait(timeout=interval_seconds)
    logger.info("Monitoramento periódico de recursos finalizado.")

def start_resource_monitor(interval_seconds: int = 300):
    """
    Inicia a thread em segundo plano para monitoramento periódico de recursos.
    Garante que apenas um monitor esteja em execução.
    
    Args:
        interval_seconds: Intervalo de tempo entre logs de recursos (em segundos). Padrão: 5 minutos.
    """
    global _monitor_thread
    if _monitor_thread is None or not _monitor_thread.is_alive():
        _stop_monitor.clear()
        _monitor_thread = threading.Thread(target=_monitor_task, args=(interval_seconds,), daemon=True)
        _monitor_thread.start()
    else:
        logger.debug("Thread de monitoramento de recursos já está em execução.")

def stop_resource_monitor():
    """Envia sinal para a thread de monitoramento em segundo plano parar."""
    global _monitor_thread
    if _monitor_thread and _monitor_thread.is_alive():
        logger.info("Parando a thread de monitoramento de recursos...")
        _stop_monitor.set()
        _monitor_thread.join(timeout=5)
        if _monitor_thread.is_alive():
            logger.warning("A thread de monitoramento de recursos não parou corretamente.")
        _monitor_thread = None
    else:
        logger.debug("Thread de monitoramento de recursos não está em execução ou já foi parada.")
</file>

</files>
